{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/uploads/avtar.jpg","path":"uploads/avtar.jpg","modified":0,"renderable":0},{"_id":"source/images/pasted-0.png","path":"images/pasted-0.png","modified":0,"renderable":0},{"_id":"source/uploads/sufei.jpg","path":"uploads/sufei.jpg","modified":0,"renderable":0},{"_id":"source/uploads/tl.jpg","path":"uploads/tl.jpg","modified":0,"renderable":0},{"_id":"source/uploads/talor.jpg","path":"uploads/talor.jpg","modified":0,"renderable":0},{"_id":"source/uploads/tl.jpeg","path":"uploads/tl.jpeg","modified":0,"renderable":0}],"Cache":[{"_id":"source/_posts/Bugs.md","hash":"e9a785afea1bc5f22ceccc885fb2e91d87eaebdc","modified":1522057594644},{"_id":"source/_posts/Diary-2.md","hash":"a82d5afd04d71692dc8457dcf63993ed32da7e8c","modified":1522057594644},{"_id":"source/_posts/First-Diary.md","hash":"b70fcf5ce35ea6ef6c504c7e5ace52efd95f4cb7","modified":1522057594646},{"_id":"source/_posts/Diary-3.md","hash":"f7561935c6c6716dbcac42f5d0ece706cdf91cdc","modified":1522057594645},{"_id":"source/_posts/Hadoop-二-（常用基本命令）.md","hash":"5e34ebafcffff1f02bac700b12ae8667f794125c","modified":1522057594649},{"_id":"source/_posts/Hadoop-五-（mapreduce）.md","hash":"6657d696dfd3226e73bdf7fee15aed93bfc5819f","modified":1522057594650},{"_id":"source/_posts/Hadoop-一.md","hash":"67922963de9b7c24d5fc13ff5bd01fd4037924dc","modified":1522057594648},{"_id":"source/_posts/Hadoop-三.md","hash":"3f6ee53e21b3a27eaafb03a6d2742f51773a232a","modified":1522057594649},{"_id":"source/_posts/Hadoop-六-（yarn框架）.md","hash":"6e7d90d464916d84e372f22f0449c0402c152327","modified":1522057594651},{"_id":"source/_posts/SS搭建.md","hash":"28d49e918d12c94286055d31cd971c2ee51c83aa","modified":1522057594653},{"_id":"source/_posts/Markdown-入门操作.md","hash":"8d029695e4badd1cc238a6f662bcb988b067e70d","modified":1522057594652},{"_id":"source/_posts/Hadoop-四-（java客户端操作HDFS）.md","hash":"f8ad53ff1b8774f9e7b9a05fe29f1b67f74403d9","modified":1522057594651},{"_id":"source/_posts/hello-world.md","hash":"2b48bd28ee8567a9aae13a91b9140ea3252abb80","modified":1522057594653},{"_id":"source/about/index.md","hash":"017fc9ee858bf5ab1e2c6da2b8fde5e2c6a90fac","modified":1522057594655},{"_id":"source/_posts/常用的基本操作链接.md","hash":"9ab60c7ad5b1c030099c1419b9e713f7fd40195f","modified":1522057594654},{"_id":"source/categories/index.md","hash":"9615c21d5469629c5014e0a818ba5f6a2faf3808","modified":1522057594656},{"_id":"source/neggings/index.md","hash":"20e88a6f90518962a74aced5972a35ad32ff87b9","modified":1522057594658},{"_id":"source/tags/index.md","hash":"02eb8fab5a5140a6f381449af0385c08c466161c","modified":1522057594659},{"_id":"source/uploads/avtar.jpg","hash":"2d003ee446fb0c79a8783e1f30e3fc9b63874980","modified":1522057594660},{"_id":"source/images/pasted-0.png","hash":"b7a1a2aaf801ed10baf22d44072317a1004cfb49","modified":1522057594657},{"_id":"source/uploads/sufei.jpg","hash":"102af907a6e179c4c0cd01eaddbfb66e6de3fc54","modified":1522057594662},{"_id":"source/uploads/tl.jpg","hash":"c0fe4d6072ccaefba79fbf1b25cb6b7e6e8650b8","modified":1522057594666},{"_id":"source/uploads/talor.jpg","hash":"7b5474cc390daf8e22e80a4e6fb88d8dce43cdfd","modified":1522057594663},{"_id":"source/uploads/tl.jpeg","hash":"6d1f0d119084ffd5b27d82d1a276b493d357e917","modified":1522057594665},{"_id":"source/_drafts/两台电脑的测试.md","hash":"b4c647699faf54bd842a4dc30ecd989cb3a76a2b","modified":1522057773515},{"_id":"source/_posts/两台电脑的测试.md","hash":"b4c647699faf54bd842a4dc30ecd989cb3a76a2b","modified":1522057774188}],"Category":[{"name":"bugs","_id":"cjf81unfp0003q87kjyxoeivy"},{"name":"diary","_id":"cjf81unfu0008q87kpyrlegjn"},{"name":"Hadoop","_id":"cjf81ung7000sq87kmnl0mi7c"},{"name":"skill","_id":"cjf81unge001bq87kf4ezpx2w"},{"name":"Markdown","_id":"cjf81ungf001fq87kcsp7lwz6"},{"name":"link","_id":"cjf81ungk001mq87k26xi67zw"}],"Data":[],"Page":[{"title":"about","date":"2018-02-03T08:29:37.000Z","_content":"#### <center>关于</center>\n\n\n##### 介绍：\n\n小小冰弟：本人主要从事java开发，此博客就是为了记记笔记，顺便写点随感。希望能坚持下去吧！加油！嘻嘻！哈哈！\n\n###### 女神镇楼\n![](http://tv06.tgbusdata.cn/v3/thumb/jpg/Zjc1MiwxMTYsODYsOCwzLDEsLTEsMCxyazUw/u/pc.tgbus.com/uploads/allimg/130618/265-13061Q41Z3-50.jpg \"爱教主，哈哈！\")","source":"about/index.md","raw":"title: about\ndate: 2018-02-03 16:29:37\n---\n#### <center>关于</center>\n\n\n##### 介绍：\n\n小小冰弟：本人主要从事java开发，此博客就是为了记记笔记，顺便写点随感。希望能坚持下去吧！加油！嘻嘻！哈哈！\n\n###### 女神镇楼\n![](http://tv06.tgbusdata.cn/v3/thumb/jpg/Zjc1MiwxMTYsODYsOCwzLDEsLTEsMCxyazUw/u/pc.tgbus.com/uploads/allimg/130618/265-13061Q41Z3-50.jpg \"爱教主，哈哈！\")","updated":"2018-03-26T09:46:34.655Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjf81unfm0001q87kv6wpjksn","content":"<h4 id=\"关于\"><a href=\"#关于\" class=\"headerlink\" title=\"关于\"></a><center>关于</center></h4><h5 id=\"介绍：\"><a href=\"#介绍：\" class=\"headerlink\" title=\"介绍：\"></a>介绍：</h5><p>小小冰弟：本人主要从事java开发，此博客就是为了记记笔记，顺便写点随感。希望能坚持下去吧！加油！嘻嘻！哈哈！</p>\n<h6 id=\"女神镇楼\"><a href=\"#女神镇楼\" class=\"headerlink\" title=\"女神镇楼\"></a>女神镇楼</h6><p><img src=\"http://tv06.tgbusdata.cn/v3/thumb/jpg/Zjc1MiwxMTYsODYsOCwzLDEsLTEsMCxyazUw/u/pc.tgbus.com/uploads/allimg/130618/265-13061Q41Z3-50.jpg\" alt=\"\" title=\"爱教主，哈哈！\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"关于\"><a href=\"#关于\" class=\"headerlink\" title=\"关于\"></a><center>关于</center></h4><h5 id=\"介绍：\"><a href=\"#介绍：\" class=\"headerlink\" title=\"介绍：\"></a>介绍：</h5><p>小小冰弟：本人主要从事java开发，此博客就是为了记记笔记，顺便写点随感。希望能坚持下去吧！加油！嘻嘻！哈哈！</p>\n<h6 id=\"女神镇楼\"><a href=\"#女神镇楼\" class=\"headerlink\" title=\"女神镇楼\"></a>女神镇楼</h6><p><img src=\"http://tv06.tgbusdata.cn/v3/thumb/jpg/Zjc1MiwxMTYsODYsOCwzLDEsLTEsMCxyazUw/u/pc.tgbus.com/uploads/allimg/130618/265-13061Q41Z3-50.jpg\" alt=\"\" title=\"爱教主，哈哈！\"></p>\n"},{"title":"categories","type":"categories","date":"2018-02-02T07:20:03.000Z","_content":"***\n##分类专属##\n","source":"categories/index.md","raw":"title: categories\ntype : categories\ndate: 2018-02-02 15:20:03\n---\n***\n##分类专属##\n","updated":"2018-03-26T09:46:34.656Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjf81ungi001kq87kl2an0fwi","content":"<hr>\n<p>##分类专属##</p>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<p>##分类专属##</p>\n"},{"title":"My neggings","password":"hadoop","date":"2018-02-05T04:04:14.000Z","_content":"##### 不念过往，或许只是给过去一个了结吧。        \n--2018.2.5 12：05\n\n\n##### 莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\n--2018.2.6 15：56\n\n\n##### 墨家十杰，一枝独秀。\n--2018.2.27 10：05\n\n##### 想成为一个厉害的人！\n--2018.2.27 10：06\n\n##### 遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\n--2018.3.2 14：33","source":"neggings/index.md","raw":"title: My neggings\npassword: hadoop\ndate: 2018-02-05 12:04:14\n---\n##### 不念过往，或许只是给过去一个了结吧。        \n--2018.2.5 12：05\n\n\n##### 莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\n--2018.2.6 15：56\n\n\n##### 墨家十杰，一枝独秀。\n--2018.2.27 10：05\n\n##### 想成为一个厉害的人！\n--2018.2.27 10：06\n\n##### 遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\n--2018.3.2 14：33","updated":"2018-03-26T09:46:34.658Z","path":"neggings/index.html","comments":1,"layout":"page","_id":"cjf81ungk001lq87kk1dkcekn","content":"<h5 id=\"不念过往，或许只是给过去一个了结吧。\"><a href=\"#不念过往，或许只是给过去一个了结吧。\" class=\"headerlink\" title=\"不念过往，或许只是给过去一个了结吧。\"></a>不念过往，或许只是给过去一个了结吧。</h5><p>–2018.2.5 12：05</p>\n<h5 id=\"莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\"><a href=\"#莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\" class=\"headerlink\" title=\"莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\"></a>莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！</h5><p>–2018.2.6 15：56</p>\n<h5 id=\"墨家十杰，一枝独秀。\"><a href=\"#墨家十杰，一枝独秀。\" class=\"headerlink\" title=\"墨家十杰，一枝独秀。\"></a>墨家十杰，一枝独秀。</h5><p>–2018.2.27 10：05</p>\n<h5 id=\"想成为一个厉害的人！\"><a href=\"#想成为一个厉害的人！\" class=\"headerlink\" title=\"想成为一个厉害的人！\"></a>想成为一个厉害的人！</h5><p>–2018.2.27 10：06</p>\n<h5 id=\"遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\"><a href=\"#遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\" class=\"headerlink\" title=\"遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\"></a>遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。</h5><p>–2018.3.2 14：33</p>\n","site":{"data":{}},"excerpt":"","more":"<h5 id=\"不念过往，或许只是给过去一个了结吧。\"><a href=\"#不念过往，或许只是给过去一个了结吧。\" class=\"headerlink\" title=\"不念过往，或许只是给过去一个了结吧。\"></a>不念过往，或许只是给过去一个了结吧。</h5><p>–2018.2.5 12：05</p>\n<h5 id=\"莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\"><a href=\"#莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\" class=\"headerlink\" title=\"莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\"></a>莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！</h5><p>–2018.2.6 15：56</p>\n<h5 id=\"墨家十杰，一枝独秀。\"><a href=\"#墨家十杰，一枝独秀。\" class=\"headerlink\" title=\"墨家十杰，一枝独秀。\"></a>墨家十杰，一枝独秀。</h5><p>–2018.2.27 10：05</p>\n<h5 id=\"想成为一个厉害的人！\"><a href=\"#想成为一个厉害的人！\" class=\"headerlink\" title=\"想成为一个厉害的人！\"></a>想成为一个厉害的人！</h5><p>–2018.2.27 10：06</p>\n<h5 id=\"遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\"><a href=\"#遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\" class=\"headerlink\" title=\"遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\"></a>遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。</h5><p>–2018.3.2 14：33</p>\n"},{"title":"tags","date":"2018-02-02T07:18:05.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-02-02 15:18:05\ntype: \"tags\"\n---\n","updated":"2018-03-26T09:46:34.659Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjf81ungl001oq87k7xv4k01h","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Bugs","author":"小小冰弟","date":"2018-03-01T02:47:20.000Z","_content":"##### 1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\n   Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RpcServerException): Unknown protocol: com.ppj2.rp.LoginServiceInterface\n\n这个就是因为我服务端放在com.ppj2.rpc包下，而客户端放在com.ppj2.rp包下导致的。\n\n##### 2.之前没有卸载干净\n[mysql装不上](https://www.cnblogs.com/qianzf/p/7078436.html) ","source":"_posts/Bugs.md","raw":"title: Bugs\nauthor: 小小冰弟\ntags: study\ncategories: bugs\ndate: 2018-03-01 10:47:20\n---\n##### 1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\n   Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RpcServerException): Unknown protocol: com.ppj2.rp.LoginServiceInterface\n\n这个就是因为我服务端放在com.ppj2.rpc包下，而客户端放在com.ppj2.rp包下导致的。\n\n##### 2.之前没有卸载干净\n[mysql装不上](https://www.cnblogs.com/qianzf/p/7078436.html) ","slug":"Bugs","published":1,"updated":"2018-03-26T09:46:34.644Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81unfi0000q87kylcvyh4p","content":"<h5 id=\"1-RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\"><a href=\"#1-RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\" class=\"headerlink\" title=\"1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\"></a>1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。</h5><p>   Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RpcServerException): Unknown protocol: com.ppj2.rp.LoginServiceInterface</p>\n<p>这个就是因为我服务端放在com.ppj2.rpc包下，而客户端放在com.ppj2.rp包下导致的。</p>\n<h5 id=\"2-之前没有卸载干净\"><a href=\"#2-之前没有卸载干净\" class=\"headerlink\" title=\"2.之前没有卸载干净\"></a>2.之前没有卸载干净</h5><p><a href=\"https://www.cnblogs.com/qianzf/p/7078436.html\" target=\"_blank\" rel=\"noopener\">mysql装不上</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<h5 id=\"1-RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\"><a href=\"#1-RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\" class=\"headerlink\" title=\"1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\"></a>1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。</h5><p>   Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RpcServerException): Unknown protocol: com.ppj2.rp.LoginServiceInterface</p>\n<p>这个就是因为我服务端放在com.ppj2.rpc包下，而客户端放在com.ppj2.rp包下导致的。</p>\n<h5 id=\"2-之前没有卸载干净\"><a href=\"#2-之前没有卸载干净\" class=\"headerlink\" title=\"2.之前没有卸载干净\"></a>2.之前没有卸载干净</h5><p><a href=\"https://www.cnblogs.com/qianzf/p/7078436.html\" target=\"_blank\" rel=\"noopener\">mysql装不上</a> </p>\n"},{"title":"Diary(3)","author":"小小冰弟","date":"2018-03-13T08:19:28.000Z","_content":"<center>渡人还是渡己</center>\n&emsp;一个谈了好久的同学分手了，我们都在为她出谋划策，其实就像我说过的喜欢一个人可以没有道理，那么不喜欢也可以那么没有道理，如果这种不喜欢两个人同时达到，世间应该会变得十分美好，但自古以来，伤情多是发生在这种时候吧。我总在不停的说服自己，去拼搏的生活，去让自己变得强大，是啊，我希望我能像大话西游里面紫霞仙子说的那样，我的男人是一个盖世英雄，他会踩着七彩祥云来娶我。我想成为一个盖世英雄，想给你七彩祥云，但坏习惯一般都是根深蒂固的，慵懒的我想变得勤奋似乎比较困难，这个时候我又在追逐心中那个关于玄学的梦，小时候我最崇拜的是竹林七贤，所以我的名字一直都喜欢带一个竹，后来有人叫我熊猫，不知道是不是因为我网名的关系哈哈，同学现在的处境让我想到了曾经的自己，那是一个牢笼，傻吗？倔强吗？尊严是何物，如果可以挽回，我曾经也会放下所有尊严去挽回，但世间中的很多事，并不是你妥协，老天就会给你机会，我无数次的想跟命运妥协，但结果总是更惨，因为你越妥协代表你越渴望，越渴望的梦被击碎，人越是会痛，我害怕痛吗，当然是怕，但为什么还不收手，因为喜欢，对于我喜欢的东西，我总是很执着，但我总是得不到，我的原因其实很大，但我从没反省过貌似，但无论如何我做了哪些过激的事或什么，我觉得我对于别人的伤害应该是微乎其微吧，而且我总是抱着天长地久的爱情观去追一个人的，也许这是根源所在，我太认定了，结果会追的急追的紧，哈哈，没办法，性子急。跟别人说了很多要学会爱自己的话，但我知道当你全身心的去爱一个人的时候自己真的没那么重要，或许有的人觉得这是不理智的爱，但我觉得看你遇到什么样的人吧，遇到值得爱的人，遍体鳞伤又能怎么样，在我彷徨无措时，美好的回忆也是你带给我的无尽的力量啊。扯了那么多，好好干吧，为了成为你的大英雄，为了配上那么优秀的你，前路再难，无所畏惧。\n  \n               \n ","source":"_posts/Diary-3.md","raw":"title: Diary(3)\nauthor: 小小冰弟\ndate: 2018-03-13 16:19:28\ntags: live\ncategories: diary\n---\n<center>渡人还是渡己</center>\n&emsp;一个谈了好久的同学分手了，我们都在为她出谋划策，其实就像我说过的喜欢一个人可以没有道理，那么不喜欢也可以那么没有道理，如果这种不喜欢两个人同时达到，世间应该会变得十分美好，但自古以来，伤情多是发生在这种时候吧。我总在不停的说服自己，去拼搏的生活，去让自己变得强大，是啊，我希望我能像大话西游里面紫霞仙子说的那样，我的男人是一个盖世英雄，他会踩着七彩祥云来娶我。我想成为一个盖世英雄，想给你七彩祥云，但坏习惯一般都是根深蒂固的，慵懒的我想变得勤奋似乎比较困难，这个时候我又在追逐心中那个关于玄学的梦，小时候我最崇拜的是竹林七贤，所以我的名字一直都喜欢带一个竹，后来有人叫我熊猫，不知道是不是因为我网名的关系哈哈，同学现在的处境让我想到了曾经的自己，那是一个牢笼，傻吗？倔强吗？尊严是何物，如果可以挽回，我曾经也会放下所有尊严去挽回，但世间中的很多事，并不是你妥协，老天就会给你机会，我无数次的想跟命运妥协，但结果总是更惨，因为你越妥协代表你越渴望，越渴望的梦被击碎，人越是会痛，我害怕痛吗，当然是怕，但为什么还不收手，因为喜欢，对于我喜欢的东西，我总是很执着，但我总是得不到，我的原因其实很大，但我从没反省过貌似，但无论如何我做了哪些过激的事或什么，我觉得我对于别人的伤害应该是微乎其微吧，而且我总是抱着天长地久的爱情观去追一个人的，也许这是根源所在，我太认定了，结果会追的急追的紧，哈哈，没办法，性子急。跟别人说了很多要学会爱自己的话，但我知道当你全身心的去爱一个人的时候自己真的没那么重要，或许有的人觉得这是不理智的爱，但我觉得看你遇到什么样的人吧，遇到值得爱的人，遍体鳞伤又能怎么样，在我彷徨无措时，美好的回忆也是你带给我的无尽的力量啊。扯了那么多，好好干吧，为了成为你的大英雄，为了配上那么优秀的你，前路再难，无所畏惧。\n  \n               \n ","slug":"Diary-3","published":1,"updated":"2018-03-26T09:46:34.645Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81unfn0002q87k7rxkp32n","content":"<p><center>渡人还是渡己</center><br>&emsp;一个谈了好久的同学分手了，我们都在为她出谋划策，其实就像我说过的喜欢一个人可以没有道理，那么不喜欢也可以那么没有道理，如果这种不喜欢两个人同时达到，世间应该会变得十分美好，但自古以来，伤情多是发生在这种时候吧。我总在不停的说服自己，去拼搏的生活，去让自己变得强大，是啊，我希望我能像大话西游里面紫霞仙子说的那样，我的男人是一个盖世英雄，他会踩着七彩祥云来娶我。我想成为一个盖世英雄，想给你七彩祥云，但坏习惯一般都是根深蒂固的，慵懒的我想变得勤奋似乎比较困难，这个时候我又在追逐心中那个关于玄学的梦，小时候我最崇拜的是竹林七贤，所以我的名字一直都喜欢带一个竹，后来有人叫我熊猫，不知道是不是因为我网名的关系哈哈，同学现在的处境让我想到了曾经的自己，那是一个牢笼，傻吗？倔强吗？尊严是何物，如果可以挽回，我曾经也会放下所有尊严去挽回，但世间中的很多事，并不是你妥协，老天就会给你机会，我无数次的想跟命运妥协，但结果总是更惨，因为你越妥协代表你越渴望，越渴望的梦被击碎，人越是会痛，我害怕痛吗，当然是怕，但为什么还不收手，因为喜欢，对于我喜欢的东西，我总是很执着，但我总是得不到，我的原因其实很大，但我从没反省过貌似，但无论如何我做了哪些过激的事或什么，我觉得我对于别人的伤害应该是微乎其微吧，而且我总是抱着天长地久的爱情观去追一个人的，也许这是根源所在，我太认定了，结果会追的急追的紧，哈哈，没办法，性子急。跟别人说了很多要学会爱自己的话，但我知道当你全身心的去爱一个人的时候自己真的没那么重要，或许有的人觉得这是不理智的爱，但我觉得看你遇到什么样的人吧，遇到值得爱的人，遍体鳞伤又能怎么样，在我彷徨无措时，美好的回忆也是你带给我的无尽的力量啊。扯了那么多，好好干吧，为了成为你的大英雄，为了配上那么优秀的你，前路再难，无所畏惧。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><center>渡人还是渡己</center><br>&emsp;一个谈了好久的同学分手了，我们都在为她出谋划策，其实就像我说过的喜欢一个人可以没有道理，那么不喜欢也可以那么没有道理，如果这种不喜欢两个人同时达到，世间应该会变得十分美好，但自古以来，伤情多是发生在这种时候吧。我总在不停的说服自己，去拼搏的生活，去让自己变得强大，是啊，我希望我能像大话西游里面紫霞仙子说的那样，我的男人是一个盖世英雄，他会踩着七彩祥云来娶我。我想成为一个盖世英雄，想给你七彩祥云，但坏习惯一般都是根深蒂固的，慵懒的我想变得勤奋似乎比较困难，这个时候我又在追逐心中那个关于玄学的梦，小时候我最崇拜的是竹林七贤，所以我的名字一直都喜欢带一个竹，后来有人叫我熊猫，不知道是不是因为我网名的关系哈哈，同学现在的处境让我想到了曾经的自己，那是一个牢笼，傻吗？倔强吗？尊严是何物，如果可以挽回，我曾经也会放下所有尊严去挽回，但世间中的很多事，并不是你妥协，老天就会给你机会，我无数次的想跟命运妥协，但结果总是更惨，因为你越妥协代表你越渴望，越渴望的梦被击碎，人越是会痛，我害怕痛吗，当然是怕，但为什么还不收手，因为喜欢，对于我喜欢的东西，我总是很执着，但我总是得不到，我的原因其实很大，但我从没反省过貌似，但无论如何我做了哪些过激的事或什么，我觉得我对于别人的伤害应该是微乎其微吧，而且我总是抱着天长地久的爱情观去追一个人的，也许这是根源所在，我太认定了，结果会追的急追的紧，哈哈，没办法，性子急。跟别人说了很多要学会爱自己的话，但我知道当你全身心的去爱一个人的时候自己真的没那么重要，或许有的人觉得这是不理智的爱，但我觉得看你遇到什么样的人吧，遇到值得爱的人，遍体鳞伤又能怎么样，在我彷徨无措时，美好的回忆也是你带给我的无尽的力量啊。扯了那么多，好好干吧，为了成为你的大英雄，为了配上那么优秀的你，前路再难，无所畏惧。</p>\n"},{"title":"First Diary","author":"小小冰弟","date":"2018-02-05T02:52:51.000Z","_content":"<center>第一篇日记</center>\n\n随便写点啥，就说点对去年的总结吧，去年过得浑浑噩噩，曾心比天高，也许是太贪心了吧，什么都没做好，这也不是第一次吃这种亏了，还是同一条河流，不过这次我差点就溺死了，呵呵，人哪，真是个可笑的动物，尤其是我这般人。过去的就让它过去吧，我不怕跌倒，我只害怕自己再没爬起来的勇气，新的一年，我可以飞得更高。","source":"_posts/First-Diary.md","raw":"title: First Diary\nauthor: 小小冰弟\ntags: live\ncategories: diary\ndate: 2018-02-05 10:52:51\n---\n<center>第一篇日记</center>\n\n随便写点啥，就说点对去年的总结吧，去年过得浑浑噩噩，曾心比天高，也许是太贪心了吧，什么都没做好，这也不是第一次吃这种亏了，还是同一条河流，不过这次我差点就溺死了，呵呵，人哪，真是个可笑的动物，尤其是我这般人。过去的就让它过去吧，我不怕跌倒，我只害怕自己再没爬起来的勇气，新的一年，我可以飞得更高。","slug":"First-Diary","published":1,"updated":"2018-03-26T09:46:34.646Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81unfr0005q87kp7v85x4e","content":"<center>第一篇日记</center>\n\n<p>随便写点啥，就说点对去年的总结吧，去年过得浑浑噩噩，曾心比天高，也许是太贪心了吧，什么都没做好，这也不是第一次吃这种亏了，还是同一条河流，不过这次我差点就溺死了，呵呵，人哪，真是个可笑的动物，尤其是我这般人。过去的就让它过去吧，我不怕跌倒，我只害怕自己再没爬起来的勇气，新的一年，我可以飞得更高。</p>\n","site":{"data":{}},"excerpt":"","more":"<center>第一篇日记</center>\n\n<p>随便写点啥，就说点对去年的总结吧，去年过得浑浑噩噩，曾心比天高，也许是太贪心了吧，什么都没做好，这也不是第一次吃这种亏了，还是同一条河流，不过这次我差点就溺死了，呵呵，人哪，真是个可笑的动物，尤其是我这般人。过去的就让它过去吧，我不怕跌倒，我只害怕自己再没爬起来的勇气，新的一年，我可以飞得更高。</p>\n"},{"title":"Diary(2)","author":"小小冰弟","date":"2018-03-01T02:52:04.000Z","_content":"盼望着盼望着，生活的脚步的近了，遥想过年时，总觉得生活太颓废，想要改变自新，但是过节嘛，感觉先玩着到公司肯定就好了，然而工作快一周了，每天晚上回去就是不听的玩吃鸡，前天晚上打到了四点多，昨天晚上打到了两点多，这应该是我们大多数人的放纵方式吧。我总是把改变留给明天或许是未来，原来我总以我还年轻自豪，现在每每想到我还年轻却这样虚度而感到心塞，也许我就适合懒懒散散的生活，却总有着反人性的思想，应该很多人跟我一样吧！或许这就是我们多都是普通人的原因吧！无论怎样，我觉得活得开心其实是最主要的，但我现在有了攀比，我可以不管它，但我不想丢弃它，我希望它在，因为我也期待自己成为一个强者啊。","source":"_posts/Diary-2.md","raw":"title: Diary(2)\nauthor: 小小冰弟\ndate: 2018-03-01 10:52:04\ntags: live\ncategories: diary\n---\n盼望着盼望着，生活的脚步的近了，遥想过年时，总觉得生活太颓废，想要改变自新，但是过节嘛，感觉先玩着到公司肯定就好了，然而工作快一周了，每天晚上回去就是不听的玩吃鸡，前天晚上打到了四点多，昨天晚上打到了两点多，这应该是我们大多数人的放纵方式吧。我总是把改变留给明天或许是未来，原来我总以我还年轻自豪，现在每每想到我还年轻却这样虚度而感到心塞，也许我就适合懒懒散散的生活，却总有着反人性的思想，应该很多人跟我一样吧！或许这就是我们多都是普通人的原因吧！无论怎样，我觉得活得开心其实是最主要的，但我现在有了攀比，我可以不管它，但我不想丢弃它，我希望它在，因为我也期待自己成为一个强者啊。","slug":"Diary-2","published":1,"updated":"2018-03-26T09:46:34.644Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81unfs0006q87k3gmxo2mt","content":"<p>盼望着盼望着，生活的脚步的近了，遥想过年时，总觉得生活太颓废，想要改变自新，但是过节嘛，感觉先玩着到公司肯定就好了，然而工作快一周了，每天晚上回去就是不听的玩吃鸡，前天晚上打到了四点多，昨天晚上打到了两点多，这应该是我们大多数人的放纵方式吧。我总是把改变留给明天或许是未来，原来我总以我还年轻自豪，现在每每想到我还年轻却这样虚度而感到心塞，也许我就适合懒懒散散的生活，却总有着反人性的思想，应该很多人跟我一样吧！或许这就是我们多都是普通人的原因吧！无论怎样，我觉得活得开心其实是最主要的，但我现在有了攀比，我可以不管它，但我不想丢弃它，我希望它在，因为我也期待自己成为一个强者啊。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>盼望着盼望着，生活的脚步的近了，遥想过年时，总觉得生活太颓废，想要改变自新，但是过节嘛，感觉先玩着到公司肯定就好了，然而工作快一周了，每天晚上回去就是不听的玩吃鸡，前天晚上打到了四点多，昨天晚上打到了两点多，这应该是我们大多数人的放纵方式吧。我总是把改变留给明天或许是未来，原来我总以我还年轻自豪，现在每每想到我还年轻却这样虚度而感到心塞，也许我就适合懒懒散散的生活，却总有着反人性的思想，应该很多人跟我一样吧！或许这就是我们多都是普通人的原因吧！无论怎样，我觉得活得开心其实是最主要的，但我现在有了攀比，我可以不管它，但我不想丢弃它，我希望它在，因为我也期待自己成为一个强者啊。</p>\n"},{"title":"Hadoop(二)（HDFS部分常用基本命令）","author":"小小冰弟","date":"2018-02-05T05:59:48.000Z","_content":"#### 其实基本跟Linux下的命令差不多\n\n#### 启动命令位于sbin目录下\n     start-dfs.sh\n     start-yarn.sh\n     jps(查看有没有启动成功)\n     访问ip地址：50070查看是否成功\n\n#### 1、显示所有命令\n    hadoop fs(以下命令都需要在前方加上hadoop fs且全路径如果为hdfs://ip:8020默认端口/ )\n\n#### 2、上传文件（三种方式）\n\n    -put 文件 hdfsdir（上传）\n    -appendToFile(追加)\n    -copyFromLocal localdir hdfsdir  (从本地复制)\n    -moveFromLocal localdir hdfsdir（从本地移动）\n\n\n#### 3、显示目录结构\n    -ls 路径 （全展示，显示结果解释在下面）\n    -lsr 路径 （递归显示文件）\n    -du 路径 （统计文件大小）\n    -dus路径 (汇总统计大小)\n    -count (统计文件夹数量、文件数量、文件总大小信息)\n显示结果代表：\n1. 首字母表示文件类型（\"d\"是文件夹，\"-\"是文件）\n2. 后面的字符与Linux一样表示权限\n3. 后面的\"-\"或者数字表示副本，文件夹没有副本\n4. 接着依次为 拥有者 所在组 文件大小 修改时间 路径\n\n#### 4、移动复制与删除\n    -mv(移动)\n    -cp(复制)\n    -rm(删除)\n    -rmr(递归删除)\n    \n    \n#### 5、创建\n    -mkdir（创建空白文件夹）\n    -touchz （创建空白文件）\n#### 6、查看\n    -cat()\n    -tail()\n    -text(显示最后1K字节内容，加上\"-f\" 便跟随查看)\n \n#### 7、其他\n    -setrep 数量 文件 (设置副本数量)\n    -chmod(修改文件权限)\n    -chown 属主 文件 (修改属主)\n    -chgrp 所在组(新的) 文件(修改所在组)","source":"_posts/Hadoop-二-（常用基本命令）.md","raw":"title: Hadoop(二)（HDFS部分常用基本命令）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-02-05 13:59:48\n---\n#### 其实基本跟Linux下的命令差不多\n\n#### 启动命令位于sbin目录下\n     start-dfs.sh\n     start-yarn.sh\n     jps(查看有没有启动成功)\n     访问ip地址：50070查看是否成功\n\n#### 1、显示所有命令\n    hadoop fs(以下命令都需要在前方加上hadoop fs且全路径如果为hdfs://ip:8020默认端口/ )\n\n#### 2、上传文件（三种方式）\n\n    -put 文件 hdfsdir（上传）\n    -appendToFile(追加)\n    -copyFromLocal localdir hdfsdir  (从本地复制)\n    -moveFromLocal localdir hdfsdir（从本地移动）\n\n\n#### 3、显示目录结构\n    -ls 路径 （全展示，显示结果解释在下面）\n    -lsr 路径 （递归显示文件）\n    -du 路径 （统计文件大小）\n    -dus路径 (汇总统计大小)\n    -count (统计文件夹数量、文件数量、文件总大小信息)\n显示结果代表：\n1. 首字母表示文件类型（\"d\"是文件夹，\"-\"是文件）\n2. 后面的字符与Linux一样表示权限\n3. 后面的\"-\"或者数字表示副本，文件夹没有副本\n4. 接着依次为 拥有者 所在组 文件大小 修改时间 路径\n\n#### 4、移动复制与删除\n    -mv(移动)\n    -cp(复制)\n    -rm(删除)\n    -rmr(递归删除)\n    \n    \n#### 5、创建\n    -mkdir（创建空白文件夹）\n    -touchz （创建空白文件）\n#### 6、查看\n    -cat()\n    -tail()\n    -text(显示最后1K字节内容，加上\"-f\" 便跟随查看)\n \n#### 7、其他\n    -setrep 数量 文件 (设置副本数量)\n    -chmod(修改文件权限)\n    -chown 属主 文件 (修改属主)\n    -chgrp 所在组(新的) 文件(修改所在组)","slug":"Hadoop-二-（常用基本命令）","published":1,"updated":"2018-03-26T09:46:34.649Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81unft0007q87kbvgg37qr","content":"<h4 id=\"其实基本跟Linux下的命令差不多\"><a href=\"#其实基本跟Linux下的命令差不多\" class=\"headerlink\" title=\"其实基本跟Linux下的命令差不多\"></a>其实基本跟Linux下的命令差不多</h4><h4 id=\"启动命令位于sbin目录下\"><a href=\"#启动命令位于sbin目录下\" class=\"headerlink\" title=\"启动命令位于sbin目录下\"></a>启动命令位于sbin目录下</h4><pre><code>start-dfs.sh\nstart-yarn.sh\njps(查看有没有启动成功)\n访问ip地址：50070查看是否成功\n</code></pre><h4 id=\"1、显示所有命令\"><a href=\"#1、显示所有命令\" class=\"headerlink\" title=\"1、显示所有命令\"></a>1、显示所有命令</h4><pre><code>hadoop fs(以下命令都需要在前方加上hadoop fs且全路径如果为hdfs://ip:8020默认端口/ )\n</code></pre><h4 id=\"2、上传文件（三种方式）\"><a href=\"#2、上传文件（三种方式）\" class=\"headerlink\" title=\"2、上传文件（三种方式）\"></a>2、上传文件（三种方式）</h4><pre><code>-put 文件 hdfsdir（上传）\n-appendToFile(追加)\n-copyFromLocal localdir hdfsdir  (从本地复制)\n-moveFromLocal localdir hdfsdir（从本地移动）\n</code></pre><h4 id=\"3、显示目录结构\"><a href=\"#3、显示目录结构\" class=\"headerlink\" title=\"3、显示目录结构\"></a>3、显示目录结构</h4><pre><code>-ls 路径 （全展示，显示结果解释在下面）\n-lsr 路径 （递归显示文件）\n-du 路径 （统计文件大小）\n-dus路径 (汇总统计大小)\n-count (统计文件夹数量、文件数量、文件总大小信息)\n</code></pre><p>显示结果代表：</p>\n<ol>\n<li>首字母表示文件类型（”d”是文件夹，”-“是文件）</li>\n<li>后面的字符与Linux一样表示权限</li>\n<li>后面的”-“或者数字表示副本，文件夹没有副本</li>\n<li>接着依次为 拥有者 所在组 文件大小 修改时间 路径</li>\n</ol>\n<h4 id=\"4、移动复制与删除\"><a href=\"#4、移动复制与删除\" class=\"headerlink\" title=\"4、移动复制与删除\"></a>4、移动复制与删除</h4><pre><code>-mv(移动)\n-cp(复制)\n-rm(删除)\n-rmr(递归删除)\n</code></pre><h4 id=\"5、创建\"><a href=\"#5、创建\" class=\"headerlink\" title=\"5、创建\"></a>5、创建</h4><pre><code>-mkdir（创建空白文件夹）\n-touchz （创建空白文件）\n</code></pre><h4 id=\"6、查看\"><a href=\"#6、查看\" class=\"headerlink\" title=\"6、查看\"></a>6、查看</h4><pre><code>-cat()\n-tail()\n-text(显示最后1K字节内容，加上&quot;-f&quot; 便跟随查看)\n</code></pre><h4 id=\"7、其他\"><a href=\"#7、其他\" class=\"headerlink\" title=\"7、其他\"></a>7、其他</h4><pre><code>-setrep 数量 文件 (设置副本数量)\n-chmod(修改文件权限)\n-chown 属主 文件 (修改属主)\n-chgrp 所在组(新的) 文件(修改所在组)\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"其实基本跟Linux下的命令差不多\"><a href=\"#其实基本跟Linux下的命令差不多\" class=\"headerlink\" title=\"其实基本跟Linux下的命令差不多\"></a>其实基本跟Linux下的命令差不多</h4><h4 id=\"启动命令位于sbin目录下\"><a href=\"#启动命令位于sbin目录下\" class=\"headerlink\" title=\"启动命令位于sbin目录下\"></a>启动命令位于sbin目录下</h4><pre><code>start-dfs.sh\nstart-yarn.sh\njps(查看有没有启动成功)\n访问ip地址：50070查看是否成功\n</code></pre><h4 id=\"1、显示所有命令\"><a href=\"#1、显示所有命令\" class=\"headerlink\" title=\"1、显示所有命令\"></a>1、显示所有命令</h4><pre><code>hadoop fs(以下命令都需要在前方加上hadoop fs且全路径如果为hdfs://ip:8020默认端口/ )\n</code></pre><h4 id=\"2、上传文件（三种方式）\"><a href=\"#2、上传文件（三种方式）\" class=\"headerlink\" title=\"2、上传文件（三种方式）\"></a>2、上传文件（三种方式）</h4><pre><code>-put 文件 hdfsdir（上传）\n-appendToFile(追加)\n-copyFromLocal localdir hdfsdir  (从本地复制)\n-moveFromLocal localdir hdfsdir（从本地移动）\n</code></pre><h4 id=\"3、显示目录结构\"><a href=\"#3、显示目录结构\" class=\"headerlink\" title=\"3、显示目录结构\"></a>3、显示目录结构</h4><pre><code>-ls 路径 （全展示，显示结果解释在下面）\n-lsr 路径 （递归显示文件）\n-du 路径 （统计文件大小）\n-dus路径 (汇总统计大小)\n-count (统计文件夹数量、文件数量、文件总大小信息)\n</code></pre><p>显示结果代表：</p>\n<ol>\n<li>首字母表示文件类型（”d”是文件夹，”-“是文件）</li>\n<li>后面的字符与Linux一样表示权限</li>\n<li>后面的”-“或者数字表示副本，文件夹没有副本</li>\n<li>接着依次为 拥有者 所在组 文件大小 修改时间 路径</li>\n</ol>\n<h4 id=\"4、移动复制与删除\"><a href=\"#4、移动复制与删除\" class=\"headerlink\" title=\"4、移动复制与删除\"></a>4、移动复制与删除</h4><pre><code>-mv(移动)\n-cp(复制)\n-rm(删除)\n-rmr(递归删除)\n</code></pre><h4 id=\"5、创建\"><a href=\"#5、创建\" class=\"headerlink\" title=\"5、创建\"></a>5、创建</h4><pre><code>-mkdir（创建空白文件夹）\n-touchz （创建空白文件）\n</code></pre><h4 id=\"6、查看\"><a href=\"#6、查看\" class=\"headerlink\" title=\"6、查看\"></a>6、查看</h4><pre><code>-cat()\n-tail()\n-text(显示最后1K字节内容，加上&quot;-f&quot; 便跟随查看)\n</code></pre><h4 id=\"7、其他\"><a href=\"#7、其他\" class=\"headerlink\" title=\"7、其他\"></a>7、其他</h4><pre><code>-setrep 数量 文件 (设置副本数量)\n-chmod(修改文件权限)\n-chown 属主 文件 (修改属主)\n-chgrp 所在组(新的) 文件(修改所在组)\n</code></pre>"},{"title":"Hadoop (一)（centos 6.8/hadoop 2.4.1版本）","author":"小小冰弟","date":"2018-02-03T08:52:44.000Z","_content":"\n#### Hadoop简介\n##### 解决问题：\n- 海量数据存储（HDFS）\n- 海量数据分析(MapReduce)\n- 资源管理调度(Yarn)\n\n\n##### Hdfs实现思想\n1. 通过分布式集群来存储文件\n2. 文件存储到Hdfs集群中是以block为单位\n3. 文件的block存放在若干个datanote节点上\n4. 文件与block的映射存放在namenode上\n5. 每个block还可以有多个副本存放在其他datanote上，提高数据可靠性\n\n刚开始咱就一点一点搭建，后面熟练以后可以直接使用cdh(封装的hadoop).\n\n\n\n\n#### Linux环境设置\n###### 1.网络连接设置及主机映射配置\n\n    虚拟机页面：edit->Virtual Network Editor->nat模式->nat settings->gateway ip设置为本机net8的ip加1\n\n\n###### 2.虚拟机设置ip两种方式：\n\n\t第一种：通过Linux图形界面进行修改（强烈推荐）\n\t\t\t进入Linux图形界面 -> 右键点击右上方的两个小电脑 -> 点击Edit connections -> 选中当前网络 \n            System eth0 -> 点击edit按钮 -> 选择IPv4 -> method选择为manual -> 点击add按钮 -> \n            添加 IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.1 -> apply\n\t\n\t\t第二种：修改配置文件方式（屌丝程序猿专用）\n\t\t\tvim /etc/sysconfig/network-scripts/ifcfg-eth0\n\t\t\tDEVICE=\"eth0\"\n\t\t\tBOOTPROTO=\"static\"               \n\t\t\tHWADDR=\"00:0C:29:3C:BF:E7\"\n\t\t\tIPV6INIT=\"yes\"\n\t\t\tNM_CONTROLLED=\"yes\"\n\t\t\tONBOOT=\"yes\"\n\t\t\tTYPE=\"Ethernet\"\n\t\t\tUUID=\"ce22eeca-ecde-4536-8cc2-ef0dc36d4a8c\"\n\t\t\tIPADDR=\"192.168.1.101\"           \n\t\t\tNETMASK=\"255.255.255.0\"          \n\t\t\tGATEWAY=\"192.168.1.1\"  \n         \n ###### 3.修改主机名\n \n\t\tvim /etc/sysconfig/network\n\t\tNETWORKING=yes\n\t\tHOSTNAME=ppj    ###   \n        \n ###### 4.修改主机名和IP的映射关系\n \n\t\tvim /etc/hosts\n\t\t\t\n\t\t192.168.x.xxx\tppj\n\t\n ##### 5.关闭防火墙\n \n\t\t#查看防火墙状态\n\t\tservice iptables status\n\t\t#关闭防火墙\n\t\tservice iptables stop\n\t\t#查看防火墙开机启动状态\n\t\tchkconfig iptables --list\n\t\t#关闭防火墙开机启动\n\t\tchkconfig iptables off  \n \n \n#### JDK安装\n##### 1.jdk查看与卸载\n    java -version (查看版本)\n    rpm -qa |grep java (查看已经安装的java)\n    rpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 (卸载方式1)\n    yum -y remove java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 （卸载方式2）\n    \n##### 2.jdk安装(需要装32位的)\n[jdk下载地址](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n\n下载压缩包上传至linux目录 /home/usr/  (个人习惯)\n    \n    cd /home/usr\n    tar -zxvf jdk-8u161-linux-arm64-vfp-hflt.tar.gz\n    mkdir /usr/java\n    mv 1.8.0_72 /usr/java/\n    \n##### 3.配置java环境\n\n    vim /etc/profile\n    ##最后添加\n    JAVA_HOME=/usr/java/jdk1.8.0_72\n    JRE_HOME=$JAVA_HOME/jre\n    PATH=$PATH:$JAVA_HOME/bin\n    CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\n\n\n\n#### Hadoop搭建\n##### 1.安装hadoop\n[hadoop下载地址](http://hadoop.apache.org/releases.html)\n下载压缩包上传至linux目录 /home/usr/  \n\t   \n       \n\t\tmkdir /cloud （存放hadoop）\n\t\ttar -zxvf hadoop-2.4.1.tar.gz -C /cloud/\n##### 2配置hadoop伪分布式（要修改4个文件）\n**位置都在/cloud/hadoop-2.4.1/etc/hadoop目录下**\n\nhadoop-env.sh\n\n\t\tvim hadoop-env.sh\n\t\texport JAVA_HOME=/usr/java/1.8.0_72\n\t\t\ncore-site.xml\n\n\t\tvim core-site.xml\n\t\t\t\n\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定HDFS的namenode的通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>fs.default.name</name>\n\t\t\t\t\t\t\t<value>hdfs://ppj:9000</value>(可以不配，默认为28820)\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 指定hadoop运行时产生文件的存放目录 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>hadoop.tmp.dir</name>\n\t\t\t\t\t\t\t<value>/cloud/hadoop-2.4.1/tmp</value>\n\t\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\nhdfs-site.xml\n\n\t\tvim hdfs-site.xml\n\t\t\t<configuration>\n\t\t\t\t<!-- 配置HDFS副本的数量 -->\n\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.replication</name>\n\t\t\t\t\t\t<value>1</value>\n\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\nmapred-site.xml\n\n\t\tvim mapred-site.xml\n\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定jobtracker地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>mapred.job.tracker</name>\n\t\t\t\t\t\t\t<value>ppj:9001</value>\n\t\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\n将hadoop添加到环境变量\n\n\t\tvim /etc/profile\n\t\texport JAVA_HOME=/usr/java/jdk1.6.0_45\n\t\texport HADOOP_HOME=/cloud/hadoop-1.1.2\n\t\texport PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin(因为待会用的命令在sbin)\n\t\tsource /etc/profile\n\t\n格式化HDFS\n\n\t\thadoop namenode -format\n\t\n启动hadoop\n\n\t  start-dfs.sh\n      start-yarn.sh\n\t\n验证集群是否启动成功\n\n\t\tjps(不包括jps应该有5个)\n\t\tNameNode\n\t\tSecondaryNameNode\n\t\tDataNode\n\t\tJobTracker\n\t\tTaskTracker\n\t\t还可以通过浏览器的方式验证\n\t\thttp://192.168.1.110:50070 (hdfs管理界面)\n\t\thttp://192.168.1.110:50030 (mr管理界面)\n\t\t\n在这个文件中添加linux主机名和IP的映射关系：C:\\Windows\\System32\\drivers\\etc\n\n\n\n#### 3.配置ssh免登陆\n\t##生成ssh免登陆密钥\n\tssh-keygen -t rsa\n\t##执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）默认在home用户目录下\n\t##将公钥拷贝到要免登陆的机器上\n    scp id_rsa.pub 目标主机：目录（如果是本机，就直接追加了）\n    先要生成authorized.keyswenjian,且权限为600（-rw------）,接着追加进去\n\tcat 存放的目录/id_rsa.pub >> ~/.ssh/authorized_keys\n    注：我本来在xshell上配了，结果回虚拟机上没有了，当然也没实现免密登录，后来回虚拟机上重设才好。","source":"_posts/Hadoop-一.md","raw":"title: Hadoop (一)（centos 6.8/hadoop 2.4.1版本）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-02-03 16:52:44\n---\n\n#### Hadoop简介\n##### 解决问题：\n- 海量数据存储（HDFS）\n- 海量数据分析(MapReduce)\n- 资源管理调度(Yarn)\n\n\n##### Hdfs实现思想\n1. 通过分布式集群来存储文件\n2. 文件存储到Hdfs集群中是以block为单位\n3. 文件的block存放在若干个datanote节点上\n4. 文件与block的映射存放在namenode上\n5. 每个block还可以有多个副本存放在其他datanote上，提高数据可靠性\n\n刚开始咱就一点一点搭建，后面熟练以后可以直接使用cdh(封装的hadoop).\n\n\n\n\n#### Linux环境设置\n###### 1.网络连接设置及主机映射配置\n\n    虚拟机页面：edit->Virtual Network Editor->nat模式->nat settings->gateway ip设置为本机net8的ip加1\n\n\n###### 2.虚拟机设置ip两种方式：\n\n\t第一种：通过Linux图形界面进行修改（强烈推荐）\n\t\t\t进入Linux图形界面 -> 右键点击右上方的两个小电脑 -> 点击Edit connections -> 选中当前网络 \n            System eth0 -> 点击edit按钮 -> 选择IPv4 -> method选择为manual -> 点击add按钮 -> \n            添加 IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.1 -> apply\n\t\n\t\t第二种：修改配置文件方式（屌丝程序猿专用）\n\t\t\tvim /etc/sysconfig/network-scripts/ifcfg-eth0\n\t\t\tDEVICE=\"eth0\"\n\t\t\tBOOTPROTO=\"static\"               \n\t\t\tHWADDR=\"00:0C:29:3C:BF:E7\"\n\t\t\tIPV6INIT=\"yes\"\n\t\t\tNM_CONTROLLED=\"yes\"\n\t\t\tONBOOT=\"yes\"\n\t\t\tTYPE=\"Ethernet\"\n\t\t\tUUID=\"ce22eeca-ecde-4536-8cc2-ef0dc36d4a8c\"\n\t\t\tIPADDR=\"192.168.1.101\"           \n\t\t\tNETMASK=\"255.255.255.0\"          \n\t\t\tGATEWAY=\"192.168.1.1\"  \n         \n ###### 3.修改主机名\n \n\t\tvim /etc/sysconfig/network\n\t\tNETWORKING=yes\n\t\tHOSTNAME=ppj    ###   \n        \n ###### 4.修改主机名和IP的映射关系\n \n\t\tvim /etc/hosts\n\t\t\t\n\t\t192.168.x.xxx\tppj\n\t\n ##### 5.关闭防火墙\n \n\t\t#查看防火墙状态\n\t\tservice iptables status\n\t\t#关闭防火墙\n\t\tservice iptables stop\n\t\t#查看防火墙开机启动状态\n\t\tchkconfig iptables --list\n\t\t#关闭防火墙开机启动\n\t\tchkconfig iptables off  \n \n \n#### JDK安装\n##### 1.jdk查看与卸载\n    java -version (查看版本)\n    rpm -qa |grep java (查看已经安装的java)\n    rpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 (卸载方式1)\n    yum -y remove java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 （卸载方式2）\n    \n##### 2.jdk安装(需要装32位的)\n[jdk下载地址](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n\n下载压缩包上传至linux目录 /home/usr/  (个人习惯)\n    \n    cd /home/usr\n    tar -zxvf jdk-8u161-linux-arm64-vfp-hflt.tar.gz\n    mkdir /usr/java\n    mv 1.8.0_72 /usr/java/\n    \n##### 3.配置java环境\n\n    vim /etc/profile\n    ##最后添加\n    JAVA_HOME=/usr/java/jdk1.8.0_72\n    JRE_HOME=$JAVA_HOME/jre\n    PATH=$PATH:$JAVA_HOME/bin\n    CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\n\n\n\n#### Hadoop搭建\n##### 1.安装hadoop\n[hadoop下载地址](http://hadoop.apache.org/releases.html)\n下载压缩包上传至linux目录 /home/usr/  \n\t   \n       \n\t\tmkdir /cloud （存放hadoop）\n\t\ttar -zxvf hadoop-2.4.1.tar.gz -C /cloud/\n##### 2配置hadoop伪分布式（要修改4个文件）\n**位置都在/cloud/hadoop-2.4.1/etc/hadoop目录下**\n\nhadoop-env.sh\n\n\t\tvim hadoop-env.sh\n\t\texport JAVA_HOME=/usr/java/1.8.0_72\n\t\t\ncore-site.xml\n\n\t\tvim core-site.xml\n\t\t\t\n\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定HDFS的namenode的通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>fs.default.name</name>\n\t\t\t\t\t\t\t<value>hdfs://ppj:9000</value>(可以不配，默认为28820)\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 指定hadoop运行时产生文件的存放目录 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>hadoop.tmp.dir</name>\n\t\t\t\t\t\t\t<value>/cloud/hadoop-2.4.1/tmp</value>\n\t\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\nhdfs-site.xml\n\n\t\tvim hdfs-site.xml\n\t\t\t<configuration>\n\t\t\t\t<!-- 配置HDFS副本的数量 -->\n\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.replication</name>\n\t\t\t\t\t\t<value>1</value>\n\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\nmapred-site.xml\n\n\t\tvim mapred-site.xml\n\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定jobtracker地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>mapred.job.tracker</name>\n\t\t\t\t\t\t\t<value>ppj:9001</value>\n\t\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\n将hadoop添加到环境变量\n\n\t\tvim /etc/profile\n\t\texport JAVA_HOME=/usr/java/jdk1.6.0_45\n\t\texport HADOOP_HOME=/cloud/hadoop-1.1.2\n\t\texport PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin(因为待会用的命令在sbin)\n\t\tsource /etc/profile\n\t\n格式化HDFS\n\n\t\thadoop namenode -format\n\t\n启动hadoop\n\n\t  start-dfs.sh\n      start-yarn.sh\n\t\n验证集群是否启动成功\n\n\t\tjps(不包括jps应该有5个)\n\t\tNameNode\n\t\tSecondaryNameNode\n\t\tDataNode\n\t\tJobTracker\n\t\tTaskTracker\n\t\t还可以通过浏览器的方式验证\n\t\thttp://192.168.1.110:50070 (hdfs管理界面)\n\t\thttp://192.168.1.110:50030 (mr管理界面)\n\t\t\n在这个文件中添加linux主机名和IP的映射关系：C:\\Windows\\System32\\drivers\\etc\n\n\n\n#### 3.配置ssh免登陆\n\t##生成ssh免登陆密钥\n\tssh-keygen -t rsa\n\t##执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）默认在home用户目录下\n\t##将公钥拷贝到要免登陆的机器上\n    scp id_rsa.pub 目标主机：目录（如果是本机，就直接追加了）\n    先要生成authorized.keyswenjian,且权限为600（-rw------）,接着追加进去\n\tcat 存放的目录/id_rsa.pub >> ~/.ssh/authorized_keys\n    注：我本来在xshell上配了，结果回虚拟机上没有了，当然也没实现免密登录，后来回虚拟机上重设才好。","slug":"Hadoop-一","published":1,"updated":"2018-03-26T09:46:34.648Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81unfv000bq87k4cf8magx","content":"<h4 id=\"Hadoop简介\"><a href=\"#Hadoop简介\" class=\"headerlink\" title=\"Hadoop简介\"></a>Hadoop简介</h4><h5 id=\"解决问题：\"><a href=\"#解决问题：\" class=\"headerlink\" title=\"解决问题：\"></a>解决问题：</h5><ul>\n<li>海量数据存储（HDFS）</li>\n<li>海量数据分析(MapReduce)</li>\n<li>资源管理调度(Yarn)</li>\n</ul>\n<h5 id=\"Hdfs实现思想\"><a href=\"#Hdfs实现思想\" class=\"headerlink\" title=\"Hdfs实现思想\"></a>Hdfs实现思想</h5><ol>\n<li>通过分布式集群来存储文件</li>\n<li>文件存储到Hdfs集群中是以block为单位</li>\n<li>文件的block存放在若干个datanote节点上</li>\n<li>文件与block的映射存放在namenode上</li>\n<li>每个block还可以有多个副本存放在其他datanote上，提高数据可靠性</li>\n</ol>\n<p>刚开始咱就一点一点搭建，后面熟练以后可以直接使用cdh(封装的hadoop).</p>\n<h4 id=\"Linux环境设置\"><a href=\"#Linux环境设置\" class=\"headerlink\" title=\"Linux环境设置\"></a>Linux环境设置</h4><h6 id=\"1-网络连接设置及主机映射配置\"><a href=\"#1-网络连接设置及主机映射配置\" class=\"headerlink\" title=\"1.网络连接设置及主机映射配置\"></a>1.网络连接设置及主机映射配置</h6><pre><code>虚拟机页面：edit-&gt;Virtual Network Editor-&gt;nat模式-&gt;nat settings-&gt;gateway ip设置为本机net8的ip加1\n</code></pre><h6 id=\"2-虚拟机设置ip两种方式：\"><a href=\"#2-虚拟机设置ip两种方式：\" class=\"headerlink\" title=\"2.虚拟机设置ip两种方式：\"></a>2.虚拟机设置ip两种方式：</h6><pre><code>第一种：通过Linux图形界面进行修改（强烈推荐）\n        进入Linux图形界面 -&gt; 右键点击右上方的两个小电脑 -&gt; 点击Edit connections -&gt; 选中当前网络 \n        System eth0 -&gt; 点击edit按钮 -&gt; 选择IPv4 -&gt; method选择为manual -&gt; 点击add按钮 -&gt; \n        添加 IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.1 -&gt; apply\n\n    第二种：修改配置文件方式（屌丝程序猿专用）\n        vim /etc/sysconfig/network-scripts/ifcfg-eth0\n        DEVICE=&quot;eth0&quot;\n        BOOTPROTO=&quot;static&quot;               \n        HWADDR=&quot;00:0C:29:3C:BF:E7&quot;\n        IPV6INIT=&quot;yes&quot;\n        NM_CONTROLLED=&quot;yes&quot;\n        ONBOOT=&quot;yes&quot;\n        TYPE=&quot;Ethernet&quot;\n        UUID=&quot;ce22eeca-ecde-4536-8cc2-ef0dc36d4a8c&quot;\n        IPADDR=&quot;192.168.1.101&quot;           \n        NETMASK=&quot;255.255.255.0&quot;          \n        GATEWAY=&quot;192.168.1.1&quot;  \n</code></pre><h6 id=\"3-修改主机名\"><a href=\"#3-修改主机名\" class=\"headerlink\" title=\"3.修改主机名\"></a>3.修改主机名</h6><pre><code>vim /etc/sysconfig/network\nNETWORKING=yes\nHOSTNAME=ppj    ###   \n</code></pre><h6 id=\"4-修改主机名和IP的映射关系\"><a href=\"#4-修改主机名和IP的映射关系\" class=\"headerlink\" title=\"4.修改主机名和IP的映射关系\"></a>4.修改主机名和IP的映射关系</h6><pre><code>vim /etc/hosts\n\n192.168.x.xxx    ppj\n</code></pre><h5 id=\"5-关闭防火墙\"><a href=\"#5-关闭防火墙\" class=\"headerlink\" title=\"5.关闭防火墙\"></a>5.关闭防火墙</h5><pre><code>#查看防火墙状态\nservice iptables status\n#关闭防火墙\nservice iptables stop\n#查看防火墙开机启动状态\nchkconfig iptables --list\n#关闭防火墙开机启动\nchkconfig iptables off  \n</code></pre><h4 id=\"JDK安装\"><a href=\"#JDK安装\" class=\"headerlink\" title=\"JDK安装\"></a>JDK安装</h4><h5 id=\"1-jdk查看与卸载\"><a href=\"#1-jdk查看与卸载\" class=\"headerlink\" title=\"1.jdk查看与卸载\"></a>1.jdk查看与卸载</h5><pre><code>java -version (查看版本)\nrpm -qa |grep java (查看已经安装的java)\nrpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 (卸载方式1)\nyum -y remove java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 （卸载方式2）\n</code></pre><h5 id=\"2-jdk安装-需要装32位的\"><a href=\"#2-jdk安装-需要装32位的\" class=\"headerlink\" title=\"2.jdk安装(需要装32位的)\"></a>2.jdk安装(需要装32位的)</h5><p><a href=\"http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\" target=\"_blank\" rel=\"noopener\">jdk下载地址</a></p>\n<p>下载压缩包上传至linux目录 /home/usr/  (个人习惯)</p>\n<pre><code>cd /home/usr\ntar -zxvf jdk-8u161-linux-arm64-vfp-hflt.tar.gz\nmkdir /usr/java\nmv 1.8.0_72 /usr/java/\n</code></pre><h5 id=\"3-配置java环境\"><a href=\"#3-配置java环境\" class=\"headerlink\" title=\"3.配置java环境\"></a>3.配置java环境</h5><pre><code>vim /etc/profile\n##最后添加\nJAVA_HOME=/usr/java/jdk1.8.0_72\nJRE_HOME=$JAVA_HOME/jre\nPATH=$PATH:$JAVA_HOME/bin\nCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n</code></pre><h4 id=\"Hadoop搭建\"><a href=\"#Hadoop搭建\" class=\"headerlink\" title=\"Hadoop搭建\"></a>Hadoop搭建</h4><h5 id=\"1-安装hadoop\"><a href=\"#1-安装hadoop\" class=\"headerlink\" title=\"1.安装hadoop\"></a>1.安装hadoop</h5><p><a href=\"http://hadoop.apache.org/releases.html\" target=\"_blank\" rel=\"noopener\">hadoop下载地址</a><br>下载压缩包上传至linux目录 /home/usr/  </p>\n<pre><code>mkdir /cloud （存放hadoop）\ntar -zxvf hadoop-2.4.1.tar.gz -C /cloud/\n</code></pre><h5 id=\"2配置hadoop伪分布式（要修改4个文件）\"><a href=\"#2配置hadoop伪分布式（要修改4个文件）\" class=\"headerlink\" title=\"2配置hadoop伪分布式（要修改4个文件）\"></a>2配置hadoop伪分布式（要修改4个文件）</h5><p><strong>位置都在/cloud/hadoop-2.4.1/etc/hadoop目录下</strong></p>\n<p>hadoop-env.sh</p>\n<pre><code>vim hadoop-env.sh\nexport JAVA_HOME=/usr/java/1.8.0_72\n</code></pre><p>core-site.xml</p>\n<pre><code>vim core-site.xml\n\n    &lt;configuration&gt;\n            &lt;!-- 指定HDFS的namenode的通信地址 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;fs.default.name&lt;/name&gt;\n                    &lt;value&gt;hdfs://ppj:9000&lt;/value&gt;(可以不配，默认为28820)\n            &lt;/property&gt;\n            &lt;!-- 指定hadoop运行时产生文件的存放目录 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n                    &lt;value&gt;/cloud/hadoop-2.4.1/tmp&lt;/value&gt;\n            &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>hdfs-site.xml</p>\n<pre><code>vim hdfs-site.xml\n    &lt;configuration&gt;\n        &lt;!-- 配置HDFS副本的数量 --&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.replication&lt;/name&gt;\n                &lt;value&gt;1&lt;/value&gt;\n        &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>mapred-site.xml</p>\n<pre><code>vim mapred-site.xml\n    &lt;configuration&gt;\n            &lt;!-- 指定jobtracker地址 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n                    &lt;value&gt;ppj:9001&lt;/value&gt;\n            &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>将hadoop添加到环境变量</p>\n<pre><code>vim /etc/profile\nexport JAVA_HOME=/usr/java/jdk1.6.0_45\nexport HADOOP_HOME=/cloud/hadoop-1.1.2\nexport PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin(因为待会用的命令在sbin)\nsource /etc/profile\n</code></pre><p>格式化HDFS</p>\n<pre><code>hadoop namenode -format\n</code></pre><p>启动hadoop</p>\n<pre><code>start-dfs.sh\nstart-yarn.sh\n</code></pre><p>验证集群是否启动成功</p>\n<pre><code>jps(不包括jps应该有5个)\nNameNode\nSecondaryNameNode\nDataNode\nJobTracker\nTaskTracker\n还可以通过浏览器的方式验证\nhttp://192.168.1.110:50070 (hdfs管理界面)\nhttp://192.168.1.110:50030 (mr管理界面)\n</code></pre><p>在这个文件中添加linux主机名和IP的映射关系：C:\\Windows\\System32\\drivers\\etc</p>\n<h4 id=\"3-配置ssh免登陆\"><a href=\"#3-配置ssh免登陆\" class=\"headerlink\" title=\"3.配置ssh免登陆\"></a>3.配置ssh免登陆</h4><pre><code>##生成ssh免登陆密钥\nssh-keygen -t rsa\n##执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）默认在home用户目录下\n##将公钥拷贝到要免登陆的机器上\nscp id_rsa.pub 目标主机：目录（如果是本机，就直接追加了）\n先要生成authorized.keyswenjian,且权限为600（-rw------）,接着追加进去\ncat 存放的目录/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys\n注：我本来在xshell上配了，结果回虚拟机上没有了，当然也没实现免密登录，后来回虚拟机上重设才好。\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"Hadoop简介\"><a href=\"#Hadoop简介\" class=\"headerlink\" title=\"Hadoop简介\"></a>Hadoop简介</h4><h5 id=\"解决问题：\"><a href=\"#解决问题：\" class=\"headerlink\" title=\"解决问题：\"></a>解决问题：</h5><ul>\n<li>海量数据存储（HDFS）</li>\n<li>海量数据分析(MapReduce)</li>\n<li>资源管理调度(Yarn)</li>\n</ul>\n<h5 id=\"Hdfs实现思想\"><a href=\"#Hdfs实现思想\" class=\"headerlink\" title=\"Hdfs实现思想\"></a>Hdfs实现思想</h5><ol>\n<li>通过分布式集群来存储文件</li>\n<li>文件存储到Hdfs集群中是以block为单位</li>\n<li>文件的block存放在若干个datanote节点上</li>\n<li>文件与block的映射存放在namenode上</li>\n<li>每个block还可以有多个副本存放在其他datanote上，提高数据可靠性</li>\n</ol>\n<p>刚开始咱就一点一点搭建，后面熟练以后可以直接使用cdh(封装的hadoop).</p>\n<h4 id=\"Linux环境设置\"><a href=\"#Linux环境设置\" class=\"headerlink\" title=\"Linux环境设置\"></a>Linux环境设置</h4><h6 id=\"1-网络连接设置及主机映射配置\"><a href=\"#1-网络连接设置及主机映射配置\" class=\"headerlink\" title=\"1.网络连接设置及主机映射配置\"></a>1.网络连接设置及主机映射配置</h6><pre><code>虚拟机页面：edit-&gt;Virtual Network Editor-&gt;nat模式-&gt;nat settings-&gt;gateway ip设置为本机net8的ip加1\n</code></pre><h6 id=\"2-虚拟机设置ip两种方式：\"><a href=\"#2-虚拟机设置ip两种方式：\" class=\"headerlink\" title=\"2.虚拟机设置ip两种方式：\"></a>2.虚拟机设置ip两种方式：</h6><pre><code>第一种：通过Linux图形界面进行修改（强烈推荐）\n        进入Linux图形界面 -&gt; 右键点击右上方的两个小电脑 -&gt; 点击Edit connections -&gt; 选中当前网络 \n        System eth0 -&gt; 点击edit按钮 -&gt; 选择IPv4 -&gt; method选择为manual -&gt; 点击add按钮 -&gt; \n        添加 IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.1 -&gt; apply\n\n    第二种：修改配置文件方式（屌丝程序猿专用）\n        vim /etc/sysconfig/network-scripts/ifcfg-eth0\n        DEVICE=&quot;eth0&quot;\n        BOOTPROTO=&quot;static&quot;               \n        HWADDR=&quot;00:0C:29:3C:BF:E7&quot;\n        IPV6INIT=&quot;yes&quot;\n        NM_CONTROLLED=&quot;yes&quot;\n        ONBOOT=&quot;yes&quot;\n        TYPE=&quot;Ethernet&quot;\n        UUID=&quot;ce22eeca-ecde-4536-8cc2-ef0dc36d4a8c&quot;\n        IPADDR=&quot;192.168.1.101&quot;           \n        NETMASK=&quot;255.255.255.0&quot;          \n        GATEWAY=&quot;192.168.1.1&quot;  \n</code></pre><h6 id=\"3-修改主机名\"><a href=\"#3-修改主机名\" class=\"headerlink\" title=\"3.修改主机名\"></a>3.修改主机名</h6><pre><code>vim /etc/sysconfig/network\nNETWORKING=yes\nHOSTNAME=ppj    ###   \n</code></pre><h6 id=\"4-修改主机名和IP的映射关系\"><a href=\"#4-修改主机名和IP的映射关系\" class=\"headerlink\" title=\"4.修改主机名和IP的映射关系\"></a>4.修改主机名和IP的映射关系</h6><pre><code>vim /etc/hosts\n\n192.168.x.xxx    ppj\n</code></pre><h5 id=\"5-关闭防火墙\"><a href=\"#5-关闭防火墙\" class=\"headerlink\" title=\"5.关闭防火墙\"></a>5.关闭防火墙</h5><pre><code>#查看防火墙状态\nservice iptables status\n#关闭防火墙\nservice iptables stop\n#查看防火墙开机启动状态\nchkconfig iptables --list\n#关闭防火墙开机启动\nchkconfig iptables off  \n</code></pre><h4 id=\"JDK安装\"><a href=\"#JDK安装\" class=\"headerlink\" title=\"JDK安装\"></a>JDK安装</h4><h5 id=\"1-jdk查看与卸载\"><a href=\"#1-jdk查看与卸载\" class=\"headerlink\" title=\"1.jdk查看与卸载\"></a>1.jdk查看与卸载</h5><pre><code>java -version (查看版本)\nrpm -qa |grep java (查看已经安装的java)\nrpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 (卸载方式1)\nyum -y remove java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 （卸载方式2）\n</code></pre><h5 id=\"2-jdk安装-需要装32位的\"><a href=\"#2-jdk安装-需要装32位的\" class=\"headerlink\" title=\"2.jdk安装(需要装32位的)\"></a>2.jdk安装(需要装32位的)</h5><p><a href=\"http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\" target=\"_blank\" rel=\"noopener\">jdk下载地址</a></p>\n<p>下载压缩包上传至linux目录 /home/usr/  (个人习惯)</p>\n<pre><code>cd /home/usr\ntar -zxvf jdk-8u161-linux-arm64-vfp-hflt.tar.gz\nmkdir /usr/java\nmv 1.8.0_72 /usr/java/\n</code></pre><h5 id=\"3-配置java环境\"><a href=\"#3-配置java环境\" class=\"headerlink\" title=\"3.配置java环境\"></a>3.配置java环境</h5><pre><code>vim /etc/profile\n##最后添加\nJAVA_HOME=/usr/java/jdk1.8.0_72\nJRE_HOME=$JAVA_HOME/jre\nPATH=$PATH:$JAVA_HOME/bin\nCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n</code></pre><h4 id=\"Hadoop搭建\"><a href=\"#Hadoop搭建\" class=\"headerlink\" title=\"Hadoop搭建\"></a>Hadoop搭建</h4><h5 id=\"1-安装hadoop\"><a href=\"#1-安装hadoop\" class=\"headerlink\" title=\"1.安装hadoop\"></a>1.安装hadoop</h5><p><a href=\"http://hadoop.apache.org/releases.html\" target=\"_blank\" rel=\"noopener\">hadoop下载地址</a><br>下载压缩包上传至linux目录 /home/usr/  </p>\n<pre><code>mkdir /cloud （存放hadoop）\ntar -zxvf hadoop-2.4.1.tar.gz -C /cloud/\n</code></pre><h5 id=\"2配置hadoop伪分布式（要修改4个文件）\"><a href=\"#2配置hadoop伪分布式（要修改4个文件）\" class=\"headerlink\" title=\"2配置hadoop伪分布式（要修改4个文件）\"></a>2配置hadoop伪分布式（要修改4个文件）</h5><p><strong>位置都在/cloud/hadoop-2.4.1/etc/hadoop目录下</strong></p>\n<p>hadoop-env.sh</p>\n<pre><code>vim hadoop-env.sh\nexport JAVA_HOME=/usr/java/1.8.0_72\n</code></pre><p>core-site.xml</p>\n<pre><code>vim core-site.xml\n\n    &lt;configuration&gt;\n            &lt;!-- 指定HDFS的namenode的通信地址 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;fs.default.name&lt;/name&gt;\n                    &lt;value&gt;hdfs://ppj:9000&lt;/value&gt;(可以不配，默认为28820)\n            &lt;/property&gt;\n            &lt;!-- 指定hadoop运行时产生文件的存放目录 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n                    &lt;value&gt;/cloud/hadoop-2.4.1/tmp&lt;/value&gt;\n            &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>hdfs-site.xml</p>\n<pre><code>vim hdfs-site.xml\n    &lt;configuration&gt;\n        &lt;!-- 配置HDFS副本的数量 --&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.replication&lt;/name&gt;\n                &lt;value&gt;1&lt;/value&gt;\n        &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>mapred-site.xml</p>\n<pre><code>vim mapred-site.xml\n    &lt;configuration&gt;\n            &lt;!-- 指定jobtracker地址 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n                    &lt;value&gt;ppj:9001&lt;/value&gt;\n            &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>将hadoop添加到环境变量</p>\n<pre><code>vim /etc/profile\nexport JAVA_HOME=/usr/java/jdk1.6.0_45\nexport HADOOP_HOME=/cloud/hadoop-1.1.2\nexport PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin(因为待会用的命令在sbin)\nsource /etc/profile\n</code></pre><p>格式化HDFS</p>\n<pre><code>hadoop namenode -format\n</code></pre><p>启动hadoop</p>\n<pre><code>start-dfs.sh\nstart-yarn.sh\n</code></pre><p>验证集群是否启动成功</p>\n<pre><code>jps(不包括jps应该有5个)\nNameNode\nSecondaryNameNode\nDataNode\nJobTracker\nTaskTracker\n还可以通过浏览器的方式验证\nhttp://192.168.1.110:50070 (hdfs管理界面)\nhttp://192.168.1.110:50030 (mr管理界面)\n</code></pre><p>在这个文件中添加linux主机名和IP的映射关系：C:\\Windows\\System32\\drivers\\etc</p>\n<h4 id=\"3-配置ssh免登陆\"><a href=\"#3-配置ssh免登陆\" class=\"headerlink\" title=\"3.配置ssh免登陆\"></a>3.配置ssh免登陆</h4><pre><code>##生成ssh免登陆密钥\nssh-keygen -t rsa\n##执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）默认在home用户目录下\n##将公钥拷贝到要免登陆的机器上\nscp id_rsa.pub 目标主机：目录（如果是本机，就直接追加了）\n先要生成authorized.keyswenjian,且权限为600（-rw------）,接着追加进去\ncat 存放的目录/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys\n注：我本来在xshell上配了，结果回虚拟机上没有了，当然也没实现免密登录，后来回虚拟机上重设才好。\n</code></pre>"},{"title":"Hadoop(五)（Mapreduce的操作）","author":"小小冰弟","date":"2018-03-02T08:46:03.000Z","_content":"#### 一.Mapreduce（用来解决海量数据的运算）\nMapReduce由两个阶段组成：Map和Reduce，用户只需要实现map()和reduce()两个函数，即可实现分布式计算，非常简单。Map是对单个的运算，reduce是将他们的结果汇总。\n\n#### 二、实现Map函数\n\n\n   \n    \n #####  1.继承hadoop的mapper类\n Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;</br>\n 四个泛型是因为需要输入输出参数，且都为键值对key-value形式封装。又因为hadoop将其序列化更加精简，所以使用的是hadoop封装的类型，如 long->LongWrite,String->Text\n \n ##### 2.实现mapper的map方法（每读取一行就调用一次该方法）\n    //默认情况下，框架传递给我们的mapper的输入数据中，key是要处理的文本中一行的起始偏移量，这一行的内容作为value\n    public class PPJMap extends Mapper<LongWritable, Text, Text, LongWritable>{\n\t@Override\n\tprotected void map(LongWritable key, Text value,Context context)throws IOException, InterruptedException {\n\t\t//具体业务逻辑就写在这个方法体中，而且我们业务要处理的数据已经被框架传递进来，在方法的参数中 key-value\n\t\t//key 是这一行数据的起始偏移量     value 是这一行的文本内容\n\t\t//将这一行的内容转换成string类型\n\t\tString line = value.toString();\n\t\t//对这一行的文本按特定分隔符切分\n\t\tString[] words = StringUtils.split(line, \" \");\n\t\t//遍历这个单词数组输出为kv形式  k：单词   v ： 1\n\t\tfor(String word : words){\n\t\t\tcontext.write(new Text(word), new LongWritable(1));\n\t\t}\n\t}\n\t}\n \n \n \n #### 三、实现Reduce函数\n    public class PPJReducer extends Reducer<Text, LongWritable, Text, LongWritable>{\n\t//框架在map处理完成之后，将所有kv对缓存起来，进行分组，然后传递一个组<key,valus{}>，调用一次reduce方法\n\t//<hello,{1,1,1,1,1,1.....}>\n\t@Override\n\tprotected void reduce(Text key, Iterable<LongWritable> values,Context context)\n\t\t\tthrows IOException, InterruptedException {\n\n\t\tlong count = 0;\n\t\t//遍历求和\n\t\tfor(LongWritable value:values){\n\t\t\t\n\t\t\tcount += value.get();\n\t\t}\n\t\t//输出这一个单词的统计结果\n\t\tcontext.write(key, new LongWritable(count));\n\t}\n\t}\n    \n\n#### 四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）\n    \n\t\tJob wcjob = Job.getInstance(new Configuration());\n\t\t\n\t\t//设置整个job所用的那些类在哪个jar包\n\t\twcjob.setJarByClass(this class);\n\t\t\n\t\t\n\t\t//本job使用的mapper和reducer的类\n\t\twcjob.setMapperClass(PPJMapper.class);\n\t\twcjob.setReducerClass(PPJReducer.class);\n\t\t\n\t\t\n\t\t//指定reduce的输出数据kv类型\n\t\twcjob.setOutputKeyClass(Text.class);\n\t\twcjob.setOutputValueClass(LongWritable.class);\n\t\t\n\t\t//指定mapper的输出数据kv类型\n\t\twcjob.setMapOutputKeyClass(Text.class);\n\t\twcjob.setMapOutputValueClass(LongWritable.class);\n\t\t\n\t\t\n\t\t//指定要处理的输入数据存放路径\n\t\tFileInputFormat.setInputPaths(wcjob, new Path(\"hdfs://ppj2:8020/ppj/src/\"));\n\t\t\n\t\t//指定处理结果的输出数据存放路径\n\t\tFileOutputFormat.setOutputPath(wcjob, new Path(\"hdfs://ppj2:8020/ppj/output/\"));\n\t\t\n\t\t//将job提交给集群运行 \n\t\twcjob.waitForCompletion(true);\n        \n        \n        \n#### 五、在hadoop上运行\n    先要上传目标文件\n    hadoop fs -put 123.txt /ppj/ (没有路径需要先创建)\n    执行jar包\n    hadoop jar ppj2.jar (执行方法所在的全类名，不包含,class)\n    \n另外输出的文件夹不需要创建，因为他会自动创建","source":"_posts/Hadoop-五-（mapreduce）.md","raw":"title: Hadoop(五)（Mapreduce的操作）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-03-02 16:46:03\n---\n#### 一.Mapreduce（用来解决海量数据的运算）\nMapReduce由两个阶段组成：Map和Reduce，用户只需要实现map()和reduce()两个函数，即可实现分布式计算，非常简单。Map是对单个的运算，reduce是将他们的结果汇总。\n\n#### 二、实现Map函数\n\n\n   \n    \n #####  1.继承hadoop的mapper类\n Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;</br>\n 四个泛型是因为需要输入输出参数，且都为键值对key-value形式封装。又因为hadoop将其序列化更加精简，所以使用的是hadoop封装的类型，如 long->LongWrite,String->Text\n \n ##### 2.实现mapper的map方法（每读取一行就调用一次该方法）\n    //默认情况下，框架传递给我们的mapper的输入数据中，key是要处理的文本中一行的起始偏移量，这一行的内容作为value\n    public class PPJMap extends Mapper<LongWritable, Text, Text, LongWritable>{\n\t@Override\n\tprotected void map(LongWritable key, Text value,Context context)throws IOException, InterruptedException {\n\t\t//具体业务逻辑就写在这个方法体中，而且我们业务要处理的数据已经被框架传递进来，在方法的参数中 key-value\n\t\t//key 是这一行数据的起始偏移量     value 是这一行的文本内容\n\t\t//将这一行的内容转换成string类型\n\t\tString line = value.toString();\n\t\t//对这一行的文本按特定分隔符切分\n\t\tString[] words = StringUtils.split(line, \" \");\n\t\t//遍历这个单词数组输出为kv形式  k：单词   v ： 1\n\t\tfor(String word : words){\n\t\t\tcontext.write(new Text(word), new LongWritable(1));\n\t\t}\n\t}\n\t}\n \n \n \n #### 三、实现Reduce函数\n    public class PPJReducer extends Reducer<Text, LongWritable, Text, LongWritable>{\n\t//框架在map处理完成之后，将所有kv对缓存起来，进行分组，然后传递一个组<key,valus{}>，调用一次reduce方法\n\t//<hello,{1,1,1,1,1,1.....}>\n\t@Override\n\tprotected void reduce(Text key, Iterable<LongWritable> values,Context context)\n\t\t\tthrows IOException, InterruptedException {\n\n\t\tlong count = 0;\n\t\t//遍历求和\n\t\tfor(LongWritable value:values){\n\t\t\t\n\t\t\tcount += value.get();\n\t\t}\n\t\t//输出这一个单词的统计结果\n\t\tcontext.write(key, new LongWritable(count));\n\t}\n\t}\n    \n\n#### 四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）\n    \n\t\tJob wcjob = Job.getInstance(new Configuration());\n\t\t\n\t\t//设置整个job所用的那些类在哪个jar包\n\t\twcjob.setJarByClass(this class);\n\t\t\n\t\t\n\t\t//本job使用的mapper和reducer的类\n\t\twcjob.setMapperClass(PPJMapper.class);\n\t\twcjob.setReducerClass(PPJReducer.class);\n\t\t\n\t\t\n\t\t//指定reduce的输出数据kv类型\n\t\twcjob.setOutputKeyClass(Text.class);\n\t\twcjob.setOutputValueClass(LongWritable.class);\n\t\t\n\t\t//指定mapper的输出数据kv类型\n\t\twcjob.setMapOutputKeyClass(Text.class);\n\t\twcjob.setMapOutputValueClass(LongWritable.class);\n\t\t\n\t\t\n\t\t//指定要处理的输入数据存放路径\n\t\tFileInputFormat.setInputPaths(wcjob, new Path(\"hdfs://ppj2:8020/ppj/src/\"));\n\t\t\n\t\t//指定处理结果的输出数据存放路径\n\t\tFileOutputFormat.setOutputPath(wcjob, new Path(\"hdfs://ppj2:8020/ppj/output/\"));\n\t\t\n\t\t//将job提交给集群运行 \n\t\twcjob.waitForCompletion(true);\n        \n        \n        \n#### 五、在hadoop上运行\n    先要上传目标文件\n    hadoop fs -put 123.txt /ppj/ (没有路径需要先创建)\n    执行jar包\n    hadoop jar ppj2.jar (执行方法所在的全类名，不包含,class)\n    \n另外输出的文件夹不需要创建，因为他会自动创建","slug":"Hadoop-五-（mapreduce）","published":1,"updated":"2018-03-26T09:46:34.650Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81unfx000dq87kd2iphi6u","content":"<h4 id=\"一-Mapreduce（用来解决海量数据的运算）\"><a href=\"#一-Mapreduce（用来解决海量数据的运算）\" class=\"headerlink\" title=\"一.Mapreduce（用来解决海量数据的运算）\"></a>一.Mapreduce（用来解决海量数据的运算）</h4><p>MapReduce由两个阶段组成：Map和Reduce，用户只需要实现map()和reduce()两个函数，即可实现分布式计算，非常简单。Map是对单个的运算，reduce是将他们的结果汇总。</p>\n<h4 id=\"二、实现Map函数\"><a href=\"#二、实现Map函数\" class=\"headerlink\" title=\"二、实现Map函数\"></a>二、实现Map函数</h4><h5 id=\"1-继承hadoop的mapper类\"><a href=\"#1-继承hadoop的mapper类\" class=\"headerlink\" title=\"1.继承hadoop的mapper类\"></a>1.继承hadoop的mapper类</h5><p> Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;<br><br> 四个泛型是因为需要输入输出参数，且都为键值对key-value形式封装。又因为hadoop将其序列化更加精简，所以使用的是hadoop封装的类型，如 long-&gt;LongWrite,String-&gt;Text</p>\n<h5 id=\"2-实现mapper的map方法（每读取一行就调用一次该方法）\"><a href=\"#2-实现mapper的map方法（每读取一行就调用一次该方法）\" class=\"headerlink\" title=\"2.实现mapper的map方法（每读取一行就调用一次该方法）\"></a>2.实现mapper的map方法（每读取一行就调用一次该方法）</h5><pre><code>//默认情况下，框架传递给我们的mapper的输入数据中，key是要处理的文本中一行的起始偏移量，这一行的内容作为value\npublic class PPJMap extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt;{\n@Override\nprotected void map(LongWritable key, Text value,Context context)throws IOException, InterruptedException {\n    //具体业务逻辑就写在这个方法体中，而且我们业务要处理的数据已经被框架传递进来，在方法的参数中 key-value\n    //key 是这一行数据的起始偏移量     value 是这一行的文本内容\n    //将这一行的内容转换成string类型\n    String line = value.toString();\n    //对这一行的文本按特定分隔符切分\n    String[] words = StringUtils.split(line, &quot; &quot;);\n    //遍历这个单词数组输出为kv形式  k：单词   v ： 1\n    for(String word : words){\n        context.write(new Text(word), new LongWritable(1));\n    }\n}\n}\n</code></pre><h4 id=\"三、实现Reduce函数\"><a href=\"#三、实现Reduce函数\" class=\"headerlink\" title=\"三、实现Reduce函数\"></a>三、实现Reduce函数</h4><pre><code>public class PPJReducer extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt;{\n//框架在map处理完成之后，将所有kv对缓存起来，进行分组，然后传递一个组&lt;key,valus{}&gt;，调用一次reduce方法\n//&lt;hello,{1,1,1,1,1,1.....}&gt;\n@Override\nprotected void reduce(Text key, Iterable&lt;LongWritable&gt; values,Context context)\n        throws IOException, InterruptedException {\n\n    long count = 0;\n    //遍历求和\n    for(LongWritable value:values){\n\n        count += value.get();\n    }\n    //输出这一个单词的统计结果\n    context.write(key, new LongWritable(count));\n}\n}\n</code></pre><h4 id=\"四、配置job类（选择操作的Mapper-Reduce，操作的文件路径，操作结果路径）\"><a href=\"#四、配置job类（选择操作的Mapper-Reduce，操作的文件路径，操作结果路径）\" class=\"headerlink\" title=\"四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）\"></a>四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）</h4><pre><code>Job wcjob = Job.getInstance(new Configuration());\n\n//设置整个job所用的那些类在哪个jar包\nwcjob.setJarByClass(this class);\n\n\n//本job使用的mapper和reducer的类\nwcjob.setMapperClass(PPJMapper.class);\nwcjob.setReducerClass(PPJReducer.class);\n\n\n//指定reduce的输出数据kv类型\nwcjob.setOutputKeyClass(Text.class);\nwcjob.setOutputValueClass(LongWritable.class);\n\n//指定mapper的输出数据kv类型\nwcjob.setMapOutputKeyClass(Text.class);\nwcjob.setMapOutputValueClass(LongWritable.class);\n\n\n//指定要处理的输入数据存放路径\nFileInputFormat.setInputPaths(wcjob, new Path(&quot;hdfs://ppj2:8020/ppj/src/&quot;));\n\n//指定处理结果的输出数据存放路径\nFileOutputFormat.setOutputPath(wcjob, new Path(&quot;hdfs://ppj2:8020/ppj/output/&quot;));\n\n//将job提交给集群运行 \nwcjob.waitForCompletion(true);\n</code></pre><h4 id=\"五、在hadoop上运行\"><a href=\"#五、在hadoop上运行\" class=\"headerlink\" title=\"五、在hadoop上运行\"></a>五、在hadoop上运行</h4><pre><code>先要上传目标文件\nhadoop fs -put 123.txt /ppj/ (没有路径需要先创建)\n执行jar包\nhadoop jar ppj2.jar (执行方法所在的全类名，不包含,class)\n</code></pre><p>另外输出的文件夹不需要创建，因为他会自动创建</p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"一-Mapreduce（用来解决海量数据的运算）\"><a href=\"#一-Mapreduce（用来解决海量数据的运算）\" class=\"headerlink\" title=\"一.Mapreduce（用来解决海量数据的运算）\"></a>一.Mapreduce（用来解决海量数据的运算）</h4><p>MapReduce由两个阶段组成：Map和Reduce，用户只需要实现map()和reduce()两个函数，即可实现分布式计算，非常简单。Map是对单个的运算，reduce是将他们的结果汇总。</p>\n<h4 id=\"二、实现Map函数\"><a href=\"#二、实现Map函数\" class=\"headerlink\" title=\"二、实现Map函数\"></a>二、实现Map函数</h4><h5 id=\"1-继承hadoop的mapper类\"><a href=\"#1-继承hadoop的mapper类\" class=\"headerlink\" title=\"1.继承hadoop的mapper类\"></a>1.继承hadoop的mapper类</h5><p> Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;<br><br> 四个泛型是因为需要输入输出参数，且都为键值对key-value形式封装。又因为hadoop将其序列化更加精简，所以使用的是hadoop封装的类型，如 long-&gt;LongWrite,String-&gt;Text</p>\n<h5 id=\"2-实现mapper的map方法（每读取一行就调用一次该方法）\"><a href=\"#2-实现mapper的map方法（每读取一行就调用一次该方法）\" class=\"headerlink\" title=\"2.实现mapper的map方法（每读取一行就调用一次该方法）\"></a>2.实现mapper的map方法（每读取一行就调用一次该方法）</h5><pre><code>//默认情况下，框架传递给我们的mapper的输入数据中，key是要处理的文本中一行的起始偏移量，这一行的内容作为value\npublic class PPJMap extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt;{\n@Override\nprotected void map(LongWritable key, Text value,Context context)throws IOException, InterruptedException {\n    //具体业务逻辑就写在这个方法体中，而且我们业务要处理的数据已经被框架传递进来，在方法的参数中 key-value\n    //key 是这一行数据的起始偏移量     value 是这一行的文本内容\n    //将这一行的内容转换成string类型\n    String line = value.toString();\n    //对这一行的文本按特定分隔符切分\n    String[] words = StringUtils.split(line, &quot; &quot;);\n    //遍历这个单词数组输出为kv形式  k：单词   v ： 1\n    for(String word : words){\n        context.write(new Text(word), new LongWritable(1));\n    }\n}\n}\n</code></pre><h4 id=\"三、实现Reduce函数\"><a href=\"#三、实现Reduce函数\" class=\"headerlink\" title=\"三、实现Reduce函数\"></a>三、实现Reduce函数</h4><pre><code>public class PPJReducer extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt;{\n//框架在map处理完成之后，将所有kv对缓存起来，进行分组，然后传递一个组&lt;key,valus{}&gt;，调用一次reduce方法\n//&lt;hello,{1,1,1,1,1,1.....}&gt;\n@Override\nprotected void reduce(Text key, Iterable&lt;LongWritable&gt; values,Context context)\n        throws IOException, InterruptedException {\n\n    long count = 0;\n    //遍历求和\n    for(LongWritable value:values){\n\n        count += value.get();\n    }\n    //输出这一个单词的统计结果\n    context.write(key, new LongWritable(count));\n}\n}\n</code></pre><h4 id=\"四、配置job类（选择操作的Mapper-Reduce，操作的文件路径，操作结果路径）\"><a href=\"#四、配置job类（选择操作的Mapper-Reduce，操作的文件路径，操作结果路径）\" class=\"headerlink\" title=\"四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）\"></a>四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）</h4><pre><code>Job wcjob = Job.getInstance(new Configuration());\n\n//设置整个job所用的那些类在哪个jar包\nwcjob.setJarByClass(this class);\n\n\n//本job使用的mapper和reducer的类\nwcjob.setMapperClass(PPJMapper.class);\nwcjob.setReducerClass(PPJReducer.class);\n\n\n//指定reduce的输出数据kv类型\nwcjob.setOutputKeyClass(Text.class);\nwcjob.setOutputValueClass(LongWritable.class);\n\n//指定mapper的输出数据kv类型\nwcjob.setMapOutputKeyClass(Text.class);\nwcjob.setMapOutputValueClass(LongWritable.class);\n\n\n//指定要处理的输入数据存放路径\nFileInputFormat.setInputPaths(wcjob, new Path(&quot;hdfs://ppj2:8020/ppj/src/&quot;));\n\n//指定处理结果的输出数据存放路径\nFileOutputFormat.setOutputPath(wcjob, new Path(&quot;hdfs://ppj2:8020/ppj/output/&quot;));\n\n//将job提交给集群运行 \nwcjob.waitForCompletion(true);\n</code></pre><h4 id=\"五、在hadoop上运行\"><a href=\"#五、在hadoop上运行\" class=\"headerlink\" title=\"五、在hadoop上运行\"></a>五、在hadoop上运行</h4><pre><code>先要上传目标文件\nhadoop fs -put 123.txt /ppj/ (没有路径需要先创建)\n执行jar包\nhadoop jar ppj2.jar (执行方法所在的全类名，不包含,class)\n</code></pre><p>另外输出的文件夹不需要创建，因为他会自动创建</p>\n"},{"title":"Hadoop(三)（Hdfs的上传与存储机制防止宕机）","author":"小小冰弟","date":"2018-02-07T10:15:26.000Z","_content":"###### HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。\n\n\n###### NameNode保存元信息的种类有：\n\n* 文件名目录名及它们之间的层级关系\n* 文件目录的所有者及其权限\n* 每个文件块的名及文件有哪些块组成\n\n\n###### Secondary用来进行fsimage与edit.log的合并操作\n\n###### DataNode主要保存block即分割的块状文件\n\n###### 简要分析HDFS的文件上传机制：\n\n1. 客户端发送上传文件请求，通知NameNode,NameNode检查没有问题回传客户端OK.\n2. 客户端开始上传文件，NameNode向edit.log文件中记录操作日志。\n3. 客户端完成上传返回成功信息，NameNode便向内存中写入本次操作产生的元数据内容，方便读取。\n4. 当edit.log满的时候，NameNode便会通知SecondaryNode进行checkPoint操作(为了不影响主机性能，重开一台服务器，因为转换需要消耗内存)。\n5. SN同意操作便会通知NN让其停止往edit.log中写入日志，但不能避免还有其它上传，所以NN便会生成一个newedit.log,来替代之前的满的edit.log的工作.\n6. 接着SN下载fsimage(磁盘文件)与edit.log到本节点上进行合并操作，生成new_fsimage文件，再上传至NN上。\n7. NN替换fsimage并且删除edit.log,并且将newedit.log更名为edit.log.","source":"_posts/Hadoop-三.md","raw":"title: Hadoop(三)（Hdfs的上传与存储机制防止宕机）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-02-07 18:15:26\n---\n###### HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。\n\n\n###### NameNode保存元信息的种类有：\n\n* 文件名目录名及它们之间的层级关系\n* 文件目录的所有者及其权限\n* 每个文件块的名及文件有哪些块组成\n\n\n###### Secondary用来进行fsimage与edit.log的合并操作\n\n###### DataNode主要保存block即分割的块状文件\n\n###### 简要分析HDFS的文件上传机制：\n\n1. 客户端发送上传文件请求，通知NameNode,NameNode检查没有问题回传客户端OK.\n2. 客户端开始上传文件，NameNode向edit.log文件中记录操作日志。\n3. 客户端完成上传返回成功信息，NameNode便向内存中写入本次操作产生的元数据内容，方便读取。\n4. 当edit.log满的时候，NameNode便会通知SecondaryNode进行checkPoint操作(为了不影响主机性能，重开一台服务器，因为转换需要消耗内存)。\n5. SN同意操作便会通知NN让其停止往edit.log中写入日志，但不能避免还有其它上传，所以NN便会生成一个newedit.log,来替代之前的满的edit.log的工作.\n6. 接着SN下载fsimage(磁盘文件)与edit.log到本节点上进行合并操作，生成new_fsimage文件，再上传至NN上。\n7. NN替换fsimage并且删除edit.log,并且将newedit.log更名为edit.log.","slug":"Hadoop-三","published":1,"updated":"2018-03-26T09:46:34.649Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81unfz000iq87kzwqt7pyf","content":"<h6 id=\"HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master-slave模式运行的，其中NameNode、SecondaryNameNode-运行在master节点，DataNode运行slave节点。\"><a href=\"#HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master-slave模式运行的，其中NameNode、SecondaryNameNode-运行在master节点，DataNode运行slave节点。\" class=\"headerlink\" title=\"HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。\"></a>HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。</h6><h6 id=\"NameNode保存元信息的种类有：\"><a href=\"#NameNode保存元信息的种类有：\" class=\"headerlink\" title=\"NameNode保存元信息的种类有：\"></a>NameNode保存元信息的种类有：</h6><ul>\n<li>文件名目录名及它们之间的层级关系</li>\n<li>文件目录的所有者及其权限</li>\n<li>每个文件块的名及文件有哪些块组成</li>\n</ul>\n<h6 id=\"Secondary用来进行fsimage与edit-log的合并操作\"><a href=\"#Secondary用来进行fsimage与edit-log的合并操作\" class=\"headerlink\" title=\"Secondary用来进行fsimage与edit.log的合并操作\"></a>Secondary用来进行fsimage与edit.log的合并操作</h6><h6 id=\"DataNode主要保存block即分割的块状文件\"><a href=\"#DataNode主要保存block即分割的块状文件\" class=\"headerlink\" title=\"DataNode主要保存block即分割的块状文件\"></a>DataNode主要保存block即分割的块状文件</h6><h6 id=\"简要分析HDFS的文件上传机制：\"><a href=\"#简要分析HDFS的文件上传机制：\" class=\"headerlink\" title=\"简要分析HDFS的文件上传机制：\"></a>简要分析HDFS的文件上传机制：</h6><ol>\n<li>客户端发送上传文件请求，通知NameNode,NameNode检查没有问题回传客户端OK.</li>\n<li>客户端开始上传文件，NameNode向edit.log文件中记录操作日志。</li>\n<li>客户端完成上传返回成功信息，NameNode便向内存中写入本次操作产生的元数据内容，方便读取。</li>\n<li>当edit.log满的时候，NameNode便会通知SecondaryNode进行checkPoint操作(为了不影响主机性能，重开一台服务器，因为转换需要消耗内存)。</li>\n<li>SN同意操作便会通知NN让其停止往edit.log中写入日志，但不能避免还有其它上传，所以NN便会生成一个newedit.log,来替代之前的满的edit.log的工作.</li>\n<li>接着SN下载fsimage(磁盘文件)与edit.log到本节点上进行合并操作，生成new_fsimage文件，再上传至NN上。</li>\n<li>NN替换fsimage并且删除edit.log,并且将newedit.log更名为edit.log.</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h6 id=\"HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master-slave模式运行的，其中NameNode、SecondaryNameNode-运行在master节点，DataNode运行slave节点。\"><a href=\"#HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master-slave模式运行的，其中NameNode、SecondaryNameNode-运行在master节点，DataNode运行slave节点。\" class=\"headerlink\" title=\"HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。\"></a>HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。</h6><h6 id=\"NameNode保存元信息的种类有：\"><a href=\"#NameNode保存元信息的种类有：\" class=\"headerlink\" title=\"NameNode保存元信息的种类有：\"></a>NameNode保存元信息的种类有：</h6><ul>\n<li>文件名目录名及它们之间的层级关系</li>\n<li>文件目录的所有者及其权限</li>\n<li>每个文件块的名及文件有哪些块组成</li>\n</ul>\n<h6 id=\"Secondary用来进行fsimage与edit-log的合并操作\"><a href=\"#Secondary用来进行fsimage与edit-log的合并操作\" class=\"headerlink\" title=\"Secondary用来进行fsimage与edit.log的合并操作\"></a>Secondary用来进行fsimage与edit.log的合并操作</h6><h6 id=\"DataNode主要保存block即分割的块状文件\"><a href=\"#DataNode主要保存block即分割的块状文件\" class=\"headerlink\" title=\"DataNode主要保存block即分割的块状文件\"></a>DataNode主要保存block即分割的块状文件</h6><h6 id=\"简要分析HDFS的文件上传机制：\"><a href=\"#简要分析HDFS的文件上传机制：\" class=\"headerlink\" title=\"简要分析HDFS的文件上传机制：\"></a>简要分析HDFS的文件上传机制：</h6><ol>\n<li>客户端发送上传文件请求，通知NameNode,NameNode检查没有问题回传客户端OK.</li>\n<li>客户端开始上传文件，NameNode向edit.log文件中记录操作日志。</li>\n<li>客户端完成上传返回成功信息，NameNode便向内存中写入本次操作产生的元数据内容，方便读取。</li>\n<li>当edit.log满的时候，NameNode便会通知SecondaryNode进行checkPoint操作(为了不影响主机性能，重开一台服务器，因为转换需要消耗内存)。</li>\n<li>SN同意操作便会通知NN让其停止往edit.log中写入日志，但不能避免还有其它上传，所以NN便会生成一个newedit.log,来替代之前的满的edit.log的工作.</li>\n<li>接着SN下载fsimage(磁盘文件)与edit.log到本节点上进行合并操作，生成new_fsimage文件，再上传至NN上。</li>\n<li>NN替换fsimage并且删除edit.log,并且将newedit.log更名为edit.log.</li>\n</ol>\n"},{"title":"SS搭建","author":"小小冰弟","date":"2018-03-01T03:29:34.000Z","_content":"# ss搭建\n\n> 本脚本适用环境\n\n    系统支持：CentOS 6+，Debian 7+，Ubuntu 12+\n    内存要求：≥128M\n    \n> 关于本脚本\n\n    1. 一键安装 Shadowsocks-Python， ShadowsocksR， Shadowsocks-Go， Shadowsocks-libev 版（四选一）服务端；\n    2. 各版本的启动脚本及配置文件名不再重合；\n    3. 每次运行可安装一种版本；\n    4. 支持以多次运行来安装多个版本，且各个版本可以共存（注意端口号需设成不同）；\n    5. 若已安装多个版本，则卸载时也需多次运行（每次卸载一种）；\n    6. Shadowsocks-Python 和 ShadowsocksR 安装后不可同时启动（因为本质上都属 Python 版）。\n    \n> 默认配置\n\n    服务器端口：自己设定（如不设定，默认为 8989）\n    密码：自己设定（如不设定，默认为 teddysun.com）\n    加密方式：自己设定（如不设定，Python 和 libev 版默认为 aes-256-gcm，R 和 Go 版默认为 aes-256-cfb）\n    协议（protocol）：自己设定（如不设定，默认为 origin）（仅限 ShadowsocksR 版）\n    混淆（obfs）：自己设定（如不设定，默认为 plain）（仅限 ShadowsocksR 版）\n备注：脚本默认创建单用户配置文件，如需配置多用户，请手动修改相应的配置文件后重启即可。\n\n> 客户端下载\n\n    常规版 Windows 客户端\n <https://github.com/shadowsocks/shadowsocks-windows/releases>\n    \n    ShadowsocksR 版 Windows 客户端\n<https://github.com/shadowsocksr/shadowsocksr-csharp/releases>\n\n----------------\n    \n## 使用方法\n\n> 使用root用户登录，运行以下命令：\n\n```\nwget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh\nchmod +x shadowsocks-all.sh\n./shadowsocks-all.sh 2>&1 | tee shadowsocks-all.log\n\n```\n\n> 安装完成后，脚本提示如下\n\n    Congratulations, your_shadowsocks_version install completed!\n    Your Server IP        :your_server_ip\n    Your Server Port      :your_server_port\n    Your Password         :your_password\n    Your Encryption Method:your_encryption_method\n    Welcome to visit:https://teddysun.com/486.html\n    Enjoy it!\n    \n> 卸载方法\n\n    若已安装多个版本，则卸载时也需多次运行（每次卸载一种）\n    使用root用户登录，运行以下命令：\n    ./shadowsocks-all.sh uninstall\n    \n> 启动脚本 \n\n    启动脚本后面的参数含义，从左至右依次为：启动，停止，重启，查看状态。\n    \n    Shadowsocks-Python 版：\n    /etc/init.d/shadowsocks-python start | stop | restart | status\n    \n    ShadowsocksR 版：\n    /etc/init.d/shadowsocks-r start | stop | restart | status\n    \n    Shadowsocks-Go 版：\n    /etc/init.d/shadowsocks-go start | stop | restart | status\n    \n    Shadowsocks-libev 版：\n    /etc/init.d/shadowsocks-libev start | stop | restart | status\n    \n> 各版本默认配置文件\n\n    Shadowsocks-Python 版：\n    /etc/shadowsocks-python/config.json\n    \n    ShadowsocksR 版：\n    /etc/shadowsocks-r/config.json\n    \n    Shadowsocks-Go 版：\n    /etc/shadowsocks-go/config.json\n    \n    Shadowsocks-libev 版：\n    /etc/shadowsocks-libev/config.json","source":"_posts/SS搭建.md","raw":"title: SS搭建\nauthor: 小小冰弟\ndate: 2018-03-01 11:29:34\ntags: free\ncategories: skill\n---\n# ss搭建\n\n> 本脚本适用环境\n\n    系统支持：CentOS 6+，Debian 7+，Ubuntu 12+\n    内存要求：≥128M\n    \n> 关于本脚本\n\n    1. 一键安装 Shadowsocks-Python， ShadowsocksR， Shadowsocks-Go， Shadowsocks-libev 版（四选一）服务端；\n    2. 各版本的启动脚本及配置文件名不再重合；\n    3. 每次运行可安装一种版本；\n    4. 支持以多次运行来安装多个版本，且各个版本可以共存（注意端口号需设成不同）；\n    5. 若已安装多个版本，则卸载时也需多次运行（每次卸载一种）；\n    6. Shadowsocks-Python 和 ShadowsocksR 安装后不可同时启动（因为本质上都属 Python 版）。\n    \n> 默认配置\n\n    服务器端口：自己设定（如不设定，默认为 8989）\n    密码：自己设定（如不设定，默认为 teddysun.com）\n    加密方式：自己设定（如不设定，Python 和 libev 版默认为 aes-256-gcm，R 和 Go 版默认为 aes-256-cfb）\n    协议（protocol）：自己设定（如不设定，默认为 origin）（仅限 ShadowsocksR 版）\n    混淆（obfs）：自己设定（如不设定，默认为 plain）（仅限 ShadowsocksR 版）\n备注：脚本默认创建单用户配置文件，如需配置多用户，请手动修改相应的配置文件后重启即可。\n\n> 客户端下载\n\n    常规版 Windows 客户端\n <https://github.com/shadowsocks/shadowsocks-windows/releases>\n    \n    ShadowsocksR 版 Windows 客户端\n<https://github.com/shadowsocksr/shadowsocksr-csharp/releases>\n\n----------------\n    \n## 使用方法\n\n> 使用root用户登录，运行以下命令：\n\n```\nwget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh\nchmod +x shadowsocks-all.sh\n./shadowsocks-all.sh 2>&1 | tee shadowsocks-all.log\n\n```\n\n> 安装完成后，脚本提示如下\n\n    Congratulations, your_shadowsocks_version install completed!\n    Your Server IP        :your_server_ip\n    Your Server Port      :your_server_port\n    Your Password         :your_password\n    Your Encryption Method:your_encryption_method\n    Welcome to visit:https://teddysun.com/486.html\n    Enjoy it!\n    \n> 卸载方法\n\n    若已安装多个版本，则卸载时也需多次运行（每次卸载一种）\n    使用root用户登录，运行以下命令：\n    ./shadowsocks-all.sh uninstall\n    \n> 启动脚本 \n\n    启动脚本后面的参数含义，从左至右依次为：启动，停止，重启，查看状态。\n    \n    Shadowsocks-Python 版：\n    /etc/init.d/shadowsocks-python start | stop | restart | status\n    \n    ShadowsocksR 版：\n    /etc/init.d/shadowsocks-r start | stop | restart | status\n    \n    Shadowsocks-Go 版：\n    /etc/init.d/shadowsocks-go start | stop | restart | status\n    \n    Shadowsocks-libev 版：\n    /etc/init.d/shadowsocks-libev start | stop | restart | status\n    \n> 各版本默认配置文件\n\n    Shadowsocks-Python 版：\n    /etc/shadowsocks-python/config.json\n    \n    ShadowsocksR 版：\n    /etc/shadowsocks-r/config.json\n    \n    Shadowsocks-Go 版：\n    /etc/shadowsocks-go/config.json\n    \n    Shadowsocks-libev 版：\n    /etc/shadowsocks-libev/config.json","slug":"SS搭建","published":1,"updated":"2018-03-26T09:46:34.653Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81ung1000kq87kjmykdcgf","content":"<h1 id=\"ss搭建\"><a href=\"#ss搭建\" class=\"headerlink\" title=\"ss搭建\"></a>ss搭建</h1><blockquote>\n<p>本脚本适用环境</p>\n</blockquote>\n<pre><code>系统支持：CentOS 6+，Debian 7+，Ubuntu 12+\n内存要求：≥128M\n</code></pre><blockquote>\n<p>关于本脚本</p>\n</blockquote>\n<pre><code>1. 一键安装 Shadowsocks-Python， ShadowsocksR， Shadowsocks-Go， Shadowsocks-libev 版（四选一）服务端；\n2. 各版本的启动脚本及配置文件名不再重合；\n3. 每次运行可安装一种版本；\n4. 支持以多次运行来安装多个版本，且各个版本可以共存（注意端口号需设成不同）；\n5. 若已安装多个版本，则卸载时也需多次运行（每次卸载一种）；\n6. Shadowsocks-Python 和 ShadowsocksR 安装后不可同时启动（因为本质上都属 Python 版）。\n</code></pre><blockquote>\n<p>默认配置</p>\n</blockquote>\n<pre><code>服务器端口：自己设定（如不设定，默认为 8989）\n密码：自己设定（如不设定，默认为 teddysun.com）\n加密方式：自己设定（如不设定，Python 和 libev 版默认为 aes-256-gcm，R 和 Go 版默认为 aes-256-cfb）\n协议（protocol）：自己设定（如不设定，默认为 origin）（仅限 ShadowsocksR 版）\n混淆（obfs）：自己设定（如不设定，默认为 plain）（仅限 ShadowsocksR 版）\n</code></pre><p>备注：脚本默认创建单用户配置文件，如需配置多用户，请手动修改相应的配置文件后重启即可。</p>\n<blockquote>\n<p>客户端下载</p>\n</blockquote>\n<pre><code>常规版 Windows 客户端\n</code></pre><p> <a href=\"https://github.com/shadowsocks/shadowsocks-windows/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/shadowsocks/shadowsocks-windows/releases</a></p>\n<pre><code>ShadowsocksR 版 Windows 客户端\n</code></pre><p><a href=\"https://github.com/shadowsocksr/shadowsocksr-csharp/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/shadowsocksr/shadowsocksr-csharp/releases</a></p>\n<hr>\n<h2 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h2><blockquote>\n<p>使用root用户登录，运行以下命令：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh</span><br><span class=\"line\">chmod +x shadowsocks-all.sh</span><br><span class=\"line\">./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>安装完成后，脚本提示如下</p>\n</blockquote>\n<pre><code>Congratulations, your_shadowsocks_version install completed!\nYour Server IP        :your_server_ip\nYour Server Port      :your_server_port\nYour Password         :your_password\nYour Encryption Method:your_encryption_method\nWelcome to visit:https://teddysun.com/486.html\nEnjoy it!\n</code></pre><blockquote>\n<p>卸载方法</p>\n</blockquote>\n<pre><code>若已安装多个版本，则卸载时也需多次运行（每次卸载一种）\n使用root用户登录，运行以下命令：\n./shadowsocks-all.sh uninstall\n</code></pre><blockquote>\n<p>启动脚本 </p>\n</blockquote>\n<pre><code>启动脚本后面的参数含义，从左至右依次为：启动，停止，重启，查看状态。\n\nShadowsocks-Python 版：\n/etc/init.d/shadowsocks-python start | stop | restart | status\n\nShadowsocksR 版：\n/etc/init.d/shadowsocks-r start | stop | restart | status\n\nShadowsocks-Go 版：\n/etc/init.d/shadowsocks-go start | stop | restart | status\n\nShadowsocks-libev 版：\n/etc/init.d/shadowsocks-libev start | stop | restart | status\n</code></pre><blockquote>\n<p>各版本默认配置文件</p>\n</blockquote>\n<pre><code>Shadowsocks-Python 版：\n/etc/shadowsocks-python/config.json\n\nShadowsocksR 版：\n/etc/shadowsocks-r/config.json\n\nShadowsocks-Go 版：\n/etc/shadowsocks-go/config.json\n\nShadowsocks-libev 版：\n/etc/shadowsocks-libev/config.json\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ss搭建\"><a href=\"#ss搭建\" class=\"headerlink\" title=\"ss搭建\"></a>ss搭建</h1><blockquote>\n<p>本脚本适用环境</p>\n</blockquote>\n<pre><code>系统支持：CentOS 6+，Debian 7+，Ubuntu 12+\n内存要求：≥128M\n</code></pre><blockquote>\n<p>关于本脚本</p>\n</blockquote>\n<pre><code>1. 一键安装 Shadowsocks-Python， ShadowsocksR， Shadowsocks-Go， Shadowsocks-libev 版（四选一）服务端；\n2. 各版本的启动脚本及配置文件名不再重合；\n3. 每次运行可安装一种版本；\n4. 支持以多次运行来安装多个版本，且各个版本可以共存（注意端口号需设成不同）；\n5. 若已安装多个版本，则卸载时也需多次运行（每次卸载一种）；\n6. Shadowsocks-Python 和 ShadowsocksR 安装后不可同时启动（因为本质上都属 Python 版）。\n</code></pre><blockquote>\n<p>默认配置</p>\n</blockquote>\n<pre><code>服务器端口：自己设定（如不设定，默认为 8989）\n密码：自己设定（如不设定，默认为 teddysun.com）\n加密方式：自己设定（如不设定，Python 和 libev 版默认为 aes-256-gcm，R 和 Go 版默认为 aes-256-cfb）\n协议（protocol）：自己设定（如不设定，默认为 origin）（仅限 ShadowsocksR 版）\n混淆（obfs）：自己设定（如不设定，默认为 plain）（仅限 ShadowsocksR 版）\n</code></pre><p>备注：脚本默认创建单用户配置文件，如需配置多用户，请手动修改相应的配置文件后重启即可。</p>\n<blockquote>\n<p>客户端下载</p>\n</blockquote>\n<pre><code>常规版 Windows 客户端\n</code></pre><p> <a href=\"https://github.com/shadowsocks/shadowsocks-windows/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/shadowsocks/shadowsocks-windows/releases</a></p>\n<pre><code>ShadowsocksR 版 Windows 客户端\n</code></pre><p><a href=\"https://github.com/shadowsocksr/shadowsocksr-csharp/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/shadowsocksr/shadowsocksr-csharp/releases</a></p>\n<hr>\n<h2 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h2><blockquote>\n<p>使用root用户登录，运行以下命令：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh</span><br><span class=\"line\">chmod +x shadowsocks-all.sh</span><br><span class=\"line\">./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>安装完成后，脚本提示如下</p>\n</blockquote>\n<pre><code>Congratulations, your_shadowsocks_version install completed!\nYour Server IP        :your_server_ip\nYour Server Port      :your_server_port\nYour Password         :your_password\nYour Encryption Method:your_encryption_method\nWelcome to visit:https://teddysun.com/486.html\nEnjoy it!\n</code></pre><blockquote>\n<p>卸载方法</p>\n</blockquote>\n<pre><code>若已安装多个版本，则卸载时也需多次运行（每次卸载一种）\n使用root用户登录，运行以下命令：\n./shadowsocks-all.sh uninstall\n</code></pre><blockquote>\n<p>启动脚本 </p>\n</blockquote>\n<pre><code>启动脚本后面的参数含义，从左至右依次为：启动，停止，重启，查看状态。\n\nShadowsocks-Python 版：\n/etc/init.d/shadowsocks-python start | stop | restart | status\n\nShadowsocksR 版：\n/etc/init.d/shadowsocks-r start | stop | restart | status\n\nShadowsocks-Go 版：\n/etc/init.d/shadowsocks-go start | stop | restart | status\n\nShadowsocks-libev 版：\n/etc/init.d/shadowsocks-libev start | stop | restart | status\n</code></pre><blockquote>\n<p>各版本默认配置文件</p>\n</blockquote>\n<pre><code>Shadowsocks-Python 版：\n/etc/shadowsocks-python/config.json\n\nShadowsocksR 版：\n/etc/shadowsocks-r/config.json\n\nShadowsocks-Go 版：\n/etc/shadowsocks-go/config.json\n\nShadowsocks-libev 版：\n/etc/shadowsocks-libev/config.json\n</code></pre>"},{"title":"Hadoop(六)（yarn框架）","author":"小小冰弟","date":"2018-03-22T06:54:59.000Z","_content":"#### 一、YARN框架\n主要就是将之前的资源管理与任务调度功能一分为二，降低系统的耦合度与单点故障的可能性（JobTracker之前是集中处理点）。\n\n#### 二、工作机制\n###### 1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。\n###### 2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)\n###### 3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）\n###### 4.向ResourceManager汇报提交信息\n###### 5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\n######  6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)\n######  7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)\n######  8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\n\n（其中MRAppMaster与Yarnchild都是动态生成的）\n\n#### 三、eclipse运行\n在eclipse中运行，并不像我们之前使用命令行运行的那样，因为它调用的是本地的job而不是hadoop的，因为它并没有使用我们修改的配置文件，所以我们需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，结果运行时我们会发现没有jar，所以我们还需要将项目本身打包放到项目中并且设置configuration\n\n     Configuration conf = new Configuration();\n     conf.set(\"mapreduce.job.jar\",\"mc.jar\")\n     \n#### 四、几种提交运行模式\n\n##### 1.本地模式\n###### windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.\n###### linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.\n##### 2.集群模式\n###### windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\n###### linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。\n###### 第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(\"mapreduce.job.jar\",\"mc.jar\")\n     \n     \n     \n     \n     \n     \n     \n     ","source":"_posts/Hadoop-六-（yarn框架）.md","raw":"title: Hadoop(六)（yarn框架）\nauthor: 小小冰弟\ndate: 2018-03-22 14:54:59\ntags: study\ncategories: Hadoop\n---\n#### 一、YARN框架\n主要就是将之前的资源管理与任务调度功能一分为二，降低系统的耦合度与单点故障的可能性（JobTracker之前是集中处理点）。\n\n#### 二、工作机制\n###### 1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。\n###### 2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)\n###### 3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）\n###### 4.向ResourceManager汇报提交信息\n###### 5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\n######  6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)\n######  7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)\n######  8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\n\n（其中MRAppMaster与Yarnchild都是动态生成的）\n\n#### 三、eclipse运行\n在eclipse中运行，并不像我们之前使用命令行运行的那样，因为它调用的是本地的job而不是hadoop的，因为它并没有使用我们修改的配置文件，所以我们需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，结果运行时我们会发现没有jar，所以我们还需要将项目本身打包放到项目中并且设置configuration\n\n     Configuration conf = new Configuration();\n     conf.set(\"mapreduce.job.jar\",\"mc.jar\")\n     \n#### 四、几种提交运行模式\n\n##### 1.本地模式\n###### windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.\n###### linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.\n##### 2.集群模式\n###### windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\n###### linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。\n###### 第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(\"mapreduce.job.jar\",\"mc.jar\")\n     \n     \n     \n     \n     \n     \n     \n     ","slug":"Hadoop-六-（yarn框架）","published":1,"updated":"2018-03-26T09:46:34.651Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81ung4000pq87k6j3qpwlh","content":"<h4 id=\"一、YARN框架\"><a href=\"#一、YARN框架\" class=\"headerlink\" title=\"一、YARN框架\"></a>一、YARN框架</h4><p>主要就是将之前的资源管理与任务调度功能一分为二，降低系统的耦合度与单点故障的可能性（JobTracker之前是集中处理点）。</p>\n<h4 id=\"二、工作机制\"><a href=\"#二、工作机制\" class=\"headerlink\" title=\"二、工作机制\"></a>二、工作机制</h4><h6 id=\"1-在java主程序中最后调用的waitforcompletion-会提交任务，向ResourceManager申请执行一个job。\"><a href=\"#1-在java主程序中最后调用的waitforcompletion-会提交任务，向ResourceManager申请执行一个job。\" class=\"headerlink\" title=\"1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。\"></a>1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。</h6><h6 id=\"2-ResourceManager返回给给job相关资源提交的路径和产生的job-id-一个staging-dir\"><a href=\"#2-ResourceManager返回给给job相关资源提交的路径和产生的job-id-一个staging-dir\" class=\"headerlink\" title=\"2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)\"></a>2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)</h6><h6 id=\"3-根据返回结果，将资源提交到staging-dir上（默认在HDFS上面）\"><a href=\"#3-根据返回结果，将资源提交到staging-dir上（默认在HDFS上面）\" class=\"headerlink\" title=\"3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）\"></a>3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）</h6><h6 id=\"4-向ResourceManager汇报提交信息\"><a href=\"#4-向ResourceManager汇报提交信息\" class=\"headerlink\" title=\"4.向ResourceManager汇报提交信息\"></a>4.向ResourceManager汇报提交信息</h6><h6 id=\"5-ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\"><a href=\"#5-ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\" class=\"headerlink\" title=\"5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\"></a>5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。</h6><h6 id=\"6-NodeManager给任务分配运行类资源的容器container-从HDFS和Resource两个地方拿资源\"><a href=\"#6-NodeManager给任务分配运行类资源的容器container-从HDFS和Resource两个地方拿资源\" class=\"headerlink\" title=\"6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)\"></a>6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)</h6><h6 id=\"7-启动MRAppMaster-MapReduce内部框架，分配谁是主进程\"><a href=\"#7-启动MRAppMaster-MapReduce内部框架，分配谁是主进程\" class=\"headerlink\" title=\"7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)\"></a>7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)</h6><h6 id=\"8-向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\"><a href=\"#8-向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\" class=\"headerlink\" title=\"8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\"></a>8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。</h6><p>（其中MRAppMaster与Yarnchild都是动态生成的）</p>\n<h4 id=\"三、eclipse运行\"><a href=\"#三、eclipse运行\" class=\"headerlink\" title=\"三、eclipse运行\"></a>三、eclipse运行</h4><p>在eclipse中运行，并不像我们之前使用命令行运行的那样，因为它调用的是本地的job而不是hadoop的，因为它并没有使用我们修改的配置文件，所以我们需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，结果运行时我们会发现没有jar，所以我们还需要将项目本身打包放到项目中并且设置configuration</p>\n<pre><code>Configuration conf = new Configuration();\nconf.set(&quot;mapreduce.job.jar&quot;,&quot;mc.jar&quot;)\n</code></pre><h4 id=\"四、几种提交运行模式\"><a href=\"#四、几种提交运行模式\" class=\"headerlink\" title=\"四、几种提交运行模式\"></a>四、几种提交运行模式</h4><h5 id=\"1-本地模式\"><a href=\"#1-本地模式\" class=\"headerlink\" title=\"1.本地模式\"></a>1.本地模式</h5><h6 id=\"windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner\"><a href=\"#windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner\" class=\"headerlink\" title=\"windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.\"></a>windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.</h6><h6 id=\"linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner\"><a href=\"#linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner\" class=\"headerlink\" title=\"linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.\"></a>linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.</h6><h5 id=\"2-集群模式\"><a href=\"#2-集群模式\" class=\"headerlink\" title=\"2.集群模式\"></a>2.集群模式</h5><h6 id=\"windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\"><a href=\"#windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\" class=\"headerlink\" title=\"windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\"></a>windows版本还是放弃吧，贼麻烦，路径的符号不一样等等</h6><h6 id=\"linux上第一种-可以直接打包项目丢到服务器上运用hadoop-jar-jar包-运行。\"><a href=\"#linux上第一种-可以直接打包项目丢到服务器上运用hadoop-jar-jar包-运行。\" class=\"headerlink\" title=\"linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。\"></a>linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。</h6><h6 id=\"第二种是在eclipse中，需要将mapred-site-xml与yarn-site-xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf-set-“mapreduce-job-jar”-”mc-jar”\"><a href=\"#第二种是在eclipse中，需要将mapred-site-xml与yarn-site-xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf-set-“mapreduce-job-jar”-”mc-jar”\" class=\"headerlink\" title=\"第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(“mapreduce.job.jar”,”mc.jar”)\"></a>第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(“mapreduce.job.jar”,”mc.jar”)</h6>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"一、YARN框架\"><a href=\"#一、YARN框架\" class=\"headerlink\" title=\"一、YARN框架\"></a>一、YARN框架</h4><p>主要就是将之前的资源管理与任务调度功能一分为二，降低系统的耦合度与单点故障的可能性（JobTracker之前是集中处理点）。</p>\n<h4 id=\"二、工作机制\"><a href=\"#二、工作机制\" class=\"headerlink\" title=\"二、工作机制\"></a>二、工作机制</h4><h6 id=\"1-在java主程序中最后调用的waitforcompletion-会提交任务，向ResourceManager申请执行一个job。\"><a href=\"#1-在java主程序中最后调用的waitforcompletion-会提交任务，向ResourceManager申请执行一个job。\" class=\"headerlink\" title=\"1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。\"></a>1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。</h6><h6 id=\"2-ResourceManager返回给给job相关资源提交的路径和产生的job-id-一个staging-dir\"><a href=\"#2-ResourceManager返回给给job相关资源提交的路径和产生的job-id-一个staging-dir\" class=\"headerlink\" title=\"2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)\"></a>2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)</h6><h6 id=\"3-根据返回结果，将资源提交到staging-dir上（默认在HDFS上面）\"><a href=\"#3-根据返回结果，将资源提交到staging-dir上（默认在HDFS上面）\" class=\"headerlink\" title=\"3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）\"></a>3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）</h6><h6 id=\"4-向ResourceManager汇报提交信息\"><a href=\"#4-向ResourceManager汇报提交信息\" class=\"headerlink\" title=\"4.向ResourceManager汇报提交信息\"></a>4.向ResourceManager汇报提交信息</h6><h6 id=\"5-ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\"><a href=\"#5-ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\" class=\"headerlink\" title=\"5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\"></a>5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。</h6><h6 id=\"6-NodeManager给任务分配运行类资源的容器container-从HDFS和Resource两个地方拿资源\"><a href=\"#6-NodeManager给任务分配运行类资源的容器container-从HDFS和Resource两个地方拿资源\" class=\"headerlink\" title=\"6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)\"></a>6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)</h6><h6 id=\"7-启动MRAppMaster-MapReduce内部框架，分配谁是主进程\"><a href=\"#7-启动MRAppMaster-MapReduce内部框架，分配谁是主进程\" class=\"headerlink\" title=\"7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)\"></a>7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)</h6><h6 id=\"8-向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\"><a href=\"#8-向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\" class=\"headerlink\" title=\"8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\"></a>8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。</h6><p>（其中MRAppMaster与Yarnchild都是动态生成的）</p>\n<h4 id=\"三、eclipse运行\"><a href=\"#三、eclipse运行\" class=\"headerlink\" title=\"三、eclipse运行\"></a>三、eclipse运行</h4><p>在eclipse中运行，并不像我们之前使用命令行运行的那样，因为它调用的是本地的job而不是hadoop的，因为它并没有使用我们修改的配置文件，所以我们需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，结果运行时我们会发现没有jar，所以我们还需要将项目本身打包放到项目中并且设置configuration</p>\n<pre><code>Configuration conf = new Configuration();\nconf.set(&quot;mapreduce.job.jar&quot;,&quot;mc.jar&quot;)\n</code></pre><h4 id=\"四、几种提交运行模式\"><a href=\"#四、几种提交运行模式\" class=\"headerlink\" title=\"四、几种提交运行模式\"></a>四、几种提交运行模式</h4><h5 id=\"1-本地模式\"><a href=\"#1-本地模式\" class=\"headerlink\" title=\"1.本地模式\"></a>1.本地模式</h5><h6 id=\"windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner\"><a href=\"#windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner\" class=\"headerlink\" title=\"windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.\"></a>windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.</h6><h6 id=\"linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner\"><a href=\"#linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner\" class=\"headerlink\" title=\"linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.\"></a>linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.</h6><h5 id=\"2-集群模式\"><a href=\"#2-集群模式\" class=\"headerlink\" title=\"2.集群模式\"></a>2.集群模式</h5><h6 id=\"windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\"><a href=\"#windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\" class=\"headerlink\" title=\"windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\"></a>windows版本还是放弃吧，贼麻烦，路径的符号不一样等等</h6><h6 id=\"linux上第一种-可以直接打包项目丢到服务器上运用hadoop-jar-jar包-运行。\"><a href=\"#linux上第一种-可以直接打包项目丢到服务器上运用hadoop-jar-jar包-运行。\" class=\"headerlink\" title=\"linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。\"></a>linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。</h6><h6 id=\"第二种是在eclipse中，需要将mapred-site-xml与yarn-site-xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf-set-“mapreduce-job-jar”-”mc-jar”\"><a href=\"#第二种是在eclipse中，需要将mapred-site-xml与yarn-site-xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf-set-“mapreduce-job-jar”-”mc-jar”\" class=\"headerlink\" title=\"第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(“mapreduce.job.jar”,”mc.jar”)\"></a>第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(“mapreduce.job.jar”,”mc.jar”)</h6>"},{"title":"Markdown 入门操作","author":"小小冰弟","date":"2018-02-03T08:00:01.000Z","_content":"### 一、Markdown的简要语法规则\n#### 标题\n\n标题是每篇文章都需要也是最常用的格式，在 Markdown 中，如果一段文字被定义为标题，只要在这段文字前加 # 号即可，随着# 数量的添加，字体越来越小。\n\n   ### # 一级标题\n   #### ##二级标题\n   ##### ###三级标题\n***\n\n#### 列表\n列表分为有序列表与无序列表，有序列表只需要在列表文字前加上序号即可，而无序列表则是在文字前加 - 或者 *\n###### 有序列表\n1. 三余无梦生\n2. 苍越孤鸣\n3. 绮罗生\n\n###### 无序列表\n- 任飘渺\n* 风逍遥\n- 欲星移\n***\n\n##### 引用\n当你想在文中引入某位大咖说的话，只需要在文本前面加上 > 即可，效果如下：\n> 小小冰弟曾说：“美梦是因为做不到，噩梦如是。”\n***\n\n##### 图片与链接\n链接: 中括号+小括号+链接 \n\n [Google](www.google.com \"谷歌\")\n\n图片: 感叹号+中括号+链接（最后还可以用引号包住并加上 选择性的 'title' 文字）\n\n![](/uploads/sufei.jpg \"苏菲女神\")\n***\n\n\n\n##### 粗体与斜体\n\n**两个 * 号包含的文本就是粗体**\n\n_只用一个 * 号包含的就是斜体_\n\n(其实 * 也可以换成 _ )\n\n##### 代码区块\n\n和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 **code** 和 **pre** 两个标签来把代码区块包起来。\n\n要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以\n\n普通文本\n\n\t\tpublic class HelloWorld {\n           public static void main(String[] args){\n              System.out.println(\"Hello World!\");\n           }\n         }\n         \n***\n\n##### [Markdown语法与快捷键](http://blog.csdn.net/wolinghuanyun/article/details/52454751)","source":"_posts/Markdown-入门操作.md","raw":"title: Markdown 入门操作\nauthor: 小小冰弟\ntags: study\ncategories: Markdown\ndate: 2018-02-03 16:00:01\n---\n### 一、Markdown的简要语法规则\n#### 标题\n\n标题是每篇文章都需要也是最常用的格式，在 Markdown 中，如果一段文字被定义为标题，只要在这段文字前加 # 号即可，随着# 数量的添加，字体越来越小。\n\n   ### # 一级标题\n   #### ##二级标题\n   ##### ###三级标题\n***\n\n#### 列表\n列表分为有序列表与无序列表，有序列表只需要在列表文字前加上序号即可，而无序列表则是在文字前加 - 或者 *\n###### 有序列表\n1. 三余无梦生\n2. 苍越孤鸣\n3. 绮罗生\n\n###### 无序列表\n- 任飘渺\n* 风逍遥\n- 欲星移\n***\n\n##### 引用\n当你想在文中引入某位大咖说的话，只需要在文本前面加上 > 即可，效果如下：\n> 小小冰弟曾说：“美梦是因为做不到，噩梦如是。”\n***\n\n##### 图片与链接\n链接: 中括号+小括号+链接 \n\n [Google](www.google.com \"谷歌\")\n\n图片: 感叹号+中括号+链接（最后还可以用引号包住并加上 选择性的 'title' 文字）\n\n![](/uploads/sufei.jpg \"苏菲女神\")\n***\n\n\n\n##### 粗体与斜体\n\n**两个 * 号包含的文本就是粗体**\n\n_只用一个 * 号包含的就是斜体_\n\n(其实 * 也可以换成 _ )\n\n##### 代码区块\n\n和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 **code** 和 **pre** 两个标签来把代码区块包起来。\n\n要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以\n\n普通文本\n\n\t\tpublic class HelloWorld {\n           public static void main(String[] args){\n              System.out.println(\"Hello World!\");\n           }\n         }\n         \n***\n\n##### [Markdown语法与快捷键](http://blog.csdn.net/wolinghuanyun/article/details/52454751)","slug":"Markdown-入门操作","published":1,"updated":"2018-03-26T09:46:34.652Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81ung6000rq87k5wknvirl","content":"<h3 id=\"一、Markdown的简要语法规则\"><a href=\"#一、Markdown的简要语法规则\" class=\"headerlink\" title=\"一、Markdown的简要语法规则\"></a>一、Markdown的简要语法规则</h3><h4 id=\"标题\"><a href=\"#标题\" class=\"headerlink\" title=\"标题\"></a>标题</h4><p>标题是每篇文章都需要也是最常用的格式，在 Markdown 中，如果一段文字被定义为标题，只要在这段文字前加 # 号即可，随着# 数量的添加，字体越来越小。</p>\n<h3 id=\"一级标题\"><a href=\"#一级标题\" class=\"headerlink\" title=\"# 一级标题\"></a># 一级标题</h3><h4 id=\"二级标题\"><a href=\"#二级标题\" class=\"headerlink\" title=\"##二级标题\"></a>##二级标题</h4><h5 id=\"三级标题\"><a href=\"#三级标题\" class=\"headerlink\" title=\"###三级标题\"></a>###三级标题</h5><hr>\n<h4 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h4><p>列表分为有序列表与无序列表，有序列表只需要在列表文字前加上序号即可，而无序列表则是在文字前加 - 或者 *</p>\n<h6 id=\"有序列表\"><a href=\"#有序列表\" class=\"headerlink\" title=\"有序列表\"></a>有序列表</h6><ol>\n<li>三余无梦生</li>\n<li>苍越孤鸣</li>\n<li>绮罗生</li>\n</ol>\n<h6 id=\"无序列表\"><a href=\"#无序列表\" class=\"headerlink\" title=\"无序列表\"></a>无序列表</h6><ul>\n<li>任飘渺</li>\n</ul>\n<ul>\n<li>风逍遥</li>\n</ul>\n<ul>\n<li>欲星移</li>\n</ul>\n<hr>\n<h5 id=\"引用\"><a href=\"#引用\" class=\"headerlink\" title=\"引用\"></a>引用</h5><p>当你想在文中引入某位大咖说的话，只需要在文本前面加上 &gt; 即可，效果如下：</p>\n<blockquote>\n<p>小小冰弟曾说：“美梦是因为做不到，噩梦如是。”</p>\n<hr>\n</blockquote>\n<h5 id=\"图片与链接\"><a href=\"#图片与链接\" class=\"headerlink\" title=\"图片与链接\"></a>图片与链接</h5><p>链接: 中括号+小括号+链接 </p>\n<p> <a href=\"www.google.com\" title=\"谷歌\">Google</a></p>\n<p>图片: 感叹号+中括号+链接（最后还可以用引号包住并加上 选择性的 ‘title’ 文字）</p>\n<p><img src=\"/uploads/sufei.jpg\" alt=\"\" title=\"苏菲女神\"></p>\n<hr>\n<h5 id=\"粗体与斜体\"><a href=\"#粗体与斜体\" class=\"headerlink\" title=\"粗体与斜体\"></a>粗体与斜体</h5><p><strong>两个 * 号包含的文本就是粗体</strong></p>\n<p><em>只用一个 * 号包含的就是斜体</em></p>\n<p>(其实 * 也可以换成 _ )</p>\n<h5 id=\"代码区块\"><a href=\"#代码区块\" class=\"headerlink\" title=\"代码区块\"></a>代码区块</h5><p>和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 <strong>code</strong> 和 <strong>pre</strong> 两个标签来把代码区块包起来。</p>\n<p>要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以</p>\n<p>普通文本</p>\n<pre><code>public class HelloWorld {\n   public static void main(String[] args){\n      System.out.println(&quot;Hello World!&quot;);\n   }\n }\n</code></pre><hr>\n<h5 id=\"Markdown语法与快捷键\"><a href=\"#Markdown语法与快捷键\" class=\"headerlink\" title=\"Markdown语法与快捷键\"></a><a href=\"http://blog.csdn.net/wolinghuanyun/article/details/52454751\" target=\"_blank\" rel=\"noopener\">Markdown语法与快捷键</a></h5>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"一、Markdown的简要语法规则\"><a href=\"#一、Markdown的简要语法规则\" class=\"headerlink\" title=\"一、Markdown的简要语法规则\"></a>一、Markdown的简要语法规则</h3><h4 id=\"标题\"><a href=\"#标题\" class=\"headerlink\" title=\"标题\"></a>标题</h4><p>标题是每篇文章都需要也是最常用的格式，在 Markdown 中，如果一段文字被定义为标题，只要在这段文字前加 # 号即可，随着# 数量的添加，字体越来越小。</p>\n<h3 id=\"一级标题\"><a href=\"#一级标题\" class=\"headerlink\" title=\"# 一级标题\"></a># 一级标题</h3><h4 id=\"二级标题\"><a href=\"#二级标题\" class=\"headerlink\" title=\"##二级标题\"></a>##二级标题</h4><h5 id=\"三级标题\"><a href=\"#三级标题\" class=\"headerlink\" title=\"###三级标题\"></a>###三级标题</h5><hr>\n<h4 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h4><p>列表分为有序列表与无序列表，有序列表只需要在列表文字前加上序号即可，而无序列表则是在文字前加 - 或者 *</p>\n<h6 id=\"有序列表\"><a href=\"#有序列表\" class=\"headerlink\" title=\"有序列表\"></a>有序列表</h6><ol>\n<li>三余无梦生</li>\n<li>苍越孤鸣</li>\n<li>绮罗生</li>\n</ol>\n<h6 id=\"无序列表\"><a href=\"#无序列表\" class=\"headerlink\" title=\"无序列表\"></a>无序列表</h6><ul>\n<li>任飘渺</li>\n</ul>\n<ul>\n<li>风逍遥</li>\n</ul>\n<ul>\n<li>欲星移</li>\n</ul>\n<hr>\n<h5 id=\"引用\"><a href=\"#引用\" class=\"headerlink\" title=\"引用\"></a>引用</h5><p>当你想在文中引入某位大咖说的话，只需要在文本前面加上 &gt; 即可，效果如下：</p>\n<blockquote>\n<p>小小冰弟曾说：“美梦是因为做不到，噩梦如是。”</p>\n<hr>\n</blockquote>\n<h5 id=\"图片与链接\"><a href=\"#图片与链接\" class=\"headerlink\" title=\"图片与链接\"></a>图片与链接</h5><p>链接: 中括号+小括号+链接 </p>\n<p> <a href=\"www.google.com\" title=\"谷歌\">Google</a></p>\n<p>图片: 感叹号+中括号+链接（最后还可以用引号包住并加上 选择性的 ‘title’ 文字）</p>\n<p><img src=\"/uploads/sufei.jpg\" alt=\"\" title=\"苏菲女神\"></p>\n<hr>\n<h5 id=\"粗体与斜体\"><a href=\"#粗体与斜体\" class=\"headerlink\" title=\"粗体与斜体\"></a>粗体与斜体</h5><p><strong>两个 * 号包含的文本就是粗体</strong></p>\n<p><em>只用一个 * 号包含的就是斜体</em></p>\n<p>(其实 * 也可以换成 _ )</p>\n<h5 id=\"代码区块\"><a href=\"#代码区块\" class=\"headerlink\" title=\"代码区块\"></a>代码区块</h5><p>和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 <strong>code</strong> 和 <strong>pre</strong> 两个标签来把代码区块包起来。</p>\n<p>要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以</p>\n<p>普通文本</p>\n<pre><code>public class HelloWorld {\n   public static void main(String[] args){\n      System.out.println(&quot;Hello World!&quot;);\n   }\n }\n</code></pre><hr>\n<h5 id=\"Markdown语法与快捷键\"><a href=\"#Markdown语法与快捷键\" class=\"headerlink\" title=\"Markdown语法与快捷键\"></a><a href=\"http://blog.csdn.net/wolinghuanyun/article/details/52454751\" target=\"_blank\" rel=\"noopener\">Markdown语法与快捷键</a></h5>"},{"title":"Hadoop(四)（java客户端操作HDFS）","author":"小小冰弟","date":"2018-03-01T01:18:28.000Z","_content":"##### 1.导包\n没有maven环境，自己导包的话，找到share/hadoop目录下commons与hdfs文件下的jar包与lib下的所有包导入工程。\n\n##### 2.准备工作\n    //配置\n    Configuration conf = new Configuration(); \n    //构造一个hdfs的客户端  \n    FileSystem fs=FileSystem.get(new URI(\"hdfs://192.168.145.102:8020\"), conf, \"root\");  \n\n##### 3.基本操作 \n     \n    //从本地上传文件到hdfs中   \n    @Test  \n    public void Upload() throws IllegalArgumentException, IOException{ \n        Path hpath = new Path(\"/\");\n        Path lpath = \"/home/wujian/jdk-7u65-linux-i586.tar.gz\"\n        fs.copyFromLocalFile(lpath, hpath);  \n        fs.close();  \n    }  \n    \n    // 从hdfs中下载文件到本地 \n    @Test  \n    public void Download() throws IllegalArgumentException, IOException{  \n        Path hpath = new Path(\"/jdk-7u65-linux-i586.tar.gz\");\n        Path lpath = \"/home/wujian/\"\n        fs.copyToLocalFile(hpath, lpath, true);  \n        fs.close();  \n    }  \n      \n    \n    //文件夹操作  \n    @Test  \n    public void Dir() throws IllegalArgumentException, IOException{  \n        //创建文件夹\n        fs.mkdirs(new Path(\"/aaa\"));  \n          \n        //判断是否存在 \n        boolean exists = fs.exists(new Path(\"/aaa\"));  \n \n        fs.close();  \n    }  \n      \n    //文件信息查看   \n    @Test  \n    public void FileStatus() throws FileNotFoundException, IllegalArgumentException, IOException{  \n        //只能列出文件信息  \n        RemoteIterator<LocatedFileStatus> listFiles = fs.listFiles(new Path(\"/\"), true);  \n        while(listFiles.hasNext()){  \n            LocatedFileStatus fileStatus = listFiles.next();  \n            System.out.println(fileStatus.getPath().getName());  \n        }  \n          \n        System.out.println(\"-----------------------\");  \n        //能列出文件和文件夹信息  \n        FileStatus[] listStatus = fs.listStatus(new Path(\"/\"));  \n        for(FileStatus f:listStatus){  \n            String type=\"-\";  \n            if(f.isDirectory()){\n             type=\"d\"; \n            }\n            System.out.println(type+\"\\t\"+f.getPath().getName());  \n        }  \n        fs.close();  \n    }  ","source":"_posts/Hadoop-四-（java客户端操作HDFS）.md","raw":"title: Hadoop(四)（java客户端操作HDFS）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-03-01 09:18:28\n---\n##### 1.导包\n没有maven环境，自己导包的话，找到share/hadoop目录下commons与hdfs文件下的jar包与lib下的所有包导入工程。\n\n##### 2.准备工作\n    //配置\n    Configuration conf = new Configuration(); \n    //构造一个hdfs的客户端  \n    FileSystem fs=FileSystem.get(new URI(\"hdfs://192.168.145.102:8020\"), conf, \"root\");  \n\n##### 3.基本操作 \n     \n    //从本地上传文件到hdfs中   \n    @Test  \n    public void Upload() throws IllegalArgumentException, IOException{ \n        Path hpath = new Path(\"/\");\n        Path lpath = \"/home/wujian/jdk-7u65-linux-i586.tar.gz\"\n        fs.copyFromLocalFile(lpath, hpath);  \n        fs.close();  \n    }  \n    \n    // 从hdfs中下载文件到本地 \n    @Test  \n    public void Download() throws IllegalArgumentException, IOException{  \n        Path hpath = new Path(\"/jdk-7u65-linux-i586.tar.gz\");\n        Path lpath = \"/home/wujian/\"\n        fs.copyToLocalFile(hpath, lpath, true);  \n        fs.close();  \n    }  \n      \n    \n    //文件夹操作  \n    @Test  \n    public void Dir() throws IllegalArgumentException, IOException{  \n        //创建文件夹\n        fs.mkdirs(new Path(\"/aaa\"));  \n          \n        //判断是否存在 \n        boolean exists = fs.exists(new Path(\"/aaa\"));  \n \n        fs.close();  \n    }  \n      \n    //文件信息查看   \n    @Test  \n    public void FileStatus() throws FileNotFoundException, IllegalArgumentException, IOException{  \n        //只能列出文件信息  \n        RemoteIterator<LocatedFileStatus> listFiles = fs.listFiles(new Path(\"/\"), true);  \n        while(listFiles.hasNext()){  \n            LocatedFileStatus fileStatus = listFiles.next();  \n            System.out.println(fileStatus.getPath().getName());  \n        }  \n          \n        System.out.println(\"-----------------------\");  \n        //能列出文件和文件夹信息  \n        FileStatus[] listStatus = fs.listStatus(new Path(\"/\"));  \n        for(FileStatus f:listStatus){  \n            String type=\"-\";  \n            if(f.isDirectory()){\n             type=\"d\"; \n            }\n            System.out.println(type+\"\\t\"+f.getPath().getName());  \n        }  \n        fs.close();  \n    }  ","slug":"Hadoop-四-（java客户端操作HDFS）","published":1,"updated":"2018-03-26T09:46:34.651Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81ung8000wq87kbii1i5wu","content":"<h5 id=\"1-导包\"><a href=\"#1-导包\" class=\"headerlink\" title=\"1.导包\"></a>1.导包</h5><p>没有maven环境，自己导包的话，找到share/hadoop目录下commons与hdfs文件下的jar包与lib下的所有包导入工程。</p>\n<h5 id=\"2-准备工作\"><a href=\"#2-准备工作\" class=\"headerlink\" title=\"2.准备工作\"></a>2.准备工作</h5><pre><code>//配置\nConfiguration conf = new Configuration(); \n//构造一个hdfs的客户端  \nFileSystem fs=FileSystem.get(new URI(&quot;hdfs://192.168.145.102:8020&quot;), conf, &quot;root&quot;);  \n</code></pre><h5 id=\"3-基本操作\"><a href=\"#3-基本操作\" class=\"headerlink\" title=\"3.基本操作\"></a>3.基本操作</h5><pre><code>//从本地上传文件到hdfs中   \n@Test  \npublic void Upload() throws IllegalArgumentException, IOException{ \n    Path hpath = new Path(&quot;/&quot;);\n    Path lpath = &quot;/home/wujian/jdk-7u65-linux-i586.tar.gz&quot;\n    fs.copyFromLocalFile(lpath, hpath);  \n    fs.close();  \n}  \n\n// 从hdfs中下载文件到本地 \n@Test  \npublic void Download() throws IllegalArgumentException, IOException{  \n    Path hpath = new Path(&quot;/jdk-7u65-linux-i586.tar.gz&quot;);\n    Path lpath = &quot;/home/wujian/&quot;\n    fs.copyToLocalFile(hpath, lpath, true);  \n    fs.close();  \n}  \n\n\n//文件夹操作  \n@Test  \npublic void Dir() throws IllegalArgumentException, IOException{  \n    //创建文件夹\n    fs.mkdirs(new Path(&quot;/aaa&quot;));  \n\n    //判断是否存在 \n    boolean exists = fs.exists(new Path(&quot;/aaa&quot;));  \n\n    fs.close();  \n}  \n\n//文件信息查看   \n@Test  \npublic void FileStatus() throws FileNotFoundException, IllegalArgumentException, IOException{  \n    //只能列出文件信息  \n    RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(new Path(&quot;/&quot;), true);  \n    while(listFiles.hasNext()){  \n        LocatedFileStatus fileStatus = listFiles.next();  \n        System.out.println(fileStatus.getPath().getName());  \n    }  \n\n    System.out.println(&quot;-----------------------&quot;);  \n    //能列出文件和文件夹信息  \n    FileStatus[] listStatus = fs.listStatus(new Path(&quot;/&quot;));  \n    for(FileStatus f:listStatus){  \n        String type=&quot;-&quot;;  \n        if(f.isDirectory()){\n         type=&quot;d&quot;; \n        }\n        System.out.println(type+&quot;\\t&quot;+f.getPath().getName());  \n    }  \n    fs.close();  \n}  \n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h5 id=\"1-导包\"><a href=\"#1-导包\" class=\"headerlink\" title=\"1.导包\"></a>1.导包</h5><p>没有maven环境，自己导包的话，找到share/hadoop目录下commons与hdfs文件下的jar包与lib下的所有包导入工程。</p>\n<h5 id=\"2-准备工作\"><a href=\"#2-准备工作\" class=\"headerlink\" title=\"2.准备工作\"></a>2.准备工作</h5><pre><code>//配置\nConfiguration conf = new Configuration(); \n//构造一个hdfs的客户端  \nFileSystem fs=FileSystem.get(new URI(&quot;hdfs://192.168.145.102:8020&quot;), conf, &quot;root&quot;);  \n</code></pre><h5 id=\"3-基本操作\"><a href=\"#3-基本操作\" class=\"headerlink\" title=\"3.基本操作\"></a>3.基本操作</h5><pre><code>//从本地上传文件到hdfs中   \n@Test  \npublic void Upload() throws IllegalArgumentException, IOException{ \n    Path hpath = new Path(&quot;/&quot;);\n    Path lpath = &quot;/home/wujian/jdk-7u65-linux-i586.tar.gz&quot;\n    fs.copyFromLocalFile(lpath, hpath);  \n    fs.close();  \n}  \n\n// 从hdfs中下载文件到本地 \n@Test  \npublic void Download() throws IllegalArgumentException, IOException{  \n    Path hpath = new Path(&quot;/jdk-7u65-linux-i586.tar.gz&quot;);\n    Path lpath = &quot;/home/wujian/&quot;\n    fs.copyToLocalFile(hpath, lpath, true);  \n    fs.close();  \n}  \n\n\n//文件夹操作  \n@Test  \npublic void Dir() throws IllegalArgumentException, IOException{  \n    //创建文件夹\n    fs.mkdirs(new Path(&quot;/aaa&quot;));  \n\n    //判断是否存在 \n    boolean exists = fs.exists(new Path(&quot;/aaa&quot;));  \n\n    fs.close();  \n}  \n\n//文件信息查看   \n@Test  \npublic void FileStatus() throws FileNotFoundException, IllegalArgumentException, IOException{  \n    //只能列出文件信息  \n    RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(new Path(&quot;/&quot;), true);  \n    while(listFiles.hasNext()){  \n        LocatedFileStatus fileStatus = listFiles.next();  \n        System.out.println(fileStatus.getPath().getName());  \n    }  \n\n    System.out.println(&quot;-----------------------&quot;);  \n    //能列出文件和文件夹信息  \n    FileStatus[] listStatus = fs.listStatus(new Path(&quot;/&quot;));  \n    for(FileStatus f:listStatus){  \n        String type=&quot;-&quot;;  \n        if(f.isDirectory()){\n         type=&quot;d&quot;; \n        }\n        System.out.println(type+&quot;\\t&quot;+f.getPath().getName());  \n    }  \n    fs.close();  \n}  \n</code></pre>"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ntags: live\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2018-03-26T09:46:34.653Z","updated":"2018-03-26T09:46:34.653Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81ung9000yq87ko0vh17bx","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n"},{"title":"常用的基本操作链接","author":"小小冰弟","date":"2018-02-05T00:53:59.000Z","_content":"#### <center>博客篇\n  \n##### [一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）](http://blog.csdn.net/gdutxiaoxu/article/details/53576018)  \n\n##### [二、hexo-admin 博客后端管理工具](https://blog.kinpzz.com/2016/12/31/hexo-admin-backend-management/)\n\n##### [三、hexo换电脑怎么处理](github.com/xxbd/xxbd.github.io/blob/master/index.html)\n\n##### [四、VM虚拟机下安装Centos7.0图文教程](http://www.centoscn.com/image-text/setup/2014/0723/3341.html)\n\n##### [五、SpringBoot](http://www.spring4all.com/article/246)\n\n##### [六、NATAPP1分钟快速新手图文教程（映射公网ip）](https://natapp.cn/article/natapp_newbie)\n\n##### 注：new post是文章，而new pages只是个主页分类(比如about,diary...)。","source":"_posts/常用的基本操作链接.md","raw":"title: 常用的基本操作链接\nauthor: 小小冰弟\ncategories: link\ntags: study\ndate: 2018-02-05 08:53:59\n---\n#### <center>博客篇\n  \n##### [一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）](http://blog.csdn.net/gdutxiaoxu/article/details/53576018)  \n\n##### [二、hexo-admin 博客后端管理工具](https://blog.kinpzz.com/2016/12/31/hexo-admin-backend-management/)\n\n##### [三、hexo换电脑怎么处理](github.com/xxbd/xxbd.github.io/blob/master/index.html)\n\n##### [四、VM虚拟机下安装Centos7.0图文教程](http://www.centoscn.com/image-text/setup/2014/0723/3341.html)\n\n##### [五、SpringBoot](http://www.spring4all.com/article/246)\n\n##### [六、NATAPP1分钟快速新手图文教程（映射公网ip）](https://natapp.cn/article/natapp_newbie)\n\n##### 注：new post是文章，而new pages只是个主页分类(比如about,diary...)。","slug":"常用的基本操作链接","published":1,"updated":"2018-03-26T09:46:34.654Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf81ungh001jq87kz6i7h0r1","content":"<h4 id=\"博客篇\"><a href=\"#博客篇\" class=\"headerlink\" title=\"博客篇\"></a><center>博客篇</center></h4><h5 id=\"一、手把手教你用Hexo-Github-搭建属于自己的博客（我觉得写得很详细）\"><a href=\"#一、手把手教你用Hexo-Github-搭建属于自己的博客（我觉得写得很详细）\" class=\"headerlink\" title=\"一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）\"></a><a href=\"http://blog.csdn.net/gdutxiaoxu/article/details/53576018\" target=\"_blank\" rel=\"noopener\">一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）</a></h5><h5 id=\"二、hexo-admin-博客后端管理工具\"><a href=\"#二、hexo-admin-博客后端管理工具\" class=\"headerlink\" title=\"二、hexo-admin 博客后端管理工具\"></a><a href=\"https://blog.kinpzz.com/2016/12/31/hexo-admin-backend-management/\" target=\"_blank\" rel=\"noopener\">二、hexo-admin 博客后端管理工具</a></h5><h5 id=\"三、hexo换电脑怎么处理\"><a href=\"#三、hexo换电脑怎么处理\" class=\"headerlink\" title=\"三、hexo换电脑怎么处理\"></a><a href=\"github.com/xxbd/xxbd.github.io/blob/master/index.html\">三、hexo换电脑怎么处理</a></h5><h5 id=\"四、VM虚拟机下安装Centos7-0图文教程\"><a href=\"#四、VM虚拟机下安装Centos7-0图文教程\" class=\"headerlink\" title=\"四、VM虚拟机下安装Centos7.0图文教程\"></a><a href=\"http://www.centoscn.com/image-text/setup/2014/0723/3341.html\" target=\"_blank\" rel=\"noopener\">四、VM虚拟机下安装Centos7.0图文教程</a></h5><h5 id=\"五、SpringBoot\"><a href=\"#五、SpringBoot\" class=\"headerlink\" title=\"五、SpringBoot\"></a><a href=\"http://www.spring4all.com/article/246\" target=\"_blank\" rel=\"noopener\">五、SpringBoot</a></h5><h5 id=\"六、NATAPP1分钟快速新手图文教程（映射公网ip）\"><a href=\"#六、NATAPP1分钟快速新手图文教程（映射公网ip）\" class=\"headerlink\" title=\"六、NATAPP1分钟快速新手图文教程（映射公网ip）\"></a><a href=\"https://natapp.cn/article/natapp_newbie\" target=\"_blank\" rel=\"noopener\">六、NATAPP1分钟快速新手图文教程（映射公网ip）</a></h5><h5 id=\"注：new-post是文章，而new-pages只是个主页分类-比如about-diary…-。\"><a href=\"#注：new-post是文章，而new-pages只是个主页分类-比如about-diary…-。\" class=\"headerlink\" title=\"注：new post是文章，而new pages只是个主页分类(比如about,diary…)。\"></a>注：new post是文章，而new pages只是个主页分类(比如about,diary…)。</h5>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"博客篇\"><a href=\"#博客篇\" class=\"headerlink\" title=\"博客篇\"></a><center>博客篇</center></h4><h5 id=\"一、手把手教你用Hexo-Github-搭建属于自己的博客（我觉得写得很详细）\"><a href=\"#一、手把手教你用Hexo-Github-搭建属于自己的博客（我觉得写得很详细）\" class=\"headerlink\" title=\"一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）\"></a><a href=\"http://blog.csdn.net/gdutxiaoxu/article/details/53576018\" target=\"_blank\" rel=\"noopener\">一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）</a></h5><h5 id=\"二、hexo-admin-博客后端管理工具\"><a href=\"#二、hexo-admin-博客后端管理工具\" class=\"headerlink\" title=\"二、hexo-admin 博客后端管理工具\"></a><a href=\"https://blog.kinpzz.com/2016/12/31/hexo-admin-backend-management/\" target=\"_blank\" rel=\"noopener\">二、hexo-admin 博客后端管理工具</a></h5><h5 id=\"三、hexo换电脑怎么处理\"><a href=\"#三、hexo换电脑怎么处理\" class=\"headerlink\" title=\"三、hexo换电脑怎么处理\"></a><a href=\"github.com/xxbd/xxbd.github.io/blob/master/index.html\">三、hexo换电脑怎么处理</a></h5><h5 id=\"四、VM虚拟机下安装Centos7-0图文教程\"><a href=\"#四、VM虚拟机下安装Centos7-0图文教程\" class=\"headerlink\" title=\"四、VM虚拟机下安装Centos7.0图文教程\"></a><a href=\"http://www.centoscn.com/image-text/setup/2014/0723/3341.html\" target=\"_blank\" rel=\"noopener\">四、VM虚拟机下安装Centos7.0图文教程</a></h5><h5 id=\"五、SpringBoot\"><a href=\"#五、SpringBoot\" class=\"headerlink\" title=\"五、SpringBoot\"></a><a href=\"http://www.spring4all.com/article/246\" target=\"_blank\" rel=\"noopener\">五、SpringBoot</a></h5><h5 id=\"六、NATAPP1分钟快速新手图文教程（映射公网ip）\"><a href=\"#六、NATAPP1分钟快速新手图文教程（映射公网ip）\" class=\"headerlink\" title=\"六、NATAPP1分钟快速新手图文教程（映射公网ip）\"></a><a href=\"https://natapp.cn/article/natapp_newbie\" target=\"_blank\" rel=\"noopener\">六、NATAPP1分钟快速新手图文教程（映射公网ip）</a></h5><h5 id=\"注：new-post是文章，而new-pages只是个主页分类-比如about-diary…-。\"><a href=\"#注：new-post是文章，而new-pages只是个主页分类-比如about-diary…-。\" class=\"headerlink\" title=\"注：new post是文章，而new pages只是个主页分类(比如about,diary…)。\"></a>注：new post是文章，而new pages只是个主页分类(比如about,diary…)。</h5>"},{"title":"两台电脑的测试","author":"小小冰弟","date":"2018-03-26T09:49:13.000Z","_content":"这仅仅就是一个普通的测试文件，并没有什么意义。","source":"_posts/两台电脑的测试.md","raw":"title: 两台电脑的测试\nauthor: 小小冰弟\ndate: 2018-03-26 17:49:13\ntags:\n---\n这仅仅就是一个普通的测试文件，并没有什么意义。","slug":"两台电脑的测试","published":1,"updated":"2018-03-26T09:49:34.188Z","_id":"cjf81vujj001qq87k8v35434h","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这仅仅就是一个普通的测试文件，并没有什么意义。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>这仅仅就是一个普通的测试文件，并没有什么意义。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjf81unfi0000q87kylcvyh4p","category_id":"cjf81unfp0003q87kjyxoeivy","_id":"cjf81unfy000eq87k66vwps1u"},{"post_id":"cjf81unfn0002q87k7rxkp32n","category_id":"cjf81unfu0008q87kpyrlegjn","_id":"cjf81ung3000mq87k7abv4rxw"},{"post_id":"cjf81unfr0005q87kp7v85x4e","category_id":"cjf81unfu0008q87kpyrlegjn","_id":"cjf81ung7000tq87kq5e5bt9h"},{"post_id":"cjf81unfs0006q87k3gmxo2mt","category_id":"cjf81unfu0008q87kpyrlegjn","_id":"cjf81unga000zq87kt5e0v5ji"},{"post_id":"cjf81ung8000wq87kbii1i5wu","category_id":"cjf81ung7000sq87kmnl0mi7c","_id":"cjf81ungc0013q87kl7zp4kmd"},{"post_id":"cjf81unft0007q87kbvgg37qr","category_id":"cjf81ung7000sq87kmnl0mi7c","_id":"cjf81ungc0016q87kn1k1pj4f"},{"post_id":"cjf81unfv000bq87k4cf8magx","category_id":"cjf81ung7000sq87kmnl0mi7c","_id":"cjf81ungd0019q87k8k0yipwc"},{"post_id":"cjf81unfx000dq87kd2iphi6u","category_id":"cjf81ung7000sq87kmnl0mi7c","_id":"cjf81unge001cq87k7hhd89le"},{"post_id":"cjf81unfz000iq87kzwqt7pyf","category_id":"cjf81ung7000sq87kmnl0mi7c","_id":"cjf81unge001dq87k9dqu1z1e"},{"post_id":"cjf81ung1000kq87kjmykdcgf","category_id":"cjf81unge001bq87kf4ezpx2w","_id":"cjf81ungf001gq87kykfds2ui"},{"post_id":"cjf81ung4000pq87k6j3qpwlh","category_id":"cjf81ung7000sq87kmnl0mi7c","_id":"cjf81ungf001hq87kyd595px0"},{"post_id":"cjf81ung6000rq87k5wknvirl","category_id":"cjf81ungf001fq87kcsp7lwz6","_id":"cjf81ungf001iq87kqh94t7y3"},{"post_id":"cjf81ungh001jq87kz6i7h0r1","category_id":"cjf81ungk001mq87k26xi67zw","_id":"cjf81ungl001pq87k1rzakck6"}],"PostTag":[{"post_id":"cjf81unfi0000q87kylcvyh4p","tag_id":"cjf81unfq0004q87k3atpxmm8","_id":"cjf81unfv000aq87kbd6x69vu"},{"post_id":"cjf81unft0007q87kbvgg37qr","tag_id":"cjf81unfq0004q87k3atpxmm8","_id":"cjf81unfw000cq87k9garedz6"},{"post_id":"cjf81unfv000bq87k4cf8magx","tag_id":"cjf81unfq0004q87k3atpxmm8","_id":"cjf81unfz000hq87kq8kcwgoi"},{"post_id":"cjf81unfn0002q87k7rxkp32n","tag_id":"cjf81unfu0009q87krgpdlt84","_id":"cjf81ung1000jq87kq74o2sey"},{"post_id":"cjf81unfx000dq87kd2iphi6u","tag_id":"cjf81unfq0004q87k3atpxmm8","_id":"cjf81ung4000oq87k6xmjya9j"},{"post_id":"cjf81unfz000iq87kzwqt7pyf","tag_id":"cjf81unfq0004q87k3atpxmm8","_id":"cjf81ung6000qq87kv4wi2ru8"},{"post_id":"cjf81unfr0005q87kp7v85x4e","tag_id":"cjf81unfu0009q87krgpdlt84","_id":"cjf81ung8000vq87kr7jd29tm"},{"post_id":"cjf81ung4000pq87k6j3qpwlh","tag_id":"cjf81unfq0004q87k3atpxmm8","_id":"cjf81ung9000xq87kjl3skiig"},{"post_id":"cjf81unfs0006q87k3gmxo2mt","tag_id":"cjf81unfu0009q87krgpdlt84","_id":"cjf81ungb0011q87kjn21huqv"},{"post_id":"cjf81ung6000rq87k5wknvirl","tag_id":"cjf81unfq0004q87k3atpxmm8","_id":"cjf81ungb0012q87kee8y2031"},{"post_id":"cjf81ung8000wq87kbii1i5wu","tag_id":"cjf81unfq0004q87k3atpxmm8","_id":"cjf81ungc0015q87ki6nmu0vg"},{"post_id":"cjf81ung1000kq87kjmykdcgf","tag_id":"cjf81ung7000uq87ks3tnjet3","_id":"cjf81ungc0017q87kbjfh5ht2"},{"post_id":"cjf81ung9000yq87ko0vh17bx","tag_id":"cjf81unfu0009q87krgpdlt84","_id":"cjf81ungd001aq87kj5or8akn"},{"post_id":"cjf81ungh001jq87kz6i7h0r1","tag_id":"cjf81unfq0004q87k3atpxmm8","_id":"cjf81ungk001nq87k6qdua3v1"}],"Tag":[{"name":"study","_id":"cjf81unfq0004q87k3atpxmm8"},{"name":"live","_id":"cjf81unfu0009q87krgpdlt84"},{"name":"free","_id":"cjf81ung7000uq87ks3tnjet3"}]}}