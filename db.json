{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/pasted-1.png","path":"images/pasted-1.png","modified":0,"renderable":0},{"_id":"source/images/pasted-2.png","path":"images/pasted-2.png","modified":0,"renderable":0},{"_id":"source/images/pasted-3.png","path":"images/pasted-3.png","modified":0,"renderable":0},{"_id":"source/images/pasted-4.png","path":"images/pasted-4.png","modified":0,"renderable":0},{"_id":"source/uploads/avtar.jpg","path":"uploads/avtar.jpg","modified":0,"renderable":0},{"_id":"source/images/pasted-0.png","path":"images/pasted-0.png","modified":0,"renderable":0},{"_id":"source/uploads/talor.jpg","path":"uploads/talor.jpg","modified":0,"renderable":0},{"_id":"source/uploads/tl.jpg","path":"uploads/tl.jpg","modified":0,"renderable":0},{"_id":"source/uploads/sufei.jpg","path":"uploads/sufei.jpg","modified":0,"renderable":0},{"_id":"source/uploads/tl.jpeg","path":"uploads/tl.jpeg","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/fireworks.js","path":"js/src/fireworks.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"source/images/pasted-5.png","path":"images/pasted-5.png","modified":0,"renderable":0},{"_id":"source/images/pasted-6.png","path":"images/pasted-6.png","modified":0,"renderable":0},{"_id":"source/images/pasted-7.png","path":"images/pasted-7.png","modified":0,"renderable":0},{"_id":"source/images/pasted-8.png","path":"images/pasted-8.png","modified":0,"renderable":0},{"_id":"source/images/pasted-9.png","path":"images/pasted-9.png","modified":0,"renderable":0},{"_id":"source/images/pasted-11.png","path":"images/pasted-11.png","modified":0,"renderable":0},{"_id":"source/images/pasted-10.png","path":"images/pasted-10.png","modified":0,"renderable":0},{"_id":"source/images/pasted-12.png","path":"images/pasted-12.png","modified":0,"renderable":0},{"_id":"source/images/pasted-13.png","path":"images/pasted-13.png","modified":0,"renderable":0},{"_id":"source/images/pasted-14.png","path":"images/pasted-14.png","modified":0,"renderable":0},{"_id":"source/images/pasted-15.png","path":"images/pasted-15.png","modified":0,"renderable":0},{"_id":"source/images/pasted-16.png","path":"images/pasted-16.png","modified":0,"renderable":0},{"_id":"source/images/pasted-18.png","path":"images/pasted-18.png","modified":0,"renderable":0},{"_id":"source/images/pasted-19.png","path":"images/pasted-19.png","modified":0,"renderable":0},{"_id":"source/images/pasted-17.png","path":"images/pasted-17.png","modified":0,"renderable":0},{"_id":"source/images/pasted-20.png","path":"images/pasted-20.png","modified":0,"renderable":0},{"_id":"source/images/pasted-21.png","path":"images/pasted-21.png","modified":0,"renderable":0},{"_id":"source/images/pasted-22.png","path":"images/pasted-22.png","modified":0,"renderable":0},{"_id":"source/images/pasted-23.png","path":"images/pasted-23.png","modified":0,"renderable":0},{"_id":"source/images/pasted-24.png","path":"images/pasted-24.png","modified":0,"renderable":0},{"_id":"source/images/pasted-25.png","path":"images/pasted-25.png","modified":0,"renderable":0},{"_id":"source/images/pasted-26.png","path":"images/pasted-26.png","modified":0,"renderable":0}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"334da94ca6f024d60d012cc26ea655681e724ad8","modified":1518019350003},{"_id":"themes/next/.editorconfig","hash":"211d2c92bfdddb3e81ea946f4ca7a539f150f4da","modified":1518019350003},{"_id":"themes/next/.gitattributes","hash":"8454b9313cb1a97b63fb87e2d29daee497ce6249","modified":1518019350003},{"_id":"themes/next/.gitignore","hash":"ee0b13c268cc8695d3883a5da84930af02d4ed08","modified":1518019350004},{"_id":"themes/next/.hound.yml","hash":"289dcf5bfe92dbd680d54d6e0668f41c9c9c0c78","modified":1518019350005},{"_id":"themes/next/.javascript_ignore","hash":"cd250ad74ca22bd2c054476456a73d9687f05f87","modified":1518019350005},{"_id":"themes/next/.jshintrc","hash":"b7d23f2ce8d99fa073f22f9960605f318acd7710","modified":1518019350005},{"_id":"themes/next/.stylintrc","hash":"3b7f9785e9ad0dab764e1c535b40df02f4ff5fd6","modified":1518019350006},{"_id":"themes/next/.travis.yml","hash":"6674fbdfe0d0c03b8a04527ffb8ab66a94253acd","modified":1518019350006},{"_id":"themes/next/LICENSE","hash":"ec44503d7e617144909e54533754f0147845f0c5","modified":1518019350006},{"_id":"themes/next/README.cn.md","hash":"87950c415dd162ff78e98b41f1148b85462103e2","modified":1518019350006},{"_id":"themes/next/README.md","hash":"927f82cfeb5969a89b815b5ec3a3f2881e3b1bb4","modified":1518019350007},{"_id":"themes/next/_config.yml","hash":"d9110e93c9ac642c9f7156e1dd6e641f0f50b50b","modified":1522060041382},{"_id":"themes/next/bower.json","hash":"486ebd72068848c97def75f36b71cbec9bb359c5","modified":1518019350007},{"_id":"themes/next/gulpfile.coffee","hash":"412defab3d93d404b7c26aaa0279e2e586e97454","modified":1518019350008},{"_id":"themes/next/package.json","hash":"3963ad558a24c78a3fd4ef23cf5f73f421854627","modified":1518019350035},{"_id":"source/_posts/Bugs.md","hash":"e9a785afea1bc5f22ceccc885fb2e91d87eaebdc","modified":1522057594644},{"_id":"source/_posts/Diary-2.md","hash":"a82d5afd04d71692dc8457dcf63993ed32da7e8c","modified":1522057594644},{"_id":"source/_posts/Diary-3.md","hash":"f7561935c6c6716dbcac42f5d0ece706cdf91cdc","modified":1522057594645},{"_id":"source/_posts/Diary-4.md","hash":"ae24b68e147a992bd7b21dd23aebe509fc5ddaad","modified":1522144351582},{"_id":"source/_posts/First-Diary.md","hash":"b70fcf5ce35ea6ef6c504c7e5ace52efd95f4cb7","modified":1522057594646},{"_id":"source/_posts/Hadoop-一.md","hash":"67922963de9b7c24d5fc13ff5bd01fd4037924dc","modified":1522057594648},{"_id":"source/_posts/Hadoop-七-（HA高可用架构配置）.md","hash":"a6cf0b9d359b57f792a9ba08abad8dfe5af16bcd","modified":1522144472813},{"_id":"source/_posts/Hadoop-三.md","hash":"3f6ee53e21b3a27eaafb03a6d2742f51773a232a","modified":1522057594649},{"_id":"source/_posts/Hadoop-九-（HBase）.md","hash":"65424157de63a81d2f976251e11572d5861eb9bd","modified":1522232479032},{"_id":"source/_posts/Hadoop-二-（常用基本命令）.md","hash":"5e34ebafcffff1f02bac700b12ae8667f794125c","modified":1522057594649},{"_id":"source/_posts/Hadoop-五-（mapreduce）.md","hash":"6657d696dfd3226e73bdf7fee15aed93bfc5819f","modified":1522057594650},{"_id":"source/_posts/Hadoop-八-（hive）.md","hash":"63a7456018b3fe329db1c18b489e186710875dac","modified":1522232465613},{"_id":"source/_posts/Hadoop-六-（yarn框架）.md","hash":"ac8e4ac258b60612b6e64d7427d60c302554d7f0","modified":1522138152615},{"_id":"source/_posts/Hadoop-十-Storm.md","hash":"cbb3c769cafbfa154275676fe272e0936097422d","modified":1522311259119},{"_id":"source/_posts/Hadoop-四-（java客户端操作HDFS）.md","hash":"f8ad53ff1b8774f9e7b9a05fe29f1b67f74403d9","modified":1522057594651},{"_id":"source/_posts/Markdown-入门操作.md","hash":"4906a3b95b538d2e183a3f2d63d89ca123253554","modified":1522396575570},{"_id":"source/_posts/Hadoop-十一-（kafka）.md","hash":"810780a8c5a6450d0ca57cf53a6e96f4c664db4c","modified":1522316773193},{"_id":"source/_posts/SS搭建.md","hash":"28d49e918d12c94286055d31cd971c2ee51c83aa","modified":1522057594653},{"_id":"source/_posts/hello-world.md","hash":"2b48bd28ee8567a9aae13a91b9140ea3252abb80","modified":1522057594653},{"_id":"source/_posts/两台电脑的测试.md","hash":"b4c647699faf54bd842a4dc30ecd989cb3a76a2b","modified":1522057774188},{"_id":"source/_posts/常用的基本操作链接.md","hash":"9ab60c7ad5b1c030099c1419b9e713f7fd40195f","modified":1522057594654},{"_id":"source/about/index.md","hash":"017fc9ee858bf5ab1e2c6da2b8fde5e2c6a90fac","modified":1522057594655},{"_id":"source/categories/index.md","hash":"9615c21d5469629c5014e0a818ba5f6a2faf3808","modified":1522057594656},{"_id":"source/images/pasted-1.png","hash":"aca3453b2e27b67a019382d5dcf3b5099be4014a","modified":1522307783826},{"_id":"source/images/pasted-2.png","hash":"2bb4146c9d01e7d02d1ed696dea2faf249e8abac","modified":1522307879883},{"_id":"source/images/pasted-3.png","hash":"3cf04aa3cc016109d8a3c3db312759ea5cb36171","modified":1522308026521},{"_id":"source/images/pasted-4.png","hash":"6fb19a7369242b763affa14b3a870fc4f9367349","modified":1522310291307},{"_id":"source/neggings/index.md","hash":"20e88a6f90518962a74aced5972a35ad32ff87b9","modified":1522057594658},{"_id":"source/tags/index.md","hash":"02eb8fab5a5140a6f381449af0385c08c466161c","modified":1522057594659},{"_id":"source/uploads/avtar.jpg","hash":"2d003ee446fb0c79a8783e1f30e3fc9b63874980","modified":1522057594660},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5adfad3ef1b870063e621bc0838268eb2c7c697a","modified":1518019350003},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"b1ec000babd42bb7ffd26f5ad8aac9b5bec79ae5","modified":1518019350004},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1228506a940114288d61812bfe60c045a0abeac1","modified":1518019350004},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1518019350004},{"_id":"themes/next/languages/de.yml","hash":"fd02d9c2035798d5dc7c1a96b4c3e24b05b31a47","modified":1518019350008},{"_id":"themes/next/languages/default.yml","hash":"b3bcd8934327448a43d9bfada5dd11b1b8c1402e","modified":1518019350008},{"_id":"themes/next/languages/en.yml","hash":"2f4b4776ca1a08cc266a19afb0d1350a3926f42c","modified":1518019350009},{"_id":"themes/next/languages/fr-FR.yml","hash":"efeeb55d5c4add54ad59a612fc0630ee1300388c","modified":1518019350009},{"_id":"themes/next/languages/id.yml","hash":"dccae33e2a5b3c9f11c0e05ec4a7201af1b25745","modified":1518019350009},{"_id":"themes/next/languages/it.yml","hash":"a215d016146b1bd92cef046042081cbe0c7f976f","modified":1518019350009},{"_id":"themes/next/languages/ja.yml","hash":"37f954e47a3bc669620ca559e3edb3b0072a4be5","modified":1518019350010},{"_id":"themes/next/languages/ko.yml","hash":"dc8f3e8c64eb7c4bb2385025b3006b8efec8b31d","modified":1518019350010},{"_id":"themes/next/languages/nl-NL.yml","hash":"213e7a002b82fb265f69dabafbbc382cfd460030","modified":1518019350010},{"_id":"themes/next/languages/pt-BR.yml","hash":"568d494a1f37726a5375b11452a45c71c3e2852d","modified":1518019350011},{"_id":"themes/next/languages/pt.yml","hash":"2efcd240c66ab1a122f061505ca0fb1e8819877b","modified":1518019350011},{"_id":"themes/next/languages/ru.yml","hash":"e33ee44e80f82e329900fc41eb0bb6823397a4d6","modified":1518019350011},{"_id":"themes/next/languages/vi.yml","hash":"a9b89ebd3e5933033d1386c7c56b66c44aca299a","modified":1518019350011},{"_id":"themes/next/languages/zh-Hans.yml","hash":"66b9b42f143c3cb2f782a94abd4c4cbd5fd7f55f","modified":1518019350012},{"_id":"themes/next/languages/zh-hk.yml","hash":"fe0d45807d015082049f05b54714988c244888da","modified":1518019350012},{"_id":"themes/next/languages/zh-tw.yml","hash":"432463b481e105073accda16c3e590e54c8e7b74","modified":1518019350012},{"_id":"themes/next/layout/_layout.swig","hash":"779c3fbd542d5aa1cae2bbac71c0add017ce92fd","modified":1518019350013},{"_id":"themes/next/layout/archive.swig","hash":"9a2c14874a75c7085d2bada5e39201d3fc4fd2b4","modified":1518019350034},{"_id":"themes/next/layout/category.swig","hash":"3cbb3f72429647411f9e85f2544bdf0e3ad2e6b2","modified":1518019350034},{"_id":"themes/next/layout/index.swig","hash":"555a357ecf17128db4e29346c92bb6298e66547a","modified":1518019350034},{"_id":"themes/next/layout/page.swig","hash":"e8fcaa641d46930237675d2ad4b56964d9e262e9","modified":1518019350034},{"_id":"themes/next/layout/post.swig","hash":"7a6ce102ca82c3a80f776e555dddae1a9981e1ed","modified":1518019350035},{"_id":"themes/next/layout/schedule.swig","hash":"87ad6055df01fa2e63e51887d34a2d8f0fbd2f5a","modified":1518019350035},{"_id":"themes/next/layout/tag.swig","hash":"34e1c016cbdf94a31f9c5d494854ff46b2a182e9","modified":1518019350035},{"_id":"themes/next/scripts/merge-configs.js","hash":"38d86aab4fc12fb741ae52099be475196b9db972","modified":1518019350036},{"_id":"themes/next/scripts/merge.js","hash":"39b84b937b2a9608b94e5872349a47200e1800ff","modified":1518019350036},{"_id":"themes/next/test/.jshintrc","hash":"c9fca43ae0d99718e45a6f5ce736a18ba5fc8fb6","modified":1518019350126},{"_id":"themes/next/test/helpers.js","hash":"f25e7f3265eb5a6e1ccbb5e5012fa9bebf134105","modified":1518019350127},{"_id":"themes/next/test/intern.js","hash":"db90b1063356727d72be0d77054fdc32fa882a66","modified":1518019350127},{"_id":"source/images/pasted-0.png","hash":"b7a1a2aaf801ed10baf22d44072317a1004cfb49","modified":1522057594657},{"_id":"source/uploads/talor.jpg","hash":"7b5474cc390daf8e22e80a4e6fb88d8dce43cdfd","modified":1522057594663},{"_id":"source/uploads/tl.jpg","hash":"c0fe4d6072ccaefba79fbf1b25cb6b7e6e8650b8","modified":1522057594666},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1518019350071},{"_id":"source/uploads/sufei.jpg","hash":"102af907a6e179c4c0cd01eaddbfb66e6de3fc54","modified":1522057594662},{"_id":"source/uploads/tl.jpeg","hash":"6d1f0d119084ffd5b27d82d1a276b493d357e917","modified":1522057594665},{"_id":"themes/next/layout/_custom/header.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1518019350013},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1518019350013},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"8c56dd26157cbc580ae41d97ac34b90ab48ced3f","modified":1518019350014},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"f83befdc740beb8dc88805efd7fbb0fef9ed19be","modified":1518019350014},{"_id":"themes/next/layout/_macro/post.swig","hash":"4ba938822d56c597490f0731893eaa2443942e0f","modified":1518019350014},{"_id":"themes/next/layout/_macro/reward.swig","hash":"357d86ec9586705bfbb2c40a8c7d247a407db21a","modified":1518019350014},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"9c7343fd470e0943ebd75f227a083a980816290b","modified":1518019350015},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"e2e4eae391476da994045ed4c7faf5e05aca2cd7","modified":1518019350015},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4adc65a602d1276615da3b887dcbf2ac68e7382b","modified":1518019350016},{"_id":"themes/next/layout/_partials/footer.swig","hash":"26e93336dc57a39590ba8dc80564a1d2ad5ff93b","modified":1518019350016},{"_id":"themes/next/layout/_partials/head.swig","hash":"664e03abcc19d722597007951e69281d1cd91e63","modified":1518019350016},{"_id":"themes/next/layout/_partials/header.swig","hash":"42ce45d932a1b2929bce0ae193eb62ba7fd3d3ae","modified":1518019350017},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"77c61e0baea3544df361b7338c3cd13dc84dde22","modified":1518019350017},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"1634fb887842698e01ff6e632597fe03c75d2d01","modified":1518019350018},{"_id":"themes/next/layout/_partials/search.swig","hash":"b4ebe4a52a3b51efe549dd1cdee846103664f5eb","modified":1518019350018},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"c0f5a0955f69ca4ed9ee64a2d5f8aa75064935ad","modified":1518019350020},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"931808ad9b8d8390c0dcf9bdeb0954eeb9185d68","modified":1518019350021},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9be624634703be496a5d2535228bc568a8373af9","modified":1518019350022},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"ba75672183d94f1de7c8bd0eeee497a58c70e889","modified":1518019350030},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"8301c9600bb3e47f7fb98b0e0332ef3c51bb1688","modified":1518019350030},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"a0bd3388587fd943baae0d84ca779a707fbcad89","modified":1518019350030},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"fa882641da3bd83d9a58a8a97f9d4c62a9ee7b5c","modified":1518019350030},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"554ec568e9d2c71e4a624a8de3cb5929050811d6","modified":1518019350031},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"db15d7e1552aa2d2386a6b8a33b3b3a40bf9e43d","modified":1518019350031},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"9a188938d46931d5f3882a140aa1c48b3a893f0c","modified":1518019350031},{"_id":"themes/next/scripts/tags/button.js","hash":"eddbb612c15ac27faf11c59c019ce188f33dec2c","modified":1518019350037},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"99b66949f18398689b904907af23c013be1b978f","modified":1518019350037},{"_id":"themes/next/scripts/tags/exturl.js","hash":"5022c0ba9f1d13192677cf1fd66005c57c3d0f53","modified":1518019350037},{"_id":"themes/next/scripts/tags/full-image.js","hash":"c9f833158c66bd72f627a0559cf96550e867aa72","modified":1518019350038},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"ac681b0d0d8d39ba3817336c0270c6787c2b6b70","modified":1518019350038},{"_id":"themes/next/scripts/tags/label.js","hash":"6f00952d70aadece844ce7fd27adc52816cc7374","modified":1518019350038},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"bcba2ff25cd7850ce6da322d8bd85a8dd00b5ceb","modified":1518019350039},{"_id":"themes/next/scripts/tags/note.js","hash":"f7eae135f35cdab23728e9d0d88b76e00715faa0","modified":1518019350039},{"_id":"themes/next/scripts/tags/tabs.js","hash":"aa7fc94a5ec27737458d9fe1a75c0db7593352fd","modified":1518019350039},{"_id":"themes/next/source/css/main.styl","hash":"a91dbb7ef799f0a171b5e726c801139efe545176","modified":1518019350071},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1518019350072},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1518019350072},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1518019350072},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1518019350072},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1518019350073},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1518019350073},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1518019350074},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1518019350074},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1518019350074},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1518019350074},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1518019350075},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1518019350075},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1518019350075},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1518019350075},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1518019350076},{"_id":"themes/next/source/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1518019350076},{"_id":"themes/next/source/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1518019350076},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1518019350076},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1518019350022},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1518019350022},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1518019350061},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1518019350061},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1518019350062},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1518019350070},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1518019350071},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"a223919d2e1bf17ca4d6abb2c86f2efca9883dc1","modified":1518019350017},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"f5e487b0d213ca0bd94aa30bc23b240d65081627","modified":1518019350017},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"b2f0d247b213e4cf8de47af6a304d98070cc7256","modified":1518019350018},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"a8c7f9ca7c605d039a1f3bf4e4d3183700a3dd62","modified":1518019350018},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"b25002a83cbd2ca0c4a5df87ad5bff26477c0457","modified":1518019350019},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"9e3d133ac5bcc6cb51702c83b2611a49811abad1","modified":1518019350019},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"d9e2d9282f9be6e04eae105964abb81e512bffed","modified":1518019350019},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"d4fbffd7fa8f2090eb32a871872665d90a885fac","modified":1518019350020},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"0a9cdd6958395fcdffc80ab60f0c6301b63664a5","modified":1518019350020},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"9b84ab576982b2c3bb0291da49143bc77fba3cc6","modified":1518019350021},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1518019350021},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1518019350022},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"ff947f3561b229bc528cb1837d4ca19612219411","modified":1518019350023},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"71397a5823e8ec8aad3b68aace13150623b3e19d","modified":1518019350023},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"753d262911c27baf663fcaf199267133528656af","modified":1518019350023},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"7b11eac3a0685fa1ab2ab6ecff60afc4f15f0d16","modified":1518019350023},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"a10b7f19d7b5725527514622899df413a34a89db","modified":1518019350024},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"7d94845f96197d9d84a405fa5d4ede75fb81b225","modified":1518019350024},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"ccc443b22bd4f8c7ac4145664686c756395b90e0","modified":1518019350024},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b1e13df83fb2b1d5d513b30b7aa6158b0837daab","modified":1518019350025},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"45f3f629c2aacc381095750e1c8649041a71a84b","modified":1518019350025},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"e6d10ee4fb70b3ae1cd37e9e36e000306734aa2e","modified":1518019350025},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"8a399df90dadba5ad4e781445b58f4765aeb701e","modified":1518019350025},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"5a8027328f060f965b3014060bebec1d7cf149c1","modified":1518019350026},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"f9a1647a8f1866deeb94052d1f87a5df99cb1e70","modified":1518019350026},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"4c501ea0b9c494181eb3c607c5526a5754e7fbd8","modified":1518019350026},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b83a51bbe0f1e2ded9819070840b0ea145f003a6","modified":1518019350028},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"1600f340e0225361580c44890568dc07dbcf2c89","modified":1518019350028},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"4dcc3213c033994d342d02b800b6229295433d30","modified":1518019350028},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"af7f3e43cbdc4f88c13f101f0f341af96ace3383","modified":1518019350028},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"493bd5999a1061b981922be92d8277a0f9152447","modified":1518019350028},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"9246162d4bc7e949ce1d12d135cbbaf5dc3024ec","modified":1518019350029},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"4050553d44ba1396174161c9a6bb0f89fa779eca","modified":1518019350029},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"7e65ff8fe586cd655b0e9d1ad2912663ff9bd36c","modified":1518019350029},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"34599633658f3b0ffb487728b7766e1c7b551f5a","modified":1518019350032},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"93479642fd076a1257fecc25fcf5d20ccdefe509","modified":1518019350033},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"fe95dd3d166634c466e19aa756e65ad6e8254d3e","modified":1518019350033},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"d8c98938719284fa06492c114d99a1904652a555","modified":1518019350033},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"3403fdd8efde1a0afd11ae8a5a97673f5903087f","modified":1518019350060},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"07f7da320689f828f6e36a6123807964a45157a0","modified":1518019350061},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"7896c3ee107e1a8b9108b6019f1c070600a1e8cc","modified":1518019350061},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"0e55cbd93852dc3f8ccb44df74d35d9918f847e0","modified":1518019350062},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"58e7dd5947817d9fc30770712fc39b2f52230d1e","modified":1518019350069},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"a25408534f8fe6e321db4bbf9dd03335d648fe17","modified":1518019350070},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"4069f918ccc312da86db6c51205fc6c6eaabb116","modified":1518019350070},{"_id":"themes/next/source/css/_variables/base.styl","hash":"b1f6ea881a4938a54603d68282b0f8efb4d7915d","modified":1518019350070},{"_id":"themes/next/source/js/src/affix.js","hash":"1b509c3b5b290a6f4607f0f06461a0c33acb69b1","modified":1518019350077},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"cb431b54ba9c692165a1f5a12e4c564a560f8058","modified":1518019350077},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"0289031200c3d4c2bdd801ee10fff13bb2c353e4","modified":1518019350078},{"_id":"themes/next/source/js/src/exturl.js","hash":"a2a0f0de07e46211f74942a468f42ee270aa555c","modified":1518019350078},{"_id":"themes/next/source/js/src/fireworks.js","hash":"bcd61cb05450882e0933e6b91415378f1caeef9b","modified":1518019350078},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"b35a7dc47b634197b93487cea8671a40a9fdffce","modified":1518019350078},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"1512c751d219577d338ac0780fb2bbd9075d5298","modified":1518019350079},{"_id":"themes/next/source/js/src/motion.js","hash":"885176ed51d468f662fbf0fc09611f45c7e5a3b1","modified":1518019350079},{"_id":"themes/next/source/js/src/post-details.js","hash":"93a18271b4123dd8f94f09d1439b47c3c19a8712","modified":1518019350080},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"b7657be25fc52ec67c75ab5481bdcb483573338b","modified":1518019350081},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"02cf91514e41200bc9df5d8bdbeb58575ec06074","modified":1518019350080},{"_id":"themes/next/source/js/src/utils.js","hash":"b3e9eca64aba59403334f3fa821f100d98d40337","modified":1518019350081},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1518019350086},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1518019350089},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"b02737510e9b89aeed6b54f89f602a9c24b06ff2","modified":1518019350090},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"bf3eef9d647cd7c9b62feda3bc708c6cdd7c0877","modified":1518019350096},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1518019350096},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"68a9b9d53126405b0fa5f3324f1fb96dbcc547aa","modified":1518019350096},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"a9b3ee1e4db71a0e4ea6d5bed292d176dd68b261","modified":1518019350096},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"b4aefc910578d76b267e86dfffdd5121c8db9aec","modified":1518019350098},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"03ddbf76c1dd1afb93eed0b670d2eee747472ef1","modified":1518019350098},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1518019350099},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"c31ff06a740955e44edd4403902e653ccabfd4db","modified":1518019350098},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"71e7183634dc1b9449f590f15ebd7201add22ca7","modified":1518019350099},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"865d6c1328ab209a4376b9d2b7a7824369565f28","modified":1518019350108},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"90fa628f156d8045357ff11eaf32e61abacf10e8","modified":1518019350109},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4ded6fee668544778e97e38c2b211fc56c848e77","modified":1518019350110},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"b930297cb98b8e1dbd5abe9bc1ed9d5935d18ce8","modified":1518019350110},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"e0acf1db27b0cc16128a59c46db1db406b5c4c58","modified":1518019350110},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"f4a570908f6c89c6edfb1c74959e733eaadea4f2","modified":1518019350110},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"bf773ad48a0b9aa77681a89d7569eefc0f7b7b18","modified":1518019350111},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"14264a210bf94232d58d7599ea2ba93bfa4fb458","modified":1518019350112},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"e33aa8fa48b6639d8d8b937d13261597dd473b3a","modified":1518019350112},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"2ce5f3bf15c523b9bfc97720d8884bb22602a454","modified":1518019350112},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1518019350113},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1518019350113},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1518019350113},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1518019350114},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1518019350114},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1518019350115},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1518019350115},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1518019350115},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1518019350116},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1518019350116},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1518019350116},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1518019350116},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1518019350117},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"8aaa675f577d5501f5f22d5ccb07c2b76310b690","modified":1518019350117},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"2d9a9f38c493fdf7c0b833bb9184b6a1645c11b2","modified":1518019350117},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"46a50b91c98b639c9a2b9265c5a1e66a5c656881","modified":1518019350118},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"8148492dd49aa876d32bb7d5b728d3f5bf6f5074","modified":1518019350118},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"63da5e80ebb61bb66a2794d5936315ca44231f0c","modified":1518019350123},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"92d92860418c4216aa59eb4cb4a556290a7ad9c3","modified":1518019350123},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1518019350125},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"dbbfb50f6502f6b81dcc9fee7b31f1e812da3464","modified":1518019350126},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1518019350126},{"_id":"themes/next/source/lib/jquery/index.js","hash":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1518019350109},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"218cc936ba3518a3591b2c9eda46bc701edf7710","modified":1518019350032},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"2530de0f3125a912756f6c0e9090cd012134a4c5","modified":1518019350032},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"8f86f694c0749a18ab3ad6f6df75466ca137a4bc","modified":1518019350040},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"237d185ac62ec9877e300947fa0109c44fb8db19","modified":1518019350040},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"8b32928686c327151e13d3ab100157f9a03cd59f","modified":1518019350041},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"7ad4081466b397e2a6204141bb7768b7c01bd93c","modified":1518019350041},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"ff4489cd582f518bba6909a301ac1292a38b4e96","modified":1518019350041},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"4f2801fc4cf3f31bf2069f41db8c6ce0e3da9e39","modified":1518019350046},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"6eb4bcc3056bd279d000607e8b4dad50d368ca69","modified":1518019350052},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"12662536c7a07fff548abe94171f34b768dd610f","modified":1518019350058},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"24ee4b356ff55fc6e58f26a929fa07750002cf29","modified":1518019350059},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"1da5c800d025345f212a3bf1be035060f4e5e6ed","modified":1518019350059},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"91ca75492cd51f2553f4d294ed2f48239fcd55eb","modified":1518019350059},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"3f40e8a9fe8e7bd5cfc4cf4cbbbcb9539462e973","modified":1518019350060},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a17e2b871a335f290afb392a08f94fd35f59c715","modified":1518019350060},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"ea9069645696f86c5df64208490876fe150c8cae","modified":1518019350060},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"60fa84aa7731760f05f52dd7d8f79b5f74ac478d","modified":1518019350063},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"25d5e45a355ee2093f3b8b8eeac125ebf3905026","modified":1518019350063},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"d0bfd1bef988c76f7d7dd72d88af6f0908a8b0db","modified":1518019350063},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"b1025c421406d2c24cc92a02ae28c1915b01e240","modified":1518019350064},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"26666c1f472bf5f3fb9bc62081cca22b4de15ccb","modified":1518019350064},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"9c99034f8e00d47e978b3959f51eb4a9ded0fcc8","modified":1518019350064},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9b913b73d31d21f057f97115ffab93cfa578b884","modified":1518019350065},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1518019350064},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"31127dcbf4c7b4ada53ffbf1638b5fe325b7cbc0","modified":1518019350066},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"748dbfbf9c08e719ddc775958003c64b00d39dab","modified":1518019350066},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"e695e58f714129ca292c2e54cd62c251aca7f7fe","modified":1518019350066},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1518019350067},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"5dbc0d0c897e46760e5dbee416530d485c747bba","modified":1518019350067},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"bce344d3a665b4c55230d2a91eac2ad16d6f32fd","modified":1518019350068},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"a5c3858f20a06fd9efd71332a1353a46ed5398af","modified":1518019350068},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"4642e30010af8b2b037f5b43146b10a934941958","modified":1518019350068},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"1f6e2ce674735269599acc6d77b3ea18d31967fc","modified":1518019350068},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"003a3b091946e3d182f3b53d7b4249f6b30d7837","modified":1518019350069},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"86197902dfd3bededba10ba62b8f9f22e0420bde","modified":1518019350069},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"f1d0b5d7af32c423eaa8bb93ab6a0b45655645dc","modified":1518019350080},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"6c26cdb36687d4f0a11dabf5290a909c3506be5c","modified":1518019350084},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"6d586bfcfb7ae48f1b12f76eec82d3ad31947501","modified":1518019350085},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"16b03db23a52623348f37c04544f2792032c1fb6","modified":1518019350085},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1518019350090},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1518019350090},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1518019350091},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1518019350091},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1518019350091},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1518019350092},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1518019350094},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1518019350095},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1518019350095},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"1d6aeda0480d0e4cb6198edf7719d601d4ae2ccc","modified":1518019350097},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1518019350097},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"3655f1fdf1e584c4d8e8d39026093ca306a5a341","modified":1518019350100},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1518019350100},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1518019350100},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"41ea797c68dbcff2f6fb3aba1d1043a22e7cc0f6","modified":1518019350122},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"a817b6c158cbc5bab3582713de9fe18a18a80552","modified":1518019350122},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"4ac683b2bc8531c84d98f51b86957be0e6f830f3","modified":1518019350085},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1518019350107},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1518019350108},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"4237c6e9d59da349639de20e559e87c2c0218cfd","modified":1518019350125},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"9f73c4696f0907aa451a855444f88fc0698fa472","modified":1518019350042},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"53cde051e0337f4bf42fb8d6d7a79fa3fa6d4ef2","modified":1518019350042},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d63e0cacc53dd375fcc113465a4328c59ff5f2c1","modified":1518019350042},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"1a0d059799a298fe17c49a44298d32cebde93785","modified":1518019350042},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"0656e753f182c9f47fef7304c847b7587a85ef0d","modified":1518019350043},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"1727702eac5d326b5c81a667944a245016668231","modified":1518019350043},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"167986d0f649516671ddf7193eebba7b421cd115","modified":1518019350043},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"50450d9fdc8a2b2be8cfca51e3e1a01ffd636c0b","modified":1518019350044},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"7fe4d4d656e86276c17cb4e48a560cb6a4def703","modified":1518019350044},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"b6f3a06a94a6ee5470c956663164d58eda818a64","modified":1518019350044},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"7fb593f90d74a99c21840679933b9ef6fdc16a61","modified":1518019350045},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"f9760ecf186954cee3ba4a149be334e9ba296b89","modified":1518019350045},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"4e3838d7ac81d9ad133960f0f7ed58a44a015285","modified":1518019350045},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"8cf318644acc8b4978537c263290363e21c7f5af","modified":1518019350045},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"6543b27fdbde7dacaef2bb50f06b5754728de7e8","modified":1518019350046},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"875cbe88d5c7f6248990e2beb97c9828920e7e24","modified":1518019350046},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"caf263d1928496688c0e1419801eafd7e6919ce5","modified":1518019350046},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"a6c6eb8adba0a090ad1f4b9124e866887f20d10d","modified":1518019350047},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"a200c0a1c5a895ac9dc41e0641a5dfcd766be99b","modified":1518019350047},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"cd9e214e502697f2f2db84eb721bac57a49b0fce","modified":1518019350047},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"d0d7a5c90d62b685520d2b47fea8ba6019ff5402","modified":1518019350048},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"27deb3d3a243d30022055dac7dad851024099a8b","modified":1518019350048},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ca88ea6999a61fb905eb6e72eba5f92d4ee31e6e","modified":1518019350048},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"b2495ae5e04dcca610aacadc47881d9e716cd440","modified":1518019350048},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5a982d8ef3b3623ea5f59e63728990f5623c1b57","modified":1518019350049},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"ccb34c52be8adba5996c6b94f9e723bd07d34c16","modified":1518019350049},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"01567edaea6978628aa5521a122a85434c418bfd","modified":1518019350049},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"7968343e41f8b94b318c36289dff1196c3eb1791","modified":1518019350049},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"6943cd2e2bad1914c4212cd98ea49bbf7898d9e7","modified":1518019350049},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"39f04c4c7237a4e10acd3002331992b79945d241","modified":1518019350050},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"761eba9811b050b25d548cc0854de4824b41eb08","modified":1518019350050},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"8dd9a1c6f4f6baa00c2cf01837e7617120cf9660","modified":1518019350050},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"11c22f0fb3f6beb13e5a425ec064a4ff974c13b7","modified":1518019350051},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"61f8cea3c01acd600e90e1bc2a07def405503748","modified":1518019350051},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"1153bb71edf253765145559674390e16dd67c633","modified":1518019350051},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"c8fe49a4bc014c24dead05b782a7082411a4abc5","modified":1518019350052},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a1521d48bb06d8d703753f52a198baa197af7da2","modified":1518019350052},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"5ef6343835f484a2c0770bd1eb9cc443609e4c39","modified":1518019350052},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"e71652d3216e289c8548b1ea2357822c1476a425","modified":1518019350052},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"2fe76476432b31993338cb45cdb3b29a518b6379","modified":1518019350053},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"a3bdd71237afc112b2aa255f278cab6baeb25351","modified":1518019350053},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"f825da191816eef69ea8efb498a7f756d5ebb498","modified":1518019350053},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"2ad1a2a9bbf6742d1b0762c4c623b68113d1e0fe","modified":1518019350054},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"2ab1322fe52ab5aafd49e68f5bd890e8380ee927","modified":1518019350054},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"b7076e58d647265ee0ad2b461fe8ce72c9373bc5","modified":1518019350054},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"9a409b798decdefdaf7a23f0b11004a8c27e82f3","modified":1518019350055},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"154a87a32d2fead480d5e909c37f6c476671c5e6","modified":1518019350055},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"b80604868e4f5cf20fccafd7ee415c20c804f700","modified":1518019350055},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"bba4f3bdb7517cd85376df3e1209b570c0548c69","modified":1518019350055},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"5dbeed535d63a50265d96b396a5440f9bb31e4ba","modified":1518019350056},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"a6e7d698702c2e383dde3fde2abde27951679084","modified":1518019350056},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"717cc7f82be9cc151e23a7678601ff2fd3a7fa1d","modified":1518019350056},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"874278147115601d2abf15987f5f7a84ada1ac6b","modified":1518019350056},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"10599e16414a8b7a76c4e79e6617b5fe3d4d1adf","modified":1518019350057},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"15975ba7456b96916b1dbac448a1a0d2c38b8f3d","modified":1518019350057},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"16087276945fa038f199692e3eabb1c52b8ea633","modified":1518019350057},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"28825ae15fa20ae3942cdaa7bcc1f3523ce59acc","modified":1518019350058},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9c8196394a89dfa40b87bf0019e80144365a9c93","modified":1518019350058},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"a07aa12cc36ac5c819670c2a3c17d07ed7a08986","modified":1518019350065},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1518019350066},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1518019350067},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1518019350082},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1518019350082},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1518019350083},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1518019350083},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1518019350083},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1518019350092},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1518019350092},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1518019350093},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1518019350093},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1518019350093},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1518019350094},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1518019350101},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1518019350103},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1518019350106},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"90a1b22129efc172e2dfcceeeb76bff58bc3192f","modified":1518019350089},{"_id":"themes/next/source/lib/three/three.min.js","hash":"26273b1cb4914850a89529b48091dc584f2c57b8","modified":1518019350121},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1518019350104},{"_id":"public/categories/index.html","hash":"712e360ee16a3d16236bdc6998f80ecd2e9e4982","modified":1523174871042},{"_id":"public/tags/index.html","hash":"c5470e3c09d9bdd967ff0bd6026a8846fc7411dc","modified":1523174871035},{"_id":"public/archives/page/3/index.html","hash":"2ce01e9e1141676322797166edd9a8e4bb6c7eac","modified":1523174871092},{"_id":"public/archives/2018/page/3/index.html","hash":"34bda1a2529d563f833b974e0c490a67a274287a","modified":1523174871093},{"_id":"public/categories/bugs/index.html","hash":"5e3e4d3aeb801e9ef6a2efbcd033151a13027bd3","modified":1523174871090},{"_id":"public/categories/Hadoop/page/2/index.html","hash":"9e78d1fe712c2635b6aa4a948f95c1b1794c6f3e","modified":1523174871090},{"_id":"public/categories/Markdown/index.html","hash":"ae2e3e9ee8ec4922c9d9ee2026f814234069928a","modified":1523174871090},{"_id":"public/categories/skill/index.html","hash":"32f0e8366090de27a750172130e7f35b32962fd1","modified":1523174871091},{"_id":"public/categories/link/index.html","hash":"d217ba103082f0cc3a65e470533800cd903f860d","modified":1523174871091},{"_id":"public/tags/free/index.html","hash":"a985514e44ea123030316ffa9ceea10d8e94e63b","modified":1523174871090},{"_id":"public/about/index.html","hash":"9633b197d2a806d61711fdfbb5e8c379802aa9b2","modified":1523174871043},{"_id":"public/neggings/index.html","hash":"be3527434da63b038e269b9f3078885939c5d03d","modified":1523174871043},{"_id":"public/2018/03/29/Hadoop-十一-（kafka）/index.html","hash":"292fe309e856080fc80404d421ac2e9524b1a34c","modified":1523174871043},{"_id":"public/2018/03/29/Hadoop-十-Storm/index.html","hash":"05e61f2f68bd21c93c1e37a4adc76ab1dfbeb683","modified":1523174871043},{"_id":"public/2018/03/28/Hadoop-九-（HBase）/index.html","hash":"987bd187b018d34efdcb60199daa879ff4595288","modified":1523174871043},{"_id":"public/2018/03/28/Hadoop-八-（hive）/index.html","hash":"b5aa23397665b343ac482cfb0100230ecd219d04","modified":1523174871043},{"_id":"public/2018/03/27/Hadoop-七-（HA高可用架构配置）/index.html","hash":"1103faf0bf1df15a158003ec761fccac44b9d82e","modified":1523174871043},{"_id":"public/2018/03/27/Diary-4/index.html","hash":"568fbf7013eaa12e50aa9b67551b5a64ff3d34ff","modified":1523174871044},{"_id":"public/2018/03/26/两台电脑的测试/index.html","hash":"424f92d9e468e23607447b55dd8017fe24ed1396","modified":1523174871044},{"_id":"public/2018/03/26/hello-world/index.html","hash":"20a80418ce57528c7a1463c630fdfcafde7c073d","modified":1523174871044},{"_id":"public/2018/03/22/Hadoop-六-（yarn框架）/index.html","hash":"186bac8984a88cc59c7f6c127c009e039be65acd","modified":1523174871044},{"_id":"public/2018/03/13/Diary-3/index.html","hash":"c7fdfa720cbb937c86fdcc38ee2e3e378a838f7d","modified":1523174871044},{"_id":"public/2018/03/02/Hadoop-五-（mapreduce）/index.html","hash":"e7031c7995c31df8a2af8e7696e4382f69e0435f","modified":1523174871044},{"_id":"public/2018/03/01/SS搭建/index.html","hash":"d72735178e6ce8b65ba9114e4c67c82fce2ba154","modified":1523174871044},{"_id":"public/2018/03/01/Diary-2/index.html","hash":"39b09bdf2358d420f33756b83958e5e3af4cd23e","modified":1523174871091},{"_id":"public/2018/03/01/Bugs/index.html","hash":"aa6d9187a56d686cd52f558436408b6200d2c032","modified":1523174871091},{"_id":"public/2018/03/01/Hadoop-四-（java客户端操作HDFS）/index.html","hash":"eb3521f9a898929b95e820792c2f9d06b314ce7a","modified":1523174871044},{"_id":"public/2018/02/07/Hadoop-三/index.html","hash":"301e9e29257313ce7b9b5549196c7bdf9895d49e","modified":1523174871091},{"_id":"public/2018/02/05/Hadoop-二-（常用基本命令）/index.html","hash":"0aa40b096205a667b4d395c8507023bdda36d06a","modified":1523174871092},{"_id":"public/2018/02/05/First-Diary/index.html","hash":"380338886614c3b159c756468cc669586dec0f5a","modified":1523174871092},{"_id":"public/2018/02/05/常用的基本操作链接/index.html","hash":"e944b675261a972ce0b5d1eca56e523f09937852","modified":1523174871092},{"_id":"public/2018/02/03/Hadoop-一/index.html","hash":"1c1b63f9d486cebe2ff88e16e060c65d47c753c8","modified":1523174871091},{"_id":"public/2018/02/03/Markdown-入门操作/index.html","hash":"0aa78c380e9507deeee45995bc19ba8529748c2d","modified":1523174871092},{"_id":"public/index.html","hash":"6bdf89c23521174abfc2d3deefc4aafa0efb703f","modified":1523174871093},{"_id":"public/page/2/index.html","hash":"461762efdc5baa3804eff46296e2cc1686a6a363","modified":1523174871093},{"_id":"public/page/3/index.html","hash":"d71f991b9e5cba711c2baf71906c47f270006564","modified":1523174871093},{"_id":"public/archives/index.html","hash":"3e30182c57e7507311d161aa48cabc9ce95a4835","modified":1523174871092},{"_id":"public/archives/page/2/index.html","hash":"973f305b84b688dc55e45685a907b12538466beb","modified":1523174871092},{"_id":"public/archives/2018/index.html","hash":"263c1279beba0de05535bec5b5dd000305833e65","modified":1523174871092},{"_id":"public/archives/2018/page/2/index.html","hash":"bed6f5d19cab55fdc7cf3576e2b62bc5f61e5cb9","modified":1523174871092},{"_id":"public/archives/2018/02/index.html","hash":"336059fca075a6b616706714763faf56abe9b474","modified":1523174871092},{"_id":"public/archives/2018/03/index.html","hash":"ff927d12056a420b75dd3c9ff7ae84e073796dfd","modified":1523174871092},{"_id":"public/archives/2018/03/page/2/index.html","hash":"78972f4719b1dcff04de633122184b84f7bc029c","modified":1523174871092},{"_id":"public/categories/diary/index.html","hash":"a9b8ae036eea42f55b0f7b842fd1e9b8458330e2","modified":1523174871093},{"_id":"public/categories/Hadoop/index.html","hash":"e40b111c3f8c7010e9c974acbc024ccdf735b91d","modified":1523174871093},{"_id":"public/tags/study/index.html","hash":"c9927144ed14d520c3baed4a3f67bbe549f91994","modified":1523174871093},{"_id":"public/tags/study/page/2/index.html","hash":"b890587c92087cbd9fc3c3920656b8517f8ea774","modified":1523174871093},{"_id":"public/tags/live/index.html","hash":"ecc7f599d7a6d3d6e4047cea8d584775923f13d9","modified":1523174871093},{"_id":"public/images/pasted-1.png","hash":"aca3453b2e27b67a019382d5dcf3b5099be4014a","modified":1522316885844},{"_id":"public/images/pasted-2.png","hash":"2bb4146c9d01e7d02d1ed696dea2faf249e8abac","modified":1522316885844},{"_id":"public/images/pasted-3.png","hash":"3cf04aa3cc016109d8a3c3db312759ea5cb36171","modified":1522316885844},{"_id":"public/uploads/avtar.jpg","hash":"2d003ee446fb0c79a8783e1f30e3fc9b63874980","modified":1522316885844},{"_id":"public/images/pasted-4.png","hash":"6fb19a7369242b763affa14b3a870fc4f9367349","modified":1522316885844},{"_id":"public/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1522316885845},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1522316885845},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1522316885845},{"_id":"public/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1522316885845},{"_id":"public/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1522316885845},{"_id":"public/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1522316885845},{"_id":"public/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1522316885845},{"_id":"public/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1522316885845},{"_id":"public/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1522316885845},{"_id":"public/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1522316885845},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1522316885845},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1522316885845},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1522316885845},{"_id":"public/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1522316885846},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1522316885846},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1522316885846},{"_id":"public/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1522316885846},{"_id":"public/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1522316885846},{"_id":"public/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1522316885846},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1522316885846},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1522316885846},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1522316885846},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1522316885846},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1522316885846},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1522316885846},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1522316885846},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1522316885846},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1522316885846},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1522316885846},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1522316885846},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1522316885846},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1522316885847},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1522316885847},{"_id":"public/live2d/device.min.js","hash":"ad8ffa5cc29d478f718c73eef31052dd4cdae7b6","modified":1522316885847},{"_id":"public/live2d/assets/exp/f02.exp.json","hash":"241b6afafa2e25c6d7a54692a8b5aa060a137ab1","modified":1522316885847},{"_id":"public/live2d/assets/exp/f01.exp.json","hash":"84073a497ddb6e56c6cfc244a0fb217ba473abf9","modified":1522316885847},{"_id":"public/live2d/assets/exp/f04.exp.json","hash":"35e746ede62e7090e7dfb08561d77772f58b4153","modified":1522316885847},{"_id":"public/live2d/assets/exp/f03.exp.json","hash":"fbf7729e504f14f83f976827fcf62301a6579a34","modified":1522316885847},{"_id":"public/live2d/assets/mtn/flickHead_00.mtn","hash":"f64c79c9171660db5c440bef229ac2e35a1597d5","modified":1522316885847},{"_id":"public/live2d/assets/mtn/flickHead_01.mtn","hash":"a1011d6bf397bcd3c3c968d9616f88fe1ffbc83c","modified":1522316885847},{"_id":"public/live2d/assets/mtn/flickHead_02.mtn","hash":"d3c9c0acb4dc25a2274f3b9faa71e5ce60ad92e4","modified":1522316885847},{"_id":"public/live2d/assets/mtn/idle_00.mtn","hash":"378b4577217c604c9d28ab4edf8b707c8d8c2fbb","modified":1522316885847},{"_id":"public/live2d/assets/mtn/idle_01.mtn","hash":"88c2494655dbb712b842f03232b619f381753d52","modified":1522316885847},{"_id":"public/live2d/assets/mtn/idle_02.mtn","hash":"7f5d2cf8706007c8659938eba132a68c470a4c26","modified":1522316885847},{"_id":"public/live2d/assets/mtn/pinchIn_00.mtn","hash":"70978b4c983f6a9fd6d3d9c24571586f7d6eac30","modified":1522316885847},{"_id":"public/live2d/assets/mtn/pinchIn_01.mtn","hash":"a5fefb45115695db72b9499e627a51b2b9394f2c","modified":1522316885847},{"_id":"public/live2d/assets/mtn/pinchIn_02.mtn","hash":"aa0d66ca9b06c374577fd7e64e89756de1e1f2ae","modified":1522316885847},{"_id":"public/live2d/assets/mtn/pinchOut_00.mtn","hash":"e07fe8fd8c2810e3c1d28b730bd49c8c25849bad","modified":1522316885847},{"_id":"public/live2d/assets/mtn/pinchOut_01.mtn","hash":"e05df948d08b17f34c993a9c1f901190509d5db0","modified":1522316885847},{"_id":"public/live2d/assets/mtn/shake_00.mtn","hash":"5185d02c7ab9f0bec3d4a890b54b2378e553373d","modified":1522316885847},{"_id":"public/live2d/assets/mtn/pinchOut_02.mtn","hash":"b323fd350d334b33bbdfb31194ae664089986c27","modified":1522316885847},{"_id":"public/live2d/assets/mtn/shake_01.mtn","hash":"e812985a56796e122018f9d57d1606a4866ff7d1","modified":1522316885848},{"_id":"public/live2d/assets/mtn/shake_02.mtn","hash":"2702970805e07777974c383613e631730982bcff","modified":1522316885848},{"_id":"public/live2d/assets/mtn/tapBody_00.mtn","hash":"835aa3d4a8fbd26c0bb66b164a19464fa3f17a99","modified":1522316885848},{"_id":"public/live2d/assets/mtn/tapBody_01.mtn","hash":"78fca17436ab5e065e27f419f135aa6c0a0b52ef","modified":1522316885848},{"_id":"public/live2d/assets/mtn/tapBody_02.mtn","hash":"a75acb51c1191ce5050d3ee1af6f2dcc787c7c5e","modified":1522316885848},{"_id":"public/live2d/assets/shizuku.model.json","hash":"19a05bd41b806a935cea42c2000626fc82da2536","modified":1522316885848},{"_id":"public/live2d/assets/shizuku.physics.json","hash":"6484d646e79a44c83784c6ae434cf7349746c5c8","modified":1522316885848},{"_id":"public/live2d/assets/shizuku.pose.json","hash":"ac5505efbf80ba0a2e5783d67fe232bc5c6f1f80","modified":1522316885848},{"_id":"public/live2d/assets/snd/flickHead_00.mp3","hash":"356388d939006b03cf9e6158c603b58d4800bec1","modified":1522316885848},{"_id":"public/live2d/assets/snd/flickHead_01.mp3","hash":"436d0bbccf6e7a2744447554947eee4563608970","modified":1522316885848},{"_id":"public/live2d/assets/snd/flickHead_02.mp3","hash":"5f63477ce63f2073e24d68fea906fe136fe6349e","modified":1522316885848},{"_id":"public/live2d/assets/snd/pinchIn_00.mp3","hash":"f9baa3b7cadec20b714135fc49cfab3ff6adeeb4","modified":1522316885848},{"_id":"public/live2d/assets/snd/pinchIn_01.mp3","hash":"d5c8cc6f61b56222a83a5174f75006f83c3b88da","modified":1522316885848},{"_id":"public/live2d/assets/snd/shake_00.mp3","hash":"f65dd58e7b44ec5c865d13c190316070b625b5fe","modified":1522316885848},{"_id":"public/live2d/assets/snd/shake_02.mp3","hash":"8882b94bce00f09232588b7301badb105fa8acab","modified":1522316885848},{"_id":"public/live2d/assets/snd/shake_01.mp3","hash":"c1e0e8a07ff268ee06c2b7825d1b645e193f21b9","modified":1522316885848},{"_id":"public/live2d/assets/snd/tapBody_00.mp3","hash":"003e68a59a9c8392e230f34c91860efbd946277a","modified":1522316885848},{"_id":"public/live2d/assets/snd/tapBody_02.mp3","hash":"15e7815ed0a0e5164e18e0c53b97aedc742a134d","modified":1522316885848},{"_id":"public/live2d/assets/snd/tapBody_01.mp3","hash":"5314b50f153df71559e51e2586581c006df00722","modified":1522316885849},{"_id":"public/uploads/tl.jpg","hash":"c0fe4d6072ccaefba79fbf1b25cb6b7e6e8650b8","modified":1522316887356},{"_id":"public/uploads/talor.jpg","hash":"7b5474cc390daf8e22e80a4e6fb88d8dce43cdfd","modified":1522316887356},{"_id":"public/images/pasted-0.png","hash":"b7a1a2aaf801ed10baf22d44072317a1004cfb49","modified":1522316887365},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1522316887365},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1522316887365},{"_id":"public/live2d/assets/moc/shizuku.1024/texture_00.png","hash":"21bdb28b31783e23b26b3aa061e90be4088665aa","modified":1522316887365},{"_id":"public/live2d/assets/moc/shizuku.1024/texture_03.png","hash":"07f568a2bb8045b6bdff7783fb4daf62c821f9ab","modified":1522316887365},{"_id":"public/live2d/assets/moc/shizuku.1024/texture_05.png","hash":"0cd00007fb8bff62a2eb08e1d7c43abab8722224","modified":1522316887366},{"_id":"public/live2d/assets/snd/pinchOut_01.mp3","hash":"8a081030fd53c07bffe3edd48f87a371ca77296b","modified":1522316887366},{"_id":"public/live2d/assets/snd/pinchIn_02.mp3","hash":"5b63e02607571ac601c500995e836e6c861b1c62","modified":1522316887366},{"_id":"public/live2d/assets/snd/pinchOut_00.mp3","hash":"0654f38f6e9fd623eaf8be11b5d58c9d12991949","modified":1522316887366},{"_id":"public/live2d/assets/snd/pinchOut_02.mp3","hash":"554edb2f3838cbdc27d1a9c6b8a9cb6eb465cbdd","modified":1522316887366},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1522316887374},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1522316887374},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1522316887374},{"_id":"public/js/src/fireworks.js","hash":"a2bd40814d4078a61410a646ea1a5dce800f6e50","modified":1522316887375},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1522316887375},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1522316887375},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1522316887375},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1522316887375},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1522316887375},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1522316887375},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1522316887375},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1522316887375},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1522316887375},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1522316887375},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1522316887375},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1522316887375},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1522316887375},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1522316887375},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1522316887375},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1522316887375},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1522316887375},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1522316887375},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1522316887376},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1522316887376},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1522316887376},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1522316887376},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1522316887376},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1522316887376},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1522316887376},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1522316887376},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1522316887377},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1522316887377},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1522316887377},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1522316887377},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1522316887377},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1522316887377},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1522316887377},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1522316887377},{"_id":"public/css/main.css","hash":"176a656d1b52053b19a06c42d671e378b567808f","modified":1522316887377},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1522316887377},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1522316887377},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1522316887377},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1522316887377},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1522316887377},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1522316887377},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1522316887378},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1522316887378},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1522316887378},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1522316887378},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1522316887378},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1522316887378},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1522316887378},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1522316887378},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1522316887378},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1522316887379},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1522316887379},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1522316887379},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1522316887379},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1522316887379},{"_id":"public/uploads/sufei.jpg","hash":"102af907a6e179c4c0cd01eaddbfb66e6de3fc54","modified":1522316887379},{"_id":"public/uploads/tl.jpeg","hash":"6d1f0d119084ffd5b27d82d1a276b493d357e917","modified":1522316887379},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1522316887379},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1522316887381},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1522316887381},{"_id":"public/live2d/script.js","hash":"6b85d115e5785ab244c8ffa8073be3930868589a","modified":1522316887381},{"_id":"public/live2d/assets/moc/shizuku.1024/texture_01.png","hash":"3d0e745f3e560071ee08beeecde186e5ea35d99e","modified":1522316887381},{"_id":"public/live2d/assets/moc/shizuku.1024/texture_04.png","hash":"f764d594841905db8b2998dd61c329866125ad97","modified":1522316887381},{"_id":"public/live2d/assets/moc/shizuku.1024/texture_02.png","hash":"055eb2da9c13e9116be93a1e60c0ea2b660af864","modified":1522316887425},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1522316887466},{"_id":"public/live2d/assets/moc/shizuku.moc","hash":"c2670a0f75830edc89d7fe6d074de4ee67e8dc5d","modified":1522316887840},{"_id":"source/literature/index.md","hash":"5441f5d6fd26ed0d68a77cc09acb7e01f34b538c","modified":1522393664458},{"_id":"source/_drafts/飘.md","hash":"ed04ca5f4231d119dede761ed8451d3b41f84d59","modified":1522394753677},{"_id":"source/_posts/飘.md","hash":"1777e413cd16c18aa2e04093421451a4d92c06a2","modified":1522739452783},{"_id":"public/categories/Feel/index.html","hash":"85a822927126de296e47709af06d612818904e80","modified":1523174871091},{"_id":"public/2018/03/30/飘/index.html","hash":"2c9e1b99cc4d53998c871da5f9cfa35065216a5d","modified":1523174871043},{"_id":"source/_drafts/SpringBoot.md","hash":"8f3ad1bcce74148b0727b38dc56faff4e19f1b96","modified":1522822949641},{"_id":"source/images/pasted-5.png","hash":"b28297f20af9f5144629fcf0df123a2fa5685cfd","modified":1522739914694},{"_id":"source/images/pasted-6.png","hash":"a79a9f3f244959f772212e4cb05e905d993db139","modified":1522739949948},{"_id":"source/images/pasted-7.png","hash":"324841b93465696eb18507477233fa81caac967c","modified":1522740051979},{"_id":"source/images/pasted-8.png","hash":"bdf323235d534cb23d64c48c29586ed7d308ed29","modified":1522740075173},{"_id":"source/images/pasted-9.png","hash":"1c46429e10b66bfcdd6f12f177d28f7881196e5d","modified":1522740087275},{"_id":"source/images/pasted-11.png","hash":"2595870d13763cc95f0d0d406722fc1a41b9bb48","modified":1522740224089},{"_id":"source/images/pasted-10.png","hash":"1c46429e10b66bfcdd6f12f177d28f7881196e5d","modified":1522740183575},{"_id":"source/images/pasted-12.png","hash":"48e0865c7ef2f936710542d6921e272735c3579b","modified":1522740243493},{"_id":"source/images/pasted-13.png","hash":"4f46cdace6ab9dd2d26c99c1f4cb485d1450cfdd","modified":1522740343031},{"_id":"source/images/pasted-14.png","hash":"026b1c81face86ecb1c491141d0f9a61cab5e22b","modified":1522742390413},{"_id":"source/images/pasted-15.png","hash":"c114ac75f9ca6bd8e35437e5eae88a27173572b4","modified":1522742516272},{"_id":"source/images/pasted-16.png","hash":"03aed0ca0a20f4f6ff4201ad1cd4e95ad8664d4f","modified":1522744245498},{"_id":"source/images/pasted-18.png","hash":"61fc7ff4fc7c341cb278eb0186f2aed81fc5e135","modified":1522746422656},{"_id":"source/images/pasted-19.png","hash":"184d43233225aa78e0194c73ee01a8b2f1ceedfb","modified":1522746475603},{"_id":"source/images/pasted-17.png","hash":"59eebe47cd81f0e88560c76c8dab3cbaa9a2e527","modified":1522744346193},{"_id":"source/images/pasted-20.png","hash":"cd3164cd16fa3e12c66468359af215de9d17470e","modified":1522746574575},{"_id":"source/images/pasted-21.png","hash":"764359812dfee8a0db1dda086049b13b8bbeed7a","modified":1522746902578},{"_id":"source/images/pasted-22.png","hash":"2ee1120dc390029e81adf9d00cf0e7c00d053bc0","modified":1522810226226},{"_id":"source/images/pasted-23.png","hash":"d4acda1db52214fd16afed50469416b1c31ee15d","modified":1522810265832},{"_id":"source/images/pasted-24.png","hash":"f6112822c1870682d870d0dde234877d7ec06788","modified":1522821827679},{"_id":"source/images/pasted-25.png","hash":"53bd11c52072e3ce3d602cfe7b5fed4672ce8c3d","modified":1522821863473},{"_id":"source/images/pasted-26.png","hash":"02eb974dc37156632800dc7bb3c2dbde948ec79c","modified":1522821883444},{"_id":"public/images/pasted-5.png","hash":"b28297f20af9f5144629fcf0df123a2fa5685cfd","modified":1522822976671},{"_id":"public/images/pasted-6.png","hash":"a79a9f3f244959f772212e4cb05e905d993db139","modified":1522822976671},{"_id":"public/images/pasted-7.png","hash":"324841b93465696eb18507477233fa81caac967c","modified":1522822976671},{"_id":"public/images/pasted-8.png","hash":"bdf323235d534cb23d64c48c29586ed7d308ed29","modified":1522822976671},{"_id":"public/images/pasted-9.png","hash":"1c46429e10b66bfcdd6f12f177d28f7881196e5d","modified":1522822976671},{"_id":"public/images/pasted-11.png","hash":"2595870d13763cc95f0d0d406722fc1a41b9bb48","modified":1522822976671},{"_id":"public/images/pasted-10.png","hash":"1c46429e10b66bfcdd6f12f177d28f7881196e5d","modified":1522822976671},{"_id":"public/images/pasted-13.png","hash":"4f46cdace6ab9dd2d26c99c1f4cb485d1450cfdd","modified":1522822976671},{"_id":"public/images/pasted-12.png","hash":"48e0865c7ef2f936710542d6921e272735c3579b","modified":1522822976671},{"_id":"public/images/pasted-18.png","hash":"61fc7ff4fc7c341cb278eb0186f2aed81fc5e135","modified":1522822976671},{"_id":"public/images/pasted-15.png","hash":"c114ac75f9ca6bd8e35437e5eae88a27173572b4","modified":1522822976671},{"_id":"public/images/pasted-14.png","hash":"026b1c81face86ecb1c491141d0f9a61cab5e22b","modified":1522822976671},{"_id":"public/images/pasted-19.png","hash":"184d43233225aa78e0194c73ee01a8b2f1ceedfb","modified":1522822976671},{"_id":"public/images/pasted-16.png","hash":"03aed0ca0a20f4f6ff4201ad1cd4e95ad8664d4f","modified":1522822976671},{"_id":"public/images/pasted-22.png","hash":"2ee1120dc390029e81adf9d00cf0e7c00d053bc0","modified":1522822976671},{"_id":"public/images/pasted-23.png","hash":"d4acda1db52214fd16afed50469416b1c31ee15d","modified":1522822976672},{"_id":"public/images/pasted-24.png","hash":"f6112822c1870682d870d0dde234877d7ec06788","modified":1522822976672},{"_id":"public/images/pasted-26.png","hash":"02eb974dc37156632800dc7bb3c2dbde948ec79c","modified":1522822976672},{"_id":"public/images/pasted-25.png","hash":"53bd11c52072e3ce3d602cfe7b5fed4672ce8c3d","modified":1522822976672},{"_id":"public/images/pasted-21.png","hash":"764359812dfee8a0db1dda086049b13b8bbeed7a","modified":1522822976674},{"_id":"public/images/pasted-17.png","hash":"59eebe47cd81f0e88560c76c8dab3cbaa9a2e527","modified":1522822976674},{"_id":"public/images/pasted-20.png","hash":"cd3164cd16fa3e12c66468359af215de9d17470e","modified":1522822976674},{"_id":"source/_posts/SpringBoot.md","hash":"05bd6c27ed69d8cadd97ffe4c32550d4ae596164","modified":1522823280538},{"_id":"public/archives/2018/04/index.html","hash":"e8cc76d07b6957cdbe49335c4f76a59d82fe3019","modified":1523174871090},{"_id":"public/categories/Spring-Boot/index.html","hash":"d637291803c11f61a2a838b81b6aef4063d5b1ed","modified":1523174871091},{"_id":"public/2018/04/03/SpringBoot/index.html","hash":"80247cc824bb8e9e682caa527e5904637cea4662","modified":1523174871043},{"_id":"source/_drafts/Optimize.md","hash":"7542aeb77498e4bb15a79659be4e91d38176a297","modified":1523174553117},{"_id":"source/_posts/Optimize.md","hash":"4bdca4c27733840410b897aa502c66a56d22e8e9","modified":1523174741387},{"_id":"public/2018/04/08/Optimize/index.html","hash":"72e12400a4ee740885b9cd78d7d575ef8ebb2126","modified":1523174871091},{"_id":"public/categories/optimize/index.html","hash":"5c7edfad996069017d62f3d7c63902fc42fa1333","modified":1523174871101}],"Category":[{"name":"bugs","_id":"cjfcc60kg0004xo7k7qr3tvdl"},{"name":"diary","_id":"cjfcc60km000axo7ksyo3a2yb"},{"name":"Hadoop","_id":"cjfcc60kz000vxo7klrkhqc6d"},{"name":"Markdown","_id":"cjfcc60le001zxo7ka60h5y8h"},{"name":"skill","_id":"cjfcc60lf0024xo7kdal7or82"},{"name":"link","_id":"cjfcc60lg0026xo7knd991mj1"},{"name":"Feel","_id":"cjfdmks4k0002j87k5hzriccb"},{"name":"Spring Boot","_id":"cjfkpo1cq0000pc7k96qj1hik"},{"name":"optimize","_id":"cjfqiwwb30001qo7kzvawyyli"}],"Data":[],"Page":[{"title":"about","date":"2018-02-03T08:29:37.000Z","_content":"#### <center>关于</center>\n\n\n##### 介绍：\n\n小小冰弟：本人主要从事java开发，此博客就是为了记记笔记，顺便写点随感。希望能坚持下去吧！加油！嘻嘻！哈哈！\n\n###### 女神镇楼\n![](http://tv06.tgbusdata.cn/v3/thumb/jpg/Zjc1MiwxMTYsODYsOCwzLDEsLTEsMCxyazUw/u/pc.tgbus.com/uploads/allimg/130618/265-13061Q41Z3-50.jpg \"爱教主，哈哈！\")","source":"about/index.md","raw":"title: about\ndate: 2018-02-03 16:29:37\n---\n#### <center>关于</center>\n\n\n##### 介绍：\n\n小小冰弟：本人主要从事java开发，此博客就是为了记记笔记，顺便写点随感。希望能坚持下去吧！加油！嘻嘻！哈哈！\n\n###### 女神镇楼\n![](http://tv06.tgbusdata.cn/v3/thumb/jpg/Zjc1MiwxMTYsODYsOCwzLDEsLTEsMCxyazUw/u/pc.tgbus.com/uploads/allimg/130618/265-13061Q41Z3-50.jpg \"爱教主，哈哈！\")","updated":"2018-03-26T09:46:34.655Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjfcc60kd0001xo7kbwnbvuh8","content":"<h4 id=\"关于\"><a href=\"#关于\" class=\"headerlink\" title=\"关于\"></a><center>关于</center></h4><h5 id=\"介绍：\"><a href=\"#介绍：\" class=\"headerlink\" title=\"介绍：\"></a>介绍：</h5><p>小小冰弟：本人主要从事java开发，此博客就是为了记记笔记，顺便写点随感。希望能坚持下去吧！加油！嘻嘻！哈哈！</p>\n<h6 id=\"女神镇楼\"><a href=\"#女神镇楼\" class=\"headerlink\" title=\"女神镇楼\"></a>女神镇楼</h6><p><img src=\"http://tv06.tgbusdata.cn/v3/thumb/jpg/Zjc1MiwxMTYsODYsOCwzLDEsLTEsMCxyazUw/u/pc.tgbus.com/uploads/allimg/130618/265-13061Q41Z3-50.jpg\" alt=\"\" title=\"爱教主，哈哈！\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"关于\"><a href=\"#关于\" class=\"headerlink\" title=\"关于\"></a><center>关于</center></h4><h5 id=\"介绍：\"><a href=\"#介绍：\" class=\"headerlink\" title=\"介绍：\"></a>介绍：</h5><p>小小冰弟：本人主要从事java开发，此博客就是为了记记笔记，顺便写点随感。希望能坚持下去吧！加油！嘻嘻！哈哈！</p>\n<h6 id=\"女神镇楼\"><a href=\"#女神镇楼\" class=\"headerlink\" title=\"女神镇楼\"></a>女神镇楼</h6><p><img src=\"http://tv06.tgbusdata.cn/v3/thumb/jpg/Zjc1MiwxMTYsODYsOCwzLDEsLTEsMCxyazUw/u/pc.tgbus.com/uploads/allimg/130618/265-13061Q41Z3-50.jpg\" alt=\"\" title=\"爱教主，哈哈！\"></p>\n"},{"title":"My neggings","password":"hadoop","date":"2018-02-05T04:04:14.000Z","_content":"##### 不念过往，或许只是给过去一个了结吧。        \n--2018.2.5 12：05\n\n\n##### 莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\n--2018.2.6 15：56\n\n\n##### 墨家十杰，一枝独秀。\n--2018.2.27 10：05\n\n##### 想成为一个厉害的人！\n--2018.2.27 10：06\n\n##### 遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\n--2018.3.2 14：33","source":"neggings/index.md","raw":"title: My neggings\npassword: hadoop\ndate: 2018-02-05 12:04:14\n---\n##### 不念过往，或许只是给过去一个了结吧。        \n--2018.2.5 12：05\n\n\n##### 莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\n--2018.2.6 15：56\n\n\n##### 墨家十杰，一枝独秀。\n--2018.2.27 10：05\n\n##### 想成为一个厉害的人！\n--2018.2.27 10：06\n\n##### 遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\n--2018.3.2 14：33","updated":"2018-03-26T09:46:34.658Z","path":"neggings/index.html","comments":1,"layout":"page","_id":"cjfcc60kf0003xo7k0hhdcs8a","content":"<h5 id=\"不念过往，或许只是给过去一个了结吧。\"><a href=\"#不念过往，或许只是给过去一个了结吧。\" class=\"headerlink\" title=\"不念过往，或许只是给过去一个了结吧。\"></a>不念过往，或许只是给过去一个了结吧。</h5><p>–2018.2.5 12：05</p>\n<h5 id=\"莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\"><a href=\"#莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\" class=\"headerlink\" title=\"莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\"></a>莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！</h5><p>–2018.2.6 15：56</p>\n<h5 id=\"墨家十杰，一枝独秀。\"><a href=\"#墨家十杰，一枝独秀。\" class=\"headerlink\" title=\"墨家十杰，一枝独秀。\"></a>墨家十杰，一枝独秀。</h5><p>–2018.2.27 10：05</p>\n<h5 id=\"想成为一个厉害的人！\"><a href=\"#想成为一个厉害的人！\" class=\"headerlink\" title=\"想成为一个厉害的人！\"></a>想成为一个厉害的人！</h5><p>–2018.2.27 10：06</p>\n<h5 id=\"遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\"><a href=\"#遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\" class=\"headerlink\" title=\"遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\"></a>遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。</h5><p>–2018.3.2 14：33</p>\n","site":{"data":{}},"excerpt":"","more":"<h5 id=\"不念过往，或许只是给过去一个了结吧。\"><a href=\"#不念过往，或许只是给过去一个了结吧。\" class=\"headerlink\" title=\"不念过往，或许只是给过去一个了结吧。\"></a>不念过往，或许只是给过去一个了结吧。</h5><p>–2018.2.5 12：05</p>\n<h5 id=\"莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\"><a href=\"#莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\" class=\"headerlink\" title=\"莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！\"></a>莫名又想到了一些事情，我真是个念旧的人哪，但是谁在乎呢？我想一直保持那种愤怒，我想继续恨着，因为我不能原谅自己，还是我不想成为那样的人呢，平凡对于我们而言太简单了，而我过早的渴望平凡了，在还没有经历任何事的时候，所以，待多年之后，希望我能羡慕平凡吧！</h5><p>–2018.2.6 15：56</p>\n<h5 id=\"墨家十杰，一枝独秀。\"><a href=\"#墨家十杰，一枝独秀。\" class=\"headerlink\" title=\"墨家十杰，一枝独秀。\"></a>墨家十杰，一枝独秀。</h5><p>–2018.2.27 10：05</p>\n<h5 id=\"想成为一个厉害的人！\"><a href=\"#想成为一个厉害的人！\" class=\"headerlink\" title=\"想成为一个厉害的人！\"></a>想成为一个厉害的人！</h5><p>–2018.2.27 10：06</p>\n<h5 id=\"遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\"><a href=\"#遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\" class=\"headerlink\" title=\"遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。\"></a>遥想公瑾当年，小乔出嫁了，雄姿英发，羽扇纶巾，谈笑间，樯橹灰飞烟灭，故国神游，多情应笑我，早生华发，一樽还酹江月。</h5><p>–2018.3.2 14：33</p>\n"},{"title":"categories","type":"categories","date":"2018-02-02T07:20:03.000Z","_content":"***\n##分类专属##\n","source":"categories/index.md","raw":"title: categories\ntype : categories\ndate: 2018-02-02 15:20:03\n---\n***\n##分类专属##\n","updated":"2018-03-26T09:46:34.656Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjfcc60ki0007xo7k1cqknucg","content":"<hr>\n<p>##分类专属##</p>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<p>##分类专属##</p>\n"},{"title":"tags","date":"2018-02-02T07:18:05.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-02-02 15:18:05\ntype: \"tags\"\n---\n","updated":"2018-03-26T09:46:34.659Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjfcc60pj0029xo7ktr5pfnv7","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Bugs","author":"小小冰弟","date":"2018-03-01T02:47:20.000Z","_content":"##### 1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\n   Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RpcServerException): Unknown protocol: com.ppj2.rp.LoginServiceInterface\n\n这个就是因为我服务端放在com.ppj2.rpc包下，而客户端放在com.ppj2.rp包下导致的。\n\n##### 2.之前没有卸载干净\n[mysql装不上](https://www.cnblogs.com/qianzf/p/7078436.html) ","source":"_posts/Bugs.md","raw":"title: Bugs\nauthor: 小小冰弟\ntags: study\ncategories: bugs\ndate: 2018-03-01 10:47:20\n---\n##### 1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\n   Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RpcServerException): Unknown protocol: com.ppj2.rp.LoginServiceInterface\n\n这个就是因为我服务端放在com.ppj2.rpc包下，而客户端放在com.ppj2.rp包下导致的。\n\n##### 2.之前没有卸载干净\n[mysql装不上](https://www.cnblogs.com/qianzf/p/7078436.html) ","slug":"Bugs","published":1,"updated":"2018-03-26T09:46:34.644Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60k90000xo7k7wmhu1rc","content":"<h5 id=\"1-RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\"><a href=\"#1-RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\" class=\"headerlink\" title=\"1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\"></a>1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。</h5><p>   Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RpcServerException): Unknown protocol: com.ppj2.rp.LoginServiceInterface</p>\n<p>这个就是因为我服务端放在com.ppj2.rpc包下，而客户端放在com.ppj2.rp包下导致的。</p>\n<h5 id=\"2-之前没有卸载干净\"><a href=\"#2-之前没有卸载干净\" class=\"headerlink\" title=\"2.之前没有卸载干净\"></a>2.之前没有卸载干净</h5><p><a href=\"https://www.cnblogs.com/qianzf/p/7078436.html\" target=\"_blank\" rel=\"noopener\">mysql装不上</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<h5 id=\"1-RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\"><a href=\"#1-RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\" class=\"headerlink\" title=\"1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。\"></a>1.RPC模式下，由于客户端与服务端协议所在包名不一致导致的无法识别。</h5><p>   Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RpcServerException): Unknown protocol: com.ppj2.rp.LoginServiceInterface</p>\n<p>这个就是因为我服务端放在com.ppj2.rpc包下，而客户端放在com.ppj2.rp包下导致的。</p>\n<h5 id=\"2-之前没有卸载干净\"><a href=\"#2-之前没有卸载干净\" class=\"headerlink\" title=\"2.之前没有卸载干净\"></a>2.之前没有卸载干净</h5><p><a href=\"https://www.cnblogs.com/qianzf/p/7078436.html\" target=\"_blank\" rel=\"noopener\">mysql装不上</a> </p>\n"},{"title":"Diary(2)","author":"小小冰弟","date":"2018-03-01T02:52:04.000Z","_content":"盼望着盼望着，生活的脚步的近了，遥想过年时，总觉得生活太颓废，想要改变自新，但是过节嘛，感觉先玩着到公司肯定就好了，然而工作快一周了，每天晚上回去就是不听的玩吃鸡，前天晚上打到了四点多，昨天晚上打到了两点多，这应该是我们大多数人的放纵方式吧。我总是把改变留给明天或许是未来，原来我总以我还年轻自豪，现在每每想到我还年轻却这样虚度而感到心塞，也许我就适合懒懒散散的生活，却总有着反人性的思想，应该很多人跟我一样吧！或许这就是我们多都是普通人的原因吧！无论怎样，我觉得活得开心其实是最主要的，但我现在有了攀比，我可以不管它，但我不想丢弃它，我希望它在，因为我也期待自己成为一个强者啊。","source":"_posts/Diary-2.md","raw":"title: Diary(2)\nauthor: 小小冰弟\ndate: 2018-03-01 10:52:04\ntags: live\ncategories: diary\n---\n盼望着盼望着，生活的脚步的近了，遥想过年时，总觉得生活太颓废，想要改变自新，但是过节嘛，感觉先玩着到公司肯定就好了，然而工作快一周了，每天晚上回去就是不听的玩吃鸡，前天晚上打到了四点多，昨天晚上打到了两点多，这应该是我们大多数人的放纵方式吧。我总是把改变留给明天或许是未来，原来我总以我还年轻自豪，现在每每想到我还年轻却这样虚度而感到心塞，也许我就适合懒懒散散的生活，却总有着反人性的思想，应该很多人跟我一样吧！或许这就是我们多都是普通人的原因吧！无论怎样，我觉得活得开心其实是最主要的，但我现在有了攀比，我可以不管它，但我不想丢弃它，我希望它在，因为我也期待自己成为一个强者啊。","slug":"Diary-2","published":1,"updated":"2018-03-26T09:46:34.644Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60kd0002xo7k0q46rijp","content":"<p>盼望着盼望着，生活的脚步的近了，遥想过年时，总觉得生活太颓废，想要改变自新，但是过节嘛，感觉先玩着到公司肯定就好了，然而工作快一周了，每天晚上回去就是不听的玩吃鸡，前天晚上打到了四点多，昨天晚上打到了两点多，这应该是我们大多数人的放纵方式吧。我总是把改变留给明天或许是未来，原来我总以我还年轻自豪，现在每每想到我还年轻却这样虚度而感到心塞，也许我就适合懒懒散散的生活，却总有着反人性的思想，应该很多人跟我一样吧！或许这就是我们多都是普通人的原因吧！无论怎样，我觉得活得开心其实是最主要的，但我现在有了攀比，我可以不管它，但我不想丢弃它，我希望它在，因为我也期待自己成为一个强者啊。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>盼望着盼望着，生活的脚步的近了，遥想过年时，总觉得生活太颓废，想要改变自新，但是过节嘛，感觉先玩着到公司肯定就好了，然而工作快一周了，每天晚上回去就是不听的玩吃鸡，前天晚上打到了四点多，昨天晚上打到了两点多，这应该是我们大多数人的放纵方式吧。我总是把改变留给明天或许是未来，原来我总以我还年轻自豪，现在每每想到我还年轻却这样虚度而感到心塞，也许我就适合懒懒散散的生活，却总有着反人性的思想，应该很多人跟我一样吧！或许这就是我们多都是普通人的原因吧！无论怎样，我觉得活得开心其实是最主要的，但我现在有了攀比，我可以不管它，但我不想丢弃它，我希望它在，因为我也期待自己成为一个强者啊。</p>\n"},{"title":"Diary(3)","author":"小小冰弟","date":"2018-03-13T08:19:28.000Z","_content":"<center>渡人还是渡己</center>\n&emsp;一个谈了好久的同学分手了，我们都在为她出谋划策，其实就像我说过的喜欢一个人可以没有道理，那么不喜欢也可以那么没有道理，如果这种不喜欢两个人同时达到，世间应该会变得十分美好，但自古以来，伤情多是发生在这种时候吧。我总在不停的说服自己，去拼搏的生活，去让自己变得强大，是啊，我希望我能像大话西游里面紫霞仙子说的那样，我的男人是一个盖世英雄，他会踩着七彩祥云来娶我。我想成为一个盖世英雄，想给你七彩祥云，但坏习惯一般都是根深蒂固的，慵懒的我想变得勤奋似乎比较困难，这个时候我又在追逐心中那个关于玄学的梦，小时候我最崇拜的是竹林七贤，所以我的名字一直都喜欢带一个竹，后来有人叫我熊猫，不知道是不是因为我网名的关系哈哈，同学现在的处境让我想到了曾经的自己，那是一个牢笼，傻吗？倔强吗？尊严是何物，如果可以挽回，我曾经也会放下所有尊严去挽回，但世间中的很多事，并不是你妥协，老天就会给你机会，我无数次的想跟命运妥协，但结果总是更惨，因为你越妥协代表你越渴望，越渴望的梦被击碎，人越是会痛，我害怕痛吗，当然是怕，但为什么还不收手，因为喜欢，对于我喜欢的东西，我总是很执着，但我总是得不到，我的原因其实很大，但我从没反省过貌似，但无论如何我做了哪些过激的事或什么，我觉得我对于别人的伤害应该是微乎其微吧，而且我总是抱着天长地久的爱情观去追一个人的，也许这是根源所在，我太认定了，结果会追的急追的紧，哈哈，没办法，性子急。跟别人说了很多要学会爱自己的话，但我知道当你全身心的去爱一个人的时候自己真的没那么重要，或许有的人觉得这是不理智的爱，但我觉得看你遇到什么样的人吧，遇到值得爱的人，遍体鳞伤又能怎么样，在我彷徨无措时，美好的回忆也是你带给我的无尽的力量啊。扯了那么多，好好干吧，为了成为你的大英雄，为了配上那么优秀的你，前路再难，无所畏惧。\n  \n               \n ","source":"_posts/Diary-3.md","raw":"title: Diary(3)\nauthor: 小小冰弟\ndate: 2018-03-13 16:19:28\ntags: live\ncategories: diary\n---\n<center>渡人还是渡己</center>\n&emsp;一个谈了好久的同学分手了，我们都在为她出谋划策，其实就像我说过的喜欢一个人可以没有道理，那么不喜欢也可以那么没有道理，如果这种不喜欢两个人同时达到，世间应该会变得十分美好，但自古以来，伤情多是发生在这种时候吧。我总在不停的说服自己，去拼搏的生活，去让自己变得强大，是啊，我希望我能像大话西游里面紫霞仙子说的那样，我的男人是一个盖世英雄，他会踩着七彩祥云来娶我。我想成为一个盖世英雄，想给你七彩祥云，但坏习惯一般都是根深蒂固的，慵懒的我想变得勤奋似乎比较困难，这个时候我又在追逐心中那个关于玄学的梦，小时候我最崇拜的是竹林七贤，所以我的名字一直都喜欢带一个竹，后来有人叫我熊猫，不知道是不是因为我网名的关系哈哈，同学现在的处境让我想到了曾经的自己，那是一个牢笼，傻吗？倔强吗？尊严是何物，如果可以挽回，我曾经也会放下所有尊严去挽回，但世间中的很多事，并不是你妥协，老天就会给你机会，我无数次的想跟命运妥协，但结果总是更惨，因为你越妥协代表你越渴望，越渴望的梦被击碎，人越是会痛，我害怕痛吗，当然是怕，但为什么还不收手，因为喜欢，对于我喜欢的东西，我总是很执着，但我总是得不到，我的原因其实很大，但我从没反省过貌似，但无论如何我做了哪些过激的事或什么，我觉得我对于别人的伤害应该是微乎其微吧，而且我总是抱着天长地久的爱情观去追一个人的，也许这是根源所在，我太认定了，结果会追的急追的紧，哈哈，没办法，性子急。跟别人说了很多要学会爱自己的话，但我知道当你全身心的去爱一个人的时候自己真的没那么重要，或许有的人觉得这是不理智的爱，但我觉得看你遇到什么样的人吧，遇到值得爱的人，遍体鳞伤又能怎么样，在我彷徨无措时，美好的回忆也是你带给我的无尽的力量啊。扯了那么多，好好干吧，为了成为你的大英雄，为了配上那么优秀的你，前路再难，无所畏惧。\n  \n               \n ","slug":"Diary-3","published":1,"updated":"2018-03-26T09:46:34.645Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60ki0006xo7k9klsapui","content":"<p><center>渡人还是渡己</center><br>&emsp;一个谈了好久的同学分手了，我们都在为她出谋划策，其实就像我说过的喜欢一个人可以没有道理，那么不喜欢也可以那么没有道理，如果这种不喜欢两个人同时达到，世间应该会变得十分美好，但自古以来，伤情多是发生在这种时候吧。我总在不停的说服自己，去拼搏的生活，去让自己变得强大，是啊，我希望我能像大话西游里面紫霞仙子说的那样，我的男人是一个盖世英雄，他会踩着七彩祥云来娶我。我想成为一个盖世英雄，想给你七彩祥云，但坏习惯一般都是根深蒂固的，慵懒的我想变得勤奋似乎比较困难，这个时候我又在追逐心中那个关于玄学的梦，小时候我最崇拜的是竹林七贤，所以我的名字一直都喜欢带一个竹，后来有人叫我熊猫，不知道是不是因为我网名的关系哈哈，同学现在的处境让我想到了曾经的自己，那是一个牢笼，傻吗？倔强吗？尊严是何物，如果可以挽回，我曾经也会放下所有尊严去挽回，但世间中的很多事，并不是你妥协，老天就会给你机会，我无数次的想跟命运妥协，但结果总是更惨，因为你越妥协代表你越渴望，越渴望的梦被击碎，人越是会痛，我害怕痛吗，当然是怕，但为什么还不收手，因为喜欢，对于我喜欢的东西，我总是很执着，但我总是得不到，我的原因其实很大，但我从没反省过貌似，但无论如何我做了哪些过激的事或什么，我觉得我对于别人的伤害应该是微乎其微吧，而且我总是抱着天长地久的爱情观去追一个人的，也许这是根源所在，我太认定了，结果会追的急追的紧，哈哈，没办法，性子急。跟别人说了很多要学会爱自己的话，但我知道当你全身心的去爱一个人的时候自己真的没那么重要，或许有的人觉得这是不理智的爱，但我觉得看你遇到什么样的人吧，遇到值得爱的人，遍体鳞伤又能怎么样，在我彷徨无措时，美好的回忆也是你带给我的无尽的力量啊。扯了那么多，好好干吧，为了成为你的大英雄，为了配上那么优秀的你，前路再难，无所畏惧。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><center>渡人还是渡己</center><br>&emsp;一个谈了好久的同学分手了，我们都在为她出谋划策，其实就像我说过的喜欢一个人可以没有道理，那么不喜欢也可以那么没有道理，如果这种不喜欢两个人同时达到，世间应该会变得十分美好，但自古以来，伤情多是发生在这种时候吧。我总在不停的说服自己，去拼搏的生活，去让自己变得强大，是啊，我希望我能像大话西游里面紫霞仙子说的那样，我的男人是一个盖世英雄，他会踩着七彩祥云来娶我。我想成为一个盖世英雄，想给你七彩祥云，但坏习惯一般都是根深蒂固的，慵懒的我想变得勤奋似乎比较困难，这个时候我又在追逐心中那个关于玄学的梦，小时候我最崇拜的是竹林七贤，所以我的名字一直都喜欢带一个竹，后来有人叫我熊猫，不知道是不是因为我网名的关系哈哈，同学现在的处境让我想到了曾经的自己，那是一个牢笼，傻吗？倔强吗？尊严是何物，如果可以挽回，我曾经也会放下所有尊严去挽回，但世间中的很多事，并不是你妥协，老天就会给你机会，我无数次的想跟命运妥协，但结果总是更惨，因为你越妥协代表你越渴望，越渴望的梦被击碎，人越是会痛，我害怕痛吗，当然是怕，但为什么还不收手，因为喜欢，对于我喜欢的东西，我总是很执着，但我总是得不到，我的原因其实很大，但我从没反省过貌似，但无论如何我做了哪些过激的事或什么，我觉得我对于别人的伤害应该是微乎其微吧，而且我总是抱着天长地久的爱情观去追一个人的，也许这是根源所在，我太认定了，结果会追的急追的紧，哈哈，没办法，性子急。跟别人说了很多要学会爱自己的话，但我知道当你全身心的去爱一个人的时候自己真的没那么重要，或许有的人觉得这是不理智的爱，但我觉得看你遇到什么样的人吧，遇到值得爱的人，遍体鳞伤又能怎么样，在我彷徨无措时，美好的回忆也是你带给我的无尽的力量啊。扯了那么多，好好干吧，为了成为你的大英雄，为了配上那么优秀的你，前路再难，无所畏惧。</p>\n"},{"title":"Diary(4)","author":"小小冰弟","date":"2018-03-27T01:05:01.000Z","_content":"&nbsp;&nbsp;这一周又开始读起了《飘》，其实这一本小说最早的时候是位同学推荐我读的，至于那是一种怎么样的情景我记不大清了，后来读了白夜行，其中刚开始女主与男主的缘分就是图书馆中的一本乱世佳人开始的，我喜欢乱世佳人这个名字，就像我骨子里中不安定的因素，喜欢不安定带来的不确定的惊喜吧。后来便买了《飘》，不过当我再度读起时候，上面已经有了尘埃，时光荏苒啊~~前天晚上又失眠了，但我很开心，就像我所觉得的一样，一个人熬夜，如果是为往事，那他一定是不幸的，但如果是为未来，那他是幸运的，而我，确实徘徊于这之间，这是一种幸运还是不幸呢？哈哈！有人说双鱼座的最大的优点就是富于想象力，这一点我深表赞同，这也是我们鱼儿能大悲大喜的原因吧，用的好，生活充满浪漫，用的不好便是处处是凄凉的景象，而我似乎找到了一种对于此种想象力的用途，那便是白日做梦，是不是很令人费解，但我不想继续深谈，因为这是个秘密。本周希望能完成hadoop的继续学习吧，都拖了那么久，我们总是对别人严，对自己松，严于律己，宽以待人真的需要去做好，就好比对待托更的UP主，我应该抱有怎么样的心情呢？就说到这吧！向上吧，少年！你的懒散输给了世界二十年，现在，像小马哥说过的一样，我失去的，我都要赢回来。","source":"_posts/Diary-4.md","raw":"title: Diary(4)\nauthor: 小小冰弟\ndate: 2018-03-27 09:05:01\ntags: live\ncategories: diary\n---\n&nbsp;&nbsp;这一周又开始读起了《飘》，其实这一本小说最早的时候是位同学推荐我读的，至于那是一种怎么样的情景我记不大清了，后来读了白夜行，其中刚开始女主与男主的缘分就是图书馆中的一本乱世佳人开始的，我喜欢乱世佳人这个名字，就像我骨子里中不安定的因素，喜欢不安定带来的不确定的惊喜吧。后来便买了《飘》，不过当我再度读起时候，上面已经有了尘埃，时光荏苒啊~~前天晚上又失眠了，但我很开心，就像我所觉得的一样，一个人熬夜，如果是为往事，那他一定是不幸的，但如果是为未来，那他是幸运的，而我，确实徘徊于这之间，这是一种幸运还是不幸呢？哈哈！有人说双鱼座的最大的优点就是富于想象力，这一点我深表赞同，这也是我们鱼儿能大悲大喜的原因吧，用的好，生活充满浪漫，用的不好便是处处是凄凉的景象，而我似乎找到了一种对于此种想象力的用途，那便是白日做梦，是不是很令人费解，但我不想继续深谈，因为这是个秘密。本周希望能完成hadoop的继续学习吧，都拖了那么久，我们总是对别人严，对自己松，严于律己，宽以待人真的需要去做好，就好比对待托更的UP主，我应该抱有怎么样的心情呢？就说到这吧！向上吧，少年！你的懒散输给了世界二十年，现在，像小马哥说过的一样，我失去的，我都要赢回来。","slug":"Diary-4","published":1,"updated":"2018-03-27T09:52:31.582Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60kj0008xo7kmhg6abiy","content":"<p>&nbsp;&nbsp;这一周又开始读起了《飘》，其实这一本小说最早的时候是位同学推荐我读的，至于那是一种怎么样的情景我记不大清了，后来读了白夜行，其中刚开始女主与男主的缘分就是图书馆中的一本乱世佳人开始的，我喜欢乱世佳人这个名字，就像我骨子里中不安定的因素，喜欢不安定带来的不确定的惊喜吧。后来便买了《飘》，不过当我再度读起时候，上面已经有了尘埃，时光荏苒啊~~前天晚上又失眠了，但我很开心，就像我所觉得的一样，一个人熬夜，如果是为往事，那他一定是不幸的，但如果是为未来，那他是幸运的，而我，确实徘徊于这之间，这是一种幸运还是不幸呢？哈哈！有人说双鱼座的最大的优点就是富于想象力，这一点我深表赞同，这也是我们鱼儿能大悲大喜的原因吧，用的好，生活充满浪漫，用的不好便是处处是凄凉的景象，而我似乎找到了一种对于此种想象力的用途，那便是白日做梦，是不是很令人费解，但我不想继续深谈，因为这是个秘密。本周希望能完成hadoop的继续学习吧，都拖了那么久，我们总是对别人严，对自己松，严于律己，宽以待人真的需要去做好，就好比对待托更的UP主，我应该抱有怎么样的心情呢？就说到这吧！向上吧，少年！你的懒散输给了世界二十年，现在，像小马哥说过的一样，我失去的，我都要赢回来。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>&nbsp;&nbsp;这一周又开始读起了《飘》，其实这一本小说最早的时候是位同学推荐我读的，至于那是一种怎么样的情景我记不大清了，后来读了白夜行，其中刚开始女主与男主的缘分就是图书馆中的一本乱世佳人开始的，我喜欢乱世佳人这个名字，就像我骨子里中不安定的因素，喜欢不安定带来的不确定的惊喜吧。后来便买了《飘》，不过当我再度读起时候，上面已经有了尘埃，时光荏苒啊~~前天晚上又失眠了，但我很开心，就像我所觉得的一样，一个人熬夜，如果是为往事，那他一定是不幸的，但如果是为未来，那他是幸运的，而我，确实徘徊于这之间，这是一种幸运还是不幸呢？哈哈！有人说双鱼座的最大的优点就是富于想象力，这一点我深表赞同，这也是我们鱼儿能大悲大喜的原因吧，用的好，生活充满浪漫，用的不好便是处处是凄凉的景象，而我似乎找到了一种对于此种想象力的用途，那便是白日做梦，是不是很令人费解，但我不想继续深谈，因为这是个秘密。本周希望能完成hadoop的继续学习吧，都拖了那么久，我们总是对别人严，对自己松，严于律己，宽以待人真的需要去做好，就好比对待托更的UP主，我应该抱有怎么样的心情呢？就说到这吧！向上吧，少年！你的懒散输给了世界二十年，现在，像小马哥说过的一样，我失去的，我都要赢回来。</p>\n"},{"title":"Hadoop (一)（centos 6.8/hadoop 2.4.1版本）","author":"小小冰弟","date":"2018-02-03T08:52:44.000Z","_content":"\n#### Hadoop简介\n##### 解决问题：\n- 海量数据存储（HDFS）\n- 海量数据分析(MapReduce)\n- 资源管理调度(Yarn)\n\n\n##### Hdfs实现思想\n1. 通过分布式集群来存储文件\n2. 文件存储到Hdfs集群中是以block为单位\n3. 文件的block存放在若干个datanote节点上\n4. 文件与block的映射存放在namenode上\n5. 每个block还可以有多个副本存放在其他datanote上，提高数据可靠性\n\n刚开始咱就一点一点搭建，后面熟练以后可以直接使用cdh(封装的hadoop).\n\n\n\n\n#### Linux环境设置\n###### 1.网络连接设置及主机映射配置\n\n    虚拟机页面：edit->Virtual Network Editor->nat模式->nat settings->gateway ip设置为本机net8的ip加1\n\n\n###### 2.虚拟机设置ip两种方式：\n\n\t第一种：通过Linux图形界面进行修改（强烈推荐）\n\t\t\t进入Linux图形界面 -> 右键点击右上方的两个小电脑 -> 点击Edit connections -> 选中当前网络 \n            System eth0 -> 点击edit按钮 -> 选择IPv4 -> method选择为manual -> 点击add按钮 -> \n            添加 IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.1 -> apply\n\t\n\t\t第二种：修改配置文件方式（屌丝程序猿专用）\n\t\t\tvim /etc/sysconfig/network-scripts/ifcfg-eth0\n\t\t\tDEVICE=\"eth0\"\n\t\t\tBOOTPROTO=\"static\"               \n\t\t\tHWADDR=\"00:0C:29:3C:BF:E7\"\n\t\t\tIPV6INIT=\"yes\"\n\t\t\tNM_CONTROLLED=\"yes\"\n\t\t\tONBOOT=\"yes\"\n\t\t\tTYPE=\"Ethernet\"\n\t\t\tUUID=\"ce22eeca-ecde-4536-8cc2-ef0dc36d4a8c\"\n\t\t\tIPADDR=\"192.168.1.101\"           \n\t\t\tNETMASK=\"255.255.255.0\"          \n\t\t\tGATEWAY=\"192.168.1.1\"  \n         \n ###### 3.修改主机名\n \n\t\tvim /etc/sysconfig/network\n\t\tNETWORKING=yes\n\t\tHOSTNAME=ppj    ###   \n        \n ###### 4.修改主机名和IP的映射关系\n \n\t\tvim /etc/hosts\n\t\t\t\n\t\t192.168.x.xxx\tppj\n\t\n ##### 5.关闭防火墙\n \n\t\t#查看防火墙状态\n\t\tservice iptables status\n\t\t#关闭防火墙\n\t\tservice iptables stop\n\t\t#查看防火墙开机启动状态\n\t\tchkconfig iptables --list\n\t\t#关闭防火墙开机启动\n\t\tchkconfig iptables off  \n \n \n#### JDK安装\n##### 1.jdk查看与卸载\n    java -version (查看版本)\n    rpm -qa |grep java (查看已经安装的java)\n    rpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 (卸载方式1)\n    yum -y remove java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 （卸载方式2）\n    \n##### 2.jdk安装(需要装32位的)\n[jdk下载地址](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n\n下载压缩包上传至linux目录 /home/usr/  (个人习惯)\n    \n    cd /home/usr\n    tar -zxvf jdk-8u161-linux-arm64-vfp-hflt.tar.gz\n    mkdir /usr/java\n    mv 1.8.0_72 /usr/java/\n    \n##### 3.配置java环境\n\n    vim /etc/profile\n    ##最后添加\n    JAVA_HOME=/usr/java/jdk1.8.0_72\n    JRE_HOME=$JAVA_HOME/jre\n    PATH=$PATH:$JAVA_HOME/bin\n    CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\n\n\n\n#### Hadoop搭建\n##### 1.安装hadoop\n[hadoop下载地址](http://hadoop.apache.org/releases.html)\n下载压缩包上传至linux目录 /home/usr/  \n\t   \n       \n\t\tmkdir /cloud （存放hadoop）\n\t\ttar -zxvf hadoop-2.4.1.tar.gz -C /cloud/\n##### 2配置hadoop伪分布式（要修改4个文件）\n**位置都在/cloud/hadoop-2.4.1/etc/hadoop目录下**\n\nhadoop-env.sh\n\n\t\tvim hadoop-env.sh\n\t\texport JAVA_HOME=/usr/java/1.8.0_72\n\t\t\ncore-site.xml\n\n\t\tvim core-site.xml\n\t\t\t\n\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定HDFS的namenode的通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>fs.default.name</name>\n\t\t\t\t\t\t\t<value>hdfs://ppj:9000</value>(可以不配，默认为28820)\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 指定hadoop运行时产生文件的存放目录 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>hadoop.tmp.dir</name>\n\t\t\t\t\t\t\t<value>/cloud/hadoop-2.4.1/tmp</value>\n\t\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\nhdfs-site.xml\n\n\t\tvim hdfs-site.xml\n\t\t\t<configuration>\n\t\t\t\t<!-- 配置HDFS副本的数量 -->\n\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.replication</name>\n\t\t\t\t\t\t<value>1</value>\n\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\nmapred-site.xml\n\n\t\tvim mapred-site.xml\n\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定jobtracker地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>mapred.job.tracker</name>\n\t\t\t\t\t\t\t<value>ppj:9001</value>\n\t\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\n将hadoop添加到环境变量\n\n\t\tvim /etc/profile\n\t\texport JAVA_HOME=/usr/java/jdk1.6.0_45\n\t\texport HADOOP_HOME=/cloud/hadoop-1.1.2\n\t\texport PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin(因为待会用的命令在sbin)\n\t\tsource /etc/profile\n\t\n格式化HDFS\n\n\t\thadoop namenode -format\n\t\n启动hadoop\n\n\t  start-dfs.sh\n      start-yarn.sh\n\t\n验证集群是否启动成功\n\n\t\tjps(不包括jps应该有5个)\n\t\tNameNode\n\t\tSecondaryNameNode\n\t\tDataNode\n\t\tJobTracker\n\t\tTaskTracker\n\t\t还可以通过浏览器的方式验证\n\t\thttp://192.168.1.110:50070 (hdfs管理界面)\n\t\thttp://192.168.1.110:50030 (mr管理界面)\n\t\t\n在这个文件中添加linux主机名和IP的映射关系：C:\\Windows\\System32\\drivers\\etc\n\n\n\n#### 3.配置ssh免登陆\n\t##生成ssh免登陆密钥\n\tssh-keygen -t rsa\n\t##执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）默认在home用户目录下\n\t##将公钥拷贝到要免登陆的机器上\n    scp id_rsa.pub 目标主机：目录（如果是本机，就直接追加了）\n    先要生成authorized.keyswenjian,且权限为600（-rw------）,接着追加进去\n\tcat 存放的目录/id_rsa.pub >> ~/.ssh/authorized_keys\n    注：我本来在xshell上配了，结果回虚拟机上没有了，当然也没实现免密登录，后来回虚拟机上重设才好。","source":"_posts/Hadoop-一.md","raw":"title: Hadoop (一)（centos 6.8/hadoop 2.4.1版本）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-02-03 16:52:44\n---\n\n#### Hadoop简介\n##### 解决问题：\n- 海量数据存储（HDFS）\n- 海量数据分析(MapReduce)\n- 资源管理调度(Yarn)\n\n\n##### Hdfs实现思想\n1. 通过分布式集群来存储文件\n2. 文件存储到Hdfs集群中是以block为单位\n3. 文件的block存放在若干个datanote节点上\n4. 文件与block的映射存放在namenode上\n5. 每个block还可以有多个副本存放在其他datanote上，提高数据可靠性\n\n刚开始咱就一点一点搭建，后面熟练以后可以直接使用cdh(封装的hadoop).\n\n\n\n\n#### Linux环境设置\n###### 1.网络连接设置及主机映射配置\n\n    虚拟机页面：edit->Virtual Network Editor->nat模式->nat settings->gateway ip设置为本机net8的ip加1\n\n\n###### 2.虚拟机设置ip两种方式：\n\n\t第一种：通过Linux图形界面进行修改（强烈推荐）\n\t\t\t进入Linux图形界面 -> 右键点击右上方的两个小电脑 -> 点击Edit connections -> 选中当前网络 \n            System eth0 -> 点击edit按钮 -> 选择IPv4 -> method选择为manual -> 点击add按钮 -> \n            添加 IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.1 -> apply\n\t\n\t\t第二种：修改配置文件方式（屌丝程序猿专用）\n\t\t\tvim /etc/sysconfig/network-scripts/ifcfg-eth0\n\t\t\tDEVICE=\"eth0\"\n\t\t\tBOOTPROTO=\"static\"               \n\t\t\tHWADDR=\"00:0C:29:3C:BF:E7\"\n\t\t\tIPV6INIT=\"yes\"\n\t\t\tNM_CONTROLLED=\"yes\"\n\t\t\tONBOOT=\"yes\"\n\t\t\tTYPE=\"Ethernet\"\n\t\t\tUUID=\"ce22eeca-ecde-4536-8cc2-ef0dc36d4a8c\"\n\t\t\tIPADDR=\"192.168.1.101\"           \n\t\t\tNETMASK=\"255.255.255.0\"          \n\t\t\tGATEWAY=\"192.168.1.1\"  \n         \n ###### 3.修改主机名\n \n\t\tvim /etc/sysconfig/network\n\t\tNETWORKING=yes\n\t\tHOSTNAME=ppj    ###   \n        \n ###### 4.修改主机名和IP的映射关系\n \n\t\tvim /etc/hosts\n\t\t\t\n\t\t192.168.x.xxx\tppj\n\t\n ##### 5.关闭防火墙\n \n\t\t#查看防火墙状态\n\t\tservice iptables status\n\t\t#关闭防火墙\n\t\tservice iptables stop\n\t\t#查看防火墙开机启动状态\n\t\tchkconfig iptables --list\n\t\t#关闭防火墙开机启动\n\t\tchkconfig iptables off  \n \n \n#### JDK安装\n##### 1.jdk查看与卸载\n    java -version (查看版本)\n    rpm -qa |grep java (查看已经安装的java)\n    rpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 (卸载方式1)\n    yum -y remove java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 （卸载方式2）\n    \n##### 2.jdk安装(需要装32位的)\n[jdk下载地址](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n\n下载压缩包上传至linux目录 /home/usr/  (个人习惯)\n    \n    cd /home/usr\n    tar -zxvf jdk-8u161-linux-arm64-vfp-hflt.tar.gz\n    mkdir /usr/java\n    mv 1.8.0_72 /usr/java/\n    \n##### 3.配置java环境\n\n    vim /etc/profile\n    ##最后添加\n    JAVA_HOME=/usr/java/jdk1.8.0_72\n    JRE_HOME=$JAVA_HOME/jre\n    PATH=$PATH:$JAVA_HOME/bin\n    CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\n\n\n\n#### Hadoop搭建\n##### 1.安装hadoop\n[hadoop下载地址](http://hadoop.apache.org/releases.html)\n下载压缩包上传至linux目录 /home/usr/  \n\t   \n       \n\t\tmkdir /cloud （存放hadoop）\n\t\ttar -zxvf hadoop-2.4.1.tar.gz -C /cloud/\n##### 2配置hadoop伪分布式（要修改4个文件）\n**位置都在/cloud/hadoop-2.4.1/etc/hadoop目录下**\n\nhadoop-env.sh\n\n\t\tvim hadoop-env.sh\n\t\texport JAVA_HOME=/usr/java/1.8.0_72\n\t\t\ncore-site.xml\n\n\t\tvim core-site.xml\n\t\t\t\n\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定HDFS的namenode的通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>fs.default.name</name>\n\t\t\t\t\t\t\t<value>hdfs://ppj:9000</value>(可以不配，默认为28820)\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 指定hadoop运行时产生文件的存放目录 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>hadoop.tmp.dir</name>\n\t\t\t\t\t\t\t<value>/cloud/hadoop-2.4.1/tmp</value>\n\t\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\nhdfs-site.xml\n\n\t\tvim hdfs-site.xml\n\t\t\t<configuration>\n\t\t\t\t<!-- 配置HDFS副本的数量 -->\n\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.replication</name>\n\t\t\t\t\t\t<value>1</value>\n\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\nmapred-site.xml\n\n\t\tvim mapred-site.xml\n\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定jobtracker地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t\t<name>mapred.job.tracker</name>\n\t\t\t\t\t\t\t<value>ppj:9001</value>\n\t\t\t\t\t</property>\n\t\t\t</configuration>\n\t\t\t\n将hadoop添加到环境变量\n\n\t\tvim /etc/profile\n\t\texport JAVA_HOME=/usr/java/jdk1.6.0_45\n\t\texport HADOOP_HOME=/cloud/hadoop-1.1.2\n\t\texport PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin(因为待会用的命令在sbin)\n\t\tsource /etc/profile\n\t\n格式化HDFS\n\n\t\thadoop namenode -format\n\t\n启动hadoop\n\n\t  start-dfs.sh\n      start-yarn.sh\n\t\n验证集群是否启动成功\n\n\t\tjps(不包括jps应该有5个)\n\t\tNameNode\n\t\tSecondaryNameNode\n\t\tDataNode\n\t\tJobTracker\n\t\tTaskTracker\n\t\t还可以通过浏览器的方式验证\n\t\thttp://192.168.1.110:50070 (hdfs管理界面)\n\t\thttp://192.168.1.110:50030 (mr管理界面)\n\t\t\n在这个文件中添加linux主机名和IP的映射关系：C:\\Windows\\System32\\drivers\\etc\n\n\n\n#### 3.配置ssh免登陆\n\t##生成ssh免登陆密钥\n\tssh-keygen -t rsa\n\t##执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）默认在home用户目录下\n\t##将公钥拷贝到要免登陆的机器上\n    scp id_rsa.pub 目标主机：目录（如果是本机，就直接追加了）\n    先要生成authorized.keyswenjian,且权限为600（-rw------）,接着追加进去\n\tcat 存放的目录/id_rsa.pub >> ~/.ssh/authorized_keys\n    注：我本来在xshell上配了，结果回虚拟机上没有了，当然也没实现免密登录，后来回虚拟机上重设才好。","slug":"Hadoop-一","published":1,"updated":"2018-03-26T09:46:34.648Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60kl0009xo7kfy2d19la","content":"<h4 id=\"Hadoop简介\"><a href=\"#Hadoop简介\" class=\"headerlink\" title=\"Hadoop简介\"></a>Hadoop简介</h4><h5 id=\"解决问题：\"><a href=\"#解决问题：\" class=\"headerlink\" title=\"解决问题：\"></a>解决问题：</h5><ul>\n<li>海量数据存储（HDFS）</li>\n<li>海量数据分析(MapReduce)</li>\n<li>资源管理调度(Yarn)</li>\n</ul>\n<h5 id=\"Hdfs实现思想\"><a href=\"#Hdfs实现思想\" class=\"headerlink\" title=\"Hdfs实现思想\"></a>Hdfs实现思想</h5><ol>\n<li>通过分布式集群来存储文件</li>\n<li>文件存储到Hdfs集群中是以block为单位</li>\n<li>文件的block存放在若干个datanote节点上</li>\n<li>文件与block的映射存放在namenode上</li>\n<li>每个block还可以有多个副本存放在其他datanote上，提高数据可靠性</li>\n</ol>\n<p>刚开始咱就一点一点搭建，后面熟练以后可以直接使用cdh(封装的hadoop).</p>\n<h4 id=\"Linux环境设置\"><a href=\"#Linux环境设置\" class=\"headerlink\" title=\"Linux环境设置\"></a>Linux环境设置</h4><h6 id=\"1-网络连接设置及主机映射配置\"><a href=\"#1-网络连接设置及主机映射配置\" class=\"headerlink\" title=\"1.网络连接设置及主机映射配置\"></a>1.网络连接设置及主机映射配置</h6><pre><code>虚拟机页面：edit-&gt;Virtual Network Editor-&gt;nat模式-&gt;nat settings-&gt;gateway ip设置为本机net8的ip加1\n</code></pre><h6 id=\"2-虚拟机设置ip两种方式：\"><a href=\"#2-虚拟机设置ip两种方式：\" class=\"headerlink\" title=\"2.虚拟机设置ip两种方式：\"></a>2.虚拟机设置ip两种方式：</h6><pre><code>第一种：通过Linux图形界面进行修改（强烈推荐）\n        进入Linux图形界面 -&gt; 右键点击右上方的两个小电脑 -&gt; 点击Edit connections -&gt; 选中当前网络 \n        System eth0 -&gt; 点击edit按钮 -&gt; 选择IPv4 -&gt; method选择为manual -&gt; 点击add按钮 -&gt; \n        添加 IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.1 -&gt; apply\n\n    第二种：修改配置文件方式（屌丝程序猿专用）\n        vim /etc/sysconfig/network-scripts/ifcfg-eth0\n        DEVICE=&quot;eth0&quot;\n        BOOTPROTO=&quot;static&quot;               \n        HWADDR=&quot;00:0C:29:3C:BF:E7&quot;\n        IPV6INIT=&quot;yes&quot;\n        NM_CONTROLLED=&quot;yes&quot;\n        ONBOOT=&quot;yes&quot;\n        TYPE=&quot;Ethernet&quot;\n        UUID=&quot;ce22eeca-ecde-4536-8cc2-ef0dc36d4a8c&quot;\n        IPADDR=&quot;192.168.1.101&quot;           \n        NETMASK=&quot;255.255.255.0&quot;          \n        GATEWAY=&quot;192.168.1.1&quot;  \n</code></pre><h6 id=\"3-修改主机名\"><a href=\"#3-修改主机名\" class=\"headerlink\" title=\"3.修改主机名\"></a>3.修改主机名</h6><pre><code>vim /etc/sysconfig/network\nNETWORKING=yes\nHOSTNAME=ppj    ###   \n</code></pre><h6 id=\"4-修改主机名和IP的映射关系\"><a href=\"#4-修改主机名和IP的映射关系\" class=\"headerlink\" title=\"4.修改主机名和IP的映射关系\"></a>4.修改主机名和IP的映射关系</h6><pre><code>vim /etc/hosts\n\n192.168.x.xxx    ppj\n</code></pre><h5 id=\"5-关闭防火墙\"><a href=\"#5-关闭防火墙\" class=\"headerlink\" title=\"5.关闭防火墙\"></a>5.关闭防火墙</h5><pre><code>#查看防火墙状态\nservice iptables status\n#关闭防火墙\nservice iptables stop\n#查看防火墙开机启动状态\nchkconfig iptables --list\n#关闭防火墙开机启动\nchkconfig iptables off  \n</code></pre><h4 id=\"JDK安装\"><a href=\"#JDK安装\" class=\"headerlink\" title=\"JDK安装\"></a>JDK安装</h4><h5 id=\"1-jdk查看与卸载\"><a href=\"#1-jdk查看与卸载\" class=\"headerlink\" title=\"1.jdk查看与卸载\"></a>1.jdk查看与卸载</h5><pre><code>java -version (查看版本)\nrpm -qa |grep java (查看已经安装的java)\nrpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 (卸载方式1)\nyum -y remove java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 （卸载方式2）\n</code></pre><h5 id=\"2-jdk安装-需要装32位的\"><a href=\"#2-jdk安装-需要装32位的\" class=\"headerlink\" title=\"2.jdk安装(需要装32位的)\"></a>2.jdk安装(需要装32位的)</h5><p><a href=\"http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\" target=\"_blank\" rel=\"noopener\">jdk下载地址</a></p>\n<p>下载压缩包上传至linux目录 /home/usr/  (个人习惯)</p>\n<pre><code>cd /home/usr\ntar -zxvf jdk-8u161-linux-arm64-vfp-hflt.tar.gz\nmkdir /usr/java\nmv 1.8.0_72 /usr/java/\n</code></pre><h5 id=\"3-配置java环境\"><a href=\"#3-配置java环境\" class=\"headerlink\" title=\"3.配置java环境\"></a>3.配置java环境</h5><pre><code>vim /etc/profile\n##最后添加\nJAVA_HOME=/usr/java/jdk1.8.0_72\nJRE_HOME=$JAVA_HOME/jre\nPATH=$PATH:$JAVA_HOME/bin\nCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n</code></pre><h4 id=\"Hadoop搭建\"><a href=\"#Hadoop搭建\" class=\"headerlink\" title=\"Hadoop搭建\"></a>Hadoop搭建</h4><h5 id=\"1-安装hadoop\"><a href=\"#1-安装hadoop\" class=\"headerlink\" title=\"1.安装hadoop\"></a>1.安装hadoop</h5><p><a href=\"http://hadoop.apache.org/releases.html\" target=\"_blank\" rel=\"noopener\">hadoop下载地址</a><br>下载压缩包上传至linux目录 /home/usr/  </p>\n<pre><code>mkdir /cloud （存放hadoop）\ntar -zxvf hadoop-2.4.1.tar.gz -C /cloud/\n</code></pre><h5 id=\"2配置hadoop伪分布式（要修改4个文件）\"><a href=\"#2配置hadoop伪分布式（要修改4个文件）\" class=\"headerlink\" title=\"2配置hadoop伪分布式（要修改4个文件）\"></a>2配置hadoop伪分布式（要修改4个文件）</h5><p><strong>位置都在/cloud/hadoop-2.4.1/etc/hadoop目录下</strong></p>\n<p>hadoop-env.sh</p>\n<pre><code>vim hadoop-env.sh\nexport JAVA_HOME=/usr/java/1.8.0_72\n</code></pre><p>core-site.xml</p>\n<pre><code>vim core-site.xml\n\n    &lt;configuration&gt;\n            &lt;!-- 指定HDFS的namenode的通信地址 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;fs.default.name&lt;/name&gt;\n                    &lt;value&gt;hdfs://ppj:9000&lt;/value&gt;(可以不配，默认为28820)\n            &lt;/property&gt;\n            &lt;!-- 指定hadoop运行时产生文件的存放目录 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n                    &lt;value&gt;/cloud/hadoop-2.4.1/tmp&lt;/value&gt;\n            &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>hdfs-site.xml</p>\n<pre><code>vim hdfs-site.xml\n    &lt;configuration&gt;\n        &lt;!-- 配置HDFS副本的数量 --&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.replication&lt;/name&gt;\n                &lt;value&gt;1&lt;/value&gt;\n        &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>mapred-site.xml</p>\n<pre><code>vim mapred-site.xml\n    &lt;configuration&gt;\n            &lt;!-- 指定jobtracker地址 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n                    &lt;value&gt;ppj:9001&lt;/value&gt;\n            &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>将hadoop添加到环境变量</p>\n<pre><code>vim /etc/profile\nexport JAVA_HOME=/usr/java/jdk1.6.0_45\nexport HADOOP_HOME=/cloud/hadoop-1.1.2\nexport PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin(因为待会用的命令在sbin)\nsource /etc/profile\n</code></pre><p>格式化HDFS</p>\n<pre><code>hadoop namenode -format\n</code></pre><p>启动hadoop</p>\n<pre><code>start-dfs.sh\nstart-yarn.sh\n</code></pre><p>验证集群是否启动成功</p>\n<pre><code>jps(不包括jps应该有5个)\nNameNode\nSecondaryNameNode\nDataNode\nJobTracker\nTaskTracker\n还可以通过浏览器的方式验证\nhttp://192.168.1.110:50070 (hdfs管理界面)\nhttp://192.168.1.110:50030 (mr管理界面)\n</code></pre><p>在这个文件中添加linux主机名和IP的映射关系：C:\\Windows\\System32\\drivers\\etc</p>\n<h4 id=\"3-配置ssh免登陆\"><a href=\"#3-配置ssh免登陆\" class=\"headerlink\" title=\"3.配置ssh免登陆\"></a>3.配置ssh免登陆</h4><pre><code>##生成ssh免登陆密钥\nssh-keygen -t rsa\n##执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）默认在home用户目录下\n##将公钥拷贝到要免登陆的机器上\nscp id_rsa.pub 目标主机：目录（如果是本机，就直接追加了）\n先要生成authorized.keyswenjian,且权限为600（-rw------）,接着追加进去\ncat 存放的目录/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys\n注：我本来在xshell上配了，结果回虚拟机上没有了，当然也没实现免密登录，后来回虚拟机上重设才好。\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"Hadoop简介\"><a href=\"#Hadoop简介\" class=\"headerlink\" title=\"Hadoop简介\"></a>Hadoop简介</h4><h5 id=\"解决问题：\"><a href=\"#解决问题：\" class=\"headerlink\" title=\"解决问题：\"></a>解决问题：</h5><ul>\n<li>海量数据存储（HDFS）</li>\n<li>海量数据分析(MapReduce)</li>\n<li>资源管理调度(Yarn)</li>\n</ul>\n<h5 id=\"Hdfs实现思想\"><a href=\"#Hdfs实现思想\" class=\"headerlink\" title=\"Hdfs实现思想\"></a>Hdfs实现思想</h5><ol>\n<li>通过分布式集群来存储文件</li>\n<li>文件存储到Hdfs集群中是以block为单位</li>\n<li>文件的block存放在若干个datanote节点上</li>\n<li>文件与block的映射存放在namenode上</li>\n<li>每个block还可以有多个副本存放在其他datanote上，提高数据可靠性</li>\n</ol>\n<p>刚开始咱就一点一点搭建，后面熟练以后可以直接使用cdh(封装的hadoop).</p>\n<h4 id=\"Linux环境设置\"><a href=\"#Linux环境设置\" class=\"headerlink\" title=\"Linux环境设置\"></a>Linux环境设置</h4><h6 id=\"1-网络连接设置及主机映射配置\"><a href=\"#1-网络连接设置及主机映射配置\" class=\"headerlink\" title=\"1.网络连接设置及主机映射配置\"></a>1.网络连接设置及主机映射配置</h6><pre><code>虚拟机页面：edit-&gt;Virtual Network Editor-&gt;nat模式-&gt;nat settings-&gt;gateway ip设置为本机net8的ip加1\n</code></pre><h6 id=\"2-虚拟机设置ip两种方式：\"><a href=\"#2-虚拟机设置ip两种方式：\" class=\"headerlink\" title=\"2.虚拟机设置ip两种方式：\"></a>2.虚拟机设置ip两种方式：</h6><pre><code>第一种：通过Linux图形界面进行修改（强烈推荐）\n        进入Linux图形界面 -&gt; 右键点击右上方的两个小电脑 -&gt; 点击Edit connections -&gt; 选中当前网络 \n        System eth0 -&gt; 点击edit按钮 -&gt; 选择IPv4 -&gt; method选择为manual -&gt; 点击add按钮 -&gt; \n        添加 IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.1 -&gt; apply\n\n    第二种：修改配置文件方式（屌丝程序猿专用）\n        vim /etc/sysconfig/network-scripts/ifcfg-eth0\n        DEVICE=&quot;eth0&quot;\n        BOOTPROTO=&quot;static&quot;               \n        HWADDR=&quot;00:0C:29:3C:BF:E7&quot;\n        IPV6INIT=&quot;yes&quot;\n        NM_CONTROLLED=&quot;yes&quot;\n        ONBOOT=&quot;yes&quot;\n        TYPE=&quot;Ethernet&quot;\n        UUID=&quot;ce22eeca-ecde-4536-8cc2-ef0dc36d4a8c&quot;\n        IPADDR=&quot;192.168.1.101&quot;           \n        NETMASK=&quot;255.255.255.0&quot;          \n        GATEWAY=&quot;192.168.1.1&quot;  \n</code></pre><h6 id=\"3-修改主机名\"><a href=\"#3-修改主机名\" class=\"headerlink\" title=\"3.修改主机名\"></a>3.修改主机名</h6><pre><code>vim /etc/sysconfig/network\nNETWORKING=yes\nHOSTNAME=ppj    ###   \n</code></pre><h6 id=\"4-修改主机名和IP的映射关系\"><a href=\"#4-修改主机名和IP的映射关系\" class=\"headerlink\" title=\"4.修改主机名和IP的映射关系\"></a>4.修改主机名和IP的映射关系</h6><pre><code>vim /etc/hosts\n\n192.168.x.xxx    ppj\n</code></pre><h5 id=\"5-关闭防火墙\"><a href=\"#5-关闭防火墙\" class=\"headerlink\" title=\"5.关闭防火墙\"></a>5.关闭防火墙</h5><pre><code>#查看防火墙状态\nservice iptables status\n#关闭防火墙\nservice iptables stop\n#查看防火墙开机启动状态\nchkconfig iptables --list\n#关闭防火墙开机启动\nchkconfig iptables off  \n</code></pre><h4 id=\"JDK安装\"><a href=\"#JDK安装\" class=\"headerlink\" title=\"JDK安装\"></a>JDK安装</h4><h5 id=\"1-jdk查看与卸载\"><a href=\"#1-jdk查看与卸载\" class=\"headerlink\" title=\"1.jdk查看与卸载\"></a>1.jdk查看与卸载</h5><pre><code>java -version (查看版本)\nrpm -qa |grep java (查看已经安装的java)\nrpm -e --nodeps java-1.6.0-openjdk-1.6.0.38-1.13.10.0.el6_7.x86_64 (卸载方式1)\nyum -y remove java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 （卸载方式2）\n</code></pre><h5 id=\"2-jdk安装-需要装32位的\"><a href=\"#2-jdk安装-需要装32位的\" class=\"headerlink\" title=\"2.jdk安装(需要装32位的)\"></a>2.jdk安装(需要装32位的)</h5><p><a href=\"http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\" target=\"_blank\" rel=\"noopener\">jdk下载地址</a></p>\n<p>下载压缩包上传至linux目录 /home/usr/  (个人习惯)</p>\n<pre><code>cd /home/usr\ntar -zxvf jdk-8u161-linux-arm64-vfp-hflt.tar.gz\nmkdir /usr/java\nmv 1.8.0_72 /usr/java/\n</code></pre><h5 id=\"3-配置java环境\"><a href=\"#3-配置java环境\" class=\"headerlink\" title=\"3.配置java环境\"></a>3.配置java环境</h5><pre><code>vim /etc/profile\n##最后添加\nJAVA_HOME=/usr/java/jdk1.8.0_72\nJRE_HOME=$JAVA_HOME/jre\nPATH=$PATH:$JAVA_HOME/bin\nCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n</code></pre><h4 id=\"Hadoop搭建\"><a href=\"#Hadoop搭建\" class=\"headerlink\" title=\"Hadoop搭建\"></a>Hadoop搭建</h4><h5 id=\"1-安装hadoop\"><a href=\"#1-安装hadoop\" class=\"headerlink\" title=\"1.安装hadoop\"></a>1.安装hadoop</h5><p><a href=\"http://hadoop.apache.org/releases.html\" target=\"_blank\" rel=\"noopener\">hadoop下载地址</a><br>下载压缩包上传至linux目录 /home/usr/  </p>\n<pre><code>mkdir /cloud （存放hadoop）\ntar -zxvf hadoop-2.4.1.tar.gz -C /cloud/\n</code></pre><h5 id=\"2配置hadoop伪分布式（要修改4个文件）\"><a href=\"#2配置hadoop伪分布式（要修改4个文件）\" class=\"headerlink\" title=\"2配置hadoop伪分布式（要修改4个文件）\"></a>2配置hadoop伪分布式（要修改4个文件）</h5><p><strong>位置都在/cloud/hadoop-2.4.1/etc/hadoop目录下</strong></p>\n<p>hadoop-env.sh</p>\n<pre><code>vim hadoop-env.sh\nexport JAVA_HOME=/usr/java/1.8.0_72\n</code></pre><p>core-site.xml</p>\n<pre><code>vim core-site.xml\n\n    &lt;configuration&gt;\n            &lt;!-- 指定HDFS的namenode的通信地址 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;fs.default.name&lt;/name&gt;\n                    &lt;value&gt;hdfs://ppj:9000&lt;/value&gt;(可以不配，默认为28820)\n            &lt;/property&gt;\n            &lt;!-- 指定hadoop运行时产生文件的存放目录 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n                    &lt;value&gt;/cloud/hadoop-2.4.1/tmp&lt;/value&gt;\n            &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>hdfs-site.xml</p>\n<pre><code>vim hdfs-site.xml\n    &lt;configuration&gt;\n        &lt;!-- 配置HDFS副本的数量 --&gt;\n        &lt;property&gt;\n                &lt;name&gt;dfs.replication&lt;/name&gt;\n                &lt;value&gt;1&lt;/value&gt;\n        &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>mapred-site.xml</p>\n<pre><code>vim mapred-site.xml\n    &lt;configuration&gt;\n            &lt;!-- 指定jobtracker地址 --&gt;\n            &lt;property&gt;\n                    &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n                    &lt;value&gt;ppj:9001&lt;/value&gt;\n            &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre><p>将hadoop添加到环境变量</p>\n<pre><code>vim /etc/profile\nexport JAVA_HOME=/usr/java/jdk1.6.0_45\nexport HADOOP_HOME=/cloud/hadoop-1.1.2\nexport PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin(因为待会用的命令在sbin)\nsource /etc/profile\n</code></pre><p>格式化HDFS</p>\n<pre><code>hadoop namenode -format\n</code></pre><p>启动hadoop</p>\n<pre><code>start-dfs.sh\nstart-yarn.sh\n</code></pre><p>验证集群是否启动成功</p>\n<pre><code>jps(不包括jps应该有5个)\nNameNode\nSecondaryNameNode\nDataNode\nJobTracker\nTaskTracker\n还可以通过浏览器的方式验证\nhttp://192.168.1.110:50070 (hdfs管理界面)\nhttp://192.168.1.110:50030 (mr管理界面)\n</code></pre><p>在这个文件中添加linux主机名和IP的映射关系：C:\\Windows\\System32\\drivers\\etc</p>\n<h4 id=\"3-配置ssh免登陆\"><a href=\"#3-配置ssh免登陆\" class=\"headerlink\" title=\"3.配置ssh免登陆\"></a>3.配置ssh免登陆</h4><pre><code>##生成ssh免登陆密钥\nssh-keygen -t rsa\n##执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）默认在home用户目录下\n##将公钥拷贝到要免登陆的机器上\nscp id_rsa.pub 目标主机：目录（如果是本机，就直接追加了）\n先要生成authorized.keyswenjian,且权限为600（-rw------）,接着追加进去\ncat 存放的目录/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys\n注：我本来在xshell上配了，结果回虚拟机上没有了，当然也没实现免密登录，后来回虚拟机上重设才好。\n</code></pre>"},{"title":"Hadoop(七)（HA高可用架构配置）","author":"小小冰弟","date":"2018-03-27T07:49:51.000Z","_content":"#### 一、Zookeeper集群\n提供少量数据的存储和管理，类似树形目录，由很多node与data组成。解压安装后只需修改配置文件即可，conf目录下。\n\n#### 二、搭建高可用的原因\n###### 1.之前一个NameNode节点肯定不行，但如果我们需要两个节点，肯定不能使两个在同一时间点响应请求。响应请求的必须是active状态。\n###### 2.另外一个standby状态的节点如何做到迅速切换到active状态呢，意味着两个NameNode必须保持元数据相同，所以我们需要将edits分离出去，这样两个NameNode就可以保持一致了，考虑到高可用的分布式，那么这个edits肯定不能一份，所以需要做数据同步，这里hadoop提供了一套框架Qjournal(依赖zookeeper实现)\n###### 3.但要做到切换，在什么状态下切换，我们需要一个监控进程来监控NameNode，在hadoop中我们把这叫做zkfc,但有时候可能active的机器并没有真正死亡，这个时候如果切换了，便会发生“脑裂”。解决方法是发送一条指令，通过ssh来kill那个进程，获取返回值来确定，如果拿不到返回值可以执行自定义shell脚本程序关闭电源啊什么什么的，称为fencing机制。\n###### 4.另外两个NameNode可以构建一个Federation,在core-site.xml里面就需要配置路径为hdfs://nameservice名称，系统可以有多个Federation来扩大集群规模。\n\n#### 三、配置\n\n1.修改core-site.xml\n\n\t\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定hdfs的nameservice为ns1 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>fs.defaultFS</name>\n\t\t\t\t\t\t<value>hdfs://ns1/</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 指定hadoop临时目录 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>hadoop.tmp.dir</name>\n\t\t\t\t\t\t<value>/clould/hadoop-2.4.1/tmp</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t\n\t\t\t\t\t<!-- 指定zookeeper地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>ha.zookeeper.quorum</name>\n\t    \t       <value>hadoop05:2181,hadoop06:2181,hadoop07:2181</value>\n\t\t\t\t\t</property>\n\t\t\t\t</configuration>\n\t\t\t\n            \n2.修改hdfs-site.xml\n\n\t\t\t\t<configuration>\n\t\t\t\t\t<!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.nameservices</name>\n\t\t\t\t\t\t<value>ns1</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- ns1下面有两个NameNode，分别是nn1，nn2 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.ha.namenodes.ns1</name>\n\t\t\t\t\t\t<value>nn1,nn2</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- nn1的RPC通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.namenode.rpc-address.ns1.nn1</name>\n\t\t\t\t\t\t<value>hadoop01:9000</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- nn1的http通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.namenode.http-address.ns1.nn1</name>\n\t\t\t\t\t\t<value>hadoop01:50070</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- nn2的RPC通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.namenode.rpc-address.ns1.nn2</name>\n\t\t\t\t\t\t<value>hadoop02:9000</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- nn2的http通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.namenode.http-address.ns1.nn2</name>\n\t\t\t\t\t\t<value>hadoop02:50070</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 指定NameNode的元数据在JournalNode上的存放位置 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.namenode.shared.edits.dir</name>\n\t\t\t\t\t\t<value>qjournal://hadoop05:8485;hadoop06:8485;hadoop07:8485/ns1</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 指定JournalNode在本地磁盘存放数据的位置 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.journalnode.edits.dir</name>\n\t\t\t\t\t\t<value>/cloud/hadoop-2.4.1/journaldata</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 开启NameNode失败自动切换 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.ha.automatic-failover.enabled</name>\n\t\t\t\t\t\t<value>true</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 配置失败自动切换实现方式 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.client.failover.proxy.provider.ns1</name>\n\t\t\t\t\t\t<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行-->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.ha.fencing.methods</name>\n\t\t\t\t\t\t<value>\n\t\t\t\t\t\t\tsshfence\n\t\t\t\t\t\t\tshell(/bin/true)(这样配置是为了测试返回的肯定是true)\n\t\t\t\t\t\t</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 使用sshfence隔离机制时需要ssh免登陆 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.ha.fencing.ssh.private-key-files</name>\n\t\t\t\t\t\t<value>/home/hadoop/.ssh/id_rsa</value>(根据自己位置定)\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 配置sshfence隔离机制超时时间 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.ha.fencing.ssh.connect-timeout</name>\n\t\t\t\t\t\t<value>30000</value>\n\t\t\t\t\t</property>\n\t\t\t\t</configuration>\n\t\t\t\n            \n3.修改mapred-site.xml\n\n\t\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定mr框架为yarn方式 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>mapreduce.framework.name</name>\n\t\t\t\t\t\t<value>yarn</value>\n\t\t\t\t\t</property>\n\t\t\t\t</configuration>\t\n\t\t\t\n4.修改yarn-site.xml\n\n\t\t\t\t<configuration>\n\t\t\t\t\t\t<!-- 开启RM高可用 -->\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.ha.enabled</name>\n\t\t\t\t\t\t   <value>true</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<!-- 指定RM的cluster id -->\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.cluster-id</name>\n\t\t\t\t\t\t   <value>yrc</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<!-- 指定RM的名字 -->\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.ha.rm-ids</name>\n\t\t\t\t\t\t   <value>rm1,rm2</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<!-- 分别指定RM的地址 -->\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.hostname.rm1</name>\n\t\t\t\t\t\t   <value>hadoop03</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.hostname.rm2</name>\n\t\t\t\t\t\t   <value>hadoop04</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<!-- 指定zk集群地址 -->\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.zk-address</name>\n\t\t\t\t\t\t   <value>hadoop05:2181,hadoop06:2181,hadoop07:2181</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.nodemanager.aux-services</name>\n\t\t\t\t\t\t   <value>mapreduce_shuffle</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t</configuration>\n\t\t\t\n\t\t\t\t\n5.修改slaves(slaves是指定子节点的位置，因为要在hadoop01上启动HDFS、在hadoop03启动yarn，所以hadoop01上的slaves文件指定的是datanode的位置，hadoop03上的slaves文件指定的是nodemanager的位置)\n\n\t\t\t\tweekend05\n\t\t\t\tweekend06\n\t\t\t\tweekend07\n\n6.配置免密码登陆\n\n\n\t #首先要配置hadoop01到hadoop02、hadoop03、hadoop04、hadoop05、hadoop06、hadoop07的免密码登陆\n    #配置hadoop03到hadoop04、hadoop05、hadoop06、hadoop07的免密码登陆\n    #注意：两个namenode之间要配置ssh免密码登陆，别忘了配置weekend02到weekend01的免登陆\n\t\t\t\t\t\t\t\n\t\t\n7.将配置好的hadoop拷贝到其他节点\n\n\t\t\t\n            \n            \n###注意：严格按照下面的步骤\n\n\t\t1.启动zookeeper集群（分别在hadoop05、hadoop06、hadoop07上启动zk）\n\t\t\tcd /weekend/zookeeper-3.4.5/bin/\n\t\t\t./zkServer.sh start\n\t\t\t#查看状态：一个leader，两个follower\n\t\t\t./zkServer.sh status\n\t\t\t\n\t\t2.启动journalnode（分别在在hadoop05、hadoop06、hadoop07上执行）\n\t\t\tcd /weekend/hadoop-2.4.1\n\t\t\tsbin/hadoop-daemon.sh start journalnode\n\t\t\t#运行jps命令检验，hadoop05、hadoop06、hadoop07上多了JournalNode进程\n\t\t\n\t\t3.格式化HDFS\n\t\t\t#在hadoop01上执行命令:\n\t\t\thdfs namenode -format\n\t\t\t#格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/cloud/hadoop-2.4.1/tmp，然后将/cloud/hadoop-2.4.1/tmp拷贝到hadoop02的/cloud/hadoop-2.4.1/下。\n\t\t\tscp -r tmp/ hadoop02:/cloud/hadoop-2.4.1/\n\t\t\t##也可以这样，建议hdfs namenode -bootstrapStandby\n\t\t\n\t\t4.格式化ZKFC(在hadoop01上执行即可)\n\t\t\thdfs zkfc -formatZK\n\t\t\n\t\t5.启动HDFS(在hadoop01上执行)\n\t\t\tsbin/start-dfs.sh\n\n\t\t6.启动YARN(#####注意#####：是在hadoop上执行start-yarn.sh，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动)\n\t\t\tsbin/start-yarn.sh\n\n\t\t\n8.到此，hadoop-2.4.1配置完毕，可以统计浏览器访问:\n\n\n\t\thttp://192.168.1.201:50070\n\t\tNameNode 'hadoop01:9000' (active)\n\t\thttp://192.168.1.202:50070\n\t\tNameNode 'hadoop02:9000' (standby)\n\t    验证HDFS HA\n\t\t首先向hdfs上传一个文件\n\t\thadoop fs -put /etc/profile /profile\n\t\thadoop fs -ls /\n\t\t然后再kill掉active的NameNode\n\t\tkill -9 <pid of NN>\n\t\t通过浏览器访问：http://192.168.1.202:50070\n\t\tNameNode 'hadoop02:9000' (active)\n\t\t这个时候hadoop02上的NameNode变成了active\n\t\t在执行命令：\n\t\thadoop fs -ls /\n\t\t-rw-r--r--   3 root supergroup       1926 2014-02-06 15:36 /profile\n\t\t刚才上传的文件依然存在！！！\n\t\t手动启动那个挂掉的NameNode\n\t\tsbin/hadoop-daemon.sh start namenode\n\t\t通过浏览器访问：http://192.168.1.201:50070\n\t\tNameNode 'hadoop01:9000' (standby)\n\t\n\t    验证YARN：\n\t\t运行一下hadoop提供的demo中的WordCount程序：\n\t\thadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar wordcount /profile /out\n\t\n\tOK，大功告成！！！\n\n\t\n\t\t\t\n\t\t\n9.测试集群工作状态的一些指令 ：\n\nbin/hdfs dfsadmin -report\t 查看hdfs的各节点状态信息\n\n\nbin/hdfs haadmin -getServiceState nn1\t\t 获取一个namenode节点的HA状态\n\nsbin/hadoop-daemon.sh start namenode  单独启动一个namenode进程\n\n\n./hadoop-daemon.sh start zkfc   单独启动一个zkfc进程\n","source":"_posts/Hadoop-七-（HA高可用架构配置）.md","raw":"title: Hadoop(七)（HA高可用架构配置）\nauthor: 小小冰弟\ndate: 2018-03-27 15:49:51\ntags: study\ncategories: Hadoop\n---\n#### 一、Zookeeper集群\n提供少量数据的存储和管理，类似树形目录，由很多node与data组成。解压安装后只需修改配置文件即可，conf目录下。\n\n#### 二、搭建高可用的原因\n###### 1.之前一个NameNode节点肯定不行，但如果我们需要两个节点，肯定不能使两个在同一时间点响应请求。响应请求的必须是active状态。\n###### 2.另外一个standby状态的节点如何做到迅速切换到active状态呢，意味着两个NameNode必须保持元数据相同，所以我们需要将edits分离出去，这样两个NameNode就可以保持一致了，考虑到高可用的分布式，那么这个edits肯定不能一份，所以需要做数据同步，这里hadoop提供了一套框架Qjournal(依赖zookeeper实现)\n###### 3.但要做到切换，在什么状态下切换，我们需要一个监控进程来监控NameNode，在hadoop中我们把这叫做zkfc,但有时候可能active的机器并没有真正死亡，这个时候如果切换了，便会发生“脑裂”。解决方法是发送一条指令，通过ssh来kill那个进程，获取返回值来确定，如果拿不到返回值可以执行自定义shell脚本程序关闭电源啊什么什么的，称为fencing机制。\n###### 4.另外两个NameNode可以构建一个Federation,在core-site.xml里面就需要配置路径为hdfs://nameservice名称，系统可以有多个Federation来扩大集群规模。\n\n#### 三、配置\n\n1.修改core-site.xml\n\n\t\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定hdfs的nameservice为ns1 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>fs.defaultFS</name>\n\t\t\t\t\t\t<value>hdfs://ns1/</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 指定hadoop临时目录 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>hadoop.tmp.dir</name>\n\t\t\t\t\t\t<value>/clould/hadoop-2.4.1/tmp</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t\n\t\t\t\t\t<!-- 指定zookeeper地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>ha.zookeeper.quorum</name>\n\t    \t       <value>hadoop05:2181,hadoop06:2181,hadoop07:2181</value>\n\t\t\t\t\t</property>\n\t\t\t\t</configuration>\n\t\t\t\n            \n2.修改hdfs-site.xml\n\n\t\t\t\t<configuration>\n\t\t\t\t\t<!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.nameservices</name>\n\t\t\t\t\t\t<value>ns1</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- ns1下面有两个NameNode，分别是nn1，nn2 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.ha.namenodes.ns1</name>\n\t\t\t\t\t\t<value>nn1,nn2</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- nn1的RPC通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.namenode.rpc-address.ns1.nn1</name>\n\t\t\t\t\t\t<value>hadoop01:9000</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- nn1的http通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.namenode.http-address.ns1.nn1</name>\n\t\t\t\t\t\t<value>hadoop01:50070</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- nn2的RPC通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.namenode.rpc-address.ns1.nn2</name>\n\t\t\t\t\t\t<value>hadoop02:9000</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- nn2的http通信地址 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.namenode.http-address.ns1.nn2</name>\n\t\t\t\t\t\t<value>hadoop02:50070</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 指定NameNode的元数据在JournalNode上的存放位置 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.namenode.shared.edits.dir</name>\n\t\t\t\t\t\t<value>qjournal://hadoop05:8485;hadoop06:8485;hadoop07:8485/ns1</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 指定JournalNode在本地磁盘存放数据的位置 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.journalnode.edits.dir</name>\n\t\t\t\t\t\t<value>/cloud/hadoop-2.4.1/journaldata</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 开启NameNode失败自动切换 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.ha.automatic-failover.enabled</name>\n\t\t\t\t\t\t<value>true</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 配置失败自动切换实现方式 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.client.failover.proxy.provider.ns1</name>\n\t\t\t\t\t\t<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行-->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.ha.fencing.methods</name>\n\t\t\t\t\t\t<value>\n\t\t\t\t\t\t\tsshfence\n\t\t\t\t\t\t\tshell(/bin/true)(这样配置是为了测试返回的肯定是true)\n\t\t\t\t\t\t</value>\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 使用sshfence隔离机制时需要ssh免登陆 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.ha.fencing.ssh.private-key-files</name>\n\t\t\t\t\t\t<value>/home/hadoop/.ssh/id_rsa</value>(根据自己位置定)\n\t\t\t\t\t</property>\n\t\t\t\t\t<!-- 配置sshfence隔离机制超时时间 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>dfs.ha.fencing.ssh.connect-timeout</name>\n\t\t\t\t\t\t<value>30000</value>\n\t\t\t\t\t</property>\n\t\t\t\t</configuration>\n\t\t\t\n            \n3.修改mapred-site.xml\n\n\t\t\t\t<configuration>\n\t\t\t\t\t<!-- 指定mr框架为yarn方式 -->\n\t\t\t\t\t<property>\n\t\t\t\t\t\t<name>mapreduce.framework.name</name>\n\t\t\t\t\t\t<value>yarn</value>\n\t\t\t\t\t</property>\n\t\t\t\t</configuration>\t\n\t\t\t\n4.修改yarn-site.xml\n\n\t\t\t\t<configuration>\n\t\t\t\t\t\t<!-- 开启RM高可用 -->\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.ha.enabled</name>\n\t\t\t\t\t\t   <value>true</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<!-- 指定RM的cluster id -->\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.cluster-id</name>\n\t\t\t\t\t\t   <value>yrc</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<!-- 指定RM的名字 -->\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.ha.rm-ids</name>\n\t\t\t\t\t\t   <value>rm1,rm2</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<!-- 分别指定RM的地址 -->\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.hostname.rm1</name>\n\t\t\t\t\t\t   <value>hadoop03</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.hostname.rm2</name>\n\t\t\t\t\t\t   <value>hadoop04</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<!-- 指定zk集群地址 -->\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.resourcemanager.zk-address</name>\n\t\t\t\t\t\t   <value>hadoop05:2181,hadoop06:2181,hadoop07:2181</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t\t\t<property>\n\t\t\t\t\t\t   <name>yarn.nodemanager.aux-services</name>\n\t\t\t\t\t\t   <value>mapreduce_shuffle</value>\n\t\t\t\t\t\t</property>\n\t\t\t\t</configuration>\n\t\t\t\n\t\t\t\t\n5.修改slaves(slaves是指定子节点的位置，因为要在hadoop01上启动HDFS、在hadoop03启动yarn，所以hadoop01上的slaves文件指定的是datanode的位置，hadoop03上的slaves文件指定的是nodemanager的位置)\n\n\t\t\t\tweekend05\n\t\t\t\tweekend06\n\t\t\t\tweekend07\n\n6.配置免密码登陆\n\n\n\t #首先要配置hadoop01到hadoop02、hadoop03、hadoop04、hadoop05、hadoop06、hadoop07的免密码登陆\n    #配置hadoop03到hadoop04、hadoop05、hadoop06、hadoop07的免密码登陆\n    #注意：两个namenode之间要配置ssh免密码登陆，别忘了配置weekend02到weekend01的免登陆\n\t\t\t\t\t\t\t\n\t\t\n7.将配置好的hadoop拷贝到其他节点\n\n\t\t\t\n            \n            \n###注意：严格按照下面的步骤\n\n\t\t1.启动zookeeper集群（分别在hadoop05、hadoop06、hadoop07上启动zk）\n\t\t\tcd /weekend/zookeeper-3.4.5/bin/\n\t\t\t./zkServer.sh start\n\t\t\t#查看状态：一个leader，两个follower\n\t\t\t./zkServer.sh status\n\t\t\t\n\t\t2.启动journalnode（分别在在hadoop05、hadoop06、hadoop07上执行）\n\t\t\tcd /weekend/hadoop-2.4.1\n\t\t\tsbin/hadoop-daemon.sh start journalnode\n\t\t\t#运行jps命令检验，hadoop05、hadoop06、hadoop07上多了JournalNode进程\n\t\t\n\t\t3.格式化HDFS\n\t\t\t#在hadoop01上执行命令:\n\t\t\thdfs namenode -format\n\t\t\t#格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/cloud/hadoop-2.4.1/tmp，然后将/cloud/hadoop-2.4.1/tmp拷贝到hadoop02的/cloud/hadoop-2.4.1/下。\n\t\t\tscp -r tmp/ hadoop02:/cloud/hadoop-2.4.1/\n\t\t\t##也可以这样，建议hdfs namenode -bootstrapStandby\n\t\t\n\t\t4.格式化ZKFC(在hadoop01上执行即可)\n\t\t\thdfs zkfc -formatZK\n\t\t\n\t\t5.启动HDFS(在hadoop01上执行)\n\t\t\tsbin/start-dfs.sh\n\n\t\t6.启动YARN(#####注意#####：是在hadoop上执行start-yarn.sh，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动)\n\t\t\tsbin/start-yarn.sh\n\n\t\t\n8.到此，hadoop-2.4.1配置完毕，可以统计浏览器访问:\n\n\n\t\thttp://192.168.1.201:50070\n\t\tNameNode 'hadoop01:9000' (active)\n\t\thttp://192.168.1.202:50070\n\t\tNameNode 'hadoop02:9000' (standby)\n\t    验证HDFS HA\n\t\t首先向hdfs上传一个文件\n\t\thadoop fs -put /etc/profile /profile\n\t\thadoop fs -ls /\n\t\t然后再kill掉active的NameNode\n\t\tkill -9 <pid of NN>\n\t\t通过浏览器访问：http://192.168.1.202:50070\n\t\tNameNode 'hadoop02:9000' (active)\n\t\t这个时候hadoop02上的NameNode变成了active\n\t\t在执行命令：\n\t\thadoop fs -ls /\n\t\t-rw-r--r--   3 root supergroup       1926 2014-02-06 15:36 /profile\n\t\t刚才上传的文件依然存在！！！\n\t\t手动启动那个挂掉的NameNode\n\t\tsbin/hadoop-daemon.sh start namenode\n\t\t通过浏览器访问：http://192.168.1.201:50070\n\t\tNameNode 'hadoop01:9000' (standby)\n\t\n\t    验证YARN：\n\t\t运行一下hadoop提供的demo中的WordCount程序：\n\t\thadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar wordcount /profile /out\n\t\n\tOK，大功告成！！！\n\n\t\n\t\t\t\n\t\t\n9.测试集群工作状态的一些指令 ：\n\nbin/hdfs dfsadmin -report\t 查看hdfs的各节点状态信息\n\n\nbin/hdfs haadmin -getServiceState nn1\t\t 获取一个namenode节点的HA状态\n\nsbin/hadoop-daemon.sh start namenode  单独启动一个namenode进程\n\n\n./hadoop-daemon.sh start zkfc   单独启动一个zkfc进程\n","slug":"Hadoop-七-（HA高可用架构配置）","published":1,"updated":"2018-03-27T09:54:32.813Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60kn000dxo7kufhug235","content":"<h4 id=\"一、Zookeeper集群\"><a href=\"#一、Zookeeper集群\" class=\"headerlink\" title=\"一、Zookeeper集群\"></a>一、Zookeeper集群</h4><p>提供少量数据的存储和管理，类似树形目录，由很多node与data组成。解压安装后只需修改配置文件即可，conf目录下。</p>\n<h4 id=\"二、搭建高可用的原因\"><a href=\"#二、搭建高可用的原因\" class=\"headerlink\" title=\"二、搭建高可用的原因\"></a>二、搭建高可用的原因</h4><h6 id=\"1-之前一个NameNode节点肯定不行，但如果我们需要两个节点，肯定不能使两个在同一时间点响应请求。响应请求的必须是active状态。\"><a href=\"#1-之前一个NameNode节点肯定不行，但如果我们需要两个节点，肯定不能使两个在同一时间点响应请求。响应请求的必须是active状态。\" class=\"headerlink\" title=\"1.之前一个NameNode节点肯定不行，但如果我们需要两个节点，肯定不能使两个在同一时间点响应请求。响应请求的必须是active状态。\"></a>1.之前一个NameNode节点肯定不行，但如果我们需要两个节点，肯定不能使两个在同一时间点响应请求。响应请求的必须是active状态。</h6><h6 id=\"2-另外一个standby状态的节点如何做到迅速切换到active状态呢，意味着两个NameNode必须保持元数据相同，所以我们需要将edits分离出去，这样两个NameNode就可以保持一致了，考虑到高可用的分布式，那么这个edits肯定不能一份，所以需要做数据同步，这里hadoop提供了一套框架Qjournal-依赖zookeeper实现\"><a href=\"#2-另外一个standby状态的节点如何做到迅速切换到active状态呢，意味着两个NameNode必须保持元数据相同，所以我们需要将edits分离出去，这样两个NameNode就可以保持一致了，考虑到高可用的分布式，那么这个edits肯定不能一份，所以需要做数据同步，这里hadoop提供了一套框架Qjournal-依赖zookeeper实现\" class=\"headerlink\" title=\"2.另外一个standby状态的节点如何做到迅速切换到active状态呢，意味着两个NameNode必须保持元数据相同，所以我们需要将edits分离出去，这样两个NameNode就可以保持一致了，考虑到高可用的分布式，那么这个edits肯定不能一份，所以需要做数据同步，这里hadoop提供了一套框架Qjournal(依赖zookeeper实现)\"></a>2.另外一个standby状态的节点如何做到迅速切换到active状态呢，意味着两个NameNode必须保持元数据相同，所以我们需要将edits分离出去，这样两个NameNode就可以保持一致了，考虑到高可用的分布式，那么这个edits肯定不能一份，所以需要做数据同步，这里hadoop提供了一套框架Qjournal(依赖zookeeper实现)</h6><h6 id=\"3-但要做到切换，在什么状态下切换，我们需要一个监控进程来监控NameNode，在hadoop中我们把这叫做zkfc-但有时候可能active的机器并没有真正死亡，这个时候如果切换了，便会发生“脑裂”。解决方法是发送一条指令，通过ssh来kill那个进程，获取返回值来确定，如果拿不到返回值可以执行自定义shell脚本程序关闭电源啊什么什么的，称为fencing机制。\"><a href=\"#3-但要做到切换，在什么状态下切换，我们需要一个监控进程来监控NameNode，在hadoop中我们把这叫做zkfc-但有时候可能active的机器并没有真正死亡，这个时候如果切换了，便会发生“脑裂”。解决方法是发送一条指令，通过ssh来kill那个进程，获取返回值来确定，如果拿不到返回值可以执行自定义shell脚本程序关闭电源啊什么什么的，称为fencing机制。\" class=\"headerlink\" title=\"3.但要做到切换，在什么状态下切换，我们需要一个监控进程来监控NameNode，在hadoop中我们把这叫做zkfc,但有时候可能active的机器并没有真正死亡，这个时候如果切换了，便会发生“脑裂”。解决方法是发送一条指令，通过ssh来kill那个进程，获取返回值来确定，如果拿不到返回值可以执行自定义shell脚本程序关闭电源啊什么什么的，称为fencing机制。\"></a>3.但要做到切换，在什么状态下切换，我们需要一个监控进程来监控NameNode，在hadoop中我们把这叫做zkfc,但有时候可能active的机器并没有真正死亡，这个时候如果切换了，便会发生“脑裂”。解决方法是发送一条指令，通过ssh来kill那个进程，获取返回值来确定，如果拿不到返回值可以执行自定义shell脚本程序关闭电源啊什么什么的，称为fencing机制。</h6><h6 id=\"4-另外两个NameNode可以构建一个Federation-在core-site-xml里面就需要配置路径为hdfs-nameservice名称，系统可以有多个Federation来扩大集群规模。\"><a href=\"#4-另外两个NameNode可以构建一个Federation-在core-site-xml里面就需要配置路径为hdfs-nameservice名称，系统可以有多个Federation来扩大集群规模。\" class=\"headerlink\" title=\"4.另外两个NameNode可以构建一个Federation,在core-site.xml里面就需要配置路径为hdfs://nameservice名称，系统可以有多个Federation来扩大集群规模。\"></a>4.另外两个NameNode可以构建一个Federation,在core-site.xml里面就需要配置路径为hdfs://nameservice名称，系统可以有多个Federation来扩大集群规模。</h6><h4 id=\"三、配置\"><a href=\"#三、配置\" class=\"headerlink\" title=\"三、配置\"></a>三、配置</h4><p>1.修改core-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;!-- 指定hdfs的nameservice为ns1 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;/name&gt;\n        &lt;value&gt;hdfs://ns1/&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 指定hadoop临时目录 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n        &lt;value&gt;/clould/hadoop-2.4.1/tmp&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 指定zookeeper地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;\n   &lt;value&gt;hadoop05:2181,hadoop06:2181,hadoop07:2181&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>2.修改hdfs-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.nameservices&lt;/name&gt;\n        &lt;value&gt;ns1&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;\n        &lt;value&gt;nn1,nn2&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- nn1的RPC通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;\n        &lt;value&gt;hadoop01:9000&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- nn1的http通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;\n        &lt;value&gt;hadoop01:50070&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- nn2的RPC通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;\n        &lt;value&gt;hadoop02:9000&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- nn2的http通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;\n        &lt;value&gt;hadoop02:50070&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;\n        &lt;value&gt;qjournal://hadoop05:8485;hadoop06:8485;hadoop07:8485/ns1&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;\n        &lt;value&gt;/cloud/hadoop-2.4.1/journaldata&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 开启NameNode失败自动切换 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 配置失败自动切换实现方式 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;\n        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;\n        &lt;value&gt;\n            sshfence\n            shell(/bin/true)(这样配置是为了测试返回的肯定是true)\n        &lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;\n        &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;(根据自己位置定)\n    &lt;/property&gt;\n    &lt;!-- 配置sshfence隔离机制超时时间 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;\n        &lt;value&gt;30000&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>3.修改mapred-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;!-- 指定mr框架为yarn方式 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n        &lt;value&gt;yarn&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;    \n</code></pre><p>4.修改yarn-site.xml</p>\n<pre><code>&lt;configuration&gt;\n        &lt;!-- 开启RM高可用 --&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;\n           &lt;value&gt;true&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- 指定RM的cluster id --&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;\n           &lt;value&gt;yrc&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- 指定RM的名字 --&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;\n           &lt;value&gt;rm1,rm2&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- 分别指定RM的地址 --&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;\n           &lt;value&gt;hadoop03&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;\n           &lt;value&gt;hadoop04&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- 指定zk集群地址 --&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;\n           &lt;value&gt;hadoop05:2181,hadoop06:2181,hadoop07:2181&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n           &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n        &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>5.修改slaves(slaves是指定子节点的位置，因为要在hadoop01上启动HDFS、在hadoop03启动yarn，所以hadoop01上的slaves文件指定的是datanode的位置，hadoop03上的slaves文件指定的是nodemanager的位置)</p>\n<pre><code>weekend05\nweekend06\nweekend07\n</code></pre><p>6.配置免密码登陆</p>\n<pre><code> #首先要配置hadoop01到hadoop02、hadoop03、hadoop04、hadoop05、hadoop06、hadoop07的免密码登陆\n#配置hadoop03到hadoop04、hadoop05、hadoop06、hadoop07的免密码登陆\n#注意：两个namenode之间要配置ssh免密码登陆，别忘了配置weekend02到weekend01的免登陆\n</code></pre><p>7.将配置好的hadoop拷贝到其他节点</p>\n<p>###注意：严格按照下面的步骤</p>\n<pre><code>1.启动zookeeper集群（分别在hadoop05、hadoop06、hadoop07上启动zk）\n    cd /weekend/zookeeper-3.4.5/bin/\n    ./zkServer.sh start\n    #查看状态：一个leader，两个follower\n    ./zkServer.sh status\n\n2.启动journalnode（分别在在hadoop05、hadoop06、hadoop07上执行）\n    cd /weekend/hadoop-2.4.1\n    sbin/hadoop-daemon.sh start journalnode\n    #运行jps命令检验，hadoop05、hadoop06、hadoop07上多了JournalNode进程\n\n3.格式化HDFS\n    #在hadoop01上执行命令:\n    hdfs namenode -format\n    #格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/cloud/hadoop-2.4.1/tmp，然后将/cloud/hadoop-2.4.1/tmp拷贝到hadoop02的/cloud/hadoop-2.4.1/下。\n    scp -r tmp/ hadoop02:/cloud/hadoop-2.4.1/\n    ##也可以这样，建议hdfs namenode -bootstrapStandby\n\n4.格式化ZKFC(在hadoop01上执行即可)\n    hdfs zkfc -formatZK\n\n5.启动HDFS(在hadoop01上执行)\n    sbin/start-dfs.sh\n\n6.启动YARN(#####注意#####：是在hadoop上执行start-yarn.sh，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动)\n    sbin/start-yarn.sh\n</code></pre><p>8.到此，hadoop-2.4.1配置完毕，可以统计浏览器访问:</p>\n<pre><code>    http://192.168.1.201:50070\n    NameNode &apos;hadoop01:9000&apos; (active)\n    http://192.168.1.202:50070\n    NameNode &apos;hadoop02:9000&apos; (standby)\n    验证HDFS HA\n    首先向hdfs上传一个文件\n    hadoop fs -put /etc/profile /profile\n    hadoop fs -ls /\n    然后再kill掉active的NameNode\n    kill -9 &lt;pid of NN&gt;\n    通过浏览器访问：http://192.168.1.202:50070\n    NameNode &apos;hadoop02:9000&apos; (active)\n    这个时候hadoop02上的NameNode变成了active\n    在执行命令：\n    hadoop fs -ls /\n    -rw-r--r--   3 root supergroup       1926 2014-02-06 15:36 /profile\n    刚才上传的文件依然存在！！！\n    手动启动那个挂掉的NameNode\n    sbin/hadoop-daemon.sh start namenode\n    通过浏览器访问：http://192.168.1.201:50070\n    NameNode &apos;hadoop01:9000&apos; (standby)\n\n    验证YARN：\n    运行一下hadoop提供的demo中的WordCount程序：\n    hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar wordcount /profile /out\n\nOK，大功告成！！！\n</code></pre><p>9.测试集群工作状态的一些指令 ：</p>\n<p>bin/hdfs dfsadmin -report     查看hdfs的各节点状态信息</p>\n<p>bin/hdfs haadmin -getServiceState nn1         获取一个namenode节点的HA状态</p>\n<p>sbin/hadoop-daemon.sh start namenode  单独启动一个namenode进程</p>\n<p>./hadoop-daemon.sh start zkfc   单独启动一个zkfc进程</p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"一、Zookeeper集群\"><a href=\"#一、Zookeeper集群\" class=\"headerlink\" title=\"一、Zookeeper集群\"></a>一、Zookeeper集群</h4><p>提供少量数据的存储和管理，类似树形目录，由很多node与data组成。解压安装后只需修改配置文件即可，conf目录下。</p>\n<h4 id=\"二、搭建高可用的原因\"><a href=\"#二、搭建高可用的原因\" class=\"headerlink\" title=\"二、搭建高可用的原因\"></a>二、搭建高可用的原因</h4><h6 id=\"1-之前一个NameNode节点肯定不行，但如果我们需要两个节点，肯定不能使两个在同一时间点响应请求。响应请求的必须是active状态。\"><a href=\"#1-之前一个NameNode节点肯定不行，但如果我们需要两个节点，肯定不能使两个在同一时间点响应请求。响应请求的必须是active状态。\" class=\"headerlink\" title=\"1.之前一个NameNode节点肯定不行，但如果我们需要两个节点，肯定不能使两个在同一时间点响应请求。响应请求的必须是active状态。\"></a>1.之前一个NameNode节点肯定不行，但如果我们需要两个节点，肯定不能使两个在同一时间点响应请求。响应请求的必须是active状态。</h6><h6 id=\"2-另外一个standby状态的节点如何做到迅速切换到active状态呢，意味着两个NameNode必须保持元数据相同，所以我们需要将edits分离出去，这样两个NameNode就可以保持一致了，考虑到高可用的分布式，那么这个edits肯定不能一份，所以需要做数据同步，这里hadoop提供了一套框架Qjournal-依赖zookeeper实现\"><a href=\"#2-另外一个standby状态的节点如何做到迅速切换到active状态呢，意味着两个NameNode必须保持元数据相同，所以我们需要将edits分离出去，这样两个NameNode就可以保持一致了，考虑到高可用的分布式，那么这个edits肯定不能一份，所以需要做数据同步，这里hadoop提供了一套框架Qjournal-依赖zookeeper实现\" class=\"headerlink\" title=\"2.另外一个standby状态的节点如何做到迅速切换到active状态呢，意味着两个NameNode必须保持元数据相同，所以我们需要将edits分离出去，这样两个NameNode就可以保持一致了，考虑到高可用的分布式，那么这个edits肯定不能一份，所以需要做数据同步，这里hadoop提供了一套框架Qjournal(依赖zookeeper实现)\"></a>2.另外一个standby状态的节点如何做到迅速切换到active状态呢，意味着两个NameNode必须保持元数据相同，所以我们需要将edits分离出去，这样两个NameNode就可以保持一致了，考虑到高可用的分布式，那么这个edits肯定不能一份，所以需要做数据同步，这里hadoop提供了一套框架Qjournal(依赖zookeeper实现)</h6><h6 id=\"3-但要做到切换，在什么状态下切换，我们需要一个监控进程来监控NameNode，在hadoop中我们把这叫做zkfc-但有时候可能active的机器并没有真正死亡，这个时候如果切换了，便会发生“脑裂”。解决方法是发送一条指令，通过ssh来kill那个进程，获取返回值来确定，如果拿不到返回值可以执行自定义shell脚本程序关闭电源啊什么什么的，称为fencing机制。\"><a href=\"#3-但要做到切换，在什么状态下切换，我们需要一个监控进程来监控NameNode，在hadoop中我们把这叫做zkfc-但有时候可能active的机器并没有真正死亡，这个时候如果切换了，便会发生“脑裂”。解决方法是发送一条指令，通过ssh来kill那个进程，获取返回值来确定，如果拿不到返回值可以执行自定义shell脚本程序关闭电源啊什么什么的，称为fencing机制。\" class=\"headerlink\" title=\"3.但要做到切换，在什么状态下切换，我们需要一个监控进程来监控NameNode，在hadoop中我们把这叫做zkfc,但有时候可能active的机器并没有真正死亡，这个时候如果切换了，便会发生“脑裂”。解决方法是发送一条指令，通过ssh来kill那个进程，获取返回值来确定，如果拿不到返回值可以执行自定义shell脚本程序关闭电源啊什么什么的，称为fencing机制。\"></a>3.但要做到切换，在什么状态下切换，我们需要一个监控进程来监控NameNode，在hadoop中我们把这叫做zkfc,但有时候可能active的机器并没有真正死亡，这个时候如果切换了，便会发生“脑裂”。解决方法是发送一条指令，通过ssh来kill那个进程，获取返回值来确定，如果拿不到返回值可以执行自定义shell脚本程序关闭电源啊什么什么的，称为fencing机制。</h6><h6 id=\"4-另外两个NameNode可以构建一个Federation-在core-site-xml里面就需要配置路径为hdfs-nameservice名称，系统可以有多个Federation来扩大集群规模。\"><a href=\"#4-另外两个NameNode可以构建一个Federation-在core-site-xml里面就需要配置路径为hdfs-nameservice名称，系统可以有多个Federation来扩大集群规模。\" class=\"headerlink\" title=\"4.另外两个NameNode可以构建一个Federation,在core-site.xml里面就需要配置路径为hdfs://nameservice名称，系统可以有多个Federation来扩大集群规模。\"></a>4.另外两个NameNode可以构建一个Federation,在core-site.xml里面就需要配置路径为hdfs://nameservice名称，系统可以有多个Federation来扩大集群规模。</h6><h4 id=\"三、配置\"><a href=\"#三、配置\" class=\"headerlink\" title=\"三、配置\"></a>三、配置</h4><p>1.修改core-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;!-- 指定hdfs的nameservice为ns1 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;/name&gt;\n        &lt;value&gt;hdfs://ns1/&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 指定hadoop临时目录 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n        &lt;value&gt;/clould/hadoop-2.4.1/tmp&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;!-- 指定zookeeper地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;\n   &lt;value&gt;hadoop05:2181,hadoop06:2181,hadoop07:2181&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>2.修改hdfs-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.nameservices&lt;/name&gt;\n        &lt;value&gt;ns1&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;\n        &lt;value&gt;nn1,nn2&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- nn1的RPC通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;\n        &lt;value&gt;hadoop01:9000&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- nn1的http通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;\n        &lt;value&gt;hadoop01:50070&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- nn2的RPC通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;\n        &lt;value&gt;hadoop02:9000&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- nn2的http通信地址 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;\n        &lt;value&gt;hadoop02:50070&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;\n        &lt;value&gt;qjournal://hadoop05:8485;hadoop06:8485;hadoop07:8485/ns1&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;\n        &lt;value&gt;/cloud/hadoop-2.4.1/journaldata&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 开启NameNode失败自动切换 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 配置失败自动切换实现方式 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;\n        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;\n        &lt;value&gt;\n            sshfence\n            shell(/bin/true)(这样配置是为了测试返回的肯定是true)\n        &lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;\n        &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;(根据自己位置定)\n    &lt;/property&gt;\n    &lt;!-- 配置sshfence隔离机制超时时间 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;\n        &lt;value&gt;30000&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>3.修改mapred-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;!-- 指定mr框架为yarn方式 --&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n        &lt;value&gt;yarn&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;    \n</code></pre><p>4.修改yarn-site.xml</p>\n<pre><code>&lt;configuration&gt;\n        &lt;!-- 开启RM高可用 --&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;\n           &lt;value&gt;true&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- 指定RM的cluster id --&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;\n           &lt;value&gt;yrc&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- 指定RM的名字 --&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;\n           &lt;value&gt;rm1,rm2&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- 分别指定RM的地址 --&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;\n           &lt;value&gt;hadoop03&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;\n           &lt;value&gt;hadoop04&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- 指定zk集群地址 --&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;\n           &lt;value&gt;hadoop05:2181,hadoop06:2181,hadoop07:2181&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n           &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n           &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n        &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>5.修改slaves(slaves是指定子节点的位置，因为要在hadoop01上启动HDFS、在hadoop03启动yarn，所以hadoop01上的slaves文件指定的是datanode的位置，hadoop03上的slaves文件指定的是nodemanager的位置)</p>\n<pre><code>weekend05\nweekend06\nweekend07\n</code></pre><p>6.配置免密码登陆</p>\n<pre><code> #首先要配置hadoop01到hadoop02、hadoop03、hadoop04、hadoop05、hadoop06、hadoop07的免密码登陆\n#配置hadoop03到hadoop04、hadoop05、hadoop06、hadoop07的免密码登陆\n#注意：两个namenode之间要配置ssh免密码登陆，别忘了配置weekend02到weekend01的免登陆\n</code></pre><p>7.将配置好的hadoop拷贝到其他节点</p>\n<p>###注意：严格按照下面的步骤</p>\n<pre><code>1.启动zookeeper集群（分别在hadoop05、hadoop06、hadoop07上启动zk）\n    cd /weekend/zookeeper-3.4.5/bin/\n    ./zkServer.sh start\n    #查看状态：一个leader，两个follower\n    ./zkServer.sh status\n\n2.启动journalnode（分别在在hadoop05、hadoop06、hadoop07上执行）\n    cd /weekend/hadoop-2.4.1\n    sbin/hadoop-daemon.sh start journalnode\n    #运行jps命令检验，hadoop05、hadoop06、hadoop07上多了JournalNode进程\n\n3.格式化HDFS\n    #在hadoop01上执行命令:\n    hdfs namenode -format\n    #格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/cloud/hadoop-2.4.1/tmp，然后将/cloud/hadoop-2.4.1/tmp拷贝到hadoop02的/cloud/hadoop-2.4.1/下。\n    scp -r tmp/ hadoop02:/cloud/hadoop-2.4.1/\n    ##也可以这样，建议hdfs namenode -bootstrapStandby\n\n4.格式化ZKFC(在hadoop01上执行即可)\n    hdfs zkfc -formatZK\n\n5.启动HDFS(在hadoop01上执行)\n    sbin/start-dfs.sh\n\n6.启动YARN(#####注意#####：是在hadoop上执行start-yarn.sh，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动)\n    sbin/start-yarn.sh\n</code></pre><p>8.到此，hadoop-2.4.1配置完毕，可以统计浏览器访问:</p>\n<pre><code>    http://192.168.1.201:50070\n    NameNode &apos;hadoop01:9000&apos; (active)\n    http://192.168.1.202:50070\n    NameNode &apos;hadoop02:9000&apos; (standby)\n    验证HDFS HA\n    首先向hdfs上传一个文件\n    hadoop fs -put /etc/profile /profile\n    hadoop fs -ls /\n    然后再kill掉active的NameNode\n    kill -9 &lt;pid of NN&gt;\n    通过浏览器访问：http://192.168.1.202:50070\n    NameNode &apos;hadoop02:9000&apos; (active)\n    这个时候hadoop02上的NameNode变成了active\n    在执行命令：\n    hadoop fs -ls /\n    -rw-r--r--   3 root supergroup       1926 2014-02-06 15:36 /profile\n    刚才上传的文件依然存在！！！\n    手动启动那个挂掉的NameNode\n    sbin/hadoop-daemon.sh start namenode\n    通过浏览器访问：http://192.168.1.201:50070\n    NameNode &apos;hadoop01:9000&apos; (standby)\n\n    验证YARN：\n    运行一下hadoop提供的demo中的WordCount程序：\n    hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar wordcount /profile /out\n\nOK，大功告成！！！\n</code></pre><p>9.测试集群工作状态的一些指令 ：</p>\n<p>bin/hdfs dfsadmin -report     查看hdfs的各节点状态信息</p>\n<p>bin/hdfs haadmin -getServiceState nn1         获取一个namenode节点的HA状态</p>\n<p>sbin/hadoop-daemon.sh start namenode  单独启动一个namenode进程</p>\n<p>./hadoop-daemon.sh start zkfc   单独启动一个zkfc进程</p>\n"},{"title":"First Diary","author":"小小冰弟","date":"2018-02-05T02:52:51.000Z","_content":"<center>第一篇日记</center>\n\n随便写点啥，就说点对去年的总结吧，去年过得浑浑噩噩，曾心比天高，也许是太贪心了吧，什么都没做好，这也不是第一次吃这种亏了，还是同一条河流，不过这次我差点就溺死了，呵呵，人哪，真是个可笑的动物，尤其是我这般人。过去的就让它过去吧，我不怕跌倒，我只害怕自己再没爬起来的勇气，新的一年，我可以飞得更高。","source":"_posts/First-Diary.md","raw":"title: First Diary\nauthor: 小小冰弟\ntags: live\ncategories: diary\ndate: 2018-02-05 10:52:51\n---\n<center>第一篇日记</center>\n\n随便写点啥，就说点对去年的总结吧，去年过得浑浑噩噩，曾心比天高，也许是太贪心了吧，什么都没做好，这也不是第一次吃这种亏了，还是同一条河流，不过这次我差点就溺死了，呵呵，人哪，真是个可笑的动物，尤其是我这般人。过去的就让它过去吧，我不怕跌倒，我只害怕自己再没爬起来的勇气，新的一年，我可以飞得更高。","slug":"First-Diary","published":1,"updated":"2018-03-26T09:46:34.646Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60kq000fxo7ki6piatl1","content":"<center>第一篇日记</center>\n\n<p>随便写点啥，就说点对去年的总结吧，去年过得浑浑噩噩，曾心比天高，也许是太贪心了吧，什么都没做好，这也不是第一次吃这种亏了，还是同一条河流，不过这次我差点就溺死了，呵呵，人哪，真是个可笑的动物，尤其是我这般人。过去的就让它过去吧，我不怕跌倒，我只害怕自己再没爬起来的勇气，新的一年，我可以飞得更高。</p>\n","site":{"data":{}},"excerpt":"","more":"<center>第一篇日记</center>\n\n<p>随便写点啥，就说点对去年的总结吧，去年过得浑浑噩噩，曾心比天高，也许是太贪心了吧，什么都没做好，这也不是第一次吃这种亏了，还是同一条河流，不过这次我差点就溺死了，呵呵，人哪，真是个可笑的动物，尤其是我这般人。过去的就让它过去吧，我不怕跌倒，我只害怕自己再没爬起来的勇气，新的一年，我可以飞得更高。</p>\n"},{"title":"Hadoop(三)（Hdfs的上传与存储机制防止宕机）","author":"小小冰弟","date":"2018-02-07T10:15:26.000Z","_content":"###### HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。\n\n\n###### NameNode保存元信息的种类有：\n\n* 文件名目录名及它们之间的层级关系\n* 文件目录的所有者及其权限\n* 每个文件块的名及文件有哪些块组成\n\n\n###### Secondary用来进行fsimage与edit.log的合并操作\n\n###### DataNode主要保存block即分割的块状文件\n\n###### 简要分析HDFS的文件上传机制：\n\n1. 客户端发送上传文件请求，通知NameNode,NameNode检查没有问题回传客户端OK.\n2. 客户端开始上传文件，NameNode向edit.log文件中记录操作日志。\n3. 客户端完成上传返回成功信息，NameNode便向内存中写入本次操作产生的元数据内容，方便读取。\n4. 当edit.log满的时候，NameNode便会通知SecondaryNode进行checkPoint操作(为了不影响主机性能，重开一台服务器，因为转换需要消耗内存)。\n5. SN同意操作便会通知NN让其停止往edit.log中写入日志，但不能避免还有其它上传，所以NN便会生成一个newedit.log,来替代之前的满的edit.log的工作.\n6. 接着SN下载fsimage(磁盘文件)与edit.log到本节点上进行合并操作，生成new_fsimage文件，再上传至NN上。\n7. NN替换fsimage并且删除edit.log,并且将newedit.log更名为edit.log.","source":"_posts/Hadoop-三.md","raw":"title: Hadoop(三)（Hdfs的上传与存储机制防止宕机）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-02-07 18:15:26\n---\n###### HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。\n\n\n###### NameNode保存元信息的种类有：\n\n* 文件名目录名及它们之间的层级关系\n* 文件目录的所有者及其权限\n* 每个文件块的名及文件有哪些块组成\n\n\n###### Secondary用来进行fsimage与edit.log的合并操作\n\n###### DataNode主要保存block即分割的块状文件\n\n###### 简要分析HDFS的文件上传机制：\n\n1. 客户端发送上传文件请求，通知NameNode,NameNode检查没有问题回传客户端OK.\n2. 客户端开始上传文件，NameNode向edit.log文件中记录操作日志。\n3. 客户端完成上传返回成功信息，NameNode便向内存中写入本次操作产生的元数据内容，方便读取。\n4. 当edit.log满的时候，NameNode便会通知SecondaryNode进行checkPoint操作(为了不影响主机性能，重开一台服务器，因为转换需要消耗内存)。\n5. SN同意操作便会通知NN让其停止往edit.log中写入日志，但不能避免还有其它上传，所以NN便会生成一个newedit.log,来替代之前的满的edit.log的工作.\n6. 接着SN下载fsimage(磁盘文件)与edit.log到本节点上进行合并操作，生成new_fsimage文件，再上传至NN上。\n7. NN替换fsimage并且删除edit.log,并且将newedit.log更名为edit.log.","slug":"Hadoop-三","published":1,"updated":"2018-03-26T09:46:34.649Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60kt000kxo7kk185ao38","content":"<h6 id=\"HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master-slave模式运行的，其中NameNode、SecondaryNameNode-运行在master节点，DataNode运行slave节点。\"><a href=\"#HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master-slave模式运行的，其中NameNode、SecondaryNameNode-运行在master节点，DataNode运行slave节点。\" class=\"headerlink\" title=\"HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。\"></a>HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。</h6><h6 id=\"NameNode保存元信息的种类有：\"><a href=\"#NameNode保存元信息的种类有：\" class=\"headerlink\" title=\"NameNode保存元信息的种类有：\"></a>NameNode保存元信息的种类有：</h6><ul>\n<li>文件名目录名及它们之间的层级关系</li>\n<li>文件目录的所有者及其权限</li>\n<li>每个文件块的名及文件有哪些块组成</li>\n</ul>\n<h6 id=\"Secondary用来进行fsimage与edit-log的合并操作\"><a href=\"#Secondary用来进行fsimage与edit-log的合并操作\" class=\"headerlink\" title=\"Secondary用来进行fsimage与edit.log的合并操作\"></a>Secondary用来进行fsimage与edit.log的合并操作</h6><h6 id=\"DataNode主要保存block即分割的块状文件\"><a href=\"#DataNode主要保存block即分割的块状文件\" class=\"headerlink\" title=\"DataNode主要保存block即分割的块状文件\"></a>DataNode主要保存block即分割的块状文件</h6><h6 id=\"简要分析HDFS的文件上传机制：\"><a href=\"#简要分析HDFS的文件上传机制：\" class=\"headerlink\" title=\"简要分析HDFS的文件上传机制：\"></a>简要分析HDFS的文件上传机制：</h6><ol>\n<li>客户端发送上传文件请求，通知NameNode,NameNode检查没有问题回传客户端OK.</li>\n<li>客户端开始上传文件，NameNode向edit.log文件中记录操作日志。</li>\n<li>客户端完成上传返回成功信息，NameNode便向内存中写入本次操作产生的元数据内容，方便读取。</li>\n<li>当edit.log满的时候，NameNode便会通知SecondaryNode进行checkPoint操作(为了不影响主机性能，重开一台服务器，因为转换需要消耗内存)。</li>\n<li>SN同意操作便会通知NN让其停止往edit.log中写入日志，但不能避免还有其它上传，所以NN便会生成一个newedit.log,来替代之前的满的edit.log的工作.</li>\n<li>接着SN下载fsimage(磁盘文件)与edit.log到本节点上进行合并操作，生成new_fsimage文件，再上传至NN上。</li>\n<li>NN替换fsimage并且删除edit.log,并且将newedit.log更名为edit.log.</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h6 id=\"HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master-slave模式运行的，其中NameNode、SecondaryNameNode-运行在master节点，DataNode运行slave节点。\"><a href=\"#HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master-slave模式运行的，其中NameNode、SecondaryNameNode-运行在master节点，DataNode运行slave节点。\" class=\"headerlink\" title=\"HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。\"></a>HDFS简介：HDFS主要由3个组件构成，分别是NameNode、SecondaryNameNode和DataNode，HSFS是以master/slave模式运行的，其中NameNode、SecondaryNameNode 运行在master节点，DataNode运行slave节点。</h6><h6 id=\"NameNode保存元信息的种类有：\"><a href=\"#NameNode保存元信息的种类有：\" class=\"headerlink\" title=\"NameNode保存元信息的种类有：\"></a>NameNode保存元信息的种类有：</h6><ul>\n<li>文件名目录名及它们之间的层级关系</li>\n<li>文件目录的所有者及其权限</li>\n<li>每个文件块的名及文件有哪些块组成</li>\n</ul>\n<h6 id=\"Secondary用来进行fsimage与edit-log的合并操作\"><a href=\"#Secondary用来进行fsimage与edit-log的合并操作\" class=\"headerlink\" title=\"Secondary用来进行fsimage与edit.log的合并操作\"></a>Secondary用来进行fsimage与edit.log的合并操作</h6><h6 id=\"DataNode主要保存block即分割的块状文件\"><a href=\"#DataNode主要保存block即分割的块状文件\" class=\"headerlink\" title=\"DataNode主要保存block即分割的块状文件\"></a>DataNode主要保存block即分割的块状文件</h6><h6 id=\"简要分析HDFS的文件上传机制：\"><a href=\"#简要分析HDFS的文件上传机制：\" class=\"headerlink\" title=\"简要分析HDFS的文件上传机制：\"></a>简要分析HDFS的文件上传机制：</h6><ol>\n<li>客户端发送上传文件请求，通知NameNode,NameNode检查没有问题回传客户端OK.</li>\n<li>客户端开始上传文件，NameNode向edit.log文件中记录操作日志。</li>\n<li>客户端完成上传返回成功信息，NameNode便向内存中写入本次操作产生的元数据内容，方便读取。</li>\n<li>当edit.log满的时候，NameNode便会通知SecondaryNode进行checkPoint操作(为了不影响主机性能，重开一台服务器，因为转换需要消耗内存)。</li>\n<li>SN同意操作便会通知NN让其停止往edit.log中写入日志，但不能避免还有其它上传，所以NN便会生成一个newedit.log,来替代之前的满的edit.log的工作.</li>\n<li>接着SN下载fsimage(磁盘文件)与edit.log到本节点上进行合并操作，生成new_fsimage文件，再上传至NN上。</li>\n<li>NN替换fsimage并且删除edit.log,并且将newedit.log更名为edit.log.</li>\n</ol>\n"},{"title":"Hadoop(九)（HBase）","author":"小小冰弟","date":"2018-03-28T09:43:17.000Z","_content":"#### 一、HBase\n&nbsp;&nbsp;与HDFS相比较，它是数据库，HDFS文件系统，普通文件不能支持快速读写，当你需要随机，实时读写访问便需要HBase了。另外HBase基本无事务特性，复杂的步骤也不适合，它的优势是可以hold住很大的表，几十亿行，几百万列。\n\n#### 二、关系型数据库\n相对于传统的关系型数据库，它建表时，不需要限定表中的字段，只需要指定若干个列族，插入数据时，列族中可以存储任意多个列，每一行有个唯一的行键，当要查询某一字段的值时（成为cell），需要指定坐标，表名>行键>列名>版本号（一个value可以有多个版本号，通过版本号区分）\n\n#### 三、Hbase集群\n每一个表在HBase中会被按照行键拆分，比如1~10000，10001~20000这样，每一个称为一个region,region存在region server上面，region的底层文件还是存在HDFS上面，众多的region server需要一个协调者，HMaser不负责存储数据，管理region server.\n\n这里你会疑问，那么多的region,它怎么找到呢？先将1~10000，10001~20000，20001~30000，30001~40000的位置存放在META表中，分为1~~20000，20001~~40000两份，然后再合并为1~~~~40000存放在Root表上，而Root表放在Zookeeper上存储\n\n#### 四、HBase命令行使用\n\n    进入hbase命令行\n    ./hbase shell\n\n    显示hbase中的表\n    list\n\n    创建user表，包含info、data两个列族\n    create 'user', 'info1', 'data1'\n    create 'user', {NAME => 'info', VERSIONS => '3'}\n\n    向user表中插入信息，row key为rk0001，列族info中添加name列标示符，值为zhangsan\n    put 'user', 'rk0001', 'info:name', 'zhangsan'\n\n    向user表中插入信息，row key为rk0001，列族info中添加gender列标示符，值为female\n    put 'user', 'rk0001', 'info:gender', 'female'\n\n    向user表中插入信息，row key为rk0001，列族info中添加age列标示符，值为20\n    put 'user', 'rk0001', 'info:age', 20\n\n    向user表中插入信息，row key为rk0001，列族data中添加pic列标示符，值为picture\n    put 'user', 'rk0001', 'data:pic', 'picture'\n\n    获取user表中row key为rk0001的所有信息\n    get 'user', 'rk0001'\n\n    获取user表中row key为rk0001，info列族的所有信息\n    get 'user', 'rk0001', 'info'\n\n    获取user表中row key为rk0001，info列族的name、age列标示符的信息\n    get 'user', 'rk0001', 'info:name', 'info:age'\n\n    获取user表中row key为rk0001，info、data列族的信息\n    get 'user', 'rk0001', 'info', 'data'\n    get 'user', 'rk0001', {COLUMN => ['info', 'data']}\n\n    get 'user', 'rk0001', {COLUMN => ['info:name', 'data:pic']}\n\n    获取user表中row key为rk0001，列族为info，版本号最新5个的信息\n    get 'user', 'rk0001', {COLUMN => 'info', VERSIONS => 2}\n    get 'user', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5}\n    get 'user', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5, TIMERANGE => [1392368783980, 1392380169184]}\n\n    获取user表中row key为rk0001，cell的值为zhangsan的信息\n    get 'people', 'rk0001', {FILTER => \"ValueFilter(=, 'binary:图片')\"}\n\n    获取user表中row key为rk0001，列标示符中含有a的信息\n    get 'people', 'rk0001', {FILTER => \"(QualifierFilter(=,'substring:a'))\"}\n\n    put 'user', 'rk0002', 'info:name', 'fanbingbing'\n    put 'user', 'rk0002', 'info:gender', 'female'\n    put 'user', 'rk0002', 'info:nationality', '中国'\n    get 'user', 'rk0002', {FILTER => \"ValueFilter(=, 'binary:中国')\"}\n\n\n    查询user表中的所有信息\n    scan 'user'\n\n    查询user表中列族为info的信息\n    scan 'user', {COLUMNS => 'info'}\n    scan 'user', {COLUMNS => 'info', RAW => true, VERSIONS => 5}\n    scan 'persion', {COLUMNS => 'info', RAW => true, VERSIONS => 3}\n    查询user表中列族为info和data的信息\n    scan 'user', {COLUMNS => ['info', 'data']}\n    scan 'user', {COLUMNS => ['info:name', 'data:pic']}\n\n\n    查询user表中列族为info、列标示符为name的信息\n    scan 'user', {COLUMNS => 'info:name'}\n\n    查询user表中列族为info、列标示符为name的信息,并且版本最新的5个\n    scan 'user', {COLUMNS => 'info:name', VERSIONS => 5}\n\n    查询user表中列族为info和data且列标示符中含有a字符的信息\n    scan 'user', {COLUMNS => ['info', 'data'], FILTER => \"(QualifierFilter(=,'substring:a'))\"}\n\n    查询user表中列族为info，rk范围是[rk0001, rk0003)的数据\n    scan 'people', {COLUMNS => 'info', STARTROW => 'rk0001', ENDROW => 'rk0003'}\n\n    查询user表中row key以rk字符开头的\n    scan 'user',{FILTER=>\"PrefixFilter('rk')\"}\n\n    查询user表中指定范围的数据\n    scan 'user', {TIMERANGE => [1392368783980, 1392380169184]}\n\n    删除数据\n    删除user表row key为rk0001，列标示符为info:name的数据\n    delete 'people', 'rk0001', 'info:name'\n    删除user表row key为rk0001，列标示符为info:name，timestamp为1392383705316的数据\n    delete 'user', 'rk0001', 'info:name', 1392383705316\n\n\n    清空user表中的数据\n    truncate 'people'\n\n\n    修改表结构\n    首先停用user表（新版本不用）\n    disable 'user'\n\n    添加两个列族f1和f2\n    alter 'people', NAME => 'f1'\n    alter 'user', NAME => 'f2'\n    启用表\n    enable 'user'\n\n\n    ###disable 'user'(新版本不用)\n    删除一个列族：\n    alter 'user', NAME => 'f1', METHOD => 'delete' 或 alter 'user', 'delete' => 'f1'\n\n    添加列族f1同时删除列族f2\n    alter 'user', {NAME => 'f1'}, {NAME => 'f2', METHOD => 'delete'}\n\n    将user表的f1列族版本号改为5\n    alter 'people', NAME => 'info', VERSIONS => 5\n    启用表\n    enable 'user'\n\n\n    删除表\n    disable 'user'\n    drop 'user'\n\n\n    get 'person', 'rk0001', {FILTER => \"ValueFilter(=, 'binary:中国')\"}\n    get 'person', 'rk0001', {FILTER => \"(QualifierFilter(=,'substring:a'))\"}\n    scan 'person', {COLUMNS => 'info:name'}\n    scan 'person', {COLUMNS => ['info', 'data'], FILTER => \"(QualifierFilter(=,'substring:a'))\"}\n    scan 'person', {COLUMNS => 'info', STARTROW => 'rk0001', ENDROW => 'rk0003'}\n\n    scan 'person', {COLUMNS => 'info', STARTROW => '20140201', ENDROW => '20140301'}\n    scan 'person', {COLUMNS => 'info:name', TIMERANGE => [1395978233636, 1395987769587]}\n    delete 'person', 'rk0001', 'info:name'\n\n    alter 'person', NAME => 'ffff'\n    alter 'person', NAME => 'info', VERSIONS => 10\n\n\n    get 'user', 'rk0002', {COLUMN => ['info:name', 'data:pic']}\n    \n    \n#### 五、搭建HBase集群\n\n1.上传hbase安装包\n\n2.解压\n\n3.配置hbase集群，要修改3个文件（首先zk集群已经安装好了）\n\t注意：要把hadoop的hdfs-site.xml和core-site.xml 放到hbase/conf下\n\t\n\t3.1修改hbase-env.sh\n\texport JAVA_HOME=/usr/java/jdk1.7.0_55\n\t//告诉hbase使用外部的zk\n\texport HBASE_MANAGES_ZK=false\n\t\n\tvim hbase-site.xml\n\t<configuration>\n\t\t<!-- 指定hbase在HDFS上存储的路径 -->\n        <property>\n                <name>hbase.rootdir</name>\n                <value>hdfs://ns1/hbase</value>\n        </property>\n\t\t<!-- 指定hbase是分布式的 -->\n        <property>\n                <name>hbase.cluster.distributed</name>\n                <value>true</value>\n        </property>\n\t\t<!-- 指定zk的地址，多个用“,”分割 -->\n        <property>\n                <name>hbase.zookeeper.quorum</name>\n                <value>hadoop05:2181,hadoop06:2181,hadoop07:2181</value>\n        </property>\n\t</configuration>\n\t\n\tvim regionservers\n\thadoop03\n\thadoop04\n\thadoop05\n\thadoop06\n\t\n\t3.2拷贝hbase到其他节点\n\t\tscp -r /weekend/hbase-0.96.2-hadoop2/ hadoop02:/weekend/\n\t\tscp -r /weekend/hbase-0.96.2-hadoop2/ hadoop03:/weekend/\n\t\tscp -r /weekend/hbase-0.96.2-hadoop2/ hadoop04:/weekend/\n\t\tscp -r /weekend/hbase-0.96.2-hadoop2/ hadoop05:/weekend/\n\t\tscp -r /weekend/hbase-0.96.2-hadoop2/ hadoop06:/weekend/\n4.将配置好的HBase拷贝到每一个节点并同步时间。\n\n5.启动所有的hbase\n\t分别启动zk\n\t\t./zkServer.sh start\n\t启动hbase集群\n\t\tstart-dfs.sh\n\t启动hbase，在主节点上运行：\n\t\tstart-hbase.sh\n6.通过浏览器访问hbase管理页面\n\t192.168.1.201:60010\n7.为保证集群的可靠性，要启动多个HMaster\n\thbase-daemon.sh start master\n\t\n#### 五、HBase的API操作\n\n\n    package cn.itcast.bigdata.hbase;\n\n\n    import java.util.List;\n\n    import org.apache.hadoop.conf.Configuration;\n    import org.apache.hadoop.hbase.Cell;\n    import org.apache.hadoop.hbase.HBaseConfiguration;\n    import org.apache.hadoop.hbase.HColumnDescriptor;\n    import org.apache.hadoop.hbase.HTableDescriptor;\n    import org.apache.hadoop.hbase.KeyValue;\n    import org.apache.hadoop.hbase.TableName;\n    import org.apache.hadoop.hbase.client.Delete;\n    import org.apache.hadoop.hbase.client.Get;\n    import org.apache.hadoop.hbase.client.HBaseAdmin;\n    import org.apache.hadoop.hbase.client.HTable;\n    import org.apache.hadoop.hbase.client.Put;\n    import org.apache.hadoop.hbase.client.Result;\n    import org.apache.hadoop.hbase.client.ResultScanner;\n    import org.apache.hadoop.hbase.client.Scan;\n    import org.apache.hadoop.hbase.filter.BinaryComparator;\n    import org.apache.hadoop.hbase.filter.BinaryPrefixComparator;\n    import org.apache.hadoop.hbase.filter.ByteArrayComparable;\n    import org.apache.hadoop.hbase.filter.ColumnPrefixFilter;\n    import org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;\n    import org.apache.hadoop.hbase.filter.FamilyFilter;\n    import org.apache.hadoop.hbase.filter.Filter;\n    import org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter;\n    import org.apache.hadoop.hbase.filter.PrefixFilter;\n    import org.apache.hadoop.hbase.filter.QualifierFilter;\n    import org.apache.hadoop.hbase.filter.RegexStringComparator;\n    import org.apache.hadoop.hbase.filter.RowFilter;\n    import org.apache.hadoop.hbase.filter.SingleColumnValueFilter;\n    import org.apache.hadoop.hbase.filter.SubstringComparator;\n    import org.apache.hadoop.hbase.master.TableNamespaceManager;\n    import org.apache.hadoop.hbase.util.Bytes;\n    import org.junit.Before;\n    import org.junit.Test;\n\n    public class HbaseDemo {\n\n\tprivate Configuration conf = null;\n\t\n\t@Before\n\tpublic void init(){\n\t\tconf = HBaseConfiguration.create();\n\t\tconf.set(\"hbase.zookeeper.quorum\", \"hadoop05,hadoop06,hadoop07\");\n\t}\n\t\n\t@Test\n\tpublic void testDrop() throws Exception{\n\t\tHBaseAdmin admin = new HBaseAdmin(conf);\n\t\tadmin.disableTable(\"account\");\n\t\tadmin.deleteTable(\"account\");\n\t\tadmin.close();\n\t}\n\t\n\t@Test\n\tpublic void testPut() throws Exception{\n\t\tHTable table = new HTable(conf, \"person_info\");\n\t\tPut p = new Put(Bytes.toBytes(\"person_rk_bj_zhang_000002\"));\n\t\tp.add(\"base_info\".getBytes(), \"name\".getBytes(), \"zhangwuji\".getBytes());\n\t\ttable.put(p);\n\t\ttable.close();\n\t}\n\t\n\t@Test\n\tpublic void testGet() throws Exception{\n\t\tHTable table = new HTable(conf, \"person_info\");\n\t\tGet get = new Get(Bytes.toBytes(\"person_rk_bj_zhang_000001\"));\n\t\tget.setMaxVersions(5);\n\t\tResult result = table.get(get);\n\t\tList<Cell> cells = result.listCells();\n\t\t\n       //result.getValue(family, qualifier);  可以从result中直接取出一个特定的value\n\t\t\n\t\t//遍历出result中所有的键值对\n\t\tfor(KeyValue kv : result.list()){\n\t\t\tString family = new String(kv.getFamily());\n\t\t\tSystem.out.println(family);\n\t\t\tString qualifier = new String(kv.getQualifier());\n\t\t\tSystem.out.println(qualifier);\n\t\t\tSystem.out.println(new String(kv.getValue()));\n\t\t\t\n\t\t}\n\t\ttable.close();\n\t}\n\t\n\t/**\n\t * 多种过滤条件的使用方法\n\t * @throws Exception\n\t */\n\t@Test\n\tpublic void testScan() throws Exception{\n\t\tHTable table = new HTable(conf, \"person_info\".getBytes());\n\t\tScan scan = new Scan(Bytes.toBytes(\"person_rk_bj_zhang_000001\"), Bytes.toBytes(\"person_rk_bj_zhang_000002\"));\n\t\t\n\t\t//前缀过滤器----针对行键\n\t\tFilter filter = new PrefixFilter(Bytes.toBytes(\"rk\"));\n\t\t\n\t\t//行过滤器\n\t\tByteArrayComparable rowComparator = new BinaryComparator(Bytes.toBytes(\"person_rk_bj_zhang_000001\"));\n\t\tRowFilter rf = new RowFilter(CompareOp.LESS_OR_EQUAL, rowComparator);\n\t\t\n\t\t/**\n         * 假设rowkey格式为：创建日期_发布日期_ID_TITLE\n         * 目标：查找  发布日期  为  2014-12-21  的数据\n         */\n        rf = new RowFilter(CompareOp.EQUAL , new SubstringComparator(\"_2014-12-21_\"));\n\t\t\n\t\t\n\t\t//单值过滤器 1 完整匹配字节数组\n\t\tnew SingleColumnValueFilter(\"base_info\".getBytes(), \"name\".getBytes(), CompareOp.EQUAL, \"zhangsan\".getBytes());\n\t\t//单值过滤器2 匹配正则表达式\n\t\tByteArrayComparable comparator = new RegexStringComparator(\"zhang.\");\n\t\tnew SingleColumnValueFilter(\"info\".getBytes(), \"NAME\".getBytes(), CompareOp.EQUAL, comparator);\n\n\t\t//单值过滤器2 匹配是否包含子串,大小写不敏感\n\t\tcomparator = new SubstringComparator(\"wu\");\n\t\tnew SingleColumnValueFilter(\"info\".getBytes(), \"NAME\".getBytes(), CompareOp.EQUAL, comparator);\n\n\t\t//键值对元数据过滤-----family过滤----字节数组完整匹配\n        FamilyFilter ff = new FamilyFilter(\n                CompareOp.EQUAL , \n                new BinaryComparator(Bytes.toBytes(\"base_info\"))   //表中不存在inf列族，过滤结果为空\n                );\n        //键值对元数据过滤-----family过滤----字节数组前缀匹配\n        ff = new FamilyFilter(\n                CompareOp.EQUAL , \n                new BinaryPrefixComparator(Bytes.toBytes(\"inf\"))   //表中存在以inf打头的列族info，过滤结果为该列族所有行\n                );\n\t\t\n        \n       //键值对元数据过滤-----qualifier过滤----字节数组完整匹配\n        \n        filter = new QualifierFilter(\n                CompareOp.EQUAL , \n                new BinaryComparator(Bytes.toBytes(\"na\"))   //表中不存在na列，过滤结果为空\n                );\n        filter = new QualifierFilter(\n                CompareOp.EQUAL , \n                new BinaryPrefixComparator(Bytes.toBytes(\"na\"))   //表中存在以na打头的列name，过滤结果为所有行的该列数据\n        \t\t);\n\t\t\n        //基于列名(即Qualifier)前缀过滤数据的ColumnPrefixFilter\n        filter = new ColumnPrefixFilter(\"na\".getBytes());\n        \n        //基于列名(即Qualifier)多个前缀过滤数据的MultipleColumnPrefixFilter\n        byte[][] prefixes = new byte[][] {Bytes.toBytes(\"na\"), Bytes.toBytes(\"me\")};\n        filter = new MultipleColumnPrefixFilter(prefixes);\n \n        //为查询设置过滤条件\n        scan.setFilter(filter);\n        \n        \n\t\tscan.addFamily(Bytes.toBytes(\"base_info\"));\n\t\tResultScanner scanner = table.getScanner(scan);\n\t\tfor(Result r : scanner){\n\t\t\t/**\n\t\t\tfor(KeyValue kv : r.list()){\n\t\t\t\tString family = new String(kv.getFamily());\n\t\t\t\tSystem.out.println(family);\n\t\t\t\tString qualifier = new String(kv.getQualifier());\n\t\t\t\tSystem.out.println(qualifier);\n\t\t\t\tSystem.out.println(new String(kv.getValue()));\n\t\t\t}\n\t\t\t*/\n\t\t\t//直接从result中取到某个特定的value\n\t\t\tbyte[] value = r.getValue(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"name\"));\n\t\t\tSystem.out.println(new String(value));\n\t\t}\n\t\ttable.close();\n\t}\n\t\n\t\n\t@Test\n\tpublic void testDel() throws Exception{\n\t\tHTable table = new HTable(conf, \"user\");\n\t\tDelete del = new Delete(Bytes.toBytes(\"rk0001\"));\n\t\tdel.deleteColumn(Bytes.toBytes(\"data\"), Bytes.toBytes(\"pic\"));\n\t\ttable.delete(del);\n\t\ttable.close();\n\t}\n\t\n\t\n\t\n\t\n\tpublic static void main(String[] args) throws Exception {\n\t\tConfiguration conf = HBaseConfiguration.create();\n       //conf.set(\"hbase.zookeeper.quorum\",\"hadoop05:2181,hadoop06:2181,hadoop07:2181\");\n            HBaseAdmin admin = new HBaseAdmin(conf);\n\t\t\n\t\tTableName tableName = TableName.valueOf(\"person_info\");\n\t\tHTableDescriptor td = new HTableDescriptor(tableName);\n\t\tHColumnDescriptor cd = new HColumnDescriptor(\"base_info\");\n\t\tcd.setMaxVersions(10);\n\t\ttd.addFamily(cd);\n\t\tadmin.createTable(td);\n\t\t\n\t\tadmin.close();\n\n\t}\n\t\n\t\n\n}\n\n","source":"_posts/Hadoop-九-（HBase）.md","raw":"title: Hadoop(九)（HBase）\nauthor: 小小冰弟\ndate: 2018-03-28 17:43:17\ntags: study\ncategories: Hadoop\n---\n#### 一、HBase\n&nbsp;&nbsp;与HDFS相比较，它是数据库，HDFS文件系统，普通文件不能支持快速读写，当你需要随机，实时读写访问便需要HBase了。另外HBase基本无事务特性，复杂的步骤也不适合，它的优势是可以hold住很大的表，几十亿行，几百万列。\n\n#### 二、关系型数据库\n相对于传统的关系型数据库，它建表时，不需要限定表中的字段，只需要指定若干个列族，插入数据时，列族中可以存储任意多个列，每一行有个唯一的行键，当要查询某一字段的值时（成为cell），需要指定坐标，表名>行键>列名>版本号（一个value可以有多个版本号，通过版本号区分）\n\n#### 三、Hbase集群\n每一个表在HBase中会被按照行键拆分，比如1~10000，10001~20000这样，每一个称为一个region,region存在region server上面，region的底层文件还是存在HDFS上面，众多的region server需要一个协调者，HMaser不负责存储数据，管理region server.\n\n这里你会疑问，那么多的region,它怎么找到呢？先将1~10000，10001~20000，20001~30000，30001~40000的位置存放在META表中，分为1~~20000，20001~~40000两份，然后再合并为1~~~~40000存放在Root表上，而Root表放在Zookeeper上存储\n\n#### 四、HBase命令行使用\n\n    进入hbase命令行\n    ./hbase shell\n\n    显示hbase中的表\n    list\n\n    创建user表，包含info、data两个列族\n    create 'user', 'info1', 'data1'\n    create 'user', {NAME => 'info', VERSIONS => '3'}\n\n    向user表中插入信息，row key为rk0001，列族info中添加name列标示符，值为zhangsan\n    put 'user', 'rk0001', 'info:name', 'zhangsan'\n\n    向user表中插入信息，row key为rk0001，列族info中添加gender列标示符，值为female\n    put 'user', 'rk0001', 'info:gender', 'female'\n\n    向user表中插入信息，row key为rk0001，列族info中添加age列标示符，值为20\n    put 'user', 'rk0001', 'info:age', 20\n\n    向user表中插入信息，row key为rk0001，列族data中添加pic列标示符，值为picture\n    put 'user', 'rk0001', 'data:pic', 'picture'\n\n    获取user表中row key为rk0001的所有信息\n    get 'user', 'rk0001'\n\n    获取user表中row key为rk0001，info列族的所有信息\n    get 'user', 'rk0001', 'info'\n\n    获取user表中row key为rk0001，info列族的name、age列标示符的信息\n    get 'user', 'rk0001', 'info:name', 'info:age'\n\n    获取user表中row key为rk0001，info、data列族的信息\n    get 'user', 'rk0001', 'info', 'data'\n    get 'user', 'rk0001', {COLUMN => ['info', 'data']}\n\n    get 'user', 'rk0001', {COLUMN => ['info:name', 'data:pic']}\n\n    获取user表中row key为rk0001，列族为info，版本号最新5个的信息\n    get 'user', 'rk0001', {COLUMN => 'info', VERSIONS => 2}\n    get 'user', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5}\n    get 'user', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5, TIMERANGE => [1392368783980, 1392380169184]}\n\n    获取user表中row key为rk0001，cell的值为zhangsan的信息\n    get 'people', 'rk0001', {FILTER => \"ValueFilter(=, 'binary:图片')\"}\n\n    获取user表中row key为rk0001，列标示符中含有a的信息\n    get 'people', 'rk0001', {FILTER => \"(QualifierFilter(=,'substring:a'))\"}\n\n    put 'user', 'rk0002', 'info:name', 'fanbingbing'\n    put 'user', 'rk0002', 'info:gender', 'female'\n    put 'user', 'rk0002', 'info:nationality', '中国'\n    get 'user', 'rk0002', {FILTER => \"ValueFilter(=, 'binary:中国')\"}\n\n\n    查询user表中的所有信息\n    scan 'user'\n\n    查询user表中列族为info的信息\n    scan 'user', {COLUMNS => 'info'}\n    scan 'user', {COLUMNS => 'info', RAW => true, VERSIONS => 5}\n    scan 'persion', {COLUMNS => 'info', RAW => true, VERSIONS => 3}\n    查询user表中列族为info和data的信息\n    scan 'user', {COLUMNS => ['info', 'data']}\n    scan 'user', {COLUMNS => ['info:name', 'data:pic']}\n\n\n    查询user表中列族为info、列标示符为name的信息\n    scan 'user', {COLUMNS => 'info:name'}\n\n    查询user表中列族为info、列标示符为name的信息,并且版本最新的5个\n    scan 'user', {COLUMNS => 'info:name', VERSIONS => 5}\n\n    查询user表中列族为info和data且列标示符中含有a字符的信息\n    scan 'user', {COLUMNS => ['info', 'data'], FILTER => \"(QualifierFilter(=,'substring:a'))\"}\n\n    查询user表中列族为info，rk范围是[rk0001, rk0003)的数据\n    scan 'people', {COLUMNS => 'info', STARTROW => 'rk0001', ENDROW => 'rk0003'}\n\n    查询user表中row key以rk字符开头的\n    scan 'user',{FILTER=>\"PrefixFilter('rk')\"}\n\n    查询user表中指定范围的数据\n    scan 'user', {TIMERANGE => [1392368783980, 1392380169184]}\n\n    删除数据\n    删除user表row key为rk0001，列标示符为info:name的数据\n    delete 'people', 'rk0001', 'info:name'\n    删除user表row key为rk0001，列标示符为info:name，timestamp为1392383705316的数据\n    delete 'user', 'rk0001', 'info:name', 1392383705316\n\n\n    清空user表中的数据\n    truncate 'people'\n\n\n    修改表结构\n    首先停用user表（新版本不用）\n    disable 'user'\n\n    添加两个列族f1和f2\n    alter 'people', NAME => 'f1'\n    alter 'user', NAME => 'f2'\n    启用表\n    enable 'user'\n\n\n    ###disable 'user'(新版本不用)\n    删除一个列族：\n    alter 'user', NAME => 'f1', METHOD => 'delete' 或 alter 'user', 'delete' => 'f1'\n\n    添加列族f1同时删除列族f2\n    alter 'user', {NAME => 'f1'}, {NAME => 'f2', METHOD => 'delete'}\n\n    将user表的f1列族版本号改为5\n    alter 'people', NAME => 'info', VERSIONS => 5\n    启用表\n    enable 'user'\n\n\n    删除表\n    disable 'user'\n    drop 'user'\n\n\n    get 'person', 'rk0001', {FILTER => \"ValueFilter(=, 'binary:中国')\"}\n    get 'person', 'rk0001', {FILTER => \"(QualifierFilter(=,'substring:a'))\"}\n    scan 'person', {COLUMNS => 'info:name'}\n    scan 'person', {COLUMNS => ['info', 'data'], FILTER => \"(QualifierFilter(=,'substring:a'))\"}\n    scan 'person', {COLUMNS => 'info', STARTROW => 'rk0001', ENDROW => 'rk0003'}\n\n    scan 'person', {COLUMNS => 'info', STARTROW => '20140201', ENDROW => '20140301'}\n    scan 'person', {COLUMNS => 'info:name', TIMERANGE => [1395978233636, 1395987769587]}\n    delete 'person', 'rk0001', 'info:name'\n\n    alter 'person', NAME => 'ffff'\n    alter 'person', NAME => 'info', VERSIONS => 10\n\n\n    get 'user', 'rk0002', {COLUMN => ['info:name', 'data:pic']}\n    \n    \n#### 五、搭建HBase集群\n\n1.上传hbase安装包\n\n2.解压\n\n3.配置hbase集群，要修改3个文件（首先zk集群已经安装好了）\n\t注意：要把hadoop的hdfs-site.xml和core-site.xml 放到hbase/conf下\n\t\n\t3.1修改hbase-env.sh\n\texport JAVA_HOME=/usr/java/jdk1.7.0_55\n\t//告诉hbase使用外部的zk\n\texport HBASE_MANAGES_ZK=false\n\t\n\tvim hbase-site.xml\n\t<configuration>\n\t\t<!-- 指定hbase在HDFS上存储的路径 -->\n        <property>\n                <name>hbase.rootdir</name>\n                <value>hdfs://ns1/hbase</value>\n        </property>\n\t\t<!-- 指定hbase是分布式的 -->\n        <property>\n                <name>hbase.cluster.distributed</name>\n                <value>true</value>\n        </property>\n\t\t<!-- 指定zk的地址，多个用“,”分割 -->\n        <property>\n                <name>hbase.zookeeper.quorum</name>\n                <value>hadoop05:2181,hadoop06:2181,hadoop07:2181</value>\n        </property>\n\t</configuration>\n\t\n\tvim regionservers\n\thadoop03\n\thadoop04\n\thadoop05\n\thadoop06\n\t\n\t3.2拷贝hbase到其他节点\n\t\tscp -r /weekend/hbase-0.96.2-hadoop2/ hadoop02:/weekend/\n\t\tscp -r /weekend/hbase-0.96.2-hadoop2/ hadoop03:/weekend/\n\t\tscp -r /weekend/hbase-0.96.2-hadoop2/ hadoop04:/weekend/\n\t\tscp -r /weekend/hbase-0.96.2-hadoop2/ hadoop05:/weekend/\n\t\tscp -r /weekend/hbase-0.96.2-hadoop2/ hadoop06:/weekend/\n4.将配置好的HBase拷贝到每一个节点并同步时间。\n\n5.启动所有的hbase\n\t分别启动zk\n\t\t./zkServer.sh start\n\t启动hbase集群\n\t\tstart-dfs.sh\n\t启动hbase，在主节点上运行：\n\t\tstart-hbase.sh\n6.通过浏览器访问hbase管理页面\n\t192.168.1.201:60010\n7.为保证集群的可靠性，要启动多个HMaster\n\thbase-daemon.sh start master\n\t\n#### 五、HBase的API操作\n\n\n    package cn.itcast.bigdata.hbase;\n\n\n    import java.util.List;\n\n    import org.apache.hadoop.conf.Configuration;\n    import org.apache.hadoop.hbase.Cell;\n    import org.apache.hadoop.hbase.HBaseConfiguration;\n    import org.apache.hadoop.hbase.HColumnDescriptor;\n    import org.apache.hadoop.hbase.HTableDescriptor;\n    import org.apache.hadoop.hbase.KeyValue;\n    import org.apache.hadoop.hbase.TableName;\n    import org.apache.hadoop.hbase.client.Delete;\n    import org.apache.hadoop.hbase.client.Get;\n    import org.apache.hadoop.hbase.client.HBaseAdmin;\n    import org.apache.hadoop.hbase.client.HTable;\n    import org.apache.hadoop.hbase.client.Put;\n    import org.apache.hadoop.hbase.client.Result;\n    import org.apache.hadoop.hbase.client.ResultScanner;\n    import org.apache.hadoop.hbase.client.Scan;\n    import org.apache.hadoop.hbase.filter.BinaryComparator;\n    import org.apache.hadoop.hbase.filter.BinaryPrefixComparator;\n    import org.apache.hadoop.hbase.filter.ByteArrayComparable;\n    import org.apache.hadoop.hbase.filter.ColumnPrefixFilter;\n    import org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;\n    import org.apache.hadoop.hbase.filter.FamilyFilter;\n    import org.apache.hadoop.hbase.filter.Filter;\n    import org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter;\n    import org.apache.hadoop.hbase.filter.PrefixFilter;\n    import org.apache.hadoop.hbase.filter.QualifierFilter;\n    import org.apache.hadoop.hbase.filter.RegexStringComparator;\n    import org.apache.hadoop.hbase.filter.RowFilter;\n    import org.apache.hadoop.hbase.filter.SingleColumnValueFilter;\n    import org.apache.hadoop.hbase.filter.SubstringComparator;\n    import org.apache.hadoop.hbase.master.TableNamespaceManager;\n    import org.apache.hadoop.hbase.util.Bytes;\n    import org.junit.Before;\n    import org.junit.Test;\n\n    public class HbaseDemo {\n\n\tprivate Configuration conf = null;\n\t\n\t@Before\n\tpublic void init(){\n\t\tconf = HBaseConfiguration.create();\n\t\tconf.set(\"hbase.zookeeper.quorum\", \"hadoop05,hadoop06,hadoop07\");\n\t}\n\t\n\t@Test\n\tpublic void testDrop() throws Exception{\n\t\tHBaseAdmin admin = new HBaseAdmin(conf);\n\t\tadmin.disableTable(\"account\");\n\t\tadmin.deleteTable(\"account\");\n\t\tadmin.close();\n\t}\n\t\n\t@Test\n\tpublic void testPut() throws Exception{\n\t\tHTable table = new HTable(conf, \"person_info\");\n\t\tPut p = new Put(Bytes.toBytes(\"person_rk_bj_zhang_000002\"));\n\t\tp.add(\"base_info\".getBytes(), \"name\".getBytes(), \"zhangwuji\".getBytes());\n\t\ttable.put(p);\n\t\ttable.close();\n\t}\n\t\n\t@Test\n\tpublic void testGet() throws Exception{\n\t\tHTable table = new HTable(conf, \"person_info\");\n\t\tGet get = new Get(Bytes.toBytes(\"person_rk_bj_zhang_000001\"));\n\t\tget.setMaxVersions(5);\n\t\tResult result = table.get(get);\n\t\tList<Cell> cells = result.listCells();\n\t\t\n       //result.getValue(family, qualifier);  可以从result中直接取出一个特定的value\n\t\t\n\t\t//遍历出result中所有的键值对\n\t\tfor(KeyValue kv : result.list()){\n\t\t\tString family = new String(kv.getFamily());\n\t\t\tSystem.out.println(family);\n\t\t\tString qualifier = new String(kv.getQualifier());\n\t\t\tSystem.out.println(qualifier);\n\t\t\tSystem.out.println(new String(kv.getValue()));\n\t\t\t\n\t\t}\n\t\ttable.close();\n\t}\n\t\n\t/**\n\t * 多种过滤条件的使用方法\n\t * @throws Exception\n\t */\n\t@Test\n\tpublic void testScan() throws Exception{\n\t\tHTable table = new HTable(conf, \"person_info\".getBytes());\n\t\tScan scan = new Scan(Bytes.toBytes(\"person_rk_bj_zhang_000001\"), Bytes.toBytes(\"person_rk_bj_zhang_000002\"));\n\t\t\n\t\t//前缀过滤器----针对行键\n\t\tFilter filter = new PrefixFilter(Bytes.toBytes(\"rk\"));\n\t\t\n\t\t//行过滤器\n\t\tByteArrayComparable rowComparator = new BinaryComparator(Bytes.toBytes(\"person_rk_bj_zhang_000001\"));\n\t\tRowFilter rf = new RowFilter(CompareOp.LESS_OR_EQUAL, rowComparator);\n\t\t\n\t\t/**\n         * 假设rowkey格式为：创建日期_发布日期_ID_TITLE\n         * 目标：查找  发布日期  为  2014-12-21  的数据\n         */\n        rf = new RowFilter(CompareOp.EQUAL , new SubstringComparator(\"_2014-12-21_\"));\n\t\t\n\t\t\n\t\t//单值过滤器 1 完整匹配字节数组\n\t\tnew SingleColumnValueFilter(\"base_info\".getBytes(), \"name\".getBytes(), CompareOp.EQUAL, \"zhangsan\".getBytes());\n\t\t//单值过滤器2 匹配正则表达式\n\t\tByteArrayComparable comparator = new RegexStringComparator(\"zhang.\");\n\t\tnew SingleColumnValueFilter(\"info\".getBytes(), \"NAME\".getBytes(), CompareOp.EQUAL, comparator);\n\n\t\t//单值过滤器2 匹配是否包含子串,大小写不敏感\n\t\tcomparator = new SubstringComparator(\"wu\");\n\t\tnew SingleColumnValueFilter(\"info\".getBytes(), \"NAME\".getBytes(), CompareOp.EQUAL, comparator);\n\n\t\t//键值对元数据过滤-----family过滤----字节数组完整匹配\n        FamilyFilter ff = new FamilyFilter(\n                CompareOp.EQUAL , \n                new BinaryComparator(Bytes.toBytes(\"base_info\"))   //表中不存在inf列族，过滤结果为空\n                );\n        //键值对元数据过滤-----family过滤----字节数组前缀匹配\n        ff = new FamilyFilter(\n                CompareOp.EQUAL , \n                new BinaryPrefixComparator(Bytes.toBytes(\"inf\"))   //表中存在以inf打头的列族info，过滤结果为该列族所有行\n                );\n\t\t\n        \n       //键值对元数据过滤-----qualifier过滤----字节数组完整匹配\n        \n        filter = new QualifierFilter(\n                CompareOp.EQUAL , \n                new BinaryComparator(Bytes.toBytes(\"na\"))   //表中不存在na列，过滤结果为空\n                );\n        filter = new QualifierFilter(\n                CompareOp.EQUAL , \n                new BinaryPrefixComparator(Bytes.toBytes(\"na\"))   //表中存在以na打头的列name，过滤结果为所有行的该列数据\n        \t\t);\n\t\t\n        //基于列名(即Qualifier)前缀过滤数据的ColumnPrefixFilter\n        filter = new ColumnPrefixFilter(\"na\".getBytes());\n        \n        //基于列名(即Qualifier)多个前缀过滤数据的MultipleColumnPrefixFilter\n        byte[][] prefixes = new byte[][] {Bytes.toBytes(\"na\"), Bytes.toBytes(\"me\")};\n        filter = new MultipleColumnPrefixFilter(prefixes);\n \n        //为查询设置过滤条件\n        scan.setFilter(filter);\n        \n        \n\t\tscan.addFamily(Bytes.toBytes(\"base_info\"));\n\t\tResultScanner scanner = table.getScanner(scan);\n\t\tfor(Result r : scanner){\n\t\t\t/**\n\t\t\tfor(KeyValue kv : r.list()){\n\t\t\t\tString family = new String(kv.getFamily());\n\t\t\t\tSystem.out.println(family);\n\t\t\t\tString qualifier = new String(kv.getQualifier());\n\t\t\t\tSystem.out.println(qualifier);\n\t\t\t\tSystem.out.println(new String(kv.getValue()));\n\t\t\t}\n\t\t\t*/\n\t\t\t//直接从result中取到某个特定的value\n\t\t\tbyte[] value = r.getValue(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"name\"));\n\t\t\tSystem.out.println(new String(value));\n\t\t}\n\t\ttable.close();\n\t}\n\t\n\t\n\t@Test\n\tpublic void testDel() throws Exception{\n\t\tHTable table = new HTable(conf, \"user\");\n\t\tDelete del = new Delete(Bytes.toBytes(\"rk0001\"));\n\t\tdel.deleteColumn(Bytes.toBytes(\"data\"), Bytes.toBytes(\"pic\"));\n\t\ttable.delete(del);\n\t\ttable.close();\n\t}\n\t\n\t\n\t\n\t\n\tpublic static void main(String[] args) throws Exception {\n\t\tConfiguration conf = HBaseConfiguration.create();\n       //conf.set(\"hbase.zookeeper.quorum\",\"hadoop05:2181,hadoop06:2181,hadoop07:2181\");\n            HBaseAdmin admin = new HBaseAdmin(conf);\n\t\t\n\t\tTableName tableName = TableName.valueOf(\"person_info\");\n\t\tHTableDescriptor td = new HTableDescriptor(tableName);\n\t\tHColumnDescriptor cd = new HColumnDescriptor(\"base_info\");\n\t\tcd.setMaxVersions(10);\n\t\ttd.addFamily(cd);\n\t\tadmin.createTable(td);\n\t\t\n\t\tadmin.close();\n\n\t}\n\t\n\t\n\n}\n\n","slug":"Hadoop-九-（HBase）","published":1,"updated":"2018-03-28T10:21:19.032Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60ku000mxo7k8p1vvquh","content":"<h4 id=\"一、HBase\"><a href=\"#一、HBase\" class=\"headerlink\" title=\"一、HBase\"></a>一、HBase</h4><p>&nbsp;&nbsp;与HDFS相比较，它是数据库，HDFS文件系统，普通文件不能支持快速读写，当你需要随机，实时读写访问便需要HBase了。另外HBase基本无事务特性，复杂的步骤也不适合，它的优势是可以hold住很大的表，几十亿行，几百万列。</p>\n<h4 id=\"二、关系型数据库\"><a href=\"#二、关系型数据库\" class=\"headerlink\" title=\"二、关系型数据库\"></a>二、关系型数据库</h4><p>相对于传统的关系型数据库，它建表时，不需要限定表中的字段，只需要指定若干个列族，插入数据时，列族中可以存储任意多个列，每一行有个唯一的行键，当要查询某一字段的值时（成为cell），需要指定坐标，表名&gt;行键&gt;列名&gt;版本号（一个value可以有多个版本号，通过版本号区分）</p>\n<h4 id=\"三、Hbase集群\"><a href=\"#三、Hbase集群\" class=\"headerlink\" title=\"三、Hbase集群\"></a>三、Hbase集群</h4><p>每一个表在HBase中会被按照行键拆分，比如1~10000，10001~20000这样，每一个称为一个region,region存在region server上面，region的底层文件还是存在HDFS上面，众多的region server需要一个协调者，HMaser不负责存储数据，管理region server.</p>\n<p>这里你会疑问，那么多的region,它怎么找到呢？先将1~10000，10001~20000，20001~30000，30001~40000的位置存放在META表中，分为1<del>20000，20001</del>40000两份，然后再合并为1~~~~40000存放在Root表上，而Root表放在Zookeeper上存储</p>\n<h4 id=\"四、HBase命令行使用\"><a href=\"#四、HBase命令行使用\" class=\"headerlink\" title=\"四、HBase命令行使用\"></a>四、HBase命令行使用</h4><pre><code>进入hbase命令行\n./hbase shell\n\n显示hbase中的表\nlist\n\n创建user表，包含info、data两个列族\ncreate &apos;user&apos;, &apos;info1&apos;, &apos;data1&apos;\ncreate &apos;user&apos;, {NAME =&gt; &apos;info&apos;, VERSIONS =&gt; &apos;3&apos;}\n\n向user表中插入信息，row key为rk0001，列族info中添加name列标示符，值为zhangsan\nput &apos;user&apos;, &apos;rk0001&apos;, &apos;info:name&apos;, &apos;zhangsan&apos;\n\n向user表中插入信息，row key为rk0001，列族info中添加gender列标示符，值为female\nput &apos;user&apos;, &apos;rk0001&apos;, &apos;info:gender&apos;, &apos;female&apos;\n\n向user表中插入信息，row key为rk0001，列族info中添加age列标示符，值为20\nput &apos;user&apos;, &apos;rk0001&apos;, &apos;info:age&apos;, 20\n\n向user表中插入信息，row key为rk0001，列族data中添加pic列标示符，值为picture\nput &apos;user&apos;, &apos;rk0001&apos;, &apos;data:pic&apos;, &apos;picture&apos;\n\n获取user表中row key为rk0001的所有信息\nget &apos;user&apos;, &apos;rk0001&apos;\n\n获取user表中row key为rk0001，info列族的所有信息\nget &apos;user&apos;, &apos;rk0001&apos;, &apos;info&apos;\n\n获取user表中row key为rk0001，info列族的name、age列标示符的信息\nget &apos;user&apos;, &apos;rk0001&apos;, &apos;info:name&apos;, &apos;info:age&apos;\n\n获取user表中row key为rk0001，info、data列族的信息\nget &apos;user&apos;, &apos;rk0001&apos;, &apos;info&apos;, &apos;data&apos;\nget &apos;user&apos;, &apos;rk0001&apos;, {COLUMN =&gt; [&apos;info&apos;, &apos;data&apos;]}\n\nget &apos;user&apos;, &apos;rk0001&apos;, {COLUMN =&gt; [&apos;info:name&apos;, &apos;data:pic&apos;]}\n\n获取user表中row key为rk0001，列族为info，版本号最新5个的信息\nget &apos;user&apos;, &apos;rk0001&apos;, {COLUMN =&gt; &apos;info&apos;, VERSIONS =&gt; 2}\nget &apos;user&apos;, &apos;rk0001&apos;, {COLUMN =&gt; &apos;info:name&apos;, VERSIONS =&gt; 5}\nget &apos;user&apos;, &apos;rk0001&apos;, {COLUMN =&gt; &apos;info:name&apos;, VERSIONS =&gt; 5, TIMERANGE =&gt; [1392368783980, 1392380169184]}\n\n获取user表中row key为rk0001，cell的值为zhangsan的信息\nget &apos;people&apos;, &apos;rk0001&apos;, {FILTER =&gt; &quot;ValueFilter(=, &apos;binary:图片&apos;)&quot;}\n\n获取user表中row key为rk0001，列标示符中含有a的信息\nget &apos;people&apos;, &apos;rk0001&apos;, {FILTER =&gt; &quot;(QualifierFilter(=,&apos;substring:a&apos;))&quot;}\n\nput &apos;user&apos;, &apos;rk0002&apos;, &apos;info:name&apos;, &apos;fanbingbing&apos;\nput &apos;user&apos;, &apos;rk0002&apos;, &apos;info:gender&apos;, &apos;female&apos;\nput &apos;user&apos;, &apos;rk0002&apos;, &apos;info:nationality&apos;, &apos;中国&apos;\nget &apos;user&apos;, &apos;rk0002&apos;, {FILTER =&gt; &quot;ValueFilter(=, &apos;binary:中国&apos;)&quot;}\n\n\n查询user表中的所有信息\nscan &apos;user&apos;\n\n查询user表中列族为info的信息\nscan &apos;user&apos;, {COLUMNS =&gt; &apos;info&apos;}\nscan &apos;user&apos;, {COLUMNS =&gt; &apos;info&apos;, RAW =&gt; true, VERSIONS =&gt; 5}\nscan &apos;persion&apos;, {COLUMNS =&gt; &apos;info&apos;, RAW =&gt; true, VERSIONS =&gt; 3}\n查询user表中列族为info和data的信息\nscan &apos;user&apos;, {COLUMNS =&gt; [&apos;info&apos;, &apos;data&apos;]}\nscan &apos;user&apos;, {COLUMNS =&gt; [&apos;info:name&apos;, &apos;data:pic&apos;]}\n\n\n查询user表中列族为info、列标示符为name的信息\nscan &apos;user&apos;, {COLUMNS =&gt; &apos;info:name&apos;}\n\n查询user表中列族为info、列标示符为name的信息,并且版本最新的5个\nscan &apos;user&apos;, {COLUMNS =&gt; &apos;info:name&apos;, VERSIONS =&gt; 5}\n\n查询user表中列族为info和data且列标示符中含有a字符的信息\nscan &apos;user&apos;, {COLUMNS =&gt; [&apos;info&apos;, &apos;data&apos;], FILTER =&gt; &quot;(QualifierFilter(=,&apos;substring:a&apos;))&quot;}\n\n查询user表中列族为info，rk范围是[rk0001, rk0003)的数据\nscan &apos;people&apos;, {COLUMNS =&gt; &apos;info&apos;, STARTROW =&gt; &apos;rk0001&apos;, ENDROW =&gt; &apos;rk0003&apos;}\n\n查询user表中row key以rk字符开头的\nscan &apos;user&apos;,{FILTER=&gt;&quot;PrefixFilter(&apos;rk&apos;)&quot;}\n\n查询user表中指定范围的数据\nscan &apos;user&apos;, {TIMERANGE =&gt; [1392368783980, 1392380169184]}\n\n删除数据\n删除user表row key为rk0001，列标示符为info:name的数据\ndelete &apos;people&apos;, &apos;rk0001&apos;, &apos;info:name&apos;\n删除user表row key为rk0001，列标示符为info:name，timestamp为1392383705316的数据\ndelete &apos;user&apos;, &apos;rk0001&apos;, &apos;info:name&apos;, 1392383705316\n\n\n清空user表中的数据\ntruncate &apos;people&apos;\n\n\n修改表结构\n首先停用user表（新版本不用）\ndisable &apos;user&apos;\n\n添加两个列族f1和f2\nalter &apos;people&apos;, NAME =&gt; &apos;f1&apos;\nalter &apos;user&apos;, NAME =&gt; &apos;f2&apos;\n启用表\nenable &apos;user&apos;\n\n\n###disable &apos;user&apos;(新版本不用)\n删除一个列族：\nalter &apos;user&apos;, NAME =&gt; &apos;f1&apos;, METHOD =&gt; &apos;delete&apos; 或 alter &apos;user&apos;, &apos;delete&apos; =&gt; &apos;f1&apos;\n\n添加列族f1同时删除列族f2\nalter &apos;user&apos;, {NAME =&gt; &apos;f1&apos;}, {NAME =&gt; &apos;f2&apos;, METHOD =&gt; &apos;delete&apos;}\n\n将user表的f1列族版本号改为5\nalter &apos;people&apos;, NAME =&gt; &apos;info&apos;, VERSIONS =&gt; 5\n启用表\nenable &apos;user&apos;\n\n\n删除表\ndisable &apos;user&apos;\ndrop &apos;user&apos;\n\n\nget &apos;person&apos;, &apos;rk0001&apos;, {FILTER =&gt; &quot;ValueFilter(=, &apos;binary:中国&apos;)&quot;}\nget &apos;person&apos;, &apos;rk0001&apos;, {FILTER =&gt; &quot;(QualifierFilter(=,&apos;substring:a&apos;))&quot;}\nscan &apos;person&apos;, {COLUMNS =&gt; &apos;info:name&apos;}\nscan &apos;person&apos;, {COLUMNS =&gt; [&apos;info&apos;, &apos;data&apos;], FILTER =&gt; &quot;(QualifierFilter(=,&apos;substring:a&apos;))&quot;}\nscan &apos;person&apos;, {COLUMNS =&gt; &apos;info&apos;, STARTROW =&gt; &apos;rk0001&apos;, ENDROW =&gt; &apos;rk0003&apos;}\n\nscan &apos;person&apos;, {COLUMNS =&gt; &apos;info&apos;, STARTROW =&gt; &apos;20140201&apos;, ENDROW =&gt; &apos;20140301&apos;}\nscan &apos;person&apos;, {COLUMNS =&gt; &apos;info:name&apos;, TIMERANGE =&gt; [1395978233636, 1395987769587]}\ndelete &apos;person&apos;, &apos;rk0001&apos;, &apos;info:name&apos;\n\nalter &apos;person&apos;, NAME =&gt; &apos;ffff&apos;\nalter &apos;person&apos;, NAME =&gt; &apos;info&apos;, VERSIONS =&gt; 10\n\n\nget &apos;user&apos;, &apos;rk0002&apos;, {COLUMN =&gt; [&apos;info:name&apos;, &apos;data:pic&apos;]}\n</code></pre><h4 id=\"五、搭建HBase集群\"><a href=\"#五、搭建HBase集群\" class=\"headerlink\" title=\"五、搭建HBase集群\"></a>五、搭建HBase集群</h4><p>1.上传hbase安装包</p>\n<p>2.解压</p>\n<p>3.配置hbase集群，要修改3个文件（首先zk集群已经安装好了）<br>    注意：要把hadoop的hdfs-site.xml和core-site.xml 放到hbase/conf下</p>\n<pre><code>3.1修改hbase-env.sh\nexport JAVA_HOME=/usr/java/jdk1.7.0_55\n//告诉hbase使用外部的zk\nexport HBASE_MANAGES_ZK=false\n\nvim hbase-site.xml\n&lt;configuration&gt;\n    &lt;!-- 指定hbase在HDFS上存储的路径 --&gt;\n    &lt;property&gt;\n            &lt;name&gt;hbase.rootdir&lt;/name&gt;\n            &lt;value&gt;hdfs://ns1/hbase&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 指定hbase是分布式的 --&gt;\n    &lt;property&gt;\n            &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;\n            &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 指定zk的地址，多个用“,”分割 --&gt;\n    &lt;property&gt;\n            &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;\n            &lt;value&gt;hadoop05:2181,hadoop06:2181,hadoop07:2181&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n\nvim regionservers\nhadoop03\nhadoop04\nhadoop05\nhadoop06\n\n3.2拷贝hbase到其他节点\n    scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop02:/weekend/\n    scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop03:/weekend/\n    scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop04:/weekend/\n    scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop05:/weekend/\n    scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop06:/weekend/\n</code></pre><p>4.将配置好的HBase拷贝到每一个节点并同步时间。</p>\n<p>5.启动所有的hbase<br>    分别启动zk<br>        ./zkServer.sh start<br>    启动hbase集群<br>        start-dfs.sh<br>    启动hbase，在主节点上运行：<br>        start-hbase.sh<br>6.通过浏览器访问hbase管理页面<br>    192.168.1.201:60010<br>7.为保证集群的可靠性，要启动多个HMaster<br>    hbase-daemon.sh start master</p>\n<h4 id=\"五、HBase的API操作\"><a href=\"#五、HBase的API操作\" class=\"headerlink\" title=\"五、HBase的API操作\"></a>五、HBase的API操作</h4><pre><code>package cn.itcast.bigdata.hbase;\n\n\nimport java.util.List;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.Cell;\nimport org.apache.hadoop.hbase.HBaseConfiguration;\nimport org.apache.hadoop.hbase.HColumnDescriptor;\nimport org.apache.hadoop.hbase.HTableDescriptor;\nimport org.apache.hadoop.hbase.KeyValue;\nimport org.apache.hadoop.hbase.TableName;\nimport org.apache.hadoop.hbase.client.Delete;\nimport org.apache.hadoop.hbase.client.Get;\nimport org.apache.hadoop.hbase.client.HBaseAdmin;\nimport org.apache.hadoop.hbase.client.HTable;\nimport org.apache.hadoop.hbase.client.Put;\nimport org.apache.hadoop.hbase.client.Result;\nimport org.apache.hadoop.hbase.client.ResultScanner;\nimport org.apache.hadoop.hbase.client.Scan;\nimport org.apache.hadoop.hbase.filter.BinaryComparator;\nimport org.apache.hadoop.hbase.filter.BinaryPrefixComparator;\nimport org.apache.hadoop.hbase.filter.ByteArrayComparable;\nimport org.apache.hadoop.hbase.filter.ColumnPrefixFilter;\nimport org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;\nimport org.apache.hadoop.hbase.filter.FamilyFilter;\nimport org.apache.hadoop.hbase.filter.Filter;\nimport org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter;\nimport org.apache.hadoop.hbase.filter.PrefixFilter;\nimport org.apache.hadoop.hbase.filter.QualifierFilter;\nimport org.apache.hadoop.hbase.filter.RegexStringComparator;\nimport org.apache.hadoop.hbase.filter.RowFilter;\nimport org.apache.hadoop.hbase.filter.SingleColumnValueFilter;\nimport org.apache.hadoop.hbase.filter.SubstringComparator;\nimport org.apache.hadoop.hbase.master.TableNamespaceManager;\nimport org.apache.hadoop.hbase.util.Bytes;\nimport org.junit.Before;\nimport org.junit.Test;\n\npublic class HbaseDemo {\n\nprivate Configuration conf = null;\n\n@Before\npublic void init(){\n    conf = HBaseConfiguration.create();\n    conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;hadoop05,hadoop06,hadoop07&quot;);\n}\n\n@Test\npublic void testDrop() throws Exception{\n    HBaseAdmin admin = new HBaseAdmin(conf);\n    admin.disableTable(&quot;account&quot;);\n    admin.deleteTable(&quot;account&quot;);\n    admin.close();\n}\n\n@Test\npublic void testPut() throws Exception{\n    HTable table = new HTable(conf, &quot;person_info&quot;);\n    Put p = new Put(Bytes.toBytes(&quot;person_rk_bj_zhang_000002&quot;));\n    p.add(&quot;base_info&quot;.getBytes(), &quot;name&quot;.getBytes(), &quot;zhangwuji&quot;.getBytes());\n    table.put(p);\n    table.close();\n}\n\n@Test\npublic void testGet() throws Exception{\n    HTable table = new HTable(conf, &quot;person_info&quot;);\n    Get get = new Get(Bytes.toBytes(&quot;person_rk_bj_zhang_000001&quot;));\n    get.setMaxVersions(5);\n    Result result = table.get(get);\n    List&lt;Cell&gt; cells = result.listCells();\n\n   //result.getValue(family, qualifier);  可以从result中直接取出一个特定的value\n\n    //遍历出result中所有的键值对\n    for(KeyValue kv : result.list()){\n        String family = new String(kv.getFamily());\n        System.out.println(family);\n        String qualifier = new String(kv.getQualifier());\n        System.out.println(qualifier);\n        System.out.println(new String(kv.getValue()));\n\n    }\n    table.close();\n}\n\n/**\n * 多种过滤条件的使用方法\n * @throws Exception\n */\n@Test\npublic void testScan() throws Exception{\n    HTable table = new HTable(conf, &quot;person_info&quot;.getBytes());\n    Scan scan = new Scan(Bytes.toBytes(&quot;person_rk_bj_zhang_000001&quot;), Bytes.toBytes(&quot;person_rk_bj_zhang_000002&quot;));\n\n    //前缀过滤器----针对行键\n    Filter filter = new PrefixFilter(Bytes.toBytes(&quot;rk&quot;));\n\n    //行过滤器\n    ByteArrayComparable rowComparator = new BinaryComparator(Bytes.toBytes(&quot;person_rk_bj_zhang_000001&quot;));\n    RowFilter rf = new RowFilter(CompareOp.LESS_OR_EQUAL, rowComparator);\n\n    /**\n     * 假设rowkey格式为：创建日期_发布日期_ID_TITLE\n     * 目标：查找  发布日期  为  2014-12-21  的数据\n     */\n    rf = new RowFilter(CompareOp.EQUAL , new SubstringComparator(&quot;_2014-12-21_&quot;));\n\n\n    //单值过滤器 1 完整匹配字节数组\n    new SingleColumnValueFilter(&quot;base_info&quot;.getBytes(), &quot;name&quot;.getBytes(), CompareOp.EQUAL, &quot;zhangsan&quot;.getBytes());\n    //单值过滤器2 匹配正则表达式\n    ByteArrayComparable comparator = new RegexStringComparator(&quot;zhang.&quot;);\n    new SingleColumnValueFilter(&quot;info&quot;.getBytes(), &quot;NAME&quot;.getBytes(), CompareOp.EQUAL, comparator);\n\n    //单值过滤器2 匹配是否包含子串,大小写不敏感\n    comparator = new SubstringComparator(&quot;wu&quot;);\n    new SingleColumnValueFilter(&quot;info&quot;.getBytes(), &quot;NAME&quot;.getBytes(), CompareOp.EQUAL, comparator);\n\n    //键值对元数据过滤-----family过滤----字节数组完整匹配\n    FamilyFilter ff = new FamilyFilter(\n            CompareOp.EQUAL , \n            new BinaryComparator(Bytes.toBytes(&quot;base_info&quot;))   //表中不存在inf列族，过滤结果为空\n            );\n    //键值对元数据过滤-----family过滤----字节数组前缀匹配\n    ff = new FamilyFilter(\n            CompareOp.EQUAL , \n            new BinaryPrefixComparator(Bytes.toBytes(&quot;inf&quot;))   //表中存在以inf打头的列族info，过滤结果为该列族所有行\n            );\n\n\n   //键值对元数据过滤-----qualifier过滤----字节数组完整匹配\n\n    filter = new QualifierFilter(\n            CompareOp.EQUAL , \n            new BinaryComparator(Bytes.toBytes(&quot;na&quot;))   //表中不存在na列，过滤结果为空\n            );\n    filter = new QualifierFilter(\n            CompareOp.EQUAL , \n            new BinaryPrefixComparator(Bytes.toBytes(&quot;na&quot;))   //表中存在以na打头的列name，过滤结果为所有行的该列数据\n            );\n\n    //基于列名(即Qualifier)前缀过滤数据的ColumnPrefixFilter\n    filter = new ColumnPrefixFilter(&quot;na&quot;.getBytes());\n\n    //基于列名(即Qualifier)多个前缀过滤数据的MultipleColumnPrefixFilter\n    byte[][] prefixes = new byte[][] {Bytes.toBytes(&quot;na&quot;), Bytes.toBytes(&quot;me&quot;)};\n    filter = new MultipleColumnPrefixFilter(prefixes);\n\n    //为查询设置过滤条件\n    scan.setFilter(filter);\n\n\n    scan.addFamily(Bytes.toBytes(&quot;base_info&quot;));\n    ResultScanner scanner = table.getScanner(scan);\n    for(Result r : scanner){\n        /**\n        for(KeyValue kv : r.list()){\n            String family = new String(kv.getFamily());\n            System.out.println(family);\n            String qualifier = new String(kv.getQualifier());\n            System.out.println(qualifier);\n            System.out.println(new String(kv.getValue()));\n        }\n        */\n        //直接从result中取到某个特定的value\n        byte[] value = r.getValue(Bytes.toBytes(&quot;base_info&quot;), Bytes.toBytes(&quot;name&quot;));\n        System.out.println(new String(value));\n    }\n    table.close();\n}\n\n\n@Test\npublic void testDel() throws Exception{\n    HTable table = new HTable(conf, &quot;user&quot;);\n    Delete del = new Delete(Bytes.toBytes(&quot;rk0001&quot;));\n    del.deleteColumn(Bytes.toBytes(&quot;data&quot;), Bytes.toBytes(&quot;pic&quot;));\n    table.delete(del);\n    table.close();\n}\n\n\n\n\npublic static void main(String[] args) throws Exception {\n    Configuration conf = HBaseConfiguration.create();\n   //conf.set(&quot;hbase.zookeeper.quorum&quot;,&quot;hadoop05:2181,hadoop06:2181,hadoop07:2181&quot;);\n        HBaseAdmin admin = new HBaseAdmin(conf);\n\n    TableName tableName = TableName.valueOf(&quot;person_info&quot;);\n    HTableDescriptor td = new HTableDescriptor(tableName);\n    HColumnDescriptor cd = new HColumnDescriptor(&quot;base_info&quot;);\n    cd.setMaxVersions(10);\n    td.addFamily(cd);\n    admin.createTable(td);\n\n    admin.close();\n\n}\n</code></pre><p>}</p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"一、HBase\"><a href=\"#一、HBase\" class=\"headerlink\" title=\"一、HBase\"></a>一、HBase</h4><p>&nbsp;&nbsp;与HDFS相比较，它是数据库，HDFS文件系统，普通文件不能支持快速读写，当你需要随机，实时读写访问便需要HBase了。另外HBase基本无事务特性，复杂的步骤也不适合，它的优势是可以hold住很大的表，几十亿行，几百万列。</p>\n<h4 id=\"二、关系型数据库\"><a href=\"#二、关系型数据库\" class=\"headerlink\" title=\"二、关系型数据库\"></a>二、关系型数据库</h4><p>相对于传统的关系型数据库，它建表时，不需要限定表中的字段，只需要指定若干个列族，插入数据时，列族中可以存储任意多个列，每一行有个唯一的行键，当要查询某一字段的值时（成为cell），需要指定坐标，表名&gt;行键&gt;列名&gt;版本号（一个value可以有多个版本号，通过版本号区分）</p>\n<h4 id=\"三、Hbase集群\"><a href=\"#三、Hbase集群\" class=\"headerlink\" title=\"三、Hbase集群\"></a>三、Hbase集群</h4><p>每一个表在HBase中会被按照行键拆分，比如1~10000，10001~20000这样，每一个称为一个region,region存在region server上面，region的底层文件还是存在HDFS上面，众多的region server需要一个协调者，HMaser不负责存储数据，管理region server.</p>\n<p>这里你会疑问，那么多的region,它怎么找到呢？先将1~10000，10001~20000，20001~30000，30001~40000的位置存放在META表中，分为1<del>20000，20001</del>40000两份，然后再合并为1~~~~40000存放在Root表上，而Root表放在Zookeeper上存储</p>\n<h4 id=\"四、HBase命令行使用\"><a href=\"#四、HBase命令行使用\" class=\"headerlink\" title=\"四、HBase命令行使用\"></a>四、HBase命令行使用</h4><pre><code>进入hbase命令行\n./hbase shell\n\n显示hbase中的表\nlist\n\n创建user表，包含info、data两个列族\ncreate &apos;user&apos;, &apos;info1&apos;, &apos;data1&apos;\ncreate &apos;user&apos;, {NAME =&gt; &apos;info&apos;, VERSIONS =&gt; &apos;3&apos;}\n\n向user表中插入信息，row key为rk0001，列族info中添加name列标示符，值为zhangsan\nput &apos;user&apos;, &apos;rk0001&apos;, &apos;info:name&apos;, &apos;zhangsan&apos;\n\n向user表中插入信息，row key为rk0001，列族info中添加gender列标示符，值为female\nput &apos;user&apos;, &apos;rk0001&apos;, &apos;info:gender&apos;, &apos;female&apos;\n\n向user表中插入信息，row key为rk0001，列族info中添加age列标示符，值为20\nput &apos;user&apos;, &apos;rk0001&apos;, &apos;info:age&apos;, 20\n\n向user表中插入信息，row key为rk0001，列族data中添加pic列标示符，值为picture\nput &apos;user&apos;, &apos;rk0001&apos;, &apos;data:pic&apos;, &apos;picture&apos;\n\n获取user表中row key为rk0001的所有信息\nget &apos;user&apos;, &apos;rk0001&apos;\n\n获取user表中row key为rk0001，info列族的所有信息\nget &apos;user&apos;, &apos;rk0001&apos;, &apos;info&apos;\n\n获取user表中row key为rk0001，info列族的name、age列标示符的信息\nget &apos;user&apos;, &apos;rk0001&apos;, &apos;info:name&apos;, &apos;info:age&apos;\n\n获取user表中row key为rk0001，info、data列族的信息\nget &apos;user&apos;, &apos;rk0001&apos;, &apos;info&apos;, &apos;data&apos;\nget &apos;user&apos;, &apos;rk0001&apos;, {COLUMN =&gt; [&apos;info&apos;, &apos;data&apos;]}\n\nget &apos;user&apos;, &apos;rk0001&apos;, {COLUMN =&gt; [&apos;info:name&apos;, &apos;data:pic&apos;]}\n\n获取user表中row key为rk0001，列族为info，版本号最新5个的信息\nget &apos;user&apos;, &apos;rk0001&apos;, {COLUMN =&gt; &apos;info&apos;, VERSIONS =&gt; 2}\nget &apos;user&apos;, &apos;rk0001&apos;, {COLUMN =&gt; &apos;info:name&apos;, VERSIONS =&gt; 5}\nget &apos;user&apos;, &apos;rk0001&apos;, {COLUMN =&gt; &apos;info:name&apos;, VERSIONS =&gt; 5, TIMERANGE =&gt; [1392368783980, 1392380169184]}\n\n获取user表中row key为rk0001，cell的值为zhangsan的信息\nget &apos;people&apos;, &apos;rk0001&apos;, {FILTER =&gt; &quot;ValueFilter(=, &apos;binary:图片&apos;)&quot;}\n\n获取user表中row key为rk0001，列标示符中含有a的信息\nget &apos;people&apos;, &apos;rk0001&apos;, {FILTER =&gt; &quot;(QualifierFilter(=,&apos;substring:a&apos;))&quot;}\n\nput &apos;user&apos;, &apos;rk0002&apos;, &apos;info:name&apos;, &apos;fanbingbing&apos;\nput &apos;user&apos;, &apos;rk0002&apos;, &apos;info:gender&apos;, &apos;female&apos;\nput &apos;user&apos;, &apos;rk0002&apos;, &apos;info:nationality&apos;, &apos;中国&apos;\nget &apos;user&apos;, &apos;rk0002&apos;, {FILTER =&gt; &quot;ValueFilter(=, &apos;binary:中国&apos;)&quot;}\n\n\n查询user表中的所有信息\nscan &apos;user&apos;\n\n查询user表中列族为info的信息\nscan &apos;user&apos;, {COLUMNS =&gt; &apos;info&apos;}\nscan &apos;user&apos;, {COLUMNS =&gt; &apos;info&apos;, RAW =&gt; true, VERSIONS =&gt; 5}\nscan &apos;persion&apos;, {COLUMNS =&gt; &apos;info&apos;, RAW =&gt; true, VERSIONS =&gt; 3}\n查询user表中列族为info和data的信息\nscan &apos;user&apos;, {COLUMNS =&gt; [&apos;info&apos;, &apos;data&apos;]}\nscan &apos;user&apos;, {COLUMNS =&gt; [&apos;info:name&apos;, &apos;data:pic&apos;]}\n\n\n查询user表中列族为info、列标示符为name的信息\nscan &apos;user&apos;, {COLUMNS =&gt; &apos;info:name&apos;}\n\n查询user表中列族为info、列标示符为name的信息,并且版本最新的5个\nscan &apos;user&apos;, {COLUMNS =&gt; &apos;info:name&apos;, VERSIONS =&gt; 5}\n\n查询user表中列族为info和data且列标示符中含有a字符的信息\nscan &apos;user&apos;, {COLUMNS =&gt; [&apos;info&apos;, &apos;data&apos;], FILTER =&gt; &quot;(QualifierFilter(=,&apos;substring:a&apos;))&quot;}\n\n查询user表中列族为info，rk范围是[rk0001, rk0003)的数据\nscan &apos;people&apos;, {COLUMNS =&gt; &apos;info&apos;, STARTROW =&gt; &apos;rk0001&apos;, ENDROW =&gt; &apos;rk0003&apos;}\n\n查询user表中row key以rk字符开头的\nscan &apos;user&apos;,{FILTER=&gt;&quot;PrefixFilter(&apos;rk&apos;)&quot;}\n\n查询user表中指定范围的数据\nscan &apos;user&apos;, {TIMERANGE =&gt; [1392368783980, 1392380169184]}\n\n删除数据\n删除user表row key为rk0001，列标示符为info:name的数据\ndelete &apos;people&apos;, &apos;rk0001&apos;, &apos;info:name&apos;\n删除user表row key为rk0001，列标示符为info:name，timestamp为1392383705316的数据\ndelete &apos;user&apos;, &apos;rk0001&apos;, &apos;info:name&apos;, 1392383705316\n\n\n清空user表中的数据\ntruncate &apos;people&apos;\n\n\n修改表结构\n首先停用user表（新版本不用）\ndisable &apos;user&apos;\n\n添加两个列族f1和f2\nalter &apos;people&apos;, NAME =&gt; &apos;f1&apos;\nalter &apos;user&apos;, NAME =&gt; &apos;f2&apos;\n启用表\nenable &apos;user&apos;\n\n\n###disable &apos;user&apos;(新版本不用)\n删除一个列族：\nalter &apos;user&apos;, NAME =&gt; &apos;f1&apos;, METHOD =&gt; &apos;delete&apos; 或 alter &apos;user&apos;, &apos;delete&apos; =&gt; &apos;f1&apos;\n\n添加列族f1同时删除列族f2\nalter &apos;user&apos;, {NAME =&gt; &apos;f1&apos;}, {NAME =&gt; &apos;f2&apos;, METHOD =&gt; &apos;delete&apos;}\n\n将user表的f1列族版本号改为5\nalter &apos;people&apos;, NAME =&gt; &apos;info&apos;, VERSIONS =&gt; 5\n启用表\nenable &apos;user&apos;\n\n\n删除表\ndisable &apos;user&apos;\ndrop &apos;user&apos;\n\n\nget &apos;person&apos;, &apos;rk0001&apos;, {FILTER =&gt; &quot;ValueFilter(=, &apos;binary:中国&apos;)&quot;}\nget &apos;person&apos;, &apos;rk0001&apos;, {FILTER =&gt; &quot;(QualifierFilter(=,&apos;substring:a&apos;))&quot;}\nscan &apos;person&apos;, {COLUMNS =&gt; &apos;info:name&apos;}\nscan &apos;person&apos;, {COLUMNS =&gt; [&apos;info&apos;, &apos;data&apos;], FILTER =&gt; &quot;(QualifierFilter(=,&apos;substring:a&apos;))&quot;}\nscan &apos;person&apos;, {COLUMNS =&gt; &apos;info&apos;, STARTROW =&gt; &apos;rk0001&apos;, ENDROW =&gt; &apos;rk0003&apos;}\n\nscan &apos;person&apos;, {COLUMNS =&gt; &apos;info&apos;, STARTROW =&gt; &apos;20140201&apos;, ENDROW =&gt; &apos;20140301&apos;}\nscan &apos;person&apos;, {COLUMNS =&gt; &apos;info:name&apos;, TIMERANGE =&gt; [1395978233636, 1395987769587]}\ndelete &apos;person&apos;, &apos;rk0001&apos;, &apos;info:name&apos;\n\nalter &apos;person&apos;, NAME =&gt; &apos;ffff&apos;\nalter &apos;person&apos;, NAME =&gt; &apos;info&apos;, VERSIONS =&gt; 10\n\n\nget &apos;user&apos;, &apos;rk0002&apos;, {COLUMN =&gt; [&apos;info:name&apos;, &apos;data:pic&apos;]}\n</code></pre><h4 id=\"五、搭建HBase集群\"><a href=\"#五、搭建HBase集群\" class=\"headerlink\" title=\"五、搭建HBase集群\"></a>五、搭建HBase集群</h4><p>1.上传hbase安装包</p>\n<p>2.解压</p>\n<p>3.配置hbase集群，要修改3个文件（首先zk集群已经安装好了）<br>    注意：要把hadoop的hdfs-site.xml和core-site.xml 放到hbase/conf下</p>\n<pre><code>3.1修改hbase-env.sh\nexport JAVA_HOME=/usr/java/jdk1.7.0_55\n//告诉hbase使用外部的zk\nexport HBASE_MANAGES_ZK=false\n\nvim hbase-site.xml\n&lt;configuration&gt;\n    &lt;!-- 指定hbase在HDFS上存储的路径 --&gt;\n    &lt;property&gt;\n            &lt;name&gt;hbase.rootdir&lt;/name&gt;\n            &lt;value&gt;hdfs://ns1/hbase&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 指定hbase是分布式的 --&gt;\n    &lt;property&gt;\n            &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;\n            &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;!-- 指定zk的地址，多个用“,”分割 --&gt;\n    &lt;property&gt;\n            &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;\n            &lt;value&gt;hadoop05:2181,hadoop06:2181,hadoop07:2181&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n\nvim regionservers\nhadoop03\nhadoop04\nhadoop05\nhadoop06\n\n3.2拷贝hbase到其他节点\n    scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop02:/weekend/\n    scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop03:/weekend/\n    scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop04:/weekend/\n    scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop05:/weekend/\n    scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop06:/weekend/\n</code></pre><p>4.将配置好的HBase拷贝到每一个节点并同步时间。</p>\n<p>5.启动所有的hbase<br>    分别启动zk<br>        ./zkServer.sh start<br>    启动hbase集群<br>        start-dfs.sh<br>    启动hbase，在主节点上运行：<br>        start-hbase.sh<br>6.通过浏览器访问hbase管理页面<br>    192.168.1.201:60010<br>7.为保证集群的可靠性，要启动多个HMaster<br>    hbase-daemon.sh start master</p>\n<h4 id=\"五、HBase的API操作\"><a href=\"#五、HBase的API操作\" class=\"headerlink\" title=\"五、HBase的API操作\"></a>五、HBase的API操作</h4><pre><code>package cn.itcast.bigdata.hbase;\n\n\nimport java.util.List;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.Cell;\nimport org.apache.hadoop.hbase.HBaseConfiguration;\nimport org.apache.hadoop.hbase.HColumnDescriptor;\nimport org.apache.hadoop.hbase.HTableDescriptor;\nimport org.apache.hadoop.hbase.KeyValue;\nimport org.apache.hadoop.hbase.TableName;\nimport org.apache.hadoop.hbase.client.Delete;\nimport org.apache.hadoop.hbase.client.Get;\nimport org.apache.hadoop.hbase.client.HBaseAdmin;\nimport org.apache.hadoop.hbase.client.HTable;\nimport org.apache.hadoop.hbase.client.Put;\nimport org.apache.hadoop.hbase.client.Result;\nimport org.apache.hadoop.hbase.client.ResultScanner;\nimport org.apache.hadoop.hbase.client.Scan;\nimport org.apache.hadoop.hbase.filter.BinaryComparator;\nimport org.apache.hadoop.hbase.filter.BinaryPrefixComparator;\nimport org.apache.hadoop.hbase.filter.ByteArrayComparable;\nimport org.apache.hadoop.hbase.filter.ColumnPrefixFilter;\nimport org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;\nimport org.apache.hadoop.hbase.filter.FamilyFilter;\nimport org.apache.hadoop.hbase.filter.Filter;\nimport org.apache.hadoop.hbase.filter.MultipleColumnPrefixFilter;\nimport org.apache.hadoop.hbase.filter.PrefixFilter;\nimport org.apache.hadoop.hbase.filter.QualifierFilter;\nimport org.apache.hadoop.hbase.filter.RegexStringComparator;\nimport org.apache.hadoop.hbase.filter.RowFilter;\nimport org.apache.hadoop.hbase.filter.SingleColumnValueFilter;\nimport org.apache.hadoop.hbase.filter.SubstringComparator;\nimport org.apache.hadoop.hbase.master.TableNamespaceManager;\nimport org.apache.hadoop.hbase.util.Bytes;\nimport org.junit.Before;\nimport org.junit.Test;\n\npublic class HbaseDemo {\n\nprivate Configuration conf = null;\n\n@Before\npublic void init(){\n    conf = HBaseConfiguration.create();\n    conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;hadoop05,hadoop06,hadoop07&quot;);\n}\n\n@Test\npublic void testDrop() throws Exception{\n    HBaseAdmin admin = new HBaseAdmin(conf);\n    admin.disableTable(&quot;account&quot;);\n    admin.deleteTable(&quot;account&quot;);\n    admin.close();\n}\n\n@Test\npublic void testPut() throws Exception{\n    HTable table = new HTable(conf, &quot;person_info&quot;);\n    Put p = new Put(Bytes.toBytes(&quot;person_rk_bj_zhang_000002&quot;));\n    p.add(&quot;base_info&quot;.getBytes(), &quot;name&quot;.getBytes(), &quot;zhangwuji&quot;.getBytes());\n    table.put(p);\n    table.close();\n}\n\n@Test\npublic void testGet() throws Exception{\n    HTable table = new HTable(conf, &quot;person_info&quot;);\n    Get get = new Get(Bytes.toBytes(&quot;person_rk_bj_zhang_000001&quot;));\n    get.setMaxVersions(5);\n    Result result = table.get(get);\n    List&lt;Cell&gt; cells = result.listCells();\n\n   //result.getValue(family, qualifier);  可以从result中直接取出一个特定的value\n\n    //遍历出result中所有的键值对\n    for(KeyValue kv : result.list()){\n        String family = new String(kv.getFamily());\n        System.out.println(family);\n        String qualifier = new String(kv.getQualifier());\n        System.out.println(qualifier);\n        System.out.println(new String(kv.getValue()));\n\n    }\n    table.close();\n}\n\n/**\n * 多种过滤条件的使用方法\n * @throws Exception\n */\n@Test\npublic void testScan() throws Exception{\n    HTable table = new HTable(conf, &quot;person_info&quot;.getBytes());\n    Scan scan = new Scan(Bytes.toBytes(&quot;person_rk_bj_zhang_000001&quot;), Bytes.toBytes(&quot;person_rk_bj_zhang_000002&quot;));\n\n    //前缀过滤器----针对行键\n    Filter filter = new PrefixFilter(Bytes.toBytes(&quot;rk&quot;));\n\n    //行过滤器\n    ByteArrayComparable rowComparator = new BinaryComparator(Bytes.toBytes(&quot;person_rk_bj_zhang_000001&quot;));\n    RowFilter rf = new RowFilter(CompareOp.LESS_OR_EQUAL, rowComparator);\n\n    /**\n     * 假设rowkey格式为：创建日期_发布日期_ID_TITLE\n     * 目标：查找  发布日期  为  2014-12-21  的数据\n     */\n    rf = new RowFilter(CompareOp.EQUAL , new SubstringComparator(&quot;_2014-12-21_&quot;));\n\n\n    //单值过滤器 1 完整匹配字节数组\n    new SingleColumnValueFilter(&quot;base_info&quot;.getBytes(), &quot;name&quot;.getBytes(), CompareOp.EQUAL, &quot;zhangsan&quot;.getBytes());\n    //单值过滤器2 匹配正则表达式\n    ByteArrayComparable comparator = new RegexStringComparator(&quot;zhang.&quot;);\n    new SingleColumnValueFilter(&quot;info&quot;.getBytes(), &quot;NAME&quot;.getBytes(), CompareOp.EQUAL, comparator);\n\n    //单值过滤器2 匹配是否包含子串,大小写不敏感\n    comparator = new SubstringComparator(&quot;wu&quot;);\n    new SingleColumnValueFilter(&quot;info&quot;.getBytes(), &quot;NAME&quot;.getBytes(), CompareOp.EQUAL, comparator);\n\n    //键值对元数据过滤-----family过滤----字节数组完整匹配\n    FamilyFilter ff = new FamilyFilter(\n            CompareOp.EQUAL , \n            new BinaryComparator(Bytes.toBytes(&quot;base_info&quot;))   //表中不存在inf列族，过滤结果为空\n            );\n    //键值对元数据过滤-----family过滤----字节数组前缀匹配\n    ff = new FamilyFilter(\n            CompareOp.EQUAL , \n            new BinaryPrefixComparator(Bytes.toBytes(&quot;inf&quot;))   //表中存在以inf打头的列族info，过滤结果为该列族所有行\n            );\n\n\n   //键值对元数据过滤-----qualifier过滤----字节数组完整匹配\n\n    filter = new QualifierFilter(\n            CompareOp.EQUAL , \n            new BinaryComparator(Bytes.toBytes(&quot;na&quot;))   //表中不存在na列，过滤结果为空\n            );\n    filter = new QualifierFilter(\n            CompareOp.EQUAL , \n            new BinaryPrefixComparator(Bytes.toBytes(&quot;na&quot;))   //表中存在以na打头的列name，过滤结果为所有行的该列数据\n            );\n\n    //基于列名(即Qualifier)前缀过滤数据的ColumnPrefixFilter\n    filter = new ColumnPrefixFilter(&quot;na&quot;.getBytes());\n\n    //基于列名(即Qualifier)多个前缀过滤数据的MultipleColumnPrefixFilter\n    byte[][] prefixes = new byte[][] {Bytes.toBytes(&quot;na&quot;), Bytes.toBytes(&quot;me&quot;)};\n    filter = new MultipleColumnPrefixFilter(prefixes);\n\n    //为查询设置过滤条件\n    scan.setFilter(filter);\n\n\n    scan.addFamily(Bytes.toBytes(&quot;base_info&quot;));\n    ResultScanner scanner = table.getScanner(scan);\n    for(Result r : scanner){\n        /**\n        for(KeyValue kv : r.list()){\n            String family = new String(kv.getFamily());\n            System.out.println(family);\n            String qualifier = new String(kv.getQualifier());\n            System.out.println(qualifier);\n            System.out.println(new String(kv.getValue()));\n        }\n        */\n        //直接从result中取到某个特定的value\n        byte[] value = r.getValue(Bytes.toBytes(&quot;base_info&quot;), Bytes.toBytes(&quot;name&quot;));\n        System.out.println(new String(value));\n    }\n    table.close();\n}\n\n\n@Test\npublic void testDel() throws Exception{\n    HTable table = new HTable(conf, &quot;user&quot;);\n    Delete del = new Delete(Bytes.toBytes(&quot;rk0001&quot;));\n    del.deleteColumn(Bytes.toBytes(&quot;data&quot;), Bytes.toBytes(&quot;pic&quot;));\n    table.delete(del);\n    table.close();\n}\n\n\n\n\npublic static void main(String[] args) throws Exception {\n    Configuration conf = HBaseConfiguration.create();\n   //conf.set(&quot;hbase.zookeeper.quorum&quot;,&quot;hadoop05:2181,hadoop06:2181,hadoop07:2181&quot;);\n        HBaseAdmin admin = new HBaseAdmin(conf);\n\n    TableName tableName = TableName.valueOf(&quot;person_info&quot;);\n    HTableDescriptor td = new HTableDescriptor(tableName);\n    HColumnDescriptor cd = new HColumnDescriptor(&quot;base_info&quot;);\n    cd.setMaxVersions(10);\n    td.addFamily(cd);\n    admin.createTable(td);\n\n    admin.close();\n\n}\n</code></pre><p>}</p>\n"},{"title":"Hadoop(二)（HDFS部分常用基本命令）","author":"小小冰弟","date":"2018-02-05T05:59:48.000Z","_content":"#### 其实基本跟Linux下的命令差不多\n\n#### 启动命令位于sbin目录下\n     start-dfs.sh\n     start-yarn.sh\n     jps(查看有没有启动成功)\n     访问ip地址：50070查看是否成功\n\n#### 1、显示所有命令\n    hadoop fs(以下命令都需要在前方加上hadoop fs且全路径如果为hdfs://ip:8020默认端口/ )\n\n#### 2、上传文件（三种方式）\n\n    -put 文件 hdfsdir（上传）\n    -appendToFile(追加)\n    -copyFromLocal localdir hdfsdir  (从本地复制)\n    -moveFromLocal localdir hdfsdir（从本地移动）\n\n\n#### 3、显示目录结构\n    -ls 路径 （全展示，显示结果解释在下面）\n    -lsr 路径 （递归显示文件）\n    -du 路径 （统计文件大小）\n    -dus路径 (汇总统计大小)\n    -count (统计文件夹数量、文件数量、文件总大小信息)\n显示结果代表：\n1. 首字母表示文件类型（\"d\"是文件夹，\"-\"是文件）\n2. 后面的字符与Linux一样表示权限\n3. 后面的\"-\"或者数字表示副本，文件夹没有副本\n4. 接着依次为 拥有者 所在组 文件大小 修改时间 路径\n\n#### 4、移动复制与删除\n    -mv(移动)\n    -cp(复制)\n    -rm(删除)\n    -rmr(递归删除)\n    \n    \n#### 5、创建\n    -mkdir（创建空白文件夹）\n    -touchz （创建空白文件）\n#### 6、查看\n    -cat()\n    -tail()\n    -text(显示最后1K字节内容，加上\"-f\" 便跟随查看)\n \n#### 7、其他\n    -setrep 数量 文件 (设置副本数量)\n    -chmod(修改文件权限)\n    -chown 属主 文件 (修改属主)\n    -chgrp 所在组(新的) 文件(修改所在组)","source":"_posts/Hadoop-二-（常用基本命令）.md","raw":"title: Hadoop(二)（HDFS部分常用基本命令）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-02-05 13:59:48\n---\n#### 其实基本跟Linux下的命令差不多\n\n#### 启动命令位于sbin目录下\n     start-dfs.sh\n     start-yarn.sh\n     jps(查看有没有启动成功)\n     访问ip地址：50070查看是否成功\n\n#### 1、显示所有命令\n    hadoop fs(以下命令都需要在前方加上hadoop fs且全路径如果为hdfs://ip:8020默认端口/ )\n\n#### 2、上传文件（三种方式）\n\n    -put 文件 hdfsdir（上传）\n    -appendToFile(追加)\n    -copyFromLocal localdir hdfsdir  (从本地复制)\n    -moveFromLocal localdir hdfsdir（从本地移动）\n\n\n#### 3、显示目录结构\n    -ls 路径 （全展示，显示结果解释在下面）\n    -lsr 路径 （递归显示文件）\n    -du 路径 （统计文件大小）\n    -dus路径 (汇总统计大小)\n    -count (统计文件夹数量、文件数量、文件总大小信息)\n显示结果代表：\n1. 首字母表示文件类型（\"d\"是文件夹，\"-\"是文件）\n2. 后面的字符与Linux一样表示权限\n3. 后面的\"-\"或者数字表示副本，文件夹没有副本\n4. 接着依次为 拥有者 所在组 文件大小 修改时间 路径\n\n#### 4、移动复制与删除\n    -mv(移动)\n    -cp(复制)\n    -rm(删除)\n    -rmr(递归删除)\n    \n    \n#### 5、创建\n    -mkdir（创建空白文件夹）\n    -touchz （创建空白文件）\n#### 6、查看\n    -cat()\n    -tail()\n    -text(显示最后1K字节内容，加上\"-f\" 便跟随查看)\n \n#### 7、其他\n    -setrep 数量 文件 (设置副本数量)\n    -chmod(修改文件权限)\n    -chown 属主 文件 (修改属主)\n    -chgrp 所在组(新的) 文件(修改所在组)","slug":"Hadoop-二-（常用基本命令）","published":1,"updated":"2018-03-26T09:46:34.649Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60kx000rxo7k0x6sc15u","content":"<h4 id=\"其实基本跟Linux下的命令差不多\"><a href=\"#其实基本跟Linux下的命令差不多\" class=\"headerlink\" title=\"其实基本跟Linux下的命令差不多\"></a>其实基本跟Linux下的命令差不多</h4><h4 id=\"启动命令位于sbin目录下\"><a href=\"#启动命令位于sbin目录下\" class=\"headerlink\" title=\"启动命令位于sbin目录下\"></a>启动命令位于sbin目录下</h4><pre><code>start-dfs.sh\nstart-yarn.sh\njps(查看有没有启动成功)\n访问ip地址：50070查看是否成功\n</code></pre><h4 id=\"1、显示所有命令\"><a href=\"#1、显示所有命令\" class=\"headerlink\" title=\"1、显示所有命令\"></a>1、显示所有命令</h4><pre><code>hadoop fs(以下命令都需要在前方加上hadoop fs且全路径如果为hdfs://ip:8020默认端口/ )\n</code></pre><h4 id=\"2、上传文件（三种方式）\"><a href=\"#2、上传文件（三种方式）\" class=\"headerlink\" title=\"2、上传文件（三种方式）\"></a>2、上传文件（三种方式）</h4><pre><code>-put 文件 hdfsdir（上传）\n-appendToFile(追加)\n-copyFromLocal localdir hdfsdir  (从本地复制)\n-moveFromLocal localdir hdfsdir（从本地移动）\n</code></pre><h4 id=\"3、显示目录结构\"><a href=\"#3、显示目录结构\" class=\"headerlink\" title=\"3、显示目录结构\"></a>3、显示目录结构</h4><pre><code>-ls 路径 （全展示，显示结果解释在下面）\n-lsr 路径 （递归显示文件）\n-du 路径 （统计文件大小）\n-dus路径 (汇总统计大小)\n-count (统计文件夹数量、文件数量、文件总大小信息)\n</code></pre><p>显示结果代表：</p>\n<ol>\n<li>首字母表示文件类型（”d”是文件夹，”-“是文件）</li>\n<li>后面的字符与Linux一样表示权限</li>\n<li>后面的”-“或者数字表示副本，文件夹没有副本</li>\n<li>接着依次为 拥有者 所在组 文件大小 修改时间 路径</li>\n</ol>\n<h4 id=\"4、移动复制与删除\"><a href=\"#4、移动复制与删除\" class=\"headerlink\" title=\"4、移动复制与删除\"></a>4、移动复制与删除</h4><pre><code>-mv(移动)\n-cp(复制)\n-rm(删除)\n-rmr(递归删除)\n</code></pre><h4 id=\"5、创建\"><a href=\"#5、创建\" class=\"headerlink\" title=\"5、创建\"></a>5、创建</h4><pre><code>-mkdir（创建空白文件夹）\n-touchz （创建空白文件）\n</code></pre><h4 id=\"6、查看\"><a href=\"#6、查看\" class=\"headerlink\" title=\"6、查看\"></a>6、查看</h4><pre><code>-cat()\n-tail()\n-text(显示最后1K字节内容，加上&quot;-f&quot; 便跟随查看)\n</code></pre><h4 id=\"7、其他\"><a href=\"#7、其他\" class=\"headerlink\" title=\"7、其他\"></a>7、其他</h4><pre><code>-setrep 数量 文件 (设置副本数量)\n-chmod(修改文件权限)\n-chown 属主 文件 (修改属主)\n-chgrp 所在组(新的) 文件(修改所在组)\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"其实基本跟Linux下的命令差不多\"><a href=\"#其实基本跟Linux下的命令差不多\" class=\"headerlink\" title=\"其实基本跟Linux下的命令差不多\"></a>其实基本跟Linux下的命令差不多</h4><h4 id=\"启动命令位于sbin目录下\"><a href=\"#启动命令位于sbin目录下\" class=\"headerlink\" title=\"启动命令位于sbin目录下\"></a>启动命令位于sbin目录下</h4><pre><code>start-dfs.sh\nstart-yarn.sh\njps(查看有没有启动成功)\n访问ip地址：50070查看是否成功\n</code></pre><h4 id=\"1、显示所有命令\"><a href=\"#1、显示所有命令\" class=\"headerlink\" title=\"1、显示所有命令\"></a>1、显示所有命令</h4><pre><code>hadoop fs(以下命令都需要在前方加上hadoop fs且全路径如果为hdfs://ip:8020默认端口/ )\n</code></pre><h4 id=\"2、上传文件（三种方式）\"><a href=\"#2、上传文件（三种方式）\" class=\"headerlink\" title=\"2、上传文件（三种方式）\"></a>2、上传文件（三种方式）</h4><pre><code>-put 文件 hdfsdir（上传）\n-appendToFile(追加)\n-copyFromLocal localdir hdfsdir  (从本地复制)\n-moveFromLocal localdir hdfsdir（从本地移动）\n</code></pre><h4 id=\"3、显示目录结构\"><a href=\"#3、显示目录结构\" class=\"headerlink\" title=\"3、显示目录结构\"></a>3、显示目录结构</h4><pre><code>-ls 路径 （全展示，显示结果解释在下面）\n-lsr 路径 （递归显示文件）\n-du 路径 （统计文件大小）\n-dus路径 (汇总统计大小)\n-count (统计文件夹数量、文件数量、文件总大小信息)\n</code></pre><p>显示结果代表：</p>\n<ol>\n<li>首字母表示文件类型（”d”是文件夹，”-“是文件）</li>\n<li>后面的字符与Linux一样表示权限</li>\n<li>后面的”-“或者数字表示副本，文件夹没有副本</li>\n<li>接着依次为 拥有者 所在组 文件大小 修改时间 路径</li>\n</ol>\n<h4 id=\"4、移动复制与删除\"><a href=\"#4、移动复制与删除\" class=\"headerlink\" title=\"4、移动复制与删除\"></a>4、移动复制与删除</h4><pre><code>-mv(移动)\n-cp(复制)\n-rm(删除)\n-rmr(递归删除)\n</code></pre><h4 id=\"5、创建\"><a href=\"#5、创建\" class=\"headerlink\" title=\"5、创建\"></a>5、创建</h4><pre><code>-mkdir（创建空白文件夹）\n-touchz （创建空白文件）\n</code></pre><h4 id=\"6、查看\"><a href=\"#6、查看\" class=\"headerlink\" title=\"6、查看\"></a>6、查看</h4><pre><code>-cat()\n-tail()\n-text(显示最后1K字节内容，加上&quot;-f&quot; 便跟随查看)\n</code></pre><h4 id=\"7、其他\"><a href=\"#7、其他\" class=\"headerlink\" title=\"7、其他\"></a>7、其他</h4><pre><code>-setrep 数量 文件 (设置副本数量)\n-chmod(修改文件权限)\n-chown 属主 文件 (修改属主)\n-chgrp 所在组(新的) 文件(修改所在组)\n</code></pre>"},{"title":"Hadoop(八)（hive）","author":"小小冰弟","date":"2018-03-28T08:45:12.000Z","_content":"#### 一、Hive\nHive是一个数据仓库基础工具在Hadoop中用来处理结构化数据。它架构在Hadoop之上，总归为大数据，并使得查询和分析方便。并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。简单点说就是你不需要会JAVA就可以使用，只要你会SQL语句就可以了。（一般存在mysql中，也可以使用自带的嵌入式的数据库derby）\n\n#### 二、Hive配置 \n ###### 1.将conf下的hive-default.xml.template 改名为 hive-site.xml \n   \n\t修改hive-site.xml（删除所有内容，只留一个<property></property>）\n\t添加如下内容：\n\t<property>\n\t  <name>javax.jdo.option.ConnectionURL</name>\n\t <value>jdbc:mysql://hadoop01:3306/hivecreateDatabaseIfNotExist=true</value>\n\t  <description>JDBC connect string for a JDBC metastore</description>\n\t</property>\n\n\t<property>\n\t  <name>javax.jdo.option.ConnectionDriverName</name>\n\t  <value>com.mysql.jdbc.Driver</value>\n\t  <description>Driver class name for a JDBC metastore</description>\n\t</property>\n\n\t<property>\n\t  <name>javax.jdo.option.ConnectionUserName</name>\n\t  <value>root</value>\n\t  <description>username to use against metastore database</description>\n\t</property>\n\n\t<property>\n\t  <name>javax.jdo.option.ConnectionPassword</name>\n\t  <value>root</value>\n\t  <description>password to use against metastore database</description>\n\t</property>\n    \n    \n    \n###### 2.安装hive和mysq\n\n    将mysql的连接jar包拷贝到$HIVE_HOME/lib目录下\n\t如果出现没有权限的问题，在mysql授权(在安装mysql的机器上执行)\n\tmysql -uroot -p\n\t#(执行下面的语句  *.*:所有库下的所有表   %：任何IP地址或主机都可以连接)\n\tGRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123' WITH GRANT OPTION;\n\tFLUSH PRIVILEGES;\n    \n###### 3.建表\nrow format delimited：表示一行代表一个数据\nfileds terminated by '\\t':表示这一行的数据按照分隔符切分作为字段属性\n\n    建表(默认是内部表)\n\tcreate table trade_detail(id bigint, account string, income double, expenses double, time string) row format delimited fields terminated by '\\t';\n\t建分区表（partitioned by (logdate string)表示在表文件夹下面会有个logdate文件夹）\n\tcreate table td_part(id bigint, account string, income double, expenses double, time string) partitioned by (logdate string) row format delimited fields terminated by '\\t';\n\t建外部表（external 表示表的路径在hdfs与本地上可以是任何路径，方便共享，不需要复制）\n\tcreate external table td_ext(id bigint, account string, income double, expenses double, time string) row format delimited fields terminated by '\\t' location '/td_ext';\n\n###### 4.分区表\n\n    普通表和分区表区别：有大量数据增加的需要建分区表\n\tcreate table book (id bigint, name string) partitioned by (pubdate string) row format delimited fields terminated by '\\t'; \n\n\t分区表加载数据\n\tload data local inpath './book.txt' overwrite into table book partition (pubdate='2010-08-22');\n\t\n\tload data local inpath '/root/data.am' into table beauty partition (nation=\"USA\");\n\n\t\n\tselect nation, avg(size) from beauties group by nation order by avg(size);\n    \n上面加载使用了local关键字是因为用了本地的，如果是hdfs上的就不要了。  \n\n\n#### 三、Hive高阶\nhive 还支持集合类型，如map,list等\n\n###### 1.数组型（collection items terminated by）\n\n    //array \n    create table tab_array(a array<int>,b array<string>)\n    row format delimited\n    fields terminated by '\\t'\n    collection items terminated by ',';\n\n    select a[0] from tab_array;\n    select * from tab_array where array_contains(b,'word');\n    insert into table tab_array select array(0),array(name,ip) from tab_ext t; \n\n###### 2.Map型（collection items terminated by and map keys terminated by）\n    //map\n    create table tab_map(name string,info map<string,string>)\n    row format delimited\n    fields terminated by '\\t'\n    collection items terminated by ','\n    map keys terminated by ':';\n\n    load data local inpath '/home/hadoop/hivetemp/tab_map.txt' overwrite into table tab_map;\n    insert into table tab_map select name,map('name',name,'ip',ip) from tab_ext; \n\n###### 3.结构型\n    //struct\n    create table tab_struct(name string,info struct<age:int,tel:string,addr:string>)\n    row format delimited\n    fields terminated by '\\t'\n    collection items terminated by ','\n\n    load data local inpath '/home/hadoop/hivetemp/tab_st.txt' overwrite into table tab_struct;\n    insert into table tab_struct select name,named_struct('age',id,'tel',name,'addr',country) from tab_ext;\n    \n###### 4.批量插入\n\n    //insert from select   通过select语句批量插入数据到别的表\n    create table tab_ip_like like tab_ip;\n    insert overwrite table tab_ip_like select * from tab_ip;\n\n    //write to hdfs  将结果写入到hdfs的文件中\n    insert overwrite local directory '/home/hadoop/hivetemp/test.txt' select * from tab_ip_part where part_flag='part1';    \n    insert overwrite directory '/hiveout.txt' select * from tab_ip_part where part_flag='part1';\n\n    //cli shell  通过shell执行hive的hql语句（*这里表前面需要家数据库点）\n    hive -S -e 'select country,count(*) from tab_ext' > /home/hadoop/hivetemp/e.txt  \n\n    select * from tab_ext sort by id desc limit 5;\n\n    select a.ip,b.book from tab_ext a join tab_ip_book b on(a.name=b.name);\n    \n###### 5. 用户自定义函数\n因为虽然本身自带了avg,sum等等通用函数，但有的时候你还是希望自己写。\n\n    0.要继承org.apache.hadoop.hive.ql.exec.UDF类实现evaluate\n\n    自定义函数调用过程：\n    1.添加jar包（在hive命令行里面执行）\n    hive> add jar /root/NUDF.jar;\n\n    2.创建临时函数（关了再开就没了）\n    hive> create temporary function getNation as 'cn.itcast.hive.udf.NationUDF';\n\n    3.调用\n    hive> select id, name, getNation(nation) from beauty;\n\n    4.将查询结果保存到HDFS中\n    hive> create table result row format delimited fields terminated by '\\t' as select * from beauty order by id desc;\t\n    hive> select id, getAreaName(id) as name from tel_rec;\n\n\n    create table result row format delimited fields terminated by '\\t' as select id, getNation(nation) from beauties;\n    \n    \n    \n","source":"_posts/Hadoop-八-（hive）.md","raw":"title: Hadoop(八)（hive）\nauthor: 小小冰弟\ndate: 2018-03-28 16:45:12\ntags: study\ncategories: Hadoop\n---\n#### 一、Hive\nHive是一个数据仓库基础工具在Hadoop中用来处理结构化数据。它架构在Hadoop之上，总归为大数据，并使得查询和分析方便。并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。简单点说就是你不需要会JAVA就可以使用，只要你会SQL语句就可以了。（一般存在mysql中，也可以使用自带的嵌入式的数据库derby）\n\n#### 二、Hive配置 \n ###### 1.将conf下的hive-default.xml.template 改名为 hive-site.xml \n   \n\t修改hive-site.xml（删除所有内容，只留一个<property></property>）\n\t添加如下内容：\n\t<property>\n\t  <name>javax.jdo.option.ConnectionURL</name>\n\t <value>jdbc:mysql://hadoop01:3306/hivecreateDatabaseIfNotExist=true</value>\n\t  <description>JDBC connect string for a JDBC metastore</description>\n\t</property>\n\n\t<property>\n\t  <name>javax.jdo.option.ConnectionDriverName</name>\n\t  <value>com.mysql.jdbc.Driver</value>\n\t  <description>Driver class name for a JDBC metastore</description>\n\t</property>\n\n\t<property>\n\t  <name>javax.jdo.option.ConnectionUserName</name>\n\t  <value>root</value>\n\t  <description>username to use against metastore database</description>\n\t</property>\n\n\t<property>\n\t  <name>javax.jdo.option.ConnectionPassword</name>\n\t  <value>root</value>\n\t  <description>password to use against metastore database</description>\n\t</property>\n    \n    \n    \n###### 2.安装hive和mysq\n\n    将mysql的连接jar包拷贝到$HIVE_HOME/lib目录下\n\t如果出现没有权限的问题，在mysql授权(在安装mysql的机器上执行)\n\tmysql -uroot -p\n\t#(执行下面的语句  *.*:所有库下的所有表   %：任何IP地址或主机都可以连接)\n\tGRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123' WITH GRANT OPTION;\n\tFLUSH PRIVILEGES;\n    \n###### 3.建表\nrow format delimited：表示一行代表一个数据\nfileds terminated by '\\t':表示这一行的数据按照分隔符切分作为字段属性\n\n    建表(默认是内部表)\n\tcreate table trade_detail(id bigint, account string, income double, expenses double, time string) row format delimited fields terminated by '\\t';\n\t建分区表（partitioned by (logdate string)表示在表文件夹下面会有个logdate文件夹）\n\tcreate table td_part(id bigint, account string, income double, expenses double, time string) partitioned by (logdate string) row format delimited fields terminated by '\\t';\n\t建外部表（external 表示表的路径在hdfs与本地上可以是任何路径，方便共享，不需要复制）\n\tcreate external table td_ext(id bigint, account string, income double, expenses double, time string) row format delimited fields terminated by '\\t' location '/td_ext';\n\n###### 4.分区表\n\n    普通表和分区表区别：有大量数据增加的需要建分区表\n\tcreate table book (id bigint, name string) partitioned by (pubdate string) row format delimited fields terminated by '\\t'; \n\n\t分区表加载数据\n\tload data local inpath './book.txt' overwrite into table book partition (pubdate='2010-08-22');\n\t\n\tload data local inpath '/root/data.am' into table beauty partition (nation=\"USA\");\n\n\t\n\tselect nation, avg(size) from beauties group by nation order by avg(size);\n    \n上面加载使用了local关键字是因为用了本地的，如果是hdfs上的就不要了。  \n\n\n#### 三、Hive高阶\nhive 还支持集合类型，如map,list等\n\n###### 1.数组型（collection items terminated by）\n\n    //array \n    create table tab_array(a array<int>,b array<string>)\n    row format delimited\n    fields terminated by '\\t'\n    collection items terminated by ',';\n\n    select a[0] from tab_array;\n    select * from tab_array where array_contains(b,'word');\n    insert into table tab_array select array(0),array(name,ip) from tab_ext t; \n\n###### 2.Map型（collection items terminated by and map keys terminated by）\n    //map\n    create table tab_map(name string,info map<string,string>)\n    row format delimited\n    fields terminated by '\\t'\n    collection items terminated by ','\n    map keys terminated by ':';\n\n    load data local inpath '/home/hadoop/hivetemp/tab_map.txt' overwrite into table tab_map;\n    insert into table tab_map select name,map('name',name,'ip',ip) from tab_ext; \n\n###### 3.结构型\n    //struct\n    create table tab_struct(name string,info struct<age:int,tel:string,addr:string>)\n    row format delimited\n    fields terminated by '\\t'\n    collection items terminated by ','\n\n    load data local inpath '/home/hadoop/hivetemp/tab_st.txt' overwrite into table tab_struct;\n    insert into table tab_struct select name,named_struct('age',id,'tel',name,'addr',country) from tab_ext;\n    \n###### 4.批量插入\n\n    //insert from select   通过select语句批量插入数据到别的表\n    create table tab_ip_like like tab_ip;\n    insert overwrite table tab_ip_like select * from tab_ip;\n\n    //write to hdfs  将结果写入到hdfs的文件中\n    insert overwrite local directory '/home/hadoop/hivetemp/test.txt' select * from tab_ip_part where part_flag='part1';    \n    insert overwrite directory '/hiveout.txt' select * from tab_ip_part where part_flag='part1';\n\n    //cli shell  通过shell执行hive的hql语句（*这里表前面需要家数据库点）\n    hive -S -e 'select country,count(*) from tab_ext' > /home/hadoop/hivetemp/e.txt  \n\n    select * from tab_ext sort by id desc limit 5;\n\n    select a.ip,b.book from tab_ext a join tab_ip_book b on(a.name=b.name);\n    \n###### 5. 用户自定义函数\n因为虽然本身自带了avg,sum等等通用函数，但有的时候你还是希望自己写。\n\n    0.要继承org.apache.hadoop.hive.ql.exec.UDF类实现evaluate\n\n    自定义函数调用过程：\n    1.添加jar包（在hive命令行里面执行）\n    hive> add jar /root/NUDF.jar;\n\n    2.创建临时函数（关了再开就没了）\n    hive> create temporary function getNation as 'cn.itcast.hive.udf.NationUDF';\n\n    3.调用\n    hive> select id, name, getNation(nation) from beauty;\n\n    4.将查询结果保存到HDFS中\n    hive> create table result row format delimited fields terminated by '\\t' as select * from beauty order by id desc;\t\n    hive> select id, getAreaName(id) as name from tel_rec;\n\n\n    create table result row format delimited fields terminated by '\\t' as select id, getNation(nation) from beauties;\n    \n    \n    \n","slug":"Hadoop-八-（hive）","published":1,"updated":"2018-03-28T10:21:05.613Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60ky000uxo7kcgl695z7","content":"<h4 id=\"一、Hive\"><a href=\"#一、Hive\" class=\"headerlink\" title=\"一、Hive\"></a>一、Hive</h4><p>Hive是一个数据仓库基础工具在Hadoop中用来处理结构化数据。它架构在Hadoop之上，总归为大数据，并使得查询和分析方便。并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。简单点说就是你不需要会JAVA就可以使用，只要你会SQL语句就可以了。（一般存在mysql中，也可以使用自带的嵌入式的数据库derby）</p>\n<h4 id=\"二、Hive配置\"><a href=\"#二、Hive配置\" class=\"headerlink\" title=\"二、Hive配置\"></a>二、Hive配置</h4><h6 id=\"1-将conf下的hive-default-xml-template-改名为-hive-site-xml\"><a href=\"#1-将conf下的hive-default-xml-template-改名为-hive-site-xml\" class=\"headerlink\" title=\"1.将conf下的hive-default.xml.template 改名为 hive-site.xml\"></a>1.将conf下的hive-default.xml.template 改名为 hive-site.xml</h6><pre><code>修改hive-site.xml（删除所有内容，只留一个&lt;property&gt;&lt;/property&gt;）\n添加如下内容：\n&lt;property&gt;\n  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;\n &lt;value&gt;jdbc:mysql://hadoop01:3306/hivecreateDatabaseIfNotExist=true&lt;/value&gt;\n  &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;\n&lt;/property&gt;\n\n&lt;property&gt;\n  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;\n  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;\n  &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;\n&lt;/property&gt;\n\n&lt;property&gt;\n  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;\n  &lt;value&gt;root&lt;/value&gt;\n  &lt;description&gt;username to use against metastore database&lt;/description&gt;\n&lt;/property&gt;\n\n&lt;property&gt;\n  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;\n  &lt;value&gt;root&lt;/value&gt;\n  &lt;description&gt;password to use against metastore database&lt;/description&gt;\n&lt;/property&gt;\n</code></pre><h6 id=\"2-安装hive和mysq\"><a href=\"#2-安装hive和mysq\" class=\"headerlink\" title=\"2.安装hive和mysq\"></a>2.安装hive和mysq</h6><pre><code>将mysql的连接jar包拷贝到$HIVE_HOME/lib目录下\n如果出现没有权限的问题，在mysql授权(在安装mysql的机器上执行)\nmysql -uroot -p\n#(执行下面的语句  *.*:所有库下的所有表   %：任何IP地址或主机都可以连接)\nGRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;123&apos; WITH GRANT OPTION;\nFLUSH PRIVILEGES;\n</code></pre><h6 id=\"3-建表\"><a href=\"#3-建表\" class=\"headerlink\" title=\"3.建表\"></a>3.建表</h6><p>row format delimited：表示一行代表一个数据<br>fileds terminated by ‘\\t’:表示这一行的数据按照分隔符切分作为字段属性</p>\n<pre><code>建表(默认是内部表)\ncreate table trade_detail(id bigint, account string, income double, expenses double, time string) row format delimited fields terminated by &apos;\\t&apos;;\n建分区表（partitioned by (logdate string)表示在表文件夹下面会有个logdate文件夹）\ncreate table td_part(id bigint, account string, income double, expenses double, time string) partitioned by (logdate string) row format delimited fields terminated by &apos;\\t&apos;;\n建外部表（external 表示表的路径在hdfs与本地上可以是任何路径，方便共享，不需要复制）\ncreate external table td_ext(id bigint, account string, income double, expenses double, time string) row format delimited fields terminated by &apos;\\t&apos; location &apos;/td_ext&apos;;\n</code></pre><h6 id=\"4-分区表\"><a href=\"#4-分区表\" class=\"headerlink\" title=\"4.分区表\"></a>4.分区表</h6><pre><code>普通表和分区表区别：有大量数据增加的需要建分区表\ncreate table book (id bigint, name string) partitioned by (pubdate string) row format delimited fields terminated by &apos;\\t&apos;; \n\n分区表加载数据\nload data local inpath &apos;./book.txt&apos; overwrite into table book partition (pubdate=&apos;2010-08-22&apos;);\n\nload data local inpath &apos;/root/data.am&apos; into table beauty partition (nation=&quot;USA&quot;);\n\n\nselect nation, avg(size) from beauties group by nation order by avg(size);\n</code></pre><p>上面加载使用了local关键字是因为用了本地的，如果是hdfs上的就不要了。  </p>\n<h4 id=\"三、Hive高阶\"><a href=\"#三、Hive高阶\" class=\"headerlink\" title=\"三、Hive高阶\"></a>三、Hive高阶</h4><p>hive 还支持集合类型，如map,list等</p>\n<h6 id=\"1-数组型（collection-items-terminated-by）\"><a href=\"#1-数组型（collection-items-terminated-by）\" class=\"headerlink\" title=\"1.数组型（collection items terminated by）\"></a>1.数组型（collection items terminated by）</h6><pre><code>//array \ncreate table tab_array(a array&lt;int&gt;,b array&lt;string&gt;)\nrow format delimited\nfields terminated by &apos;\\t&apos;\ncollection items terminated by &apos;,&apos;;\n\nselect a[0] from tab_array;\nselect * from tab_array where array_contains(b,&apos;word&apos;);\ninsert into table tab_array select array(0),array(name,ip) from tab_ext t; \n</code></pre><h6 id=\"2-Map型（collection-items-terminated-by-and-map-keys-terminated-by）\"><a href=\"#2-Map型（collection-items-terminated-by-and-map-keys-terminated-by）\" class=\"headerlink\" title=\"2.Map型（collection items terminated by and map keys terminated by）\"></a>2.Map型（collection items terminated by and map keys terminated by）</h6><pre><code>//map\ncreate table tab_map(name string,info map&lt;string,string&gt;)\nrow format delimited\nfields terminated by &apos;\\t&apos;\ncollection items terminated by &apos;,&apos;\nmap keys terminated by &apos;:&apos;;\n\nload data local inpath &apos;/home/hadoop/hivetemp/tab_map.txt&apos; overwrite into table tab_map;\ninsert into table tab_map select name,map(&apos;name&apos;,name,&apos;ip&apos;,ip) from tab_ext; \n</code></pre><h6 id=\"3-结构型\"><a href=\"#3-结构型\" class=\"headerlink\" title=\"3.结构型\"></a>3.结构型</h6><pre><code>//struct\ncreate table tab_struct(name string,info struct&lt;age:int,tel:string,addr:string&gt;)\nrow format delimited\nfields terminated by &apos;\\t&apos;\ncollection items terminated by &apos;,&apos;\n\nload data local inpath &apos;/home/hadoop/hivetemp/tab_st.txt&apos; overwrite into table tab_struct;\ninsert into table tab_struct select name,named_struct(&apos;age&apos;,id,&apos;tel&apos;,name,&apos;addr&apos;,country) from tab_ext;\n</code></pre><h6 id=\"4-批量插入\"><a href=\"#4-批量插入\" class=\"headerlink\" title=\"4.批量插入\"></a>4.批量插入</h6><pre><code>//insert from select   通过select语句批量插入数据到别的表\ncreate table tab_ip_like like tab_ip;\ninsert overwrite table tab_ip_like select * from tab_ip;\n\n//write to hdfs  将结果写入到hdfs的文件中\ninsert overwrite local directory &apos;/home/hadoop/hivetemp/test.txt&apos; select * from tab_ip_part where part_flag=&apos;part1&apos;;    \ninsert overwrite directory &apos;/hiveout.txt&apos; select * from tab_ip_part where part_flag=&apos;part1&apos;;\n\n//cli shell  通过shell执行hive的hql语句（*这里表前面需要家数据库点）\nhive -S -e &apos;select country,count(*) from tab_ext&apos; &gt; /home/hadoop/hivetemp/e.txt  \n\nselect * from tab_ext sort by id desc limit 5;\n\nselect a.ip,b.book from tab_ext a join tab_ip_book b on(a.name=b.name);\n</code></pre><h6 id=\"5-用户自定义函数\"><a href=\"#5-用户自定义函数\" class=\"headerlink\" title=\"5. 用户自定义函数\"></a>5. 用户自定义函数</h6><p>因为虽然本身自带了avg,sum等等通用函数，但有的时候你还是希望自己写。</p>\n<pre><code>0.要继承org.apache.hadoop.hive.ql.exec.UDF类实现evaluate\n\n自定义函数调用过程：\n1.添加jar包（在hive命令行里面执行）\nhive&gt; add jar /root/NUDF.jar;\n\n2.创建临时函数（关了再开就没了）\nhive&gt; create temporary function getNation as &apos;cn.itcast.hive.udf.NationUDF&apos;;\n\n3.调用\nhive&gt; select id, name, getNation(nation) from beauty;\n\n4.将查询结果保存到HDFS中\nhive&gt; create table result row format delimited fields terminated by &apos;\\t&apos; as select * from beauty order by id desc;    \nhive&gt; select id, getAreaName(id) as name from tel_rec;\n\n\ncreate table result row format delimited fields terminated by &apos;\\t&apos; as select id, getNation(nation) from beauties;\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"一、Hive\"><a href=\"#一、Hive\" class=\"headerlink\" title=\"一、Hive\"></a>一、Hive</h4><p>Hive是一个数据仓库基础工具在Hadoop中用来处理结构化数据。它架构在Hadoop之上，总归为大数据，并使得查询和分析方便。并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。简单点说就是你不需要会JAVA就可以使用，只要你会SQL语句就可以了。（一般存在mysql中，也可以使用自带的嵌入式的数据库derby）</p>\n<h4 id=\"二、Hive配置\"><a href=\"#二、Hive配置\" class=\"headerlink\" title=\"二、Hive配置\"></a>二、Hive配置</h4><h6 id=\"1-将conf下的hive-default-xml-template-改名为-hive-site-xml\"><a href=\"#1-将conf下的hive-default-xml-template-改名为-hive-site-xml\" class=\"headerlink\" title=\"1.将conf下的hive-default.xml.template 改名为 hive-site.xml\"></a>1.将conf下的hive-default.xml.template 改名为 hive-site.xml</h6><pre><code>修改hive-site.xml（删除所有内容，只留一个&lt;property&gt;&lt;/property&gt;）\n添加如下内容：\n&lt;property&gt;\n  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;\n &lt;value&gt;jdbc:mysql://hadoop01:3306/hivecreateDatabaseIfNotExist=true&lt;/value&gt;\n  &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;\n&lt;/property&gt;\n\n&lt;property&gt;\n  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;\n  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;\n  &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;\n&lt;/property&gt;\n\n&lt;property&gt;\n  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;\n  &lt;value&gt;root&lt;/value&gt;\n  &lt;description&gt;username to use against metastore database&lt;/description&gt;\n&lt;/property&gt;\n\n&lt;property&gt;\n  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;\n  &lt;value&gt;root&lt;/value&gt;\n  &lt;description&gt;password to use against metastore database&lt;/description&gt;\n&lt;/property&gt;\n</code></pre><h6 id=\"2-安装hive和mysq\"><a href=\"#2-安装hive和mysq\" class=\"headerlink\" title=\"2.安装hive和mysq\"></a>2.安装hive和mysq</h6><pre><code>将mysql的连接jar包拷贝到$HIVE_HOME/lib目录下\n如果出现没有权限的问题，在mysql授权(在安装mysql的机器上执行)\nmysql -uroot -p\n#(执行下面的语句  *.*:所有库下的所有表   %：任何IP地址或主机都可以连接)\nGRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;123&apos; WITH GRANT OPTION;\nFLUSH PRIVILEGES;\n</code></pre><h6 id=\"3-建表\"><a href=\"#3-建表\" class=\"headerlink\" title=\"3.建表\"></a>3.建表</h6><p>row format delimited：表示一行代表一个数据<br>fileds terminated by ‘\\t’:表示这一行的数据按照分隔符切分作为字段属性</p>\n<pre><code>建表(默认是内部表)\ncreate table trade_detail(id bigint, account string, income double, expenses double, time string) row format delimited fields terminated by &apos;\\t&apos;;\n建分区表（partitioned by (logdate string)表示在表文件夹下面会有个logdate文件夹）\ncreate table td_part(id bigint, account string, income double, expenses double, time string) partitioned by (logdate string) row format delimited fields terminated by &apos;\\t&apos;;\n建外部表（external 表示表的路径在hdfs与本地上可以是任何路径，方便共享，不需要复制）\ncreate external table td_ext(id bigint, account string, income double, expenses double, time string) row format delimited fields terminated by &apos;\\t&apos; location &apos;/td_ext&apos;;\n</code></pre><h6 id=\"4-分区表\"><a href=\"#4-分区表\" class=\"headerlink\" title=\"4.分区表\"></a>4.分区表</h6><pre><code>普通表和分区表区别：有大量数据增加的需要建分区表\ncreate table book (id bigint, name string) partitioned by (pubdate string) row format delimited fields terminated by &apos;\\t&apos;; \n\n分区表加载数据\nload data local inpath &apos;./book.txt&apos; overwrite into table book partition (pubdate=&apos;2010-08-22&apos;);\n\nload data local inpath &apos;/root/data.am&apos; into table beauty partition (nation=&quot;USA&quot;);\n\n\nselect nation, avg(size) from beauties group by nation order by avg(size);\n</code></pre><p>上面加载使用了local关键字是因为用了本地的，如果是hdfs上的就不要了。  </p>\n<h4 id=\"三、Hive高阶\"><a href=\"#三、Hive高阶\" class=\"headerlink\" title=\"三、Hive高阶\"></a>三、Hive高阶</h4><p>hive 还支持集合类型，如map,list等</p>\n<h6 id=\"1-数组型（collection-items-terminated-by）\"><a href=\"#1-数组型（collection-items-terminated-by）\" class=\"headerlink\" title=\"1.数组型（collection items terminated by）\"></a>1.数组型（collection items terminated by）</h6><pre><code>//array \ncreate table tab_array(a array&lt;int&gt;,b array&lt;string&gt;)\nrow format delimited\nfields terminated by &apos;\\t&apos;\ncollection items terminated by &apos;,&apos;;\n\nselect a[0] from tab_array;\nselect * from tab_array where array_contains(b,&apos;word&apos;);\ninsert into table tab_array select array(0),array(name,ip) from tab_ext t; \n</code></pre><h6 id=\"2-Map型（collection-items-terminated-by-and-map-keys-terminated-by）\"><a href=\"#2-Map型（collection-items-terminated-by-and-map-keys-terminated-by）\" class=\"headerlink\" title=\"2.Map型（collection items terminated by and map keys terminated by）\"></a>2.Map型（collection items terminated by and map keys terminated by）</h6><pre><code>//map\ncreate table tab_map(name string,info map&lt;string,string&gt;)\nrow format delimited\nfields terminated by &apos;\\t&apos;\ncollection items terminated by &apos;,&apos;\nmap keys terminated by &apos;:&apos;;\n\nload data local inpath &apos;/home/hadoop/hivetemp/tab_map.txt&apos; overwrite into table tab_map;\ninsert into table tab_map select name,map(&apos;name&apos;,name,&apos;ip&apos;,ip) from tab_ext; \n</code></pre><h6 id=\"3-结构型\"><a href=\"#3-结构型\" class=\"headerlink\" title=\"3.结构型\"></a>3.结构型</h6><pre><code>//struct\ncreate table tab_struct(name string,info struct&lt;age:int,tel:string,addr:string&gt;)\nrow format delimited\nfields terminated by &apos;\\t&apos;\ncollection items terminated by &apos;,&apos;\n\nload data local inpath &apos;/home/hadoop/hivetemp/tab_st.txt&apos; overwrite into table tab_struct;\ninsert into table tab_struct select name,named_struct(&apos;age&apos;,id,&apos;tel&apos;,name,&apos;addr&apos;,country) from tab_ext;\n</code></pre><h6 id=\"4-批量插入\"><a href=\"#4-批量插入\" class=\"headerlink\" title=\"4.批量插入\"></a>4.批量插入</h6><pre><code>//insert from select   通过select语句批量插入数据到别的表\ncreate table tab_ip_like like tab_ip;\ninsert overwrite table tab_ip_like select * from tab_ip;\n\n//write to hdfs  将结果写入到hdfs的文件中\ninsert overwrite local directory &apos;/home/hadoop/hivetemp/test.txt&apos; select * from tab_ip_part where part_flag=&apos;part1&apos;;    \ninsert overwrite directory &apos;/hiveout.txt&apos; select * from tab_ip_part where part_flag=&apos;part1&apos;;\n\n//cli shell  通过shell执行hive的hql语句（*这里表前面需要家数据库点）\nhive -S -e &apos;select country,count(*) from tab_ext&apos; &gt; /home/hadoop/hivetemp/e.txt  \n\nselect * from tab_ext sort by id desc limit 5;\n\nselect a.ip,b.book from tab_ext a join tab_ip_book b on(a.name=b.name);\n</code></pre><h6 id=\"5-用户自定义函数\"><a href=\"#5-用户自定义函数\" class=\"headerlink\" title=\"5. 用户自定义函数\"></a>5. 用户自定义函数</h6><p>因为虽然本身自带了avg,sum等等通用函数，但有的时候你还是希望自己写。</p>\n<pre><code>0.要继承org.apache.hadoop.hive.ql.exec.UDF类实现evaluate\n\n自定义函数调用过程：\n1.添加jar包（在hive命令行里面执行）\nhive&gt; add jar /root/NUDF.jar;\n\n2.创建临时函数（关了再开就没了）\nhive&gt; create temporary function getNation as &apos;cn.itcast.hive.udf.NationUDF&apos;;\n\n3.调用\nhive&gt; select id, name, getNation(nation) from beauty;\n\n4.将查询结果保存到HDFS中\nhive&gt; create table result row format delimited fields terminated by &apos;\\t&apos; as select * from beauty order by id desc;    \nhive&gt; select id, getAreaName(id) as name from tel_rec;\n\n\ncreate table result row format delimited fields terminated by &apos;\\t&apos; as select id, getNation(nation) from beauties;\n</code></pre>"},{"title":"Hadoop(六)（yarn框架）","author":"小小冰弟","date":"2018-03-22T06:54:59.000Z","_content":"#### 一、YARN框架\n主要就是将之前的资源管理与任务调度功能一分为二，降低系统的耦合度与单点故障的可能性（JobTracker之前是集中处理点）。\n\n#### 二、工作机制\n###### 1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。\n###### 2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)\n###### 3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）\n###### 4.向ResourceManager汇报提交信息\n###### 5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\n######  6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)\n######  7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)\n######  8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\n\n（其中MRAppMaster与Yarnchild都是动态生成的）\n\n#### 三、eclipse运行\n在eclipse中运行，并不像我们之前使用命令行运行的那样，因为它调用的是本地的job而不是hadoop的，因为它并没有使用我们修改的配置文件，所以我们需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，结果运行时我们会发现没有jar，所以我们还需要将项目本身打包放到项目中并且设置configuration\n\n     Configuration conf = new Configuration();\n     conf.set(\"mapreduce.job.jar\",\"mc.jar\")\n     \n#### 四、几种提交运行模式\n\n##### 1.本地模式\n###### windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.\n###### linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.\n##### 2.集群模式\n###### windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\n###### linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。\n###### 第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(\"mapreduce.job.jar\",\"mc.jar\")\n\n\n#### 五、hadoop中的序列化\n主要有4个接口，分别是Comparator（字节比较器）, Comparable（对象比较）, Writable（序列化）, Configurable（参数配置）。\n\nhadoop的序列化的特点是： \n###### 1、节省资源：由于带宽和存储是集群中的最宝贵的资源所以我们必须想法设法缩小传递信息的大小和存储大小，hadoop的序列化就为了更好地坐到这一点而设计的。 \n###### 2、对象可重用：JDK的反序列化会不断地创建对象，这肯定会造成一定的系统开销，但是在hadoop的反序列化中，能重复的利用一个对象的readField方法来重新产生不同的对象。 \n###### 3、可扩展性：当前hadoop的序列化有多中选择可以利用实现hadoop的WritableComparable接口。 \n\n也可使用开源的序列化框架protocol Buffers，Avro等框架。我们可以注意到的是hadoop2.X之后是实现一个YARN，所有应用（mapreduce，或者其他spark实时或者离线的计算框架都可以运行在YARN上），YARN还负责对资源的调度等等。YARN的序列化就是用Google开发的序列化框架protocol Buffers，proto目前支持支持三种语言C++，java，Python所以RPC这一层我们就可以利用其他语言来做文章，满足其他语言开发者的需求。\n\n#### 六、shuffle过程\n这其实就是mapreduce的细节问题\n中间会经历 分组 排序 转发的过程\n\n1.首先hadoop会根据PartitionerClass来进行归类。</n>\n\n    job.setPartitionerClass(xxx.class);\n    \n\n\n2.设置reduce任务并发数，应该跟并发数，即分组数量一样\n\n    job.setNumReduceTask();\n    \n或许你会问，为什么没有设置maptask的数量\n\n1.maptask的并发数是由切片的数量决定的，多少个切片，多少个maptask.\n2.切片就是一个逻辑概念，指的是文件中数据的偏移量范围。\n3.切片的具体大小应该根据处理的文件大小来调整，一般64M这样（好像是）\n     \n","source":"_posts/Hadoop-六-（yarn框架）.md","raw":"title: Hadoop(六)（yarn框架）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-03-22 14:54:59\n---\n#### 一、YARN框架\n主要就是将之前的资源管理与任务调度功能一分为二，降低系统的耦合度与单点故障的可能性（JobTracker之前是集中处理点）。\n\n#### 二、工作机制\n###### 1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。\n###### 2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)\n###### 3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）\n###### 4.向ResourceManager汇报提交信息\n###### 5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\n######  6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)\n######  7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)\n######  8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\n\n（其中MRAppMaster与Yarnchild都是动态生成的）\n\n#### 三、eclipse运行\n在eclipse中运行，并不像我们之前使用命令行运行的那样，因为它调用的是本地的job而不是hadoop的，因为它并没有使用我们修改的配置文件，所以我们需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，结果运行时我们会发现没有jar，所以我们还需要将项目本身打包放到项目中并且设置configuration\n\n     Configuration conf = new Configuration();\n     conf.set(\"mapreduce.job.jar\",\"mc.jar\")\n     \n#### 四、几种提交运行模式\n\n##### 1.本地模式\n###### windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.\n###### linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.\n##### 2.集群模式\n###### windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\n###### linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。\n###### 第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(\"mapreduce.job.jar\",\"mc.jar\")\n\n\n#### 五、hadoop中的序列化\n主要有4个接口，分别是Comparator（字节比较器）, Comparable（对象比较）, Writable（序列化）, Configurable（参数配置）。\n\nhadoop的序列化的特点是： \n###### 1、节省资源：由于带宽和存储是集群中的最宝贵的资源所以我们必须想法设法缩小传递信息的大小和存储大小，hadoop的序列化就为了更好地坐到这一点而设计的。 \n###### 2、对象可重用：JDK的反序列化会不断地创建对象，这肯定会造成一定的系统开销，但是在hadoop的反序列化中，能重复的利用一个对象的readField方法来重新产生不同的对象。 \n###### 3、可扩展性：当前hadoop的序列化有多中选择可以利用实现hadoop的WritableComparable接口。 \n\n也可使用开源的序列化框架protocol Buffers，Avro等框架。我们可以注意到的是hadoop2.X之后是实现一个YARN，所有应用（mapreduce，或者其他spark实时或者离线的计算框架都可以运行在YARN上），YARN还负责对资源的调度等等。YARN的序列化就是用Google开发的序列化框架protocol Buffers，proto目前支持支持三种语言C++，java，Python所以RPC这一层我们就可以利用其他语言来做文章，满足其他语言开发者的需求。\n\n#### 六、shuffle过程\n这其实就是mapreduce的细节问题\n中间会经历 分组 排序 转发的过程\n\n1.首先hadoop会根据PartitionerClass来进行归类。</n>\n\n    job.setPartitionerClass(xxx.class);\n    \n\n\n2.设置reduce任务并发数，应该跟并发数，即分组数量一样\n\n    job.setNumReduceTask();\n    \n或许你会问，为什么没有设置maptask的数量\n\n1.maptask的并发数是由切片的数量决定的，多少个切片，多少个maptask.\n2.切片就是一个逻辑概念，指的是文件中数据的偏移量范围。\n3.切片的具体大小应该根据处理的文件大小来调整，一般64M这样（好像是）\n     \n","slug":"Hadoop-六-（yarn框架）","published":1,"updated":"2018-03-27T08:09:12.615Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60kz000yxo7kjqq1618s","content":"<h4 id=\"一、YARN框架\"><a href=\"#一、YARN框架\" class=\"headerlink\" title=\"一、YARN框架\"></a>一、YARN框架</h4><p>主要就是将之前的资源管理与任务调度功能一分为二，降低系统的耦合度与单点故障的可能性（JobTracker之前是集中处理点）。</p>\n<h4 id=\"二、工作机制\"><a href=\"#二、工作机制\" class=\"headerlink\" title=\"二、工作机制\"></a>二、工作机制</h4><h6 id=\"1-在java主程序中最后调用的waitforcompletion-会提交任务，向ResourceManager申请执行一个job。\"><a href=\"#1-在java主程序中最后调用的waitforcompletion-会提交任务，向ResourceManager申请执行一个job。\" class=\"headerlink\" title=\"1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。\"></a>1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。</h6><h6 id=\"2-ResourceManager返回给给job相关资源提交的路径和产生的job-id-一个staging-dir\"><a href=\"#2-ResourceManager返回给给job相关资源提交的路径和产生的job-id-一个staging-dir\" class=\"headerlink\" title=\"2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)\"></a>2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)</h6><h6 id=\"3-根据返回结果，将资源提交到staging-dir上（默认在HDFS上面）\"><a href=\"#3-根据返回结果，将资源提交到staging-dir上（默认在HDFS上面）\" class=\"headerlink\" title=\"3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）\"></a>3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）</h6><h6 id=\"4-向ResourceManager汇报提交信息\"><a href=\"#4-向ResourceManager汇报提交信息\" class=\"headerlink\" title=\"4.向ResourceManager汇报提交信息\"></a>4.向ResourceManager汇报提交信息</h6><h6 id=\"5-ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\"><a href=\"#5-ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\" class=\"headerlink\" title=\"5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\"></a>5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。</h6><h6 id=\"6-NodeManager给任务分配运行类资源的容器container-从HDFS和Resource两个地方拿资源\"><a href=\"#6-NodeManager给任务分配运行类资源的容器container-从HDFS和Resource两个地方拿资源\" class=\"headerlink\" title=\"6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)\"></a>6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)</h6><h6 id=\"7-启动MRAppMaster-MapReduce内部框架，分配谁是主进程\"><a href=\"#7-启动MRAppMaster-MapReduce内部框架，分配谁是主进程\" class=\"headerlink\" title=\"7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)\"></a>7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)</h6><h6 id=\"8-向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\"><a href=\"#8-向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\" class=\"headerlink\" title=\"8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\"></a>8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。</h6><p>（其中MRAppMaster与Yarnchild都是动态生成的）</p>\n<h4 id=\"三、eclipse运行\"><a href=\"#三、eclipse运行\" class=\"headerlink\" title=\"三、eclipse运行\"></a>三、eclipse运行</h4><p>在eclipse中运行，并不像我们之前使用命令行运行的那样，因为它调用的是本地的job而不是hadoop的，因为它并没有使用我们修改的配置文件，所以我们需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，结果运行时我们会发现没有jar，所以我们还需要将项目本身打包放到项目中并且设置configuration</p>\n<pre><code>Configuration conf = new Configuration();\nconf.set(&quot;mapreduce.job.jar&quot;,&quot;mc.jar&quot;)\n</code></pre><h4 id=\"四、几种提交运行模式\"><a href=\"#四、几种提交运行模式\" class=\"headerlink\" title=\"四、几种提交运行模式\"></a>四、几种提交运行模式</h4><h5 id=\"1-本地模式\"><a href=\"#1-本地模式\" class=\"headerlink\" title=\"1.本地模式\"></a>1.本地模式</h5><h6 id=\"windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner\"><a href=\"#windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner\" class=\"headerlink\" title=\"windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.\"></a>windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.</h6><h6 id=\"linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner\"><a href=\"#linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner\" class=\"headerlink\" title=\"linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.\"></a>linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.</h6><h5 id=\"2-集群模式\"><a href=\"#2-集群模式\" class=\"headerlink\" title=\"2.集群模式\"></a>2.集群模式</h5><h6 id=\"windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\"><a href=\"#windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\" class=\"headerlink\" title=\"windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\"></a>windows版本还是放弃吧，贼麻烦，路径的符号不一样等等</h6><h6 id=\"linux上第一种-可以直接打包项目丢到服务器上运用hadoop-jar-jar包-运行。\"><a href=\"#linux上第一种-可以直接打包项目丢到服务器上运用hadoop-jar-jar包-运行。\" class=\"headerlink\" title=\"linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。\"></a>linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。</h6><h6 id=\"第二种是在eclipse中，需要将mapred-site-xml与yarn-site-xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf-set-“mapreduce-job-jar”-”mc-jar”\"><a href=\"#第二种是在eclipse中，需要将mapred-site-xml与yarn-site-xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf-set-“mapreduce-job-jar”-”mc-jar”\" class=\"headerlink\" title=\"第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(“mapreduce.job.jar”,”mc.jar”)\"></a>第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(“mapreduce.job.jar”,”mc.jar”)</h6><h4 id=\"五、hadoop中的序列化\"><a href=\"#五、hadoop中的序列化\" class=\"headerlink\" title=\"五、hadoop中的序列化\"></a>五、hadoop中的序列化</h4><p>主要有4个接口，分别是Comparator（字节比较器）, Comparable（对象比较）, Writable（序列化）, Configurable（参数配置）。</p>\n<p>hadoop的序列化的特点是： </p>\n<h6 id=\"1、节省资源：由于带宽和存储是集群中的最宝贵的资源所以我们必须想法设法缩小传递信息的大小和存储大小，hadoop的序列化就为了更好地坐到这一点而设计的。\"><a href=\"#1、节省资源：由于带宽和存储是集群中的最宝贵的资源所以我们必须想法设法缩小传递信息的大小和存储大小，hadoop的序列化就为了更好地坐到这一点而设计的。\" class=\"headerlink\" title=\"1、节省资源：由于带宽和存储是集群中的最宝贵的资源所以我们必须想法设法缩小传递信息的大小和存储大小，hadoop的序列化就为了更好地坐到这一点而设计的。\"></a>1、节省资源：由于带宽和存储是集群中的最宝贵的资源所以我们必须想法设法缩小传递信息的大小和存储大小，hadoop的序列化就为了更好地坐到这一点而设计的。</h6><h6 id=\"2、对象可重用：JDK的反序列化会不断地创建对象，这肯定会造成一定的系统开销，但是在hadoop的反序列化中，能重复的利用一个对象的readField方法来重新产生不同的对象。\"><a href=\"#2、对象可重用：JDK的反序列化会不断地创建对象，这肯定会造成一定的系统开销，但是在hadoop的反序列化中，能重复的利用一个对象的readField方法来重新产生不同的对象。\" class=\"headerlink\" title=\"2、对象可重用：JDK的反序列化会不断地创建对象，这肯定会造成一定的系统开销，但是在hadoop的反序列化中，能重复的利用一个对象的readField方法来重新产生不同的对象。\"></a>2、对象可重用：JDK的反序列化会不断地创建对象，这肯定会造成一定的系统开销，但是在hadoop的反序列化中，能重复的利用一个对象的readField方法来重新产生不同的对象。</h6><h6 id=\"3、可扩展性：当前hadoop的序列化有多中选择可以利用实现hadoop的WritableComparable接口。\"><a href=\"#3、可扩展性：当前hadoop的序列化有多中选择可以利用实现hadoop的WritableComparable接口。\" class=\"headerlink\" title=\"3、可扩展性：当前hadoop的序列化有多中选择可以利用实现hadoop的WritableComparable接口。\"></a>3、可扩展性：当前hadoop的序列化有多中选择可以利用实现hadoop的WritableComparable接口。</h6><p>也可使用开源的序列化框架protocol Buffers，Avro等框架。我们可以注意到的是hadoop2.X之后是实现一个YARN，所有应用（mapreduce，或者其他spark实时或者离线的计算框架都可以运行在YARN上），YARN还负责对资源的调度等等。YARN的序列化就是用Google开发的序列化框架protocol Buffers，proto目前支持支持三种语言C++，java，Python所以RPC这一层我们就可以利用其他语言来做文章，满足其他语言开发者的需求。</p>\n<h4 id=\"六、shuffle过程\"><a href=\"#六、shuffle过程\" class=\"headerlink\" title=\"六、shuffle过程\"></a>六、shuffle过程</h4><p>这其实就是mapreduce的细节问题<br>中间会经历 分组 排序 转发的过程</p>\n<p>1.首先hadoop会根据PartitionerClass来进行归类。</p>\n<pre><code>job.setPartitionerClass(xxx.class);\n</code></pre><p>2.设置reduce任务并发数，应该跟并发数，即分组数量一样</p>\n<pre><code>job.setNumReduceTask();\n</code></pre><p>或许你会问，为什么没有设置maptask的数量</p>\n<p>1.maptask的并发数是由切片的数量决定的，多少个切片，多少个maptask.<br>2.切片就是一个逻辑概念，指的是文件中数据的偏移量范围。<br>3.切片的具体大小应该根据处理的文件大小来调整，一般64M这样（好像是）</p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"一、YARN框架\"><a href=\"#一、YARN框架\" class=\"headerlink\" title=\"一、YARN框架\"></a>一、YARN框架</h4><p>主要就是将之前的资源管理与任务调度功能一分为二，降低系统的耦合度与单点故障的可能性（JobTracker之前是集中处理点）。</p>\n<h4 id=\"二、工作机制\"><a href=\"#二、工作机制\" class=\"headerlink\" title=\"二、工作机制\"></a>二、工作机制</h4><h6 id=\"1-在java主程序中最后调用的waitforcompletion-会提交任务，向ResourceManager申请执行一个job。\"><a href=\"#1-在java主程序中最后调用的waitforcompletion-会提交任务，向ResourceManager申请执行一个job。\" class=\"headerlink\" title=\"1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。\"></a>1.在java主程序中最后调用的waitforcompletion()会提交任务，向ResourceManager申请执行一个job。</h6><h6 id=\"2-ResourceManager返回给给job相关资源提交的路径和产生的job-id-一个staging-dir\"><a href=\"#2-ResourceManager返回给给job相关资源提交的路径和产生的job-id-一个staging-dir\" class=\"headerlink\" title=\"2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)\"></a>2.ResourceManager返回给给job相关资源提交的路径和产生的job_id(一个staging dir)</h6><h6 id=\"3-根据返回结果，将资源提交到staging-dir上（默认在HDFS上面）\"><a href=\"#3-根据返回结果，将资源提交到staging-dir上（默认在HDFS上面）\" class=\"headerlink\" title=\"3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）\"></a>3.根据返回结果，将资源提交到staging dir上（默认在HDFS上面）</h6><h6 id=\"4-向ResourceManager汇报提交信息\"><a href=\"#4-向ResourceManager汇报提交信息\" class=\"headerlink\" title=\"4.向ResourceManager汇报提交信息\"></a>4.向ResourceManager汇报提交信息</h6><h6 id=\"5-ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\"><a href=\"#5-ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\" class=\"headerlink\" title=\"5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。\"></a>5.ResourceManager将job加入任务队列，NodeManager从ResourceManager领取任务。</h6><h6 id=\"6-NodeManager给任务分配运行类资源的容器container-从HDFS和Resource两个地方拿资源\"><a href=\"#6-NodeManager给任务分配运行类资源的容器container-从HDFS和Resource两个地方拿资源\" class=\"headerlink\" title=\"6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)\"></a>6.NodeManager给任务分配运行类资源的容器container(从HDFS和Resource两个地方拿资源)</h6><h6 id=\"7-启动MRAppMaster-MapReduce内部框架，分配谁是主进程\"><a href=\"#7-启动MRAppMaster-MapReduce内部框架，分配谁是主进程\" class=\"headerlink\" title=\"7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)\"></a>7.启动MRAppMaster(MapReduce内部框架，分配谁是主进程)</h6><h6 id=\"8-向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\"><a href=\"#8-向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\" class=\"headerlink\" title=\"8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。\"></a>8.向ResoourceManger注册，启动Maptask任务进程，启动Reducetask任务进程，执行完之后会自动回收。</h6><p>（其中MRAppMaster与Yarnchild都是动态生成的）</p>\n<h4 id=\"三、eclipse运行\"><a href=\"#三、eclipse运行\" class=\"headerlink\" title=\"三、eclipse运行\"></a>三、eclipse运行</h4><p>在eclipse中运行，并不像我们之前使用命令行运行的那样，因为它调用的是本地的job而不是hadoop的，因为它并没有使用我们修改的配置文件，所以我们需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，结果运行时我们会发现没有jar，所以我们还需要将项目本身打包放到项目中并且设置configuration</p>\n<pre><code>Configuration conf = new Configuration();\nconf.set(&quot;mapreduce.job.jar&quot;,&quot;mc.jar&quot;)\n</code></pre><h4 id=\"四、几种提交运行模式\"><a href=\"#四、几种提交运行模式\" class=\"headerlink\" title=\"四、几种提交运行模式\"></a>四、几种提交运行模式</h4><h5 id=\"1-本地模式\"><a href=\"#1-本地模式\" class=\"headerlink\" title=\"1.本地模式\"></a>1.本地模式</h5><h6 id=\"windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner\"><a href=\"#windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner\" class=\"headerlink\" title=\"windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.\"></a>windows版本：输出输出可以放在本地，也可以放在hdfs上，但是用的是localjobrunner.</h6><h6 id=\"linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner\"><a href=\"#linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner\" class=\"headerlink\" title=\"linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.\"></a>linux版本：输出输出可以放在本地，也可以放在hdfs上，也是用的是localjobrunner.</h6><h5 id=\"2-集群模式\"><a href=\"#2-集群模式\" class=\"headerlink\" title=\"2.集群模式\"></a>2.集群模式</h5><h6 id=\"windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\"><a href=\"#windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\" class=\"headerlink\" title=\"windows版本还是放弃吧，贼麻烦，路径的符号不一样等等\"></a>windows版本还是放弃吧，贼麻烦，路径的符号不一样等等</h6><h6 id=\"linux上第一种-可以直接打包项目丢到服务器上运用hadoop-jar-jar包-运行。\"><a href=\"#linux上第一种-可以直接打包项目丢到服务器上运用hadoop-jar-jar包-运行。\" class=\"headerlink\" title=\"linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。\"></a>linux上第一种 可以直接打包项目丢到服务器上运用hadoop jar jar包 运行。</h6><h6 id=\"第二种是在eclipse中，需要将mapred-site-xml与yarn-site-xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf-set-“mapreduce-job-jar”-”mc-jar”\"><a href=\"#第二种是在eclipse中，需要将mapred-site-xml与yarn-site-xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf-set-“mapreduce-job-jar”-”mc-jar”\" class=\"headerlink\" title=\"第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(“mapreduce.job.jar”,”mc.jar”)\"></a>第二种是在eclipse中，需要将mapred.site.xml与yarn.site.xml文件放入项目中让其读取，另外在main方法中添加一个conf的参数conf.set(“mapreduce.job.jar”,”mc.jar”)</h6><h4 id=\"五、hadoop中的序列化\"><a href=\"#五、hadoop中的序列化\" class=\"headerlink\" title=\"五、hadoop中的序列化\"></a>五、hadoop中的序列化</h4><p>主要有4个接口，分别是Comparator（字节比较器）, Comparable（对象比较）, Writable（序列化）, Configurable（参数配置）。</p>\n<p>hadoop的序列化的特点是： </p>\n<h6 id=\"1、节省资源：由于带宽和存储是集群中的最宝贵的资源所以我们必须想法设法缩小传递信息的大小和存储大小，hadoop的序列化就为了更好地坐到这一点而设计的。\"><a href=\"#1、节省资源：由于带宽和存储是集群中的最宝贵的资源所以我们必须想法设法缩小传递信息的大小和存储大小，hadoop的序列化就为了更好地坐到这一点而设计的。\" class=\"headerlink\" title=\"1、节省资源：由于带宽和存储是集群中的最宝贵的资源所以我们必须想法设法缩小传递信息的大小和存储大小，hadoop的序列化就为了更好地坐到这一点而设计的。\"></a>1、节省资源：由于带宽和存储是集群中的最宝贵的资源所以我们必须想法设法缩小传递信息的大小和存储大小，hadoop的序列化就为了更好地坐到这一点而设计的。</h6><h6 id=\"2、对象可重用：JDK的反序列化会不断地创建对象，这肯定会造成一定的系统开销，但是在hadoop的反序列化中，能重复的利用一个对象的readField方法来重新产生不同的对象。\"><a href=\"#2、对象可重用：JDK的反序列化会不断地创建对象，这肯定会造成一定的系统开销，但是在hadoop的反序列化中，能重复的利用一个对象的readField方法来重新产生不同的对象。\" class=\"headerlink\" title=\"2、对象可重用：JDK的反序列化会不断地创建对象，这肯定会造成一定的系统开销，但是在hadoop的反序列化中，能重复的利用一个对象的readField方法来重新产生不同的对象。\"></a>2、对象可重用：JDK的反序列化会不断地创建对象，这肯定会造成一定的系统开销，但是在hadoop的反序列化中，能重复的利用一个对象的readField方法来重新产生不同的对象。</h6><h6 id=\"3、可扩展性：当前hadoop的序列化有多中选择可以利用实现hadoop的WritableComparable接口。\"><a href=\"#3、可扩展性：当前hadoop的序列化有多中选择可以利用实现hadoop的WritableComparable接口。\" class=\"headerlink\" title=\"3、可扩展性：当前hadoop的序列化有多中选择可以利用实现hadoop的WritableComparable接口。\"></a>3、可扩展性：当前hadoop的序列化有多中选择可以利用实现hadoop的WritableComparable接口。</h6><p>也可使用开源的序列化框架protocol Buffers，Avro等框架。我们可以注意到的是hadoop2.X之后是实现一个YARN，所有应用（mapreduce，或者其他spark实时或者离线的计算框架都可以运行在YARN上），YARN还负责对资源的调度等等。YARN的序列化就是用Google开发的序列化框架protocol Buffers，proto目前支持支持三种语言C++，java，Python所以RPC这一层我们就可以利用其他语言来做文章，满足其他语言开发者的需求。</p>\n<h4 id=\"六、shuffle过程\"><a href=\"#六、shuffle过程\" class=\"headerlink\" title=\"六、shuffle过程\"></a>六、shuffle过程</h4><p>这其实就是mapreduce的细节问题<br>中间会经历 分组 排序 转发的过程</p>\n<p>1.首先hadoop会根据PartitionerClass来进行归类。</p>\n<pre><code>job.setPartitionerClass(xxx.class);\n</code></pre><p>2.设置reduce任务并发数，应该跟并发数，即分组数量一样</p>\n<pre><code>job.setNumReduceTask();\n</code></pre><p>或许你会问，为什么没有设置maptask的数量</p>\n<p>1.maptask的并发数是由切片的数量决定的，多少个切片，多少个maptask.<br>2.切片就是一个逻辑概念，指的是文件中数据的偏移量范围。<br>3.切片的具体大小应该根据处理的文件大小来调整，一般64M这样（好像是）</p>\n"},{"title":"Hadoop(五)（Mapreduce的操作）","author":"小小冰弟","date":"2018-03-02T08:46:03.000Z","_content":"#### 一.Mapreduce（用来解决海量数据的运算）\nMapReduce由两个阶段组成：Map和Reduce，用户只需要实现map()和reduce()两个函数，即可实现分布式计算，非常简单。Map是对单个的运算，reduce是将他们的结果汇总。\n\n#### 二、实现Map函数\n\n\n   \n    \n #####  1.继承hadoop的mapper类\n Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;</br>\n 四个泛型是因为需要输入输出参数，且都为键值对key-value形式封装。又因为hadoop将其序列化更加精简，所以使用的是hadoop封装的类型，如 long->LongWrite,String->Text\n \n ##### 2.实现mapper的map方法（每读取一行就调用一次该方法）\n    //默认情况下，框架传递给我们的mapper的输入数据中，key是要处理的文本中一行的起始偏移量，这一行的内容作为value\n    public class PPJMap extends Mapper<LongWritable, Text, Text, LongWritable>{\n\t@Override\n\tprotected void map(LongWritable key, Text value,Context context)throws IOException, InterruptedException {\n\t\t//具体业务逻辑就写在这个方法体中，而且我们业务要处理的数据已经被框架传递进来，在方法的参数中 key-value\n\t\t//key 是这一行数据的起始偏移量     value 是这一行的文本内容\n\t\t//将这一行的内容转换成string类型\n\t\tString line = value.toString();\n\t\t//对这一行的文本按特定分隔符切分\n\t\tString[] words = StringUtils.split(line, \" \");\n\t\t//遍历这个单词数组输出为kv形式  k：单词   v ： 1\n\t\tfor(String word : words){\n\t\t\tcontext.write(new Text(word), new LongWritable(1));\n\t\t}\n\t}\n\t}\n \n \n \n #### 三、实现Reduce函数\n    public class PPJReducer extends Reducer<Text, LongWritable, Text, LongWritable>{\n\t//框架在map处理完成之后，将所有kv对缓存起来，进行分组，然后传递一个组<key,valus{}>，调用一次reduce方法\n\t//<hello,{1,1,1,1,1,1.....}>\n\t@Override\n\tprotected void reduce(Text key, Iterable<LongWritable> values,Context context)\n\t\t\tthrows IOException, InterruptedException {\n\n\t\tlong count = 0;\n\t\t//遍历求和\n\t\tfor(LongWritable value:values){\n\t\t\t\n\t\t\tcount += value.get();\n\t\t}\n\t\t//输出这一个单词的统计结果\n\t\tcontext.write(key, new LongWritable(count));\n\t}\n\t}\n    \n\n#### 四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）\n    \n\t\tJob wcjob = Job.getInstance(new Configuration());\n\t\t\n\t\t//设置整个job所用的那些类在哪个jar包\n\t\twcjob.setJarByClass(this class);\n\t\t\n\t\t\n\t\t//本job使用的mapper和reducer的类\n\t\twcjob.setMapperClass(PPJMapper.class);\n\t\twcjob.setReducerClass(PPJReducer.class);\n\t\t\n\t\t\n\t\t//指定reduce的输出数据kv类型\n\t\twcjob.setOutputKeyClass(Text.class);\n\t\twcjob.setOutputValueClass(LongWritable.class);\n\t\t\n\t\t//指定mapper的输出数据kv类型\n\t\twcjob.setMapOutputKeyClass(Text.class);\n\t\twcjob.setMapOutputValueClass(LongWritable.class);\n\t\t\n\t\t\n\t\t//指定要处理的输入数据存放路径\n\t\tFileInputFormat.setInputPaths(wcjob, new Path(\"hdfs://ppj2:8020/ppj/src/\"));\n\t\t\n\t\t//指定处理结果的输出数据存放路径\n\t\tFileOutputFormat.setOutputPath(wcjob, new Path(\"hdfs://ppj2:8020/ppj/output/\"));\n\t\t\n\t\t//将job提交给集群运行 \n\t\twcjob.waitForCompletion(true);\n        \n        \n        \n#### 五、在hadoop上运行\n    先要上传目标文件\n    hadoop fs -put 123.txt /ppj/ (没有路径需要先创建)\n    执行jar包\n    hadoop jar ppj2.jar (执行方法所在的全类名，不包含,class)\n    \n另外输出的文件夹不需要创建，因为他会自动创建","source":"_posts/Hadoop-五-（mapreduce）.md","raw":"title: Hadoop(五)（Mapreduce的操作）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-03-02 16:46:03\n---\n#### 一.Mapreduce（用来解决海量数据的运算）\nMapReduce由两个阶段组成：Map和Reduce，用户只需要实现map()和reduce()两个函数，即可实现分布式计算，非常简单。Map是对单个的运算，reduce是将他们的结果汇总。\n\n#### 二、实现Map函数\n\n\n   \n    \n #####  1.继承hadoop的mapper类\n Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;</br>\n 四个泛型是因为需要输入输出参数，且都为键值对key-value形式封装。又因为hadoop将其序列化更加精简，所以使用的是hadoop封装的类型，如 long->LongWrite,String->Text\n \n ##### 2.实现mapper的map方法（每读取一行就调用一次该方法）\n    //默认情况下，框架传递给我们的mapper的输入数据中，key是要处理的文本中一行的起始偏移量，这一行的内容作为value\n    public class PPJMap extends Mapper<LongWritable, Text, Text, LongWritable>{\n\t@Override\n\tprotected void map(LongWritable key, Text value,Context context)throws IOException, InterruptedException {\n\t\t//具体业务逻辑就写在这个方法体中，而且我们业务要处理的数据已经被框架传递进来，在方法的参数中 key-value\n\t\t//key 是这一行数据的起始偏移量     value 是这一行的文本内容\n\t\t//将这一行的内容转换成string类型\n\t\tString line = value.toString();\n\t\t//对这一行的文本按特定分隔符切分\n\t\tString[] words = StringUtils.split(line, \" \");\n\t\t//遍历这个单词数组输出为kv形式  k：单词   v ： 1\n\t\tfor(String word : words){\n\t\t\tcontext.write(new Text(word), new LongWritable(1));\n\t\t}\n\t}\n\t}\n \n \n \n #### 三、实现Reduce函数\n    public class PPJReducer extends Reducer<Text, LongWritable, Text, LongWritable>{\n\t//框架在map处理完成之后，将所有kv对缓存起来，进行分组，然后传递一个组<key,valus{}>，调用一次reduce方法\n\t//<hello,{1,1,1,1,1,1.....}>\n\t@Override\n\tprotected void reduce(Text key, Iterable<LongWritable> values,Context context)\n\t\t\tthrows IOException, InterruptedException {\n\n\t\tlong count = 0;\n\t\t//遍历求和\n\t\tfor(LongWritable value:values){\n\t\t\t\n\t\t\tcount += value.get();\n\t\t}\n\t\t//输出这一个单词的统计结果\n\t\tcontext.write(key, new LongWritable(count));\n\t}\n\t}\n    \n\n#### 四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）\n    \n\t\tJob wcjob = Job.getInstance(new Configuration());\n\t\t\n\t\t//设置整个job所用的那些类在哪个jar包\n\t\twcjob.setJarByClass(this class);\n\t\t\n\t\t\n\t\t//本job使用的mapper和reducer的类\n\t\twcjob.setMapperClass(PPJMapper.class);\n\t\twcjob.setReducerClass(PPJReducer.class);\n\t\t\n\t\t\n\t\t//指定reduce的输出数据kv类型\n\t\twcjob.setOutputKeyClass(Text.class);\n\t\twcjob.setOutputValueClass(LongWritable.class);\n\t\t\n\t\t//指定mapper的输出数据kv类型\n\t\twcjob.setMapOutputKeyClass(Text.class);\n\t\twcjob.setMapOutputValueClass(LongWritable.class);\n\t\t\n\t\t\n\t\t//指定要处理的输入数据存放路径\n\t\tFileInputFormat.setInputPaths(wcjob, new Path(\"hdfs://ppj2:8020/ppj/src/\"));\n\t\t\n\t\t//指定处理结果的输出数据存放路径\n\t\tFileOutputFormat.setOutputPath(wcjob, new Path(\"hdfs://ppj2:8020/ppj/output/\"));\n\t\t\n\t\t//将job提交给集群运行 \n\t\twcjob.waitForCompletion(true);\n        \n        \n        \n#### 五、在hadoop上运行\n    先要上传目标文件\n    hadoop fs -put 123.txt /ppj/ (没有路径需要先创建)\n    执行jar包\n    hadoop jar ppj2.jar (执行方法所在的全类名，不包含,class)\n    \n另外输出的文件夹不需要创建，因为他会自动创建","slug":"Hadoop-五-（mapreduce）","published":1,"updated":"2018-03-26T09:46:34.650Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60l00010xo7ka6qj1hto","content":"<h4 id=\"一-Mapreduce（用来解决海量数据的运算）\"><a href=\"#一-Mapreduce（用来解决海量数据的运算）\" class=\"headerlink\" title=\"一.Mapreduce（用来解决海量数据的运算）\"></a>一.Mapreduce（用来解决海量数据的运算）</h4><p>MapReduce由两个阶段组成：Map和Reduce，用户只需要实现map()和reduce()两个函数，即可实现分布式计算，非常简单。Map是对单个的运算，reduce是将他们的结果汇总。</p>\n<h4 id=\"二、实现Map函数\"><a href=\"#二、实现Map函数\" class=\"headerlink\" title=\"二、实现Map函数\"></a>二、实现Map函数</h4><h5 id=\"1-继承hadoop的mapper类\"><a href=\"#1-继承hadoop的mapper类\" class=\"headerlink\" title=\"1.继承hadoop的mapper类\"></a>1.继承hadoop的mapper类</h5><p> Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;<br><br> 四个泛型是因为需要输入输出参数，且都为键值对key-value形式封装。又因为hadoop将其序列化更加精简，所以使用的是hadoop封装的类型，如 long-&gt;LongWrite,String-&gt;Text</p>\n<h5 id=\"2-实现mapper的map方法（每读取一行就调用一次该方法）\"><a href=\"#2-实现mapper的map方法（每读取一行就调用一次该方法）\" class=\"headerlink\" title=\"2.实现mapper的map方法（每读取一行就调用一次该方法）\"></a>2.实现mapper的map方法（每读取一行就调用一次该方法）</h5><pre><code>//默认情况下，框架传递给我们的mapper的输入数据中，key是要处理的文本中一行的起始偏移量，这一行的内容作为value\npublic class PPJMap extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt;{\n@Override\nprotected void map(LongWritable key, Text value,Context context)throws IOException, InterruptedException {\n    //具体业务逻辑就写在这个方法体中，而且我们业务要处理的数据已经被框架传递进来，在方法的参数中 key-value\n    //key 是这一行数据的起始偏移量     value 是这一行的文本内容\n    //将这一行的内容转换成string类型\n    String line = value.toString();\n    //对这一行的文本按特定分隔符切分\n    String[] words = StringUtils.split(line, &quot; &quot;);\n    //遍历这个单词数组输出为kv形式  k：单词   v ： 1\n    for(String word : words){\n        context.write(new Text(word), new LongWritable(1));\n    }\n}\n}\n</code></pre><h4 id=\"三、实现Reduce函数\"><a href=\"#三、实现Reduce函数\" class=\"headerlink\" title=\"三、实现Reduce函数\"></a>三、实现Reduce函数</h4><pre><code>public class PPJReducer extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt;{\n//框架在map处理完成之后，将所有kv对缓存起来，进行分组，然后传递一个组&lt;key,valus{}&gt;，调用一次reduce方法\n//&lt;hello,{1,1,1,1,1,1.....}&gt;\n@Override\nprotected void reduce(Text key, Iterable&lt;LongWritable&gt; values,Context context)\n        throws IOException, InterruptedException {\n\n    long count = 0;\n    //遍历求和\n    for(LongWritable value:values){\n\n        count += value.get();\n    }\n    //输出这一个单词的统计结果\n    context.write(key, new LongWritable(count));\n}\n}\n</code></pre><h4 id=\"四、配置job类（选择操作的Mapper-Reduce，操作的文件路径，操作结果路径）\"><a href=\"#四、配置job类（选择操作的Mapper-Reduce，操作的文件路径，操作结果路径）\" class=\"headerlink\" title=\"四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）\"></a>四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）</h4><pre><code>Job wcjob = Job.getInstance(new Configuration());\n\n//设置整个job所用的那些类在哪个jar包\nwcjob.setJarByClass(this class);\n\n\n//本job使用的mapper和reducer的类\nwcjob.setMapperClass(PPJMapper.class);\nwcjob.setReducerClass(PPJReducer.class);\n\n\n//指定reduce的输出数据kv类型\nwcjob.setOutputKeyClass(Text.class);\nwcjob.setOutputValueClass(LongWritable.class);\n\n//指定mapper的输出数据kv类型\nwcjob.setMapOutputKeyClass(Text.class);\nwcjob.setMapOutputValueClass(LongWritable.class);\n\n\n//指定要处理的输入数据存放路径\nFileInputFormat.setInputPaths(wcjob, new Path(&quot;hdfs://ppj2:8020/ppj/src/&quot;));\n\n//指定处理结果的输出数据存放路径\nFileOutputFormat.setOutputPath(wcjob, new Path(&quot;hdfs://ppj2:8020/ppj/output/&quot;));\n\n//将job提交给集群运行 \nwcjob.waitForCompletion(true);\n</code></pre><h4 id=\"五、在hadoop上运行\"><a href=\"#五、在hadoop上运行\" class=\"headerlink\" title=\"五、在hadoop上运行\"></a>五、在hadoop上运行</h4><pre><code>先要上传目标文件\nhadoop fs -put 123.txt /ppj/ (没有路径需要先创建)\n执行jar包\nhadoop jar ppj2.jar (执行方法所在的全类名，不包含,class)\n</code></pre><p>另外输出的文件夹不需要创建，因为他会自动创建</p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"一-Mapreduce（用来解决海量数据的运算）\"><a href=\"#一-Mapreduce（用来解决海量数据的运算）\" class=\"headerlink\" title=\"一.Mapreduce（用来解决海量数据的运算）\"></a>一.Mapreduce（用来解决海量数据的运算）</h4><p>MapReduce由两个阶段组成：Map和Reduce，用户只需要实现map()和reduce()两个函数，即可实现分布式计算，非常简单。Map是对单个的运算，reduce是将他们的结果汇总。</p>\n<h4 id=\"二、实现Map函数\"><a href=\"#二、实现Map函数\" class=\"headerlink\" title=\"二、实现Map函数\"></a>二、实现Map函数</h4><h5 id=\"1-继承hadoop的mapper类\"><a href=\"#1-继承hadoop的mapper类\" class=\"headerlink\" title=\"1.继承hadoop的mapper类\"></a>1.继承hadoop的mapper类</h5><p> Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;<br><br> 四个泛型是因为需要输入输出参数，且都为键值对key-value形式封装。又因为hadoop将其序列化更加精简，所以使用的是hadoop封装的类型，如 long-&gt;LongWrite,String-&gt;Text</p>\n<h5 id=\"2-实现mapper的map方法（每读取一行就调用一次该方法）\"><a href=\"#2-实现mapper的map方法（每读取一行就调用一次该方法）\" class=\"headerlink\" title=\"2.实现mapper的map方法（每读取一行就调用一次该方法）\"></a>2.实现mapper的map方法（每读取一行就调用一次该方法）</h5><pre><code>//默认情况下，框架传递给我们的mapper的输入数据中，key是要处理的文本中一行的起始偏移量，这一行的内容作为value\npublic class PPJMap extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt;{\n@Override\nprotected void map(LongWritable key, Text value,Context context)throws IOException, InterruptedException {\n    //具体业务逻辑就写在这个方法体中，而且我们业务要处理的数据已经被框架传递进来，在方法的参数中 key-value\n    //key 是这一行数据的起始偏移量     value 是这一行的文本内容\n    //将这一行的内容转换成string类型\n    String line = value.toString();\n    //对这一行的文本按特定分隔符切分\n    String[] words = StringUtils.split(line, &quot; &quot;);\n    //遍历这个单词数组输出为kv形式  k：单词   v ： 1\n    for(String word : words){\n        context.write(new Text(word), new LongWritable(1));\n    }\n}\n}\n</code></pre><h4 id=\"三、实现Reduce函数\"><a href=\"#三、实现Reduce函数\" class=\"headerlink\" title=\"三、实现Reduce函数\"></a>三、实现Reduce函数</h4><pre><code>public class PPJReducer extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt;{\n//框架在map处理完成之后，将所有kv对缓存起来，进行分组，然后传递一个组&lt;key,valus{}&gt;，调用一次reduce方法\n//&lt;hello,{1,1,1,1,1,1.....}&gt;\n@Override\nprotected void reduce(Text key, Iterable&lt;LongWritable&gt; values,Context context)\n        throws IOException, InterruptedException {\n\n    long count = 0;\n    //遍历求和\n    for(LongWritable value:values){\n\n        count += value.get();\n    }\n    //输出这一个单词的统计结果\n    context.write(key, new LongWritable(count));\n}\n}\n</code></pre><h4 id=\"四、配置job类（选择操作的Mapper-Reduce，操作的文件路径，操作结果路径）\"><a href=\"#四、配置job类（选择操作的Mapper-Reduce，操作的文件路径，操作结果路径）\" class=\"headerlink\" title=\"四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）\"></a>四、配置job类（选择操作的Mapper,Reduce，操作的文件路径，操作结果路径）</h4><pre><code>Job wcjob = Job.getInstance(new Configuration());\n\n//设置整个job所用的那些类在哪个jar包\nwcjob.setJarByClass(this class);\n\n\n//本job使用的mapper和reducer的类\nwcjob.setMapperClass(PPJMapper.class);\nwcjob.setReducerClass(PPJReducer.class);\n\n\n//指定reduce的输出数据kv类型\nwcjob.setOutputKeyClass(Text.class);\nwcjob.setOutputValueClass(LongWritable.class);\n\n//指定mapper的输出数据kv类型\nwcjob.setMapOutputKeyClass(Text.class);\nwcjob.setMapOutputValueClass(LongWritable.class);\n\n\n//指定要处理的输入数据存放路径\nFileInputFormat.setInputPaths(wcjob, new Path(&quot;hdfs://ppj2:8020/ppj/src/&quot;));\n\n//指定处理结果的输出数据存放路径\nFileOutputFormat.setOutputPath(wcjob, new Path(&quot;hdfs://ppj2:8020/ppj/output/&quot;));\n\n//将job提交给集群运行 \nwcjob.waitForCompletion(true);\n</code></pre><h4 id=\"五、在hadoop上运行\"><a href=\"#五、在hadoop上运行\" class=\"headerlink\" title=\"五、在hadoop上运行\"></a>五、在hadoop上运行</h4><pre><code>先要上传目标文件\nhadoop fs -put 123.txt /ppj/ (没有路径需要先创建)\n执行jar包\nhadoop jar ppj2.jar (执行方法所在的全类名，不包含,class)\n</code></pre><p>另外输出的文件夹不需要创建，因为他会自动创建</p>\n"},{"title":"Hadoop(四)（java客户端操作HDFS）","author":"小小冰弟","date":"2018-03-01T01:18:28.000Z","_content":"##### 1.导包\n没有maven环境，自己导包的话，找到share/hadoop目录下commons与hdfs文件下的jar包与lib下的所有包导入工程。\n\n##### 2.准备工作\n    //配置\n    Configuration conf = new Configuration(); \n    //构造一个hdfs的客户端  \n    FileSystem fs=FileSystem.get(new URI(\"hdfs://192.168.145.102:8020\"), conf, \"root\");  \n\n##### 3.基本操作 \n     \n    //从本地上传文件到hdfs中   \n    @Test  \n    public void Upload() throws IllegalArgumentException, IOException{ \n        Path hpath = new Path(\"/\");\n        Path lpath = \"/home/wujian/jdk-7u65-linux-i586.tar.gz\"\n        fs.copyFromLocalFile(lpath, hpath);  \n        fs.close();  \n    }  \n    \n    // 从hdfs中下载文件到本地 \n    @Test  \n    public void Download() throws IllegalArgumentException, IOException{  \n        Path hpath = new Path(\"/jdk-7u65-linux-i586.tar.gz\");\n        Path lpath = \"/home/wujian/\"\n        fs.copyToLocalFile(hpath, lpath, true);  \n        fs.close();  \n    }  \n      \n    \n    //文件夹操作  \n    @Test  \n    public void Dir() throws IllegalArgumentException, IOException{  \n        //创建文件夹\n        fs.mkdirs(new Path(\"/aaa\"));  \n          \n        //判断是否存在 \n        boolean exists = fs.exists(new Path(\"/aaa\"));  \n \n        fs.close();  \n    }  \n      \n    //文件信息查看   \n    @Test  \n    public void FileStatus() throws FileNotFoundException, IllegalArgumentException, IOException{  \n        //只能列出文件信息  \n        RemoteIterator<LocatedFileStatus> listFiles = fs.listFiles(new Path(\"/\"), true);  \n        while(listFiles.hasNext()){  \n            LocatedFileStatus fileStatus = listFiles.next();  \n            System.out.println(fileStatus.getPath().getName());  \n        }  \n          \n        System.out.println(\"-----------------------\");  \n        //能列出文件和文件夹信息  \n        FileStatus[] listStatus = fs.listStatus(new Path(\"/\"));  \n        for(FileStatus f:listStatus){  \n            String type=\"-\";  \n            if(f.isDirectory()){\n             type=\"d\"; \n            }\n            System.out.println(type+\"\\t\"+f.getPath().getName());  \n        }  \n        fs.close();  \n    }  ","source":"_posts/Hadoop-四-（java客户端操作HDFS）.md","raw":"title: Hadoop(四)（java客户端操作HDFS）\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-03-01 09:18:28\n---\n##### 1.导包\n没有maven环境，自己导包的话，找到share/hadoop目录下commons与hdfs文件下的jar包与lib下的所有包导入工程。\n\n##### 2.准备工作\n    //配置\n    Configuration conf = new Configuration(); \n    //构造一个hdfs的客户端  \n    FileSystem fs=FileSystem.get(new URI(\"hdfs://192.168.145.102:8020\"), conf, \"root\");  \n\n##### 3.基本操作 \n     \n    //从本地上传文件到hdfs中   \n    @Test  \n    public void Upload() throws IllegalArgumentException, IOException{ \n        Path hpath = new Path(\"/\");\n        Path lpath = \"/home/wujian/jdk-7u65-linux-i586.tar.gz\"\n        fs.copyFromLocalFile(lpath, hpath);  \n        fs.close();  \n    }  \n    \n    // 从hdfs中下载文件到本地 \n    @Test  \n    public void Download() throws IllegalArgumentException, IOException{  \n        Path hpath = new Path(\"/jdk-7u65-linux-i586.tar.gz\");\n        Path lpath = \"/home/wujian/\"\n        fs.copyToLocalFile(hpath, lpath, true);  \n        fs.close();  \n    }  \n      \n    \n    //文件夹操作  \n    @Test  \n    public void Dir() throws IllegalArgumentException, IOException{  \n        //创建文件夹\n        fs.mkdirs(new Path(\"/aaa\"));  \n          \n        //判断是否存在 \n        boolean exists = fs.exists(new Path(\"/aaa\"));  \n \n        fs.close();  \n    }  \n      \n    //文件信息查看   \n    @Test  \n    public void FileStatus() throws FileNotFoundException, IllegalArgumentException, IOException{  \n        //只能列出文件信息  \n        RemoteIterator<LocatedFileStatus> listFiles = fs.listFiles(new Path(\"/\"), true);  \n        while(listFiles.hasNext()){  \n            LocatedFileStatus fileStatus = listFiles.next();  \n            System.out.println(fileStatus.getPath().getName());  \n        }  \n          \n        System.out.println(\"-----------------------\");  \n        //能列出文件和文件夹信息  \n        FileStatus[] listStatus = fs.listStatus(new Path(\"/\"));  \n        for(FileStatus f:listStatus){  \n            String type=\"-\";  \n            if(f.isDirectory()){\n             type=\"d\"; \n            }\n            System.out.println(type+\"\\t\"+f.getPath().getName());  \n        }  \n        fs.close();  \n    }  ","slug":"Hadoop-四-（java客户端操作HDFS）","published":1,"updated":"2018-03-26T09:46:34.651Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60l20014xo7kpyad7t9a","content":"<h5 id=\"1-导包\"><a href=\"#1-导包\" class=\"headerlink\" title=\"1.导包\"></a>1.导包</h5><p>没有maven环境，自己导包的话，找到share/hadoop目录下commons与hdfs文件下的jar包与lib下的所有包导入工程。</p>\n<h5 id=\"2-准备工作\"><a href=\"#2-准备工作\" class=\"headerlink\" title=\"2.准备工作\"></a>2.准备工作</h5><pre><code>//配置\nConfiguration conf = new Configuration(); \n//构造一个hdfs的客户端  \nFileSystem fs=FileSystem.get(new URI(&quot;hdfs://192.168.145.102:8020&quot;), conf, &quot;root&quot;);  \n</code></pre><h5 id=\"3-基本操作\"><a href=\"#3-基本操作\" class=\"headerlink\" title=\"3.基本操作\"></a>3.基本操作</h5><pre><code>//从本地上传文件到hdfs中   \n@Test  \npublic void Upload() throws IllegalArgumentException, IOException{ \n    Path hpath = new Path(&quot;/&quot;);\n    Path lpath = &quot;/home/wujian/jdk-7u65-linux-i586.tar.gz&quot;\n    fs.copyFromLocalFile(lpath, hpath);  \n    fs.close();  \n}  \n\n// 从hdfs中下载文件到本地 \n@Test  \npublic void Download() throws IllegalArgumentException, IOException{  \n    Path hpath = new Path(&quot;/jdk-7u65-linux-i586.tar.gz&quot;);\n    Path lpath = &quot;/home/wujian/&quot;\n    fs.copyToLocalFile(hpath, lpath, true);  \n    fs.close();  \n}  \n\n\n//文件夹操作  \n@Test  \npublic void Dir() throws IllegalArgumentException, IOException{  \n    //创建文件夹\n    fs.mkdirs(new Path(&quot;/aaa&quot;));  \n\n    //判断是否存在 \n    boolean exists = fs.exists(new Path(&quot;/aaa&quot;));  \n\n    fs.close();  \n}  \n\n//文件信息查看   \n@Test  \npublic void FileStatus() throws FileNotFoundException, IllegalArgumentException, IOException{  \n    //只能列出文件信息  \n    RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(new Path(&quot;/&quot;), true);  \n    while(listFiles.hasNext()){  \n        LocatedFileStatus fileStatus = listFiles.next();  \n        System.out.println(fileStatus.getPath().getName());  \n    }  \n\n    System.out.println(&quot;-----------------------&quot;);  \n    //能列出文件和文件夹信息  \n    FileStatus[] listStatus = fs.listStatus(new Path(&quot;/&quot;));  \n    for(FileStatus f:listStatus){  \n        String type=&quot;-&quot;;  \n        if(f.isDirectory()){\n         type=&quot;d&quot;; \n        }\n        System.out.println(type+&quot;\\t&quot;+f.getPath().getName());  \n    }  \n    fs.close();  \n}  \n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h5 id=\"1-导包\"><a href=\"#1-导包\" class=\"headerlink\" title=\"1.导包\"></a>1.导包</h5><p>没有maven环境，自己导包的话，找到share/hadoop目录下commons与hdfs文件下的jar包与lib下的所有包导入工程。</p>\n<h5 id=\"2-准备工作\"><a href=\"#2-准备工作\" class=\"headerlink\" title=\"2.准备工作\"></a>2.准备工作</h5><pre><code>//配置\nConfiguration conf = new Configuration(); \n//构造一个hdfs的客户端  \nFileSystem fs=FileSystem.get(new URI(&quot;hdfs://192.168.145.102:8020&quot;), conf, &quot;root&quot;);  \n</code></pre><h5 id=\"3-基本操作\"><a href=\"#3-基本操作\" class=\"headerlink\" title=\"3.基本操作\"></a>3.基本操作</h5><pre><code>//从本地上传文件到hdfs中   \n@Test  \npublic void Upload() throws IllegalArgumentException, IOException{ \n    Path hpath = new Path(&quot;/&quot;);\n    Path lpath = &quot;/home/wujian/jdk-7u65-linux-i586.tar.gz&quot;\n    fs.copyFromLocalFile(lpath, hpath);  \n    fs.close();  \n}  \n\n// 从hdfs中下载文件到本地 \n@Test  \npublic void Download() throws IllegalArgumentException, IOException{  \n    Path hpath = new Path(&quot;/jdk-7u65-linux-i586.tar.gz&quot;);\n    Path lpath = &quot;/home/wujian/&quot;\n    fs.copyToLocalFile(hpath, lpath, true);  \n    fs.close();  \n}  \n\n\n//文件夹操作  \n@Test  \npublic void Dir() throws IllegalArgumentException, IOException{  \n    //创建文件夹\n    fs.mkdirs(new Path(&quot;/aaa&quot;));  \n\n    //判断是否存在 \n    boolean exists = fs.exists(new Path(&quot;/aaa&quot;));  \n\n    fs.close();  \n}  \n\n//文件信息查看   \n@Test  \npublic void FileStatus() throws FileNotFoundException, IllegalArgumentException, IOException{  \n    //只能列出文件信息  \n    RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(new Path(&quot;/&quot;), true);  \n    while(listFiles.hasNext()){  \n        LocatedFileStatus fileStatus = listFiles.next();  \n        System.out.println(fileStatus.getPath().getName());  \n    }  \n\n    System.out.println(&quot;-----------------------&quot;);  \n    //能列出文件和文件夹信息  \n    FileStatus[] listStatus = fs.listStatus(new Path(&quot;/&quot;));  \n    for(FileStatus f:listStatus){  \n        String type=&quot;-&quot;;  \n        if(f.isDirectory()){\n         type=&quot;d&quot;; \n        }\n        System.out.println(type+&quot;\\t&quot;+f.getPath().getName());  \n    }  \n    fs.close();  \n}  \n</code></pre>"},{"title":"Hadoop(十)(Storm)","author":"小小冰弟","date":"2018-03-29T06:57:18.000Z","_content":"#### 一、Storm\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进行实时的数据处理如实时分析，在线机器学习，持续计算，主要运用于流式计算，例如网上的实时数据要写入数据库，中间需要个处理过程，通常结合消息队列（消息源）和数据库（存储地）一起使用。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Storm集群中真正运行topology的主要有三个实体：工作进程、线程和任务。Storm集群中的每台机器上都可以运行多个工作进程，每个 工作进程又可创建多个线程，每个线程可以执行多个任务，任务是真正进行数据处理的实体，我们开发的spout、bolt就是作为一个或者多个任务的方式执 行的。\n\n因此，计算任务在多个线程、进程和服务器之间并行进行，支持灵活的水平扩展。\n\n\n\n#### 二、Storm基本组件\n\n##### 1、Topologies ： 拓扑，也俗称一个任务（与Hadoop的MapReduce job不同，不会终止）\n \n 一个topology是spouts和bolts组成的图， 通过stream groupings将图中的spouts和bolts连接起来。\n \n ###### Topology运行机制\n**(1)Storm提交后，会把代码首先存放到Nimbus节点的inbox目录下，之后，会把当前Storm运行的配置生成一个stormconf.ser文件放到Nimbus节点的stormdist目录中，在此目录中同时还有序列化之后的Topology代码文件；**\n\n**(2)在设定Topology所关联的Spouts和Bolts时，可以同时设置当前Spout和Bolt的executor数目和task数目，默认情况下，一个Topology的task的总和是和executor的总和一致的。之后，系统根据worker的数目，尽量平均的分配这些task的执行。worker在哪个supervisor节点上运行是由storm本身决定的；**\n\n**(3)任务分配好之后，Nimbes节点会将任务的信息提交到zookeeper集群，同时在zookeeper集群中会有workerbeats节点，这里存储了当前Topology的所有worker进程的心跳信息；**\n\n**(4)Supervisor节点会不断的轮询zookeeper集群，在zookeeper的assignments节点中保存了所有Topology的任务分配信息、代码存储目录、任务之间的关联关系等，Supervisor通过轮询此节点的内容，来领取自己的任务，启动worker进程运行；**\n\n**(5)一个Topology运行之后，就会不断的通过Spouts来发送Stream流，通过Bolts来不断的处理接收到的Stream流，Stream流是无界的。**\n\n**最后一步会不间断的执行，除非手动结束Topology。**\n\n \n \n ##### 2、Spouts ： 拓扑的消息源\n \n消息源spout是Storm里面一个topology里面的消息生产者；\n\nSpouts可以是可靠的也可以是不可靠的：如果这个tuple没有被storm成功处理，可靠的消息源spouts可以重新发射一个tuple， 但是不可靠的消息源spouts一旦发出一个tuple就不能重发了；\n\n消息源可以发射多条消息流stream：使用OutputFieldsDeclarer.declareStream来定义多个stream， 然后使用SpoutOutputCollector来发射指定的stream。\n\n \n \n ##### 3、Bolts ： 拓扑的处理逻辑单元\n \n所有的消息处理逻辑被封装在bolts里面；\n\nBolts可以做很多事情：过滤，聚合，查询数据库等等。\n\nBolts可以简单的做消息流的传递，也可以通过多级Bolts的组合来完成复杂的消息流处理；比如求TopN、聚合操作等（如果要把这个过程做得更具有扩展性那么可能需要更多的步骤）。\n\nBolts可以发射多条消息流： \n     使用OutputFieldsDeclarer.declareStream定义stream；\n     使用OutputCollector.emit来选择要发射的stream；\n\nBolts的主要方法是execute,：\n     它以一个tuple作为输入，使用OutputCollector来发射tuple；\n     通过调用OutputCollector的ack方法，以通知这个tuple的发射者spout；\n\nBolts一般的流程： \n     处理一个输入tuple,  发射0个或者多个tuple, 然后调用ack通知storm自己已经处理过这个tuple了；\n    storm提供了一个IBasicBolt会自动调用ack。\n\n ##### 4、tuple：消息元组(用来固定消息的传递格式，几个字符串啊等等)\n ##### 5、Streams ： 流\n \n消息流stream是storm里的关键抽象；\n一个消息流是一个没有边界的tuple序列， 而这些tuple序列会以一种分布式的方式并行地创建和处理；\n通过对stream中tuple序列中每个字段命名来定义stream；\n在默认的情况下，tuple的字段类型可以是：integer，long，short， byte，string，double，float，boolean和byte array；\n可以自定义类型（只要实现相应的序列化器）。\n\n ##### 6、Stream groupings ：流的分组策略\n \n定义一个topology的关键一步是定义每个bolt接收什么样的流作为输入；\n\nstream grouping就是用来定义一个stream应该如何分配数据给bolts；\n\nStorm里面有7种类型的stream grouping：\nShuffle Grouping——随机分组， 随机派发stream里面的tuple，保证每个bolt接收到的tuple数目大致相同；\nFields Grouping——按字段分组， 比如按userid来分组， 具有同样userid的tuple会被分到相同的Bolts里的一个task， 而不同的userid则会被分配到不同的bolts里的task；\n\nAll Grouping——广播发送，对于每一个tuple，所有的bolts都会收到；\n\nGlobal Grouping——全局分组， 这个tuple被分配到storm中的一个bolt的其中一个task。再具体一点就是分配给id值最低的那个task；\n\nNon Grouping——不分组，这个分组的意思是说stream不关心到底谁会收到它的tuple。目前这种分组和Shuffle grouping是一样的效果， 有一点不同的是storm会把这个bolt放到这个bolt的订阅者同一个线程里面去执行；\n\nDirect Grouping——直接分组， 这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。\n消息处理者可以通过TopologyContext来获取处理它的消息的task的id （OutputCollector.emit方法也会返回task的id）；\n\nLocal or shuffle grouping——如果目标bolt有一个或者多个task在同一个工作进程中，tuple将会被随机发生给这些tasks。否则，和普通的Shuffle Grouping行为一致。\n\n\n\n ##### 7、Tasks ： 任务处理单元\n \n每一个spout和bolt会被当作很多task在整个集群里执行\n\n每一个executor对应到一个线程，在这个线程上运行多个task\n\nstream grouping则是定义怎么从一堆task发射tuple到另外一堆task\n\n可以调用TopologyBuilder类的setSpout和setBolt来设置并行度（也就是有多少个task）\n\n ##### 8、Executor :工作线程\n ##### 9、Workers ：工作进程\n \n 一个topology可能会在一个或者多个worker（工作进程）里面执行；\n\n每个worker是一个物理JVM并且执行整个topology的一部分；\n\n比如，对于并行度是300的topology来说，如果我们使用50个工作进程来执行，那么每个工作进程会处理其中的6个tasks；\nStorm会尽量均匀的工作分配给所有的worker；\n\n ##### 10、Configuration ： topology的配置\n\n\n\n\n\n\n\n#### 三、Storm集群管理架构\n\n主要分为两部分：\n1. Nimbus  负责协调管理\n2. Supervisor 负责具体运算\n\n具体配置：\n\n###### 1、安装一个zookeeper集群\n\n###### 2、上传storm的安装包，解压\n\n###### 3、修改配置文件storm.yaml\n\n      #所使用的zookeeper集群主机\n      storm.zookeeper.servers:\n           - \"hadoop01\"\n           - \"hadoop02\"\n           - \"hadoop03\"\n\n      #nimbus所在的主机名\n      nimbus.host: \"hadoop01\"\n\n###### 4.占用的端口\n    supervisor.slots.ports\n    -6701\n    -6702\n    -6703\n    -6704\n    -6705\n\n\n###### 5.启动storm\n\n    在nimbus主机上\n    nohup ./storm nimbus\n    nohup ./storm ui （开启后便可以访问可视化页面管理，端口号8080）\n\n    在supervisor主机上\n    nohup ./storm supervisor \n    \n    \n**注意事项：\n启动Storm后台进程时，需要对conf/storm.yaml配置文件中设置的storm.local.dir目录具有写权限。\nstorm后台进程被启动后，将在Storm安装部署目录下的logs/子目录下生成各个进程的日志文件。\n经测试，Storm UI必须和Storm Nimbus部署在同一台机器上，否则UI无法正常工作，因为UI进程会检查本机是否存在Nimbus链接。\n为了方便使用，可以将bin/storm加入到系统环境变量中。\n至此，Storm集群已经部署、配置完毕，可以向集群提交拓扑运行了。**\n\n    提交Topologies\n    命令格式：storm jar 【jar路径】 【拓扑包名.拓扑类名】【stormIP地址】【storm端口】【拓扑名称】【参    数】\n    eg：storm jar /home/storm/storm-starter.jar storm.starter.WordCountTopology wordcountTop;\n    #提交storm-starter.jar到远程集群，并启动wordcountTop拓扑。\n    \n    停止Topologies\n    查看当前运行的topo： storm list \n    命令格式：storm kill 【拓扑名称】\n    样例：storm kill wordcountTop#     \n    杀掉wordcountTop拓扑。\n\n\n\n\n\n#### 四、Storm的JAVA开发\n\n##### 1.编写Spout\n    package cn.itcast.stormdemo;\n\n    import java.util.Map;\n    import java.util.Random;\n\n    import backtype.storm.spout.SpoutOutputCollector;\n    import backtype.storm.task.TopologyContext;\n    import backtype.storm.topology.OutputFieldsDeclarer;\n    import backtype.storm.topology.base.BaseRichSpout;\n    import backtype.storm.tuple.Fields;\n    import backtype.storm.tuple.Values;\n    import backtype.storm.utils.Utils;\n\n    public class RandomWordSpout extends BaseRichSpout{\n\n\tprivate SpoutOutputCollector collector;\n\t\n\t//模拟一些数据\n\tString[] words = {\"iphone\",\"xiaomi\",\"mate\",\"sony\",\"sumsung\",\"moto\",\"meizu\"};\n\t\n\t//不断地往下一个组件发送tuple消息\n\t//这里面是该spout组件的核心逻辑\n\t@Override\n\tpublic void nextTuple() {\n\n\t\t//可以从kafka消息队列中拿到数据,简便起见，我们从words数组中随机挑选一个商品名发送出去\n\t\tRandom random = new Random();\n\t\tint index = random.nextInt(words.length);()保证不超过数组的大小\n\t\t\n\t\t//通过随机数拿到一个商品名\n\t\tString godName = words[index];\n\t\t\n\t\t\n\t\t//将商品名封装成tuple，发送消息给下一个组件（这里可以传进去一个数组，但之后的声明便也需要一一对应）\n\t\tcollector.emit(new Values(godName));\n\t\t\n\t\t//每发送一个消息，休眠500ms\n\t\tUtils.sleep(500);\n\t\t\n\t\t\n\t}\n\n\t//初始化方法，在spout组件实例化时调用一次\n\t@Override\n\tpublic void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {\n\n\t\tthis.collector = collector;\n\t\t\n\t\t\n\t}\n\n\t//声明本spout组件发送出去的tuple中的数据的字段名\n\t@Override\n\tpublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\n\t\tdeclarer.declare(new Fields(\"orignname\"));（\n\t\t\n\t}\n\n    }\n\n\n##### 2.编写转换大小写的Bolt\n\n\n    public class UpperBolt extends BaseBasicBolt{\n\n\t\n\t//业务处理逻辑\n\t@Override\n\tpublic void execute(Tuple tuple, BasicOutputCollector collector) {\n\t\t\n\t\t//先获取到上一个组件传递过来的数据,数据在tuple里面\n\t\tString godName = tuple.getString(0);\n\t\t\n\t\t//将商品名转换成大写\n\t\tString godName_upper = godName.toUpperCase();\n\t\t\n\t\t//将转换完成的商品名发送出去\n\t\tcollector.emit(new Values(godName_upper));\n\t\t\n\t}\n\n\t\n\t\n\t//声明该bolt组件要发出去的tuple的字段\n\t@Override\n\tpublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\t\t\n\t\tdeclarer.declare(new Fields(\"uppername\"));\n\t}\n\n    }\n\n##### 3.编写添加后缀的Bolt\n\n\n    public class SuffixBolt extends BaseBasicBolt{\n\t\n\tFileWriter fileWriter = null;\n\t\n\t\n\t//在bolt组件运行过程中只会被调用一次，因为这是最后一个bolt,分布式有很多个进程以此来区分\n\t@Override\n\tpublic void prepare(Map stormConf, TopologyContext context) {\n\n\t\ttry {\n\t\t\tfileWriter = new FileWriter(\"/home/hadoop/stormoutput/\"+UUID.randomUUID());\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\t\n\t}\n\t\n\t\n\t\n\t//该bolt组件的核心处理逻辑\n\t//每收到一个tuple消息，就会被调用一次\n\t@Override\n\tpublic void execute(Tuple tuple, BasicOutputCollector collector) {\n\n\t\t//先拿到上一个组件发送过来的商品名称\n\t\tString upper_name = tuple.getString(0);\n\t\tString suffix_name = upper_name + \"_itisok\";\n\t\t\n\t\t\n\t\t//为上一个组件发送过来的商品名称添加后缀\n\t\t\n\t\ttry {\n\t\t\tfileWriter.write(suffix_name);\n\t\t\tfileWriter.write(\"\\n\");\n\t\t\tfileWriter.flush();\n\t\t\t\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\t\n\t\t\n\t\t\n\t}\n\n\t\n\t\n\t\n\t//本bolt已经不需要发送tuple消息到下一个组件，所以不需要再声明tuple的字段\n\t@Override\n\tpublic void declareOutputFields(OutputFieldsDeclarer arg0) {\n\n\t\t\n\t}\n\n    }\n\n##### 4.主程序编写\n\n \n * 组织各个处理组件形成一个完整的处理流程，就是所谓的topology(类似于mapreduce程序中的job)\n * 并且将该topology提交给storm集群去运行，topology提交到集群后就将永无休止地运行，除非人为或者异常退出\n * @author duanhaitao@itcast.cn\n \n \n \n    public class TopoMain {\n\n\t\n\tpublic static void main(String[] args) throws Exception {\n\t\t\n\t\tTopologyBuilder builder = new TopologyBuilder();\n\t\t\n\t\t//将我们的spout组件设置到topology中去，并且取名为randomSpout  \n\t\t//parallelism_hint ：4  表示用4个excutor来执行这个组件\n\t\t//setNumTasks(8) 设置的是该组件执行时的并发task数量，也就意味着1个excutor会运行2个task\n\t\tbuilder.setSpout(\"randomspout\", new RandomWordSpout(), 4).setNumTasks(8);\n\t\t\n\t\t//将大写转换bolt组件设置到topology，并且指定它接收randomspout组件的消息\n\t\t//.shuffleGrouping(\"randomspout\")包含两层含义：\n\t\t//1、upperbolt组件接收的tuple消息一定来自于randomspout组件\n\t\t//2、randomspout组件和upperbolt组件的大量并发task实例之间收发消息时采用的分组策略是随机分组shuffleGrouping\n\t\tbuilder.setBolt(\"upperbolt\", new UpperBolt(), 4).shuffleGrouping(\"randomspout\");\n\t\t\n\t\t//将添加后缀的bolt组件设置到topology，并且指定它接收upperbolt组件的消息\n\t\tbuilder.setBolt(\"suffixbolt\", new SuffixBolt(), 4).shuffleGrouping(\"upperbolt\");\n\t\t\n\t\t//用builder来创建一个topology\n\t\tStormTopology demotop = builder.createTopology();\n\t\t\n\t\t\n\t\t//配置一些topology在集群中运行时的参数\n\t\tConfig conf = new Config();\n\t\t//这里设置的是整个demotop所占用的槽位数，也就是worker的数量\n\t\tconf.setNumWorkers(4);\n\t\tconf.setDebug(true);\n\t\tconf.setNumAckers(0);\n\t\t\n\t\t\n\t\t//将这个topology提交给storm集群运行,名字叫demotopo\n\t\tStormSubmitter.submitTopology(\"demotopo\", conf, demotop);\n\t\t\n\t}\n   }\n   \n  \n##### 5.运行程序\n\n  \n   ","source":"_posts/Hadoop-十-Storm.md","raw":"title: Hadoop(十)(Storm)\nauthor: 小小冰弟\ntags: study\ncategories: Hadoop\ndate: 2018-03-29 14:57:18\n---\n#### 一、Storm\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进行实时的数据处理如实时分析，在线机器学习，持续计算，主要运用于流式计算，例如网上的实时数据要写入数据库，中间需要个处理过程，通常结合消息队列（消息源）和数据库（存储地）一起使用。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Storm集群中真正运行topology的主要有三个实体：工作进程、线程和任务。Storm集群中的每台机器上都可以运行多个工作进程，每个 工作进程又可创建多个线程，每个线程可以执行多个任务，任务是真正进行数据处理的实体，我们开发的spout、bolt就是作为一个或者多个任务的方式执 行的。\n\n因此，计算任务在多个线程、进程和服务器之间并行进行，支持灵活的水平扩展。\n\n\n\n#### 二、Storm基本组件\n\n##### 1、Topologies ： 拓扑，也俗称一个任务（与Hadoop的MapReduce job不同，不会终止）\n \n 一个topology是spouts和bolts组成的图， 通过stream groupings将图中的spouts和bolts连接起来。\n \n ###### Topology运行机制\n**(1)Storm提交后，会把代码首先存放到Nimbus节点的inbox目录下，之后，会把当前Storm运行的配置生成一个stormconf.ser文件放到Nimbus节点的stormdist目录中，在此目录中同时还有序列化之后的Topology代码文件；**\n\n**(2)在设定Topology所关联的Spouts和Bolts时，可以同时设置当前Spout和Bolt的executor数目和task数目，默认情况下，一个Topology的task的总和是和executor的总和一致的。之后，系统根据worker的数目，尽量平均的分配这些task的执行。worker在哪个supervisor节点上运行是由storm本身决定的；**\n\n**(3)任务分配好之后，Nimbes节点会将任务的信息提交到zookeeper集群，同时在zookeeper集群中会有workerbeats节点，这里存储了当前Topology的所有worker进程的心跳信息；**\n\n**(4)Supervisor节点会不断的轮询zookeeper集群，在zookeeper的assignments节点中保存了所有Topology的任务分配信息、代码存储目录、任务之间的关联关系等，Supervisor通过轮询此节点的内容，来领取自己的任务，启动worker进程运行；**\n\n**(5)一个Topology运行之后，就会不断的通过Spouts来发送Stream流，通过Bolts来不断的处理接收到的Stream流，Stream流是无界的。**\n\n**最后一步会不间断的执行，除非手动结束Topology。**\n\n \n \n ##### 2、Spouts ： 拓扑的消息源\n \n消息源spout是Storm里面一个topology里面的消息生产者；\n\nSpouts可以是可靠的也可以是不可靠的：如果这个tuple没有被storm成功处理，可靠的消息源spouts可以重新发射一个tuple， 但是不可靠的消息源spouts一旦发出一个tuple就不能重发了；\n\n消息源可以发射多条消息流stream：使用OutputFieldsDeclarer.declareStream来定义多个stream， 然后使用SpoutOutputCollector来发射指定的stream。\n\n \n \n ##### 3、Bolts ： 拓扑的处理逻辑单元\n \n所有的消息处理逻辑被封装在bolts里面；\n\nBolts可以做很多事情：过滤，聚合，查询数据库等等。\n\nBolts可以简单的做消息流的传递，也可以通过多级Bolts的组合来完成复杂的消息流处理；比如求TopN、聚合操作等（如果要把这个过程做得更具有扩展性那么可能需要更多的步骤）。\n\nBolts可以发射多条消息流： \n     使用OutputFieldsDeclarer.declareStream定义stream；\n     使用OutputCollector.emit来选择要发射的stream；\n\nBolts的主要方法是execute,：\n     它以一个tuple作为输入，使用OutputCollector来发射tuple；\n     通过调用OutputCollector的ack方法，以通知这个tuple的发射者spout；\n\nBolts一般的流程： \n     处理一个输入tuple,  发射0个或者多个tuple, 然后调用ack通知storm自己已经处理过这个tuple了；\n    storm提供了一个IBasicBolt会自动调用ack。\n\n ##### 4、tuple：消息元组(用来固定消息的传递格式，几个字符串啊等等)\n ##### 5、Streams ： 流\n \n消息流stream是storm里的关键抽象；\n一个消息流是一个没有边界的tuple序列， 而这些tuple序列会以一种分布式的方式并行地创建和处理；\n通过对stream中tuple序列中每个字段命名来定义stream；\n在默认的情况下，tuple的字段类型可以是：integer，long，short， byte，string，double，float，boolean和byte array；\n可以自定义类型（只要实现相应的序列化器）。\n\n ##### 6、Stream groupings ：流的分组策略\n \n定义一个topology的关键一步是定义每个bolt接收什么样的流作为输入；\n\nstream grouping就是用来定义一个stream应该如何分配数据给bolts；\n\nStorm里面有7种类型的stream grouping：\nShuffle Grouping——随机分组， 随机派发stream里面的tuple，保证每个bolt接收到的tuple数目大致相同；\nFields Grouping——按字段分组， 比如按userid来分组， 具有同样userid的tuple会被分到相同的Bolts里的一个task， 而不同的userid则会被分配到不同的bolts里的task；\n\nAll Grouping——广播发送，对于每一个tuple，所有的bolts都会收到；\n\nGlobal Grouping——全局分组， 这个tuple被分配到storm中的一个bolt的其中一个task。再具体一点就是分配给id值最低的那个task；\n\nNon Grouping——不分组，这个分组的意思是说stream不关心到底谁会收到它的tuple。目前这种分组和Shuffle grouping是一样的效果， 有一点不同的是storm会把这个bolt放到这个bolt的订阅者同一个线程里面去执行；\n\nDirect Grouping——直接分组， 这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。\n消息处理者可以通过TopologyContext来获取处理它的消息的task的id （OutputCollector.emit方法也会返回task的id）；\n\nLocal or shuffle grouping——如果目标bolt有一个或者多个task在同一个工作进程中，tuple将会被随机发生给这些tasks。否则，和普通的Shuffle Grouping行为一致。\n\n\n\n ##### 7、Tasks ： 任务处理单元\n \n每一个spout和bolt会被当作很多task在整个集群里执行\n\n每一个executor对应到一个线程，在这个线程上运行多个task\n\nstream grouping则是定义怎么从一堆task发射tuple到另外一堆task\n\n可以调用TopologyBuilder类的setSpout和setBolt来设置并行度（也就是有多少个task）\n\n ##### 8、Executor :工作线程\n ##### 9、Workers ：工作进程\n \n 一个topology可能会在一个或者多个worker（工作进程）里面执行；\n\n每个worker是一个物理JVM并且执行整个topology的一部分；\n\n比如，对于并行度是300的topology来说，如果我们使用50个工作进程来执行，那么每个工作进程会处理其中的6个tasks；\nStorm会尽量均匀的工作分配给所有的worker；\n\n ##### 10、Configuration ： topology的配置\n\n\n\n\n\n\n\n#### 三、Storm集群管理架构\n\n主要分为两部分：\n1. Nimbus  负责协调管理\n2. Supervisor 负责具体运算\n\n具体配置：\n\n###### 1、安装一个zookeeper集群\n\n###### 2、上传storm的安装包，解压\n\n###### 3、修改配置文件storm.yaml\n\n      #所使用的zookeeper集群主机\n      storm.zookeeper.servers:\n           - \"hadoop01\"\n           - \"hadoop02\"\n           - \"hadoop03\"\n\n      #nimbus所在的主机名\n      nimbus.host: \"hadoop01\"\n\n###### 4.占用的端口\n    supervisor.slots.ports\n    -6701\n    -6702\n    -6703\n    -6704\n    -6705\n\n\n###### 5.启动storm\n\n    在nimbus主机上\n    nohup ./storm nimbus\n    nohup ./storm ui （开启后便可以访问可视化页面管理，端口号8080）\n\n    在supervisor主机上\n    nohup ./storm supervisor \n    \n    \n**注意事项：\n启动Storm后台进程时，需要对conf/storm.yaml配置文件中设置的storm.local.dir目录具有写权限。\nstorm后台进程被启动后，将在Storm安装部署目录下的logs/子目录下生成各个进程的日志文件。\n经测试，Storm UI必须和Storm Nimbus部署在同一台机器上，否则UI无法正常工作，因为UI进程会检查本机是否存在Nimbus链接。\n为了方便使用，可以将bin/storm加入到系统环境变量中。\n至此，Storm集群已经部署、配置完毕，可以向集群提交拓扑运行了。**\n\n    提交Topologies\n    命令格式：storm jar 【jar路径】 【拓扑包名.拓扑类名】【stormIP地址】【storm端口】【拓扑名称】【参    数】\n    eg：storm jar /home/storm/storm-starter.jar storm.starter.WordCountTopology wordcountTop;\n    #提交storm-starter.jar到远程集群，并启动wordcountTop拓扑。\n    \n    停止Topologies\n    查看当前运行的topo： storm list \n    命令格式：storm kill 【拓扑名称】\n    样例：storm kill wordcountTop#     \n    杀掉wordcountTop拓扑。\n\n\n\n\n\n#### 四、Storm的JAVA开发\n\n##### 1.编写Spout\n    package cn.itcast.stormdemo;\n\n    import java.util.Map;\n    import java.util.Random;\n\n    import backtype.storm.spout.SpoutOutputCollector;\n    import backtype.storm.task.TopologyContext;\n    import backtype.storm.topology.OutputFieldsDeclarer;\n    import backtype.storm.topology.base.BaseRichSpout;\n    import backtype.storm.tuple.Fields;\n    import backtype.storm.tuple.Values;\n    import backtype.storm.utils.Utils;\n\n    public class RandomWordSpout extends BaseRichSpout{\n\n\tprivate SpoutOutputCollector collector;\n\t\n\t//模拟一些数据\n\tString[] words = {\"iphone\",\"xiaomi\",\"mate\",\"sony\",\"sumsung\",\"moto\",\"meizu\"};\n\t\n\t//不断地往下一个组件发送tuple消息\n\t//这里面是该spout组件的核心逻辑\n\t@Override\n\tpublic void nextTuple() {\n\n\t\t//可以从kafka消息队列中拿到数据,简便起见，我们从words数组中随机挑选一个商品名发送出去\n\t\tRandom random = new Random();\n\t\tint index = random.nextInt(words.length);()保证不超过数组的大小\n\t\t\n\t\t//通过随机数拿到一个商品名\n\t\tString godName = words[index];\n\t\t\n\t\t\n\t\t//将商品名封装成tuple，发送消息给下一个组件（这里可以传进去一个数组，但之后的声明便也需要一一对应）\n\t\tcollector.emit(new Values(godName));\n\t\t\n\t\t//每发送一个消息，休眠500ms\n\t\tUtils.sleep(500);\n\t\t\n\t\t\n\t}\n\n\t//初始化方法，在spout组件实例化时调用一次\n\t@Override\n\tpublic void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {\n\n\t\tthis.collector = collector;\n\t\t\n\t\t\n\t}\n\n\t//声明本spout组件发送出去的tuple中的数据的字段名\n\t@Override\n\tpublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\n\t\tdeclarer.declare(new Fields(\"orignname\"));（\n\t\t\n\t}\n\n    }\n\n\n##### 2.编写转换大小写的Bolt\n\n\n    public class UpperBolt extends BaseBasicBolt{\n\n\t\n\t//业务处理逻辑\n\t@Override\n\tpublic void execute(Tuple tuple, BasicOutputCollector collector) {\n\t\t\n\t\t//先获取到上一个组件传递过来的数据,数据在tuple里面\n\t\tString godName = tuple.getString(0);\n\t\t\n\t\t//将商品名转换成大写\n\t\tString godName_upper = godName.toUpperCase();\n\t\t\n\t\t//将转换完成的商品名发送出去\n\t\tcollector.emit(new Values(godName_upper));\n\t\t\n\t}\n\n\t\n\t\n\t//声明该bolt组件要发出去的tuple的字段\n\t@Override\n\tpublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\t\t\n\t\tdeclarer.declare(new Fields(\"uppername\"));\n\t}\n\n    }\n\n##### 3.编写添加后缀的Bolt\n\n\n    public class SuffixBolt extends BaseBasicBolt{\n\t\n\tFileWriter fileWriter = null;\n\t\n\t\n\t//在bolt组件运行过程中只会被调用一次，因为这是最后一个bolt,分布式有很多个进程以此来区分\n\t@Override\n\tpublic void prepare(Map stormConf, TopologyContext context) {\n\n\t\ttry {\n\t\t\tfileWriter = new FileWriter(\"/home/hadoop/stormoutput/\"+UUID.randomUUID());\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\t\n\t}\n\t\n\t\n\t\n\t//该bolt组件的核心处理逻辑\n\t//每收到一个tuple消息，就会被调用一次\n\t@Override\n\tpublic void execute(Tuple tuple, BasicOutputCollector collector) {\n\n\t\t//先拿到上一个组件发送过来的商品名称\n\t\tString upper_name = tuple.getString(0);\n\t\tString suffix_name = upper_name + \"_itisok\";\n\t\t\n\t\t\n\t\t//为上一个组件发送过来的商品名称添加后缀\n\t\t\n\t\ttry {\n\t\t\tfileWriter.write(suffix_name);\n\t\t\tfileWriter.write(\"\\n\");\n\t\t\tfileWriter.flush();\n\t\t\t\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\t\n\t\t\n\t\t\n\t}\n\n\t\n\t\n\t\n\t//本bolt已经不需要发送tuple消息到下一个组件，所以不需要再声明tuple的字段\n\t@Override\n\tpublic void declareOutputFields(OutputFieldsDeclarer arg0) {\n\n\t\t\n\t}\n\n    }\n\n##### 4.主程序编写\n\n \n * 组织各个处理组件形成一个完整的处理流程，就是所谓的topology(类似于mapreduce程序中的job)\n * 并且将该topology提交给storm集群去运行，topology提交到集群后就将永无休止地运行，除非人为或者异常退出\n * @author duanhaitao@itcast.cn\n \n \n \n    public class TopoMain {\n\n\t\n\tpublic static void main(String[] args) throws Exception {\n\t\t\n\t\tTopologyBuilder builder = new TopologyBuilder();\n\t\t\n\t\t//将我们的spout组件设置到topology中去，并且取名为randomSpout  \n\t\t//parallelism_hint ：4  表示用4个excutor来执行这个组件\n\t\t//setNumTasks(8) 设置的是该组件执行时的并发task数量，也就意味着1个excutor会运行2个task\n\t\tbuilder.setSpout(\"randomspout\", new RandomWordSpout(), 4).setNumTasks(8);\n\t\t\n\t\t//将大写转换bolt组件设置到topology，并且指定它接收randomspout组件的消息\n\t\t//.shuffleGrouping(\"randomspout\")包含两层含义：\n\t\t//1、upperbolt组件接收的tuple消息一定来自于randomspout组件\n\t\t//2、randomspout组件和upperbolt组件的大量并发task实例之间收发消息时采用的分组策略是随机分组shuffleGrouping\n\t\tbuilder.setBolt(\"upperbolt\", new UpperBolt(), 4).shuffleGrouping(\"randomspout\");\n\t\t\n\t\t//将添加后缀的bolt组件设置到topology，并且指定它接收upperbolt组件的消息\n\t\tbuilder.setBolt(\"suffixbolt\", new SuffixBolt(), 4).shuffleGrouping(\"upperbolt\");\n\t\t\n\t\t//用builder来创建一个topology\n\t\tStormTopology demotop = builder.createTopology();\n\t\t\n\t\t\n\t\t//配置一些topology在集群中运行时的参数\n\t\tConfig conf = new Config();\n\t\t//这里设置的是整个demotop所占用的槽位数，也就是worker的数量\n\t\tconf.setNumWorkers(4);\n\t\tconf.setDebug(true);\n\t\tconf.setNumAckers(0);\n\t\t\n\t\t\n\t\t//将这个topology提交给storm集群运行,名字叫demotopo\n\t\tStormSubmitter.submitTopology(\"demotopo\", conf, demotop);\n\t\t\n\t}\n   }\n   \n  \n##### 5.运行程序\n\n  \n   ","slug":"Hadoop-十-Storm","published":1,"updated":"2018-03-29T08:14:19.119Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60l30016xo7kbpqwyxa3","content":"<h4 id=\"一、Storm\"><a href=\"#一、Storm\" class=\"headerlink\" title=\"一、Storm\"></a>一、Storm</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进行实时的数据处理如实时分析，在线机器学习，持续计算，主要运用于流式计算，例如网上的实时数据要写入数据库，中间需要个处理过程，通常结合消息队列（消息源）和数据库（存储地）一起使用。</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Storm集群中真正运行topology的主要有三个实体：工作进程、线程和任务。Storm集群中的每台机器上都可以运行多个工作进程，每个 工作进程又可创建多个线程，每个线程可以执行多个任务，任务是真正进行数据处理的实体，我们开发的spout、bolt就是作为一个或者多个任务的方式执 行的。</p>\n<p>因此，计算任务在多个线程、进程和服务器之间并行进行，支持灵活的水平扩展。</p>\n<h4 id=\"二、Storm基本组件\"><a href=\"#二、Storm基本组件\" class=\"headerlink\" title=\"二、Storm基本组件\"></a>二、Storm基本组件</h4><h5 id=\"1、Topologies-：-拓扑，也俗称一个任务（与Hadoop的MapReduce-job不同，不会终止）\"><a href=\"#1、Topologies-：-拓扑，也俗称一个任务（与Hadoop的MapReduce-job不同，不会终止）\" class=\"headerlink\" title=\"1、Topologies ： 拓扑，也俗称一个任务（与Hadoop的MapReduce job不同，不会终止）\"></a>1、Topologies ： 拓扑，也俗称一个任务（与Hadoop的MapReduce job不同，不会终止）</h5><p> 一个topology是spouts和bolts组成的图， 通过stream groupings将图中的spouts和bolts连接起来。</p>\n<h6 id=\"Topology运行机制\"><a href=\"#Topology运行机制\" class=\"headerlink\" title=\"Topology运行机制\"></a>Topology运行机制</h6><p><strong>(1)Storm提交后，会把代码首先存放到Nimbus节点的inbox目录下，之后，会把当前Storm运行的配置生成一个stormconf.ser文件放到Nimbus节点的stormdist目录中，在此目录中同时还有序列化之后的Topology代码文件；</strong></p>\n<p><strong>(2)在设定Topology所关联的Spouts和Bolts时，可以同时设置当前Spout和Bolt的executor数目和task数目，默认情况下，一个Topology的task的总和是和executor的总和一致的。之后，系统根据worker的数目，尽量平均的分配这些task的执行。worker在哪个supervisor节点上运行是由storm本身决定的；</strong></p>\n<p><strong>(3)任务分配好之后，Nimbes节点会将任务的信息提交到zookeeper集群，同时在zookeeper集群中会有workerbeats节点，这里存储了当前Topology的所有worker进程的心跳信息；</strong></p>\n<p><strong>(4)Supervisor节点会不断的轮询zookeeper集群，在zookeeper的assignments节点中保存了所有Topology的任务分配信息、代码存储目录、任务之间的关联关系等，Supervisor通过轮询此节点的内容，来领取自己的任务，启动worker进程运行；</strong></p>\n<p><strong>(5)一个Topology运行之后，就会不断的通过Spouts来发送Stream流，通过Bolts来不断的处理接收到的Stream流，Stream流是无界的。</strong></p>\n<p><strong>最后一步会不间断的执行，除非手动结束Topology。</strong></p>\n<h5 id=\"2、Spouts-：-拓扑的消息源\"><a href=\"#2、Spouts-：-拓扑的消息源\" class=\"headerlink\" title=\"2、Spouts ： 拓扑的消息源\"></a>2、Spouts ： 拓扑的消息源</h5><p>消息源spout是Storm里面一个topology里面的消息生产者；</p>\n<p>Spouts可以是可靠的也可以是不可靠的：如果这个tuple没有被storm成功处理，可靠的消息源spouts可以重新发射一个tuple， 但是不可靠的消息源spouts一旦发出一个tuple就不能重发了；</p>\n<p>消息源可以发射多条消息流stream：使用OutputFieldsDeclarer.declareStream来定义多个stream， 然后使用SpoutOutputCollector来发射指定的stream。</p>\n<h5 id=\"3、Bolts-：-拓扑的处理逻辑单元\"><a href=\"#3、Bolts-：-拓扑的处理逻辑单元\" class=\"headerlink\" title=\"3、Bolts ： 拓扑的处理逻辑单元\"></a>3、Bolts ： 拓扑的处理逻辑单元</h5><p>所有的消息处理逻辑被封装在bolts里面；</p>\n<p>Bolts可以做很多事情：过滤，聚合，查询数据库等等。</p>\n<p>Bolts可以简单的做消息流的传递，也可以通过多级Bolts的组合来完成复杂的消息流处理；比如求TopN、聚合操作等（如果要把这个过程做得更具有扩展性那么可能需要更多的步骤）。</p>\n<p>Bolts可以发射多条消息流：<br>     使用OutputFieldsDeclarer.declareStream定义stream；<br>     使用OutputCollector.emit来选择要发射的stream；</p>\n<p>Bolts的主要方法是execute,：<br>     它以一个tuple作为输入，使用OutputCollector来发射tuple；<br>     通过调用OutputCollector的ack方法，以通知这个tuple的发射者spout；</p>\n<p>Bolts一般的流程：<br>     处理一个输入tuple,  发射0个或者多个tuple, 然后调用ack通知storm自己已经处理过这个tuple了；<br>    storm提供了一个IBasicBolt会自动调用ack。</p>\n<h5 id=\"4、tuple：消息元组-用来固定消息的传递格式，几个字符串啊等等\"><a href=\"#4、tuple：消息元组-用来固定消息的传递格式，几个字符串啊等等\" class=\"headerlink\" title=\"4、tuple：消息元组(用来固定消息的传递格式，几个字符串啊等等)\"></a>4、tuple：消息元组(用来固定消息的传递格式，几个字符串啊等等)</h5><h5 id=\"5、Streams-：-流\"><a href=\"#5、Streams-：-流\" class=\"headerlink\" title=\"5、Streams ： 流\"></a>5、Streams ： 流</h5><p>消息流stream是storm里的关键抽象；<br>一个消息流是一个没有边界的tuple序列， 而这些tuple序列会以一种分布式的方式并行地创建和处理；<br>通过对stream中tuple序列中每个字段命名来定义stream；<br>在默认的情况下，tuple的字段类型可以是：integer，long，short， byte，string，double，float，boolean和byte array；<br>可以自定义类型（只要实现相应的序列化器）。</p>\n<h5 id=\"6、Stream-groupings-：流的分组策略\"><a href=\"#6、Stream-groupings-：流的分组策略\" class=\"headerlink\" title=\"6、Stream groupings ：流的分组策略\"></a>6、Stream groupings ：流的分组策略</h5><p>定义一个topology的关键一步是定义每个bolt接收什么样的流作为输入；</p>\n<p>stream grouping就是用来定义一个stream应该如何分配数据给bolts；</p>\n<p>Storm里面有7种类型的stream grouping：<br>Shuffle Grouping——随机分组， 随机派发stream里面的tuple，保证每个bolt接收到的tuple数目大致相同；<br>Fields Grouping——按字段分组， 比如按userid来分组， 具有同样userid的tuple会被分到相同的Bolts里的一个task， 而不同的userid则会被分配到不同的bolts里的task；</p>\n<p>All Grouping——广播发送，对于每一个tuple，所有的bolts都会收到；</p>\n<p>Global Grouping——全局分组， 这个tuple被分配到storm中的一个bolt的其中一个task。再具体一点就是分配给id值最低的那个task；</p>\n<p>Non Grouping——不分组，这个分组的意思是说stream不关心到底谁会收到它的tuple。目前这种分组和Shuffle grouping是一样的效果， 有一点不同的是storm会把这个bolt放到这个bolt的订阅者同一个线程里面去执行；</p>\n<p>Direct Grouping——直接分组， 这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。<br>消息处理者可以通过TopologyContext来获取处理它的消息的task的id （OutputCollector.emit方法也会返回task的id）；</p>\n<p>Local or shuffle grouping——如果目标bolt有一个或者多个task在同一个工作进程中，tuple将会被随机发生给这些tasks。否则，和普通的Shuffle Grouping行为一致。</p>\n<h5 id=\"7、Tasks-：-任务处理单元\"><a href=\"#7、Tasks-：-任务处理单元\" class=\"headerlink\" title=\"7、Tasks ： 任务处理单元\"></a>7、Tasks ： 任务处理单元</h5><p>每一个spout和bolt会被当作很多task在整个集群里执行</p>\n<p>每一个executor对应到一个线程，在这个线程上运行多个task</p>\n<p>stream grouping则是定义怎么从一堆task发射tuple到另外一堆task</p>\n<p>可以调用TopologyBuilder类的setSpout和setBolt来设置并行度（也就是有多少个task）</p>\n<h5 id=\"8、Executor-工作线程\"><a href=\"#8、Executor-工作线程\" class=\"headerlink\" title=\"8、Executor :工作线程\"></a>8、Executor :工作线程</h5><h5 id=\"9、Workers-：工作进程\"><a href=\"#9、Workers-：工作进程\" class=\"headerlink\" title=\"9、Workers ：工作进程\"></a>9、Workers ：工作进程</h5><p> 一个topology可能会在一个或者多个worker（工作进程）里面执行；</p>\n<p>每个worker是一个物理JVM并且执行整个topology的一部分；</p>\n<p>比如，对于并行度是300的topology来说，如果我们使用50个工作进程来执行，那么每个工作进程会处理其中的6个tasks；<br>Storm会尽量均匀的工作分配给所有的worker；</p>\n<h5 id=\"10、Configuration-：-topology的配置\"><a href=\"#10、Configuration-：-topology的配置\" class=\"headerlink\" title=\"10、Configuration ： topology的配置\"></a>10、Configuration ： topology的配置</h5><h4 id=\"三、Storm集群管理架构\"><a href=\"#三、Storm集群管理架构\" class=\"headerlink\" title=\"三、Storm集群管理架构\"></a>三、Storm集群管理架构</h4><p>主要分为两部分：</p>\n<ol>\n<li>Nimbus  负责协调管理</li>\n<li>Supervisor 负责具体运算</li>\n</ol>\n<p>具体配置：</p>\n<h6 id=\"1、安装一个zookeeper集群\"><a href=\"#1、安装一个zookeeper集群\" class=\"headerlink\" title=\"1、安装一个zookeeper集群\"></a>1、安装一个zookeeper集群</h6><h6 id=\"2、上传storm的安装包，解压\"><a href=\"#2、上传storm的安装包，解压\" class=\"headerlink\" title=\"2、上传storm的安装包，解压\"></a>2、上传storm的安装包，解压</h6><h6 id=\"3、修改配置文件storm-yaml\"><a href=\"#3、修改配置文件storm-yaml\" class=\"headerlink\" title=\"3、修改配置文件storm.yaml\"></a>3、修改配置文件storm.yaml</h6><pre><code>#所使用的zookeeper集群主机\nstorm.zookeeper.servers:\n     - &quot;hadoop01&quot;\n     - &quot;hadoop02&quot;\n     - &quot;hadoop03&quot;\n\n#nimbus所在的主机名\nnimbus.host: &quot;hadoop01&quot;\n</code></pre><h6 id=\"4-占用的端口\"><a href=\"#4-占用的端口\" class=\"headerlink\" title=\"4.占用的端口\"></a>4.占用的端口</h6><pre><code>supervisor.slots.ports\n-6701\n-6702\n-6703\n-6704\n-6705\n</code></pre><h6 id=\"5-启动storm\"><a href=\"#5-启动storm\" class=\"headerlink\" title=\"5.启动storm\"></a>5.启动storm</h6><pre><code>在nimbus主机上\nnohup ./storm nimbus\nnohup ./storm ui （开启后便可以访问可视化页面管理，端口号8080）\n\n在supervisor主机上\nnohup ./storm supervisor \n</code></pre><p><strong>注意事项：<br>启动Storm后台进程时，需要对conf/storm.yaml配置文件中设置的storm.local.dir目录具有写权限。<br>storm后台进程被启动后，将在Storm安装部署目录下的logs/子目录下生成各个进程的日志文件。<br>经测试，Storm UI必须和Storm Nimbus部署在同一台机器上，否则UI无法正常工作，因为UI进程会检查本机是否存在Nimbus链接。<br>为了方便使用，可以将bin/storm加入到系统环境变量中。<br>至此，Storm集群已经部署、配置完毕，可以向集群提交拓扑运行了。</strong></p>\n<pre><code>提交Topologies\n命令格式：storm jar 【jar路径】 【拓扑包名.拓扑类名】【stormIP地址】【storm端口】【拓扑名称】【参    数】\neg：storm jar /home/storm/storm-starter.jar storm.starter.WordCountTopology wordcountTop;\n#提交storm-starter.jar到远程集群，并启动wordcountTop拓扑。\n\n停止Topologies\n查看当前运行的topo： storm list \n命令格式：storm kill 【拓扑名称】\n样例：storm kill wordcountTop#     \n杀掉wordcountTop拓扑。\n</code></pre><h4 id=\"四、Storm的JAVA开发\"><a href=\"#四、Storm的JAVA开发\" class=\"headerlink\" title=\"四、Storm的JAVA开发\"></a>四、Storm的JAVA开发</h4><h5 id=\"1-编写Spout\"><a href=\"#1-编写Spout\" class=\"headerlink\" title=\"1.编写Spout\"></a>1.编写Spout</h5><pre><code>package cn.itcast.stormdemo;\n\nimport java.util.Map;\nimport java.util.Random;\n\nimport backtype.storm.spout.SpoutOutputCollector;\nimport backtype.storm.task.TopologyContext;\nimport backtype.storm.topology.OutputFieldsDeclarer;\nimport backtype.storm.topology.base.BaseRichSpout;\nimport backtype.storm.tuple.Fields;\nimport backtype.storm.tuple.Values;\nimport backtype.storm.utils.Utils;\n\npublic class RandomWordSpout extends BaseRichSpout{\n\nprivate SpoutOutputCollector collector;\n\n//模拟一些数据\nString[] words = {&quot;iphone&quot;,&quot;xiaomi&quot;,&quot;mate&quot;,&quot;sony&quot;,&quot;sumsung&quot;,&quot;moto&quot;,&quot;meizu&quot;};\n\n//不断地往下一个组件发送tuple消息\n//这里面是该spout组件的核心逻辑\n@Override\npublic void nextTuple() {\n\n    //可以从kafka消息队列中拿到数据,简便起见，我们从words数组中随机挑选一个商品名发送出去\n    Random random = new Random();\n    int index = random.nextInt(words.length);()保证不超过数组的大小\n\n    //通过随机数拿到一个商品名\n    String godName = words[index];\n\n\n    //将商品名封装成tuple，发送消息给下一个组件（这里可以传进去一个数组，但之后的声明便也需要一一对应）\n    collector.emit(new Values(godName));\n\n    //每发送一个消息，休眠500ms\n    Utils.sleep(500);\n\n\n}\n\n//初始化方法，在spout组件实例化时调用一次\n@Override\npublic void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {\n\n    this.collector = collector;\n\n\n}\n\n//声明本spout组件发送出去的tuple中的数据的字段名\n@Override\npublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\n    declarer.declare(new Fields(&quot;orignname&quot;));（\n\n}\n\n}\n</code></pre><h5 id=\"2-编写转换大小写的Bolt\"><a href=\"#2-编写转换大小写的Bolt\" class=\"headerlink\" title=\"2.编写转换大小写的Bolt\"></a>2.编写转换大小写的Bolt</h5><pre><code>public class UpperBolt extends BaseBasicBolt{\n\n\n//业务处理逻辑\n@Override\npublic void execute(Tuple tuple, BasicOutputCollector collector) {\n\n    //先获取到上一个组件传递过来的数据,数据在tuple里面\n    String godName = tuple.getString(0);\n\n    //将商品名转换成大写\n    String godName_upper = godName.toUpperCase();\n\n    //将转换完成的商品名发送出去\n    collector.emit(new Values(godName_upper));\n\n}\n\n\n\n//声明该bolt组件要发出去的tuple的字段\n@Override\npublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\n    declarer.declare(new Fields(&quot;uppername&quot;));\n}\n\n}\n</code></pre><h5 id=\"3-编写添加后缀的Bolt\"><a href=\"#3-编写添加后缀的Bolt\" class=\"headerlink\" title=\"3.编写添加后缀的Bolt\"></a>3.编写添加后缀的Bolt</h5><pre><code>public class SuffixBolt extends BaseBasicBolt{\n\nFileWriter fileWriter = null;\n\n\n//在bolt组件运行过程中只会被调用一次，因为这是最后一个bolt,分布式有很多个进程以此来区分\n@Override\npublic void prepare(Map stormConf, TopologyContext context) {\n\n    try {\n        fileWriter = new FileWriter(&quot;/home/hadoop/stormoutput/&quot;+UUID.randomUUID());\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n\n}\n\n\n\n//该bolt组件的核心处理逻辑\n//每收到一个tuple消息，就会被调用一次\n@Override\npublic void execute(Tuple tuple, BasicOutputCollector collector) {\n\n    //先拿到上一个组件发送过来的商品名称\n    String upper_name = tuple.getString(0);\n    String suffix_name = upper_name + &quot;_itisok&quot;;\n\n\n    //为上一个组件发送过来的商品名称添加后缀\n\n    try {\n        fileWriter.write(suffix_name);\n        fileWriter.write(&quot;\\n&quot;);\n        fileWriter.flush();\n\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n\n\n\n}\n\n\n\n\n//本bolt已经不需要发送tuple消息到下一个组件，所以不需要再声明tuple的字段\n@Override\npublic void declareOutputFields(OutputFieldsDeclarer arg0) {\n\n\n}\n\n}\n</code></pre><h5 id=\"4-主程序编写\"><a href=\"#4-主程序编写\" class=\"headerlink\" title=\"4.主程序编写\"></a>4.主程序编写</h5><ul>\n<li>组织各个处理组件形成一个完整的处理流程，就是所谓的topology(类似于mapreduce程序中的job)</li>\n<li>并且将该topology提交给storm集群去运行，topology提交到集群后就将永无休止地运行，除非人为或者异常退出</li>\n<li>@author duanhaitao@itcast.cn</li>\n</ul>\n<pre><code>public class TopoMain {\n\n\npublic static void main(String[] args) throws Exception {\n\n    TopologyBuilder builder = new TopologyBuilder();\n\n    //将我们的spout组件设置到topology中去，并且取名为randomSpout  \n    //parallelism_hint ：4  表示用4个excutor来执行这个组件\n    //setNumTasks(8) 设置的是该组件执行时的并发task数量，也就意味着1个excutor会运行2个task\n    builder.setSpout(&quot;randomspout&quot;, new RandomWordSpout(), 4).setNumTasks(8);\n\n    //将大写转换bolt组件设置到topology，并且指定它接收randomspout组件的消息\n    //.shuffleGrouping(&quot;randomspout&quot;)包含两层含义：\n    //1、upperbolt组件接收的tuple消息一定来自于randomspout组件\n    //2、randomspout组件和upperbolt组件的大量并发task实例之间收发消息时采用的分组策略是随机分组shuffleGrouping\n    builder.setBolt(&quot;upperbolt&quot;, new UpperBolt(), 4).shuffleGrouping(&quot;randomspout&quot;);\n\n    //将添加后缀的bolt组件设置到topology，并且指定它接收upperbolt组件的消息\n    builder.setBolt(&quot;suffixbolt&quot;, new SuffixBolt(), 4).shuffleGrouping(&quot;upperbolt&quot;);\n\n    //用builder来创建一个topology\n    StormTopology demotop = builder.createTopology();\n\n\n    //配置一些topology在集群中运行时的参数\n    Config conf = new Config();\n    //这里设置的是整个demotop所占用的槽位数，也就是worker的数量\n    conf.setNumWorkers(4);\n    conf.setDebug(true);\n    conf.setNumAckers(0);\n\n\n    //将这个topology提交给storm集群运行,名字叫demotopo\n    StormSubmitter.submitTopology(&quot;demotopo&quot;, conf, demotop);\n\n}\n</code></pre><p>   }</p>\n<h5 id=\"5-运行程序\"><a href=\"#5-运行程序\" class=\"headerlink\" title=\"5.运行程序\"></a>5.运行程序</h5>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"一、Storm\"><a href=\"#一、Storm\" class=\"headerlink\" title=\"一、Storm\"></a>一、Storm</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进行实时的数据处理如实时分析，在线机器学习，持续计算，主要运用于流式计算，例如网上的实时数据要写入数据库，中间需要个处理过程，通常结合消息队列（消息源）和数据库（存储地）一起使用。</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Storm集群中真正运行topology的主要有三个实体：工作进程、线程和任务。Storm集群中的每台机器上都可以运行多个工作进程，每个 工作进程又可创建多个线程，每个线程可以执行多个任务，任务是真正进行数据处理的实体，我们开发的spout、bolt就是作为一个或者多个任务的方式执 行的。</p>\n<p>因此，计算任务在多个线程、进程和服务器之间并行进行，支持灵活的水平扩展。</p>\n<h4 id=\"二、Storm基本组件\"><a href=\"#二、Storm基本组件\" class=\"headerlink\" title=\"二、Storm基本组件\"></a>二、Storm基本组件</h4><h5 id=\"1、Topologies-：-拓扑，也俗称一个任务（与Hadoop的MapReduce-job不同，不会终止）\"><a href=\"#1、Topologies-：-拓扑，也俗称一个任务（与Hadoop的MapReduce-job不同，不会终止）\" class=\"headerlink\" title=\"1、Topologies ： 拓扑，也俗称一个任务（与Hadoop的MapReduce job不同，不会终止）\"></a>1、Topologies ： 拓扑，也俗称一个任务（与Hadoop的MapReduce job不同，不会终止）</h5><p> 一个topology是spouts和bolts组成的图， 通过stream groupings将图中的spouts和bolts连接起来。</p>\n<h6 id=\"Topology运行机制\"><a href=\"#Topology运行机制\" class=\"headerlink\" title=\"Topology运行机制\"></a>Topology运行机制</h6><p><strong>(1)Storm提交后，会把代码首先存放到Nimbus节点的inbox目录下，之后，会把当前Storm运行的配置生成一个stormconf.ser文件放到Nimbus节点的stormdist目录中，在此目录中同时还有序列化之后的Topology代码文件；</strong></p>\n<p><strong>(2)在设定Topology所关联的Spouts和Bolts时，可以同时设置当前Spout和Bolt的executor数目和task数目，默认情况下，一个Topology的task的总和是和executor的总和一致的。之后，系统根据worker的数目，尽量平均的分配这些task的执行。worker在哪个supervisor节点上运行是由storm本身决定的；</strong></p>\n<p><strong>(3)任务分配好之后，Nimbes节点会将任务的信息提交到zookeeper集群，同时在zookeeper集群中会有workerbeats节点，这里存储了当前Topology的所有worker进程的心跳信息；</strong></p>\n<p><strong>(4)Supervisor节点会不断的轮询zookeeper集群，在zookeeper的assignments节点中保存了所有Topology的任务分配信息、代码存储目录、任务之间的关联关系等，Supervisor通过轮询此节点的内容，来领取自己的任务，启动worker进程运行；</strong></p>\n<p><strong>(5)一个Topology运行之后，就会不断的通过Spouts来发送Stream流，通过Bolts来不断的处理接收到的Stream流，Stream流是无界的。</strong></p>\n<p><strong>最后一步会不间断的执行，除非手动结束Topology。</strong></p>\n<h5 id=\"2、Spouts-：-拓扑的消息源\"><a href=\"#2、Spouts-：-拓扑的消息源\" class=\"headerlink\" title=\"2、Spouts ： 拓扑的消息源\"></a>2、Spouts ： 拓扑的消息源</h5><p>消息源spout是Storm里面一个topology里面的消息生产者；</p>\n<p>Spouts可以是可靠的也可以是不可靠的：如果这个tuple没有被storm成功处理，可靠的消息源spouts可以重新发射一个tuple， 但是不可靠的消息源spouts一旦发出一个tuple就不能重发了；</p>\n<p>消息源可以发射多条消息流stream：使用OutputFieldsDeclarer.declareStream来定义多个stream， 然后使用SpoutOutputCollector来发射指定的stream。</p>\n<h5 id=\"3、Bolts-：-拓扑的处理逻辑单元\"><a href=\"#3、Bolts-：-拓扑的处理逻辑单元\" class=\"headerlink\" title=\"3、Bolts ： 拓扑的处理逻辑单元\"></a>3、Bolts ： 拓扑的处理逻辑单元</h5><p>所有的消息处理逻辑被封装在bolts里面；</p>\n<p>Bolts可以做很多事情：过滤，聚合，查询数据库等等。</p>\n<p>Bolts可以简单的做消息流的传递，也可以通过多级Bolts的组合来完成复杂的消息流处理；比如求TopN、聚合操作等（如果要把这个过程做得更具有扩展性那么可能需要更多的步骤）。</p>\n<p>Bolts可以发射多条消息流：<br>     使用OutputFieldsDeclarer.declareStream定义stream；<br>     使用OutputCollector.emit来选择要发射的stream；</p>\n<p>Bolts的主要方法是execute,：<br>     它以一个tuple作为输入，使用OutputCollector来发射tuple；<br>     通过调用OutputCollector的ack方法，以通知这个tuple的发射者spout；</p>\n<p>Bolts一般的流程：<br>     处理一个输入tuple,  发射0个或者多个tuple, 然后调用ack通知storm自己已经处理过这个tuple了；<br>    storm提供了一个IBasicBolt会自动调用ack。</p>\n<h5 id=\"4、tuple：消息元组-用来固定消息的传递格式，几个字符串啊等等\"><a href=\"#4、tuple：消息元组-用来固定消息的传递格式，几个字符串啊等等\" class=\"headerlink\" title=\"4、tuple：消息元组(用来固定消息的传递格式，几个字符串啊等等)\"></a>4、tuple：消息元组(用来固定消息的传递格式，几个字符串啊等等)</h5><h5 id=\"5、Streams-：-流\"><a href=\"#5、Streams-：-流\" class=\"headerlink\" title=\"5、Streams ： 流\"></a>5、Streams ： 流</h5><p>消息流stream是storm里的关键抽象；<br>一个消息流是一个没有边界的tuple序列， 而这些tuple序列会以一种分布式的方式并行地创建和处理；<br>通过对stream中tuple序列中每个字段命名来定义stream；<br>在默认的情况下，tuple的字段类型可以是：integer，long，short， byte，string，double，float，boolean和byte array；<br>可以自定义类型（只要实现相应的序列化器）。</p>\n<h5 id=\"6、Stream-groupings-：流的分组策略\"><a href=\"#6、Stream-groupings-：流的分组策略\" class=\"headerlink\" title=\"6、Stream groupings ：流的分组策略\"></a>6、Stream groupings ：流的分组策略</h5><p>定义一个topology的关键一步是定义每个bolt接收什么样的流作为输入；</p>\n<p>stream grouping就是用来定义一个stream应该如何分配数据给bolts；</p>\n<p>Storm里面有7种类型的stream grouping：<br>Shuffle Grouping——随机分组， 随机派发stream里面的tuple，保证每个bolt接收到的tuple数目大致相同；<br>Fields Grouping——按字段分组， 比如按userid来分组， 具有同样userid的tuple会被分到相同的Bolts里的一个task， 而不同的userid则会被分配到不同的bolts里的task；</p>\n<p>All Grouping——广播发送，对于每一个tuple，所有的bolts都会收到；</p>\n<p>Global Grouping——全局分组， 这个tuple被分配到storm中的一个bolt的其中一个task。再具体一点就是分配给id值最低的那个task；</p>\n<p>Non Grouping——不分组，这个分组的意思是说stream不关心到底谁会收到它的tuple。目前这种分组和Shuffle grouping是一样的效果， 有一点不同的是storm会把这个bolt放到这个bolt的订阅者同一个线程里面去执行；</p>\n<p>Direct Grouping——直接分组， 这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。<br>消息处理者可以通过TopologyContext来获取处理它的消息的task的id （OutputCollector.emit方法也会返回task的id）；</p>\n<p>Local or shuffle grouping——如果目标bolt有一个或者多个task在同一个工作进程中，tuple将会被随机发生给这些tasks。否则，和普通的Shuffle Grouping行为一致。</p>\n<h5 id=\"7、Tasks-：-任务处理单元\"><a href=\"#7、Tasks-：-任务处理单元\" class=\"headerlink\" title=\"7、Tasks ： 任务处理单元\"></a>7、Tasks ： 任务处理单元</h5><p>每一个spout和bolt会被当作很多task在整个集群里执行</p>\n<p>每一个executor对应到一个线程，在这个线程上运行多个task</p>\n<p>stream grouping则是定义怎么从一堆task发射tuple到另外一堆task</p>\n<p>可以调用TopologyBuilder类的setSpout和setBolt来设置并行度（也就是有多少个task）</p>\n<h5 id=\"8、Executor-工作线程\"><a href=\"#8、Executor-工作线程\" class=\"headerlink\" title=\"8、Executor :工作线程\"></a>8、Executor :工作线程</h5><h5 id=\"9、Workers-：工作进程\"><a href=\"#9、Workers-：工作进程\" class=\"headerlink\" title=\"9、Workers ：工作进程\"></a>9、Workers ：工作进程</h5><p> 一个topology可能会在一个或者多个worker（工作进程）里面执行；</p>\n<p>每个worker是一个物理JVM并且执行整个topology的一部分；</p>\n<p>比如，对于并行度是300的topology来说，如果我们使用50个工作进程来执行，那么每个工作进程会处理其中的6个tasks；<br>Storm会尽量均匀的工作分配给所有的worker；</p>\n<h5 id=\"10、Configuration-：-topology的配置\"><a href=\"#10、Configuration-：-topology的配置\" class=\"headerlink\" title=\"10、Configuration ： topology的配置\"></a>10、Configuration ： topology的配置</h5><h4 id=\"三、Storm集群管理架构\"><a href=\"#三、Storm集群管理架构\" class=\"headerlink\" title=\"三、Storm集群管理架构\"></a>三、Storm集群管理架构</h4><p>主要分为两部分：</p>\n<ol>\n<li>Nimbus  负责协调管理</li>\n<li>Supervisor 负责具体运算</li>\n</ol>\n<p>具体配置：</p>\n<h6 id=\"1、安装一个zookeeper集群\"><a href=\"#1、安装一个zookeeper集群\" class=\"headerlink\" title=\"1、安装一个zookeeper集群\"></a>1、安装一个zookeeper集群</h6><h6 id=\"2、上传storm的安装包，解压\"><a href=\"#2、上传storm的安装包，解压\" class=\"headerlink\" title=\"2、上传storm的安装包，解压\"></a>2、上传storm的安装包，解压</h6><h6 id=\"3、修改配置文件storm-yaml\"><a href=\"#3、修改配置文件storm-yaml\" class=\"headerlink\" title=\"3、修改配置文件storm.yaml\"></a>3、修改配置文件storm.yaml</h6><pre><code>#所使用的zookeeper集群主机\nstorm.zookeeper.servers:\n     - &quot;hadoop01&quot;\n     - &quot;hadoop02&quot;\n     - &quot;hadoop03&quot;\n\n#nimbus所在的主机名\nnimbus.host: &quot;hadoop01&quot;\n</code></pre><h6 id=\"4-占用的端口\"><a href=\"#4-占用的端口\" class=\"headerlink\" title=\"4.占用的端口\"></a>4.占用的端口</h6><pre><code>supervisor.slots.ports\n-6701\n-6702\n-6703\n-6704\n-6705\n</code></pre><h6 id=\"5-启动storm\"><a href=\"#5-启动storm\" class=\"headerlink\" title=\"5.启动storm\"></a>5.启动storm</h6><pre><code>在nimbus主机上\nnohup ./storm nimbus\nnohup ./storm ui （开启后便可以访问可视化页面管理，端口号8080）\n\n在supervisor主机上\nnohup ./storm supervisor \n</code></pre><p><strong>注意事项：<br>启动Storm后台进程时，需要对conf/storm.yaml配置文件中设置的storm.local.dir目录具有写权限。<br>storm后台进程被启动后，将在Storm安装部署目录下的logs/子目录下生成各个进程的日志文件。<br>经测试，Storm UI必须和Storm Nimbus部署在同一台机器上，否则UI无法正常工作，因为UI进程会检查本机是否存在Nimbus链接。<br>为了方便使用，可以将bin/storm加入到系统环境变量中。<br>至此，Storm集群已经部署、配置完毕，可以向集群提交拓扑运行了。</strong></p>\n<pre><code>提交Topologies\n命令格式：storm jar 【jar路径】 【拓扑包名.拓扑类名】【stormIP地址】【storm端口】【拓扑名称】【参    数】\neg：storm jar /home/storm/storm-starter.jar storm.starter.WordCountTopology wordcountTop;\n#提交storm-starter.jar到远程集群，并启动wordcountTop拓扑。\n\n停止Topologies\n查看当前运行的topo： storm list \n命令格式：storm kill 【拓扑名称】\n样例：storm kill wordcountTop#     \n杀掉wordcountTop拓扑。\n</code></pre><h4 id=\"四、Storm的JAVA开发\"><a href=\"#四、Storm的JAVA开发\" class=\"headerlink\" title=\"四、Storm的JAVA开发\"></a>四、Storm的JAVA开发</h4><h5 id=\"1-编写Spout\"><a href=\"#1-编写Spout\" class=\"headerlink\" title=\"1.编写Spout\"></a>1.编写Spout</h5><pre><code>package cn.itcast.stormdemo;\n\nimport java.util.Map;\nimport java.util.Random;\n\nimport backtype.storm.spout.SpoutOutputCollector;\nimport backtype.storm.task.TopologyContext;\nimport backtype.storm.topology.OutputFieldsDeclarer;\nimport backtype.storm.topology.base.BaseRichSpout;\nimport backtype.storm.tuple.Fields;\nimport backtype.storm.tuple.Values;\nimport backtype.storm.utils.Utils;\n\npublic class RandomWordSpout extends BaseRichSpout{\n\nprivate SpoutOutputCollector collector;\n\n//模拟一些数据\nString[] words = {&quot;iphone&quot;,&quot;xiaomi&quot;,&quot;mate&quot;,&quot;sony&quot;,&quot;sumsung&quot;,&quot;moto&quot;,&quot;meizu&quot;};\n\n//不断地往下一个组件发送tuple消息\n//这里面是该spout组件的核心逻辑\n@Override\npublic void nextTuple() {\n\n    //可以从kafka消息队列中拿到数据,简便起见，我们从words数组中随机挑选一个商品名发送出去\n    Random random = new Random();\n    int index = random.nextInt(words.length);()保证不超过数组的大小\n\n    //通过随机数拿到一个商品名\n    String godName = words[index];\n\n\n    //将商品名封装成tuple，发送消息给下一个组件（这里可以传进去一个数组，但之后的声明便也需要一一对应）\n    collector.emit(new Values(godName));\n\n    //每发送一个消息，休眠500ms\n    Utils.sleep(500);\n\n\n}\n\n//初始化方法，在spout组件实例化时调用一次\n@Override\npublic void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {\n\n    this.collector = collector;\n\n\n}\n\n//声明本spout组件发送出去的tuple中的数据的字段名\n@Override\npublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\n    declarer.declare(new Fields(&quot;orignname&quot;));（\n\n}\n\n}\n</code></pre><h5 id=\"2-编写转换大小写的Bolt\"><a href=\"#2-编写转换大小写的Bolt\" class=\"headerlink\" title=\"2.编写转换大小写的Bolt\"></a>2.编写转换大小写的Bolt</h5><pre><code>public class UpperBolt extends BaseBasicBolt{\n\n\n//业务处理逻辑\n@Override\npublic void execute(Tuple tuple, BasicOutputCollector collector) {\n\n    //先获取到上一个组件传递过来的数据,数据在tuple里面\n    String godName = tuple.getString(0);\n\n    //将商品名转换成大写\n    String godName_upper = godName.toUpperCase();\n\n    //将转换完成的商品名发送出去\n    collector.emit(new Values(godName_upper));\n\n}\n\n\n\n//声明该bolt组件要发出去的tuple的字段\n@Override\npublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\n    declarer.declare(new Fields(&quot;uppername&quot;));\n}\n\n}\n</code></pre><h5 id=\"3-编写添加后缀的Bolt\"><a href=\"#3-编写添加后缀的Bolt\" class=\"headerlink\" title=\"3.编写添加后缀的Bolt\"></a>3.编写添加后缀的Bolt</h5><pre><code>public class SuffixBolt extends BaseBasicBolt{\n\nFileWriter fileWriter = null;\n\n\n//在bolt组件运行过程中只会被调用一次，因为这是最后一个bolt,分布式有很多个进程以此来区分\n@Override\npublic void prepare(Map stormConf, TopologyContext context) {\n\n    try {\n        fileWriter = new FileWriter(&quot;/home/hadoop/stormoutput/&quot;+UUID.randomUUID());\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n\n}\n\n\n\n//该bolt组件的核心处理逻辑\n//每收到一个tuple消息，就会被调用一次\n@Override\npublic void execute(Tuple tuple, BasicOutputCollector collector) {\n\n    //先拿到上一个组件发送过来的商品名称\n    String upper_name = tuple.getString(0);\n    String suffix_name = upper_name + &quot;_itisok&quot;;\n\n\n    //为上一个组件发送过来的商品名称添加后缀\n\n    try {\n        fileWriter.write(suffix_name);\n        fileWriter.write(&quot;\\n&quot;);\n        fileWriter.flush();\n\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n\n\n\n}\n\n\n\n\n//本bolt已经不需要发送tuple消息到下一个组件，所以不需要再声明tuple的字段\n@Override\npublic void declareOutputFields(OutputFieldsDeclarer arg0) {\n\n\n}\n\n}\n</code></pre><h5 id=\"4-主程序编写\"><a href=\"#4-主程序编写\" class=\"headerlink\" title=\"4.主程序编写\"></a>4.主程序编写</h5><ul>\n<li>组织各个处理组件形成一个完整的处理流程，就是所谓的topology(类似于mapreduce程序中的job)</li>\n<li>并且将该topology提交给storm集群去运行，topology提交到集群后就将永无休止地运行，除非人为或者异常退出</li>\n<li>@author duanhaitao@itcast.cn</li>\n</ul>\n<pre><code>public class TopoMain {\n\n\npublic static void main(String[] args) throws Exception {\n\n    TopologyBuilder builder = new TopologyBuilder();\n\n    //将我们的spout组件设置到topology中去，并且取名为randomSpout  \n    //parallelism_hint ：4  表示用4个excutor来执行这个组件\n    //setNumTasks(8) 设置的是该组件执行时的并发task数量，也就意味着1个excutor会运行2个task\n    builder.setSpout(&quot;randomspout&quot;, new RandomWordSpout(), 4).setNumTasks(8);\n\n    //将大写转换bolt组件设置到topology，并且指定它接收randomspout组件的消息\n    //.shuffleGrouping(&quot;randomspout&quot;)包含两层含义：\n    //1、upperbolt组件接收的tuple消息一定来自于randomspout组件\n    //2、randomspout组件和upperbolt组件的大量并发task实例之间收发消息时采用的分组策略是随机分组shuffleGrouping\n    builder.setBolt(&quot;upperbolt&quot;, new UpperBolt(), 4).shuffleGrouping(&quot;randomspout&quot;);\n\n    //将添加后缀的bolt组件设置到topology，并且指定它接收upperbolt组件的消息\n    builder.setBolt(&quot;suffixbolt&quot;, new SuffixBolt(), 4).shuffleGrouping(&quot;upperbolt&quot;);\n\n    //用builder来创建一个topology\n    StormTopology demotop = builder.createTopology();\n\n\n    //配置一些topology在集群中运行时的参数\n    Config conf = new Config();\n    //这里设置的是整个demotop所占用的槽位数，也就是worker的数量\n    conf.setNumWorkers(4);\n    conf.setDebug(true);\n    conf.setNumAckers(0);\n\n\n    //将这个topology提交给storm集群运行,名字叫demotopo\n    StormSubmitter.submitTopology(&quot;demotopo&quot;, conf, demotop);\n\n}\n</code></pre><p>   }</p>\n<h5 id=\"5-运行程序\"><a href=\"#5-运行程序\" class=\"headerlink\" title=\"5.运行程序\"></a>5.运行程序</h5>"},{"title":"Markdown 入门操作","author":"小小冰弟","date":"2018-02-03T08:00:01.000Z","_content":"### 一、Markdown的简要语法规则\n#### 标题\n\n标题是每篇文章都需要也是最常用的格式，在 Markdown 中，如果一段文字被定义为标题，只要在这段文字前加 # 号即可，随着# 数量的添加，字体越来越小。\n\n   ### # 一级标题\n   #### ##二级标题\n   ##### ###三级标题\n***\n\n#### 列表\n列表分为有序列表与无序列表，有序列表只需要在列表文字前加上序号即可，而无序列表则是在文字前加 - 或者 *\n###### 有序列表\n1. 三余无梦生\n2. 苍越孤鸣\n3. 绮罗生\n\n###### 无序列表\n- 任飘渺\n* 风逍遥\n- 欲星移\n***\n\n##### 引用\n当你想在文中引入某位大咖说的话，只需要在文本前面加上 > 即可，效果如下：\n> 小小冰弟曾说：“美梦是因为做不到，噩梦如是。”\n***\n\n##### 图片与链接\n链接: 中括号+小括号+链接 \n\n [Google](www.google.com \"谷歌\")\n\n图片: 感叹号+中括号+链接（最后还可以用引号包住并加上 选择性的 'title' 文字）\n\n![](/uploads/sufei.jpg \"苏菲女神\")\n***\n\n\n\n##### 粗体与斜体\n\n**两个 * 号包含的文本就是粗体**\n\n_只用一个 * 号包含的就是斜体_\n\n(其实 * 也可以换成 _ )\n\n##### 代码区块\n\n和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 **code** 和 **pre** 两个标签来把代码区块包起来。\n\n要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以\n\n普通文本\n\n\t\tpublic class HelloWorld {\n           public static void main(String[] args){\n              System.out.println(\"Hello World!\");\n           }\n         }\n         \n***\n\n##### 居中，左右对齐\n居中：center标签\n<center>诶嘿</center>\n左对齐：P标签，加上 align = \"left\"\n<p align=\"left\">诶嘿</p>\n右对齐：P标签，加上 align = \"right\"\n<p align=\"right\">诶嘿</p>\n\n##### [Markdown语法与快捷键](http://blog.csdn.net/wolinghuanyun/article/details/52454751)","source":"_posts/Markdown-入门操作.md","raw":"title: Markdown 入门操作\nauthor: 小小冰弟\ntags: study\ncategories: Markdown\ndate: 2018-02-03 16:00:01\n---\n### 一、Markdown的简要语法规则\n#### 标题\n\n标题是每篇文章都需要也是最常用的格式，在 Markdown 中，如果一段文字被定义为标题，只要在这段文字前加 # 号即可，随着# 数量的添加，字体越来越小。\n\n   ### # 一级标题\n   #### ##二级标题\n   ##### ###三级标题\n***\n\n#### 列表\n列表分为有序列表与无序列表，有序列表只需要在列表文字前加上序号即可，而无序列表则是在文字前加 - 或者 *\n###### 有序列表\n1. 三余无梦生\n2. 苍越孤鸣\n3. 绮罗生\n\n###### 无序列表\n- 任飘渺\n* 风逍遥\n- 欲星移\n***\n\n##### 引用\n当你想在文中引入某位大咖说的话，只需要在文本前面加上 > 即可，效果如下：\n> 小小冰弟曾说：“美梦是因为做不到，噩梦如是。”\n***\n\n##### 图片与链接\n链接: 中括号+小括号+链接 \n\n [Google](www.google.com \"谷歌\")\n\n图片: 感叹号+中括号+链接（最后还可以用引号包住并加上 选择性的 'title' 文字）\n\n![](/uploads/sufei.jpg \"苏菲女神\")\n***\n\n\n\n##### 粗体与斜体\n\n**两个 * 号包含的文本就是粗体**\n\n_只用一个 * 号包含的就是斜体_\n\n(其实 * 也可以换成 _ )\n\n##### 代码区块\n\n和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 **code** 和 **pre** 两个标签来把代码区块包起来。\n\n要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以\n\n普通文本\n\n\t\tpublic class HelloWorld {\n           public static void main(String[] args){\n              System.out.println(\"Hello World!\");\n           }\n         }\n         \n***\n\n##### 居中，左右对齐\n居中：center标签\n<center>诶嘿</center>\n左对齐：P标签，加上 align = \"left\"\n<p align=\"left\">诶嘿</p>\n右对齐：P标签，加上 align = \"right\"\n<p align=\"right\">诶嘿</p>\n\n##### [Markdown语法与快捷键](http://blog.csdn.net/wolinghuanyun/article/details/52454751)","slug":"Markdown-入门操作","published":1,"updated":"2018-03-30T07:56:15.570Z","_id":"cjfcc60l4001axo7kvvhxd7wl","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"一、Markdown的简要语法规则\"><a href=\"#一、Markdown的简要语法规则\" class=\"headerlink\" title=\"一、Markdown的简要语法规则\"></a>一、Markdown的简要语法规则</h3><h4 id=\"标题\"><a href=\"#标题\" class=\"headerlink\" title=\"标题\"></a>标题</h4><p>标题是每篇文章都需要也是最常用的格式，在 Markdown 中，如果一段文字被定义为标题，只要在这段文字前加 # 号即可，随着# 数量的添加，字体越来越小。</p>\n<h3 id=\"一级标题\"><a href=\"#一级标题\" class=\"headerlink\" title=\"# 一级标题\"></a># 一级标题</h3><h4 id=\"二级标题\"><a href=\"#二级标题\" class=\"headerlink\" title=\"##二级标题\"></a>##二级标题</h4><h5 id=\"三级标题\"><a href=\"#三级标题\" class=\"headerlink\" title=\"###三级标题\"></a>###三级标题</h5><hr>\n<h4 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h4><p>列表分为有序列表与无序列表，有序列表只需要在列表文字前加上序号即可，而无序列表则是在文字前加 - 或者 *</p>\n<h6 id=\"有序列表\"><a href=\"#有序列表\" class=\"headerlink\" title=\"有序列表\"></a>有序列表</h6><ol>\n<li>三余无梦生</li>\n<li>苍越孤鸣</li>\n<li>绮罗生</li>\n</ol>\n<h6 id=\"无序列表\"><a href=\"#无序列表\" class=\"headerlink\" title=\"无序列表\"></a>无序列表</h6><ul>\n<li>任飘渺</li>\n</ul>\n<ul>\n<li>风逍遥</li>\n</ul>\n<ul>\n<li>欲星移</li>\n</ul>\n<hr>\n<h5 id=\"引用\"><a href=\"#引用\" class=\"headerlink\" title=\"引用\"></a>引用</h5><p>当你想在文中引入某位大咖说的话，只需要在文本前面加上 &gt; 即可，效果如下：</p>\n<blockquote>\n<p>小小冰弟曾说：“美梦是因为做不到，噩梦如是。”</p>\n<hr>\n</blockquote>\n<h5 id=\"图片与链接\"><a href=\"#图片与链接\" class=\"headerlink\" title=\"图片与链接\"></a>图片与链接</h5><p>链接: 中括号+小括号+链接 </p>\n<p> <a href=\"www.google.com\" title=\"谷歌\">Google</a></p>\n<p>图片: 感叹号+中括号+链接（最后还可以用引号包住并加上 选择性的 ‘title’ 文字）</p>\n<p><img src=\"/uploads/sufei.jpg\" alt=\"\" title=\"苏菲女神\"></p>\n<hr>\n<h5 id=\"粗体与斜体\"><a href=\"#粗体与斜体\" class=\"headerlink\" title=\"粗体与斜体\"></a>粗体与斜体</h5><p><strong>两个 * 号包含的文本就是粗体</strong></p>\n<p><em>只用一个 * 号包含的就是斜体</em></p>\n<p>(其实 * 也可以换成 _ )</p>\n<h5 id=\"代码区块\"><a href=\"#代码区块\" class=\"headerlink\" title=\"代码区块\"></a>代码区块</h5><p>和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 <strong>code</strong> 和 <strong>pre</strong> 两个标签来把代码区块包起来。</p>\n<p>要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以</p>\n<p>普通文本</p>\n<pre><code>public class HelloWorld {\n   public static void main(String[] args){\n      System.out.println(&quot;Hello World!&quot;);\n   }\n }\n</code></pre><hr>\n<h5 id=\"居中，左右对齐\"><a href=\"#居中，左右对齐\" class=\"headerlink\" title=\"居中，左右对齐\"></a>居中，左右对齐</h5><p>居中：center标签</p>\n<p><center>诶嘿</center><br>左对齐：P标签，加上 align = “left”</p>\n<p align=\"left\">诶嘿</p><br>右对齐：P标签，加上 align = “right”<br><p align=\"right\">诶嘿</p>\n\n<h5 id=\"Markdown语法与快捷键\"><a href=\"#Markdown语法与快捷键\" class=\"headerlink\" title=\"Markdown语法与快捷键\"></a><a href=\"http://blog.csdn.net/wolinghuanyun/article/details/52454751\" target=\"_blank\" rel=\"noopener\">Markdown语法与快捷键</a></h5>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"一、Markdown的简要语法规则\"><a href=\"#一、Markdown的简要语法规则\" class=\"headerlink\" title=\"一、Markdown的简要语法规则\"></a>一、Markdown的简要语法规则</h3><h4 id=\"标题\"><a href=\"#标题\" class=\"headerlink\" title=\"标题\"></a>标题</h4><p>标题是每篇文章都需要也是最常用的格式，在 Markdown 中，如果一段文字被定义为标题，只要在这段文字前加 # 号即可，随着# 数量的添加，字体越来越小。</p>\n<h3 id=\"一级标题\"><a href=\"#一级标题\" class=\"headerlink\" title=\"# 一级标题\"></a># 一级标题</h3><h4 id=\"二级标题\"><a href=\"#二级标题\" class=\"headerlink\" title=\"##二级标题\"></a>##二级标题</h4><h5 id=\"三级标题\"><a href=\"#三级标题\" class=\"headerlink\" title=\"###三级标题\"></a>###三级标题</h5><hr>\n<h4 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h4><p>列表分为有序列表与无序列表，有序列表只需要在列表文字前加上序号即可，而无序列表则是在文字前加 - 或者 *</p>\n<h6 id=\"有序列表\"><a href=\"#有序列表\" class=\"headerlink\" title=\"有序列表\"></a>有序列表</h6><ol>\n<li>三余无梦生</li>\n<li>苍越孤鸣</li>\n<li>绮罗生</li>\n</ol>\n<h6 id=\"无序列表\"><a href=\"#无序列表\" class=\"headerlink\" title=\"无序列表\"></a>无序列表</h6><ul>\n<li>任飘渺</li>\n</ul>\n<ul>\n<li>风逍遥</li>\n</ul>\n<ul>\n<li>欲星移</li>\n</ul>\n<hr>\n<h5 id=\"引用\"><a href=\"#引用\" class=\"headerlink\" title=\"引用\"></a>引用</h5><p>当你想在文中引入某位大咖说的话，只需要在文本前面加上 &gt; 即可，效果如下：</p>\n<blockquote>\n<p>小小冰弟曾说：“美梦是因为做不到，噩梦如是。”</p>\n<hr>\n</blockquote>\n<h5 id=\"图片与链接\"><a href=\"#图片与链接\" class=\"headerlink\" title=\"图片与链接\"></a>图片与链接</h5><p>链接: 中括号+小括号+链接 </p>\n<p> <a href=\"www.google.com\" title=\"谷歌\">Google</a></p>\n<p>图片: 感叹号+中括号+链接（最后还可以用引号包住并加上 选择性的 ‘title’ 文字）</p>\n<p><img src=\"/uploads/sufei.jpg\" alt=\"\" title=\"苏菲女神\"></p>\n<hr>\n<h5 id=\"粗体与斜体\"><a href=\"#粗体与斜体\" class=\"headerlink\" title=\"粗体与斜体\"></a>粗体与斜体</h5><p><strong>两个 * 号包含的文本就是粗体</strong></p>\n<p><em>只用一个 * 号包含的就是斜体</em></p>\n<p>(其实 * 也可以换成 _ )</p>\n<h5 id=\"代码区块\"><a href=\"#代码区块\" class=\"headerlink\" title=\"代码区块\"></a>代码区块</h5><p>和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 <strong>code</strong> 和 <strong>pre</strong> 两个标签来把代码区块包起来。</p>\n<p>要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以</p>\n<p>普通文本</p>\n<pre><code>public class HelloWorld {\n   public static void main(String[] args){\n      System.out.println(&quot;Hello World!&quot;);\n   }\n }\n</code></pre><hr>\n<h5 id=\"居中，左右对齐\"><a href=\"#居中，左右对齐\" class=\"headerlink\" title=\"居中，左右对齐\"></a>居中，左右对齐</h5><p>居中：center标签</p>\n<p><center>诶嘿</center><br>左对齐：P标签，加上 align = “left”</p>\n<p align=\"left\">诶嘿</p><br>右对齐：P标签，加上 align = “right”<br><p align=\"right\">诶嘿</p>\n\n<h5 id=\"Markdown语法与快捷键\"><a href=\"#Markdown语法与快捷键\" class=\"headerlink\" title=\"Markdown语法与快捷键\"></a><a href=\"http://blog.csdn.net/wolinghuanyun/article/details/52454751\" target=\"_blank\" rel=\"noopener\">Markdown语法与快捷键</a></h5>"},{"title":"SS搭建","author":"小小冰弟","date":"2018-03-01T03:29:34.000Z","_content":"# ss搭建\n\n> 本脚本适用环境\n\n    系统支持：CentOS 6+，Debian 7+，Ubuntu 12+\n    内存要求：≥128M\n    \n> 关于本脚本\n\n    1. 一键安装 Shadowsocks-Python， ShadowsocksR， Shadowsocks-Go， Shadowsocks-libev 版（四选一）服务端；\n    2. 各版本的启动脚本及配置文件名不再重合；\n    3. 每次运行可安装一种版本；\n    4. 支持以多次运行来安装多个版本，且各个版本可以共存（注意端口号需设成不同）；\n    5. 若已安装多个版本，则卸载时也需多次运行（每次卸载一种）；\n    6. Shadowsocks-Python 和 ShadowsocksR 安装后不可同时启动（因为本质上都属 Python 版）。\n    \n> 默认配置\n\n    服务器端口：自己设定（如不设定，默认为 8989）\n    密码：自己设定（如不设定，默认为 teddysun.com）\n    加密方式：自己设定（如不设定，Python 和 libev 版默认为 aes-256-gcm，R 和 Go 版默认为 aes-256-cfb）\n    协议（protocol）：自己设定（如不设定，默认为 origin）（仅限 ShadowsocksR 版）\n    混淆（obfs）：自己设定（如不设定，默认为 plain）（仅限 ShadowsocksR 版）\n备注：脚本默认创建单用户配置文件，如需配置多用户，请手动修改相应的配置文件后重启即可。\n\n> 客户端下载\n\n    常规版 Windows 客户端\n <https://github.com/shadowsocks/shadowsocks-windows/releases>\n    \n    ShadowsocksR 版 Windows 客户端\n<https://github.com/shadowsocksr/shadowsocksr-csharp/releases>\n\n----------------\n    \n## 使用方法\n\n> 使用root用户登录，运行以下命令：\n\n```\nwget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh\nchmod +x shadowsocks-all.sh\n./shadowsocks-all.sh 2>&1 | tee shadowsocks-all.log\n\n```\n\n> 安装完成后，脚本提示如下\n\n    Congratulations, your_shadowsocks_version install completed!\n    Your Server IP        :your_server_ip\n    Your Server Port      :your_server_port\n    Your Password         :your_password\n    Your Encryption Method:your_encryption_method\n    Welcome to visit:https://teddysun.com/486.html\n    Enjoy it!\n    \n> 卸载方法\n\n    若已安装多个版本，则卸载时也需多次运行（每次卸载一种）\n    使用root用户登录，运行以下命令：\n    ./shadowsocks-all.sh uninstall\n    \n> 启动脚本 \n\n    启动脚本后面的参数含义，从左至右依次为：启动，停止，重启，查看状态。\n    \n    Shadowsocks-Python 版：\n    /etc/init.d/shadowsocks-python start | stop | restart | status\n    \n    ShadowsocksR 版：\n    /etc/init.d/shadowsocks-r start | stop | restart | status\n    \n    Shadowsocks-Go 版：\n    /etc/init.d/shadowsocks-go start | stop | restart | status\n    \n    Shadowsocks-libev 版：\n    /etc/init.d/shadowsocks-libev start | stop | restart | status\n    \n> 各版本默认配置文件\n\n    Shadowsocks-Python 版：\n    /etc/shadowsocks-python/config.json\n    \n    ShadowsocksR 版：\n    /etc/shadowsocks-r/config.json\n    \n    Shadowsocks-Go 版：\n    /etc/shadowsocks-go/config.json\n    \n    Shadowsocks-libev 版：\n    /etc/shadowsocks-libev/config.json","source":"_posts/SS搭建.md","raw":"title: SS搭建\nauthor: 小小冰弟\ndate: 2018-03-01 11:29:34\ntags: free\ncategories: skill\n---\n# ss搭建\n\n> 本脚本适用环境\n\n    系统支持：CentOS 6+，Debian 7+，Ubuntu 12+\n    内存要求：≥128M\n    \n> 关于本脚本\n\n    1. 一键安装 Shadowsocks-Python， ShadowsocksR， Shadowsocks-Go， Shadowsocks-libev 版（四选一）服务端；\n    2. 各版本的启动脚本及配置文件名不再重合；\n    3. 每次运行可安装一种版本；\n    4. 支持以多次运行来安装多个版本，且各个版本可以共存（注意端口号需设成不同）；\n    5. 若已安装多个版本，则卸载时也需多次运行（每次卸载一种）；\n    6. Shadowsocks-Python 和 ShadowsocksR 安装后不可同时启动（因为本质上都属 Python 版）。\n    \n> 默认配置\n\n    服务器端口：自己设定（如不设定，默认为 8989）\n    密码：自己设定（如不设定，默认为 teddysun.com）\n    加密方式：自己设定（如不设定，Python 和 libev 版默认为 aes-256-gcm，R 和 Go 版默认为 aes-256-cfb）\n    协议（protocol）：自己设定（如不设定，默认为 origin）（仅限 ShadowsocksR 版）\n    混淆（obfs）：自己设定（如不设定，默认为 plain）（仅限 ShadowsocksR 版）\n备注：脚本默认创建单用户配置文件，如需配置多用户，请手动修改相应的配置文件后重启即可。\n\n> 客户端下载\n\n    常规版 Windows 客户端\n <https://github.com/shadowsocks/shadowsocks-windows/releases>\n    \n    ShadowsocksR 版 Windows 客户端\n<https://github.com/shadowsocksr/shadowsocksr-csharp/releases>\n\n----------------\n    \n## 使用方法\n\n> 使用root用户登录，运行以下命令：\n\n```\nwget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh\nchmod +x shadowsocks-all.sh\n./shadowsocks-all.sh 2>&1 | tee shadowsocks-all.log\n\n```\n\n> 安装完成后，脚本提示如下\n\n    Congratulations, your_shadowsocks_version install completed!\n    Your Server IP        :your_server_ip\n    Your Server Port      :your_server_port\n    Your Password         :your_password\n    Your Encryption Method:your_encryption_method\n    Welcome to visit:https://teddysun.com/486.html\n    Enjoy it!\n    \n> 卸载方法\n\n    若已安装多个版本，则卸载时也需多次运行（每次卸载一种）\n    使用root用户登录，运行以下命令：\n    ./shadowsocks-all.sh uninstall\n    \n> 启动脚本 \n\n    启动脚本后面的参数含义，从左至右依次为：启动，停止，重启，查看状态。\n    \n    Shadowsocks-Python 版：\n    /etc/init.d/shadowsocks-python start | stop | restart | status\n    \n    ShadowsocksR 版：\n    /etc/init.d/shadowsocks-r start | stop | restart | status\n    \n    Shadowsocks-Go 版：\n    /etc/init.d/shadowsocks-go start | stop | restart | status\n    \n    Shadowsocks-libev 版：\n    /etc/init.d/shadowsocks-libev start | stop | restart | status\n    \n> 各版本默认配置文件\n\n    Shadowsocks-Python 版：\n    /etc/shadowsocks-python/config.json\n    \n    ShadowsocksR 版：\n    /etc/shadowsocks-r/config.json\n    \n    Shadowsocks-Go 版：\n    /etc/shadowsocks-go/config.json\n    \n    Shadowsocks-libev 版：\n    /etc/shadowsocks-libev/config.json","slug":"SS搭建","published":1,"updated":"2018-03-26T09:46:34.653Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60l6001dxo7k8ktwe038","content":"<h1 id=\"ss搭建\"><a href=\"#ss搭建\" class=\"headerlink\" title=\"ss搭建\"></a>ss搭建</h1><blockquote>\n<p>本脚本适用环境</p>\n</blockquote>\n<pre><code>系统支持：CentOS 6+，Debian 7+，Ubuntu 12+\n内存要求：≥128M\n</code></pre><blockquote>\n<p>关于本脚本</p>\n</blockquote>\n<pre><code>1. 一键安装 Shadowsocks-Python， ShadowsocksR， Shadowsocks-Go， Shadowsocks-libev 版（四选一）服务端；\n2. 各版本的启动脚本及配置文件名不再重合；\n3. 每次运行可安装一种版本；\n4. 支持以多次运行来安装多个版本，且各个版本可以共存（注意端口号需设成不同）；\n5. 若已安装多个版本，则卸载时也需多次运行（每次卸载一种）；\n6. Shadowsocks-Python 和 ShadowsocksR 安装后不可同时启动（因为本质上都属 Python 版）。\n</code></pre><blockquote>\n<p>默认配置</p>\n</blockquote>\n<pre><code>服务器端口：自己设定（如不设定，默认为 8989）\n密码：自己设定（如不设定，默认为 teddysun.com）\n加密方式：自己设定（如不设定，Python 和 libev 版默认为 aes-256-gcm，R 和 Go 版默认为 aes-256-cfb）\n协议（protocol）：自己设定（如不设定，默认为 origin）（仅限 ShadowsocksR 版）\n混淆（obfs）：自己设定（如不设定，默认为 plain）（仅限 ShadowsocksR 版）\n</code></pre><p>备注：脚本默认创建单用户配置文件，如需配置多用户，请手动修改相应的配置文件后重启即可。</p>\n<blockquote>\n<p>客户端下载</p>\n</blockquote>\n<pre><code>常规版 Windows 客户端\n</code></pre><p> <a href=\"https://github.com/shadowsocks/shadowsocks-windows/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/shadowsocks/shadowsocks-windows/releases</a></p>\n<pre><code>ShadowsocksR 版 Windows 客户端\n</code></pre><p><a href=\"https://github.com/shadowsocksr/shadowsocksr-csharp/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/shadowsocksr/shadowsocksr-csharp/releases</a></p>\n<hr>\n<h2 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h2><blockquote>\n<p>使用root用户登录，运行以下命令：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh</span><br><span class=\"line\">chmod +x shadowsocks-all.sh</span><br><span class=\"line\">./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>安装完成后，脚本提示如下</p>\n</blockquote>\n<pre><code>Congratulations, your_shadowsocks_version install completed!\nYour Server IP        :your_server_ip\nYour Server Port      :your_server_port\nYour Password         :your_password\nYour Encryption Method:your_encryption_method\nWelcome to visit:https://teddysun.com/486.html\nEnjoy it!\n</code></pre><blockquote>\n<p>卸载方法</p>\n</blockquote>\n<pre><code>若已安装多个版本，则卸载时也需多次运行（每次卸载一种）\n使用root用户登录，运行以下命令：\n./shadowsocks-all.sh uninstall\n</code></pre><blockquote>\n<p>启动脚本 </p>\n</blockquote>\n<pre><code>启动脚本后面的参数含义，从左至右依次为：启动，停止，重启，查看状态。\n\nShadowsocks-Python 版：\n/etc/init.d/shadowsocks-python start | stop | restart | status\n\nShadowsocksR 版：\n/etc/init.d/shadowsocks-r start | stop | restart | status\n\nShadowsocks-Go 版：\n/etc/init.d/shadowsocks-go start | stop | restart | status\n\nShadowsocks-libev 版：\n/etc/init.d/shadowsocks-libev start | stop | restart | status\n</code></pre><blockquote>\n<p>各版本默认配置文件</p>\n</blockquote>\n<pre><code>Shadowsocks-Python 版：\n/etc/shadowsocks-python/config.json\n\nShadowsocksR 版：\n/etc/shadowsocks-r/config.json\n\nShadowsocks-Go 版：\n/etc/shadowsocks-go/config.json\n\nShadowsocks-libev 版：\n/etc/shadowsocks-libev/config.json\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ss搭建\"><a href=\"#ss搭建\" class=\"headerlink\" title=\"ss搭建\"></a>ss搭建</h1><blockquote>\n<p>本脚本适用环境</p>\n</blockquote>\n<pre><code>系统支持：CentOS 6+，Debian 7+，Ubuntu 12+\n内存要求：≥128M\n</code></pre><blockquote>\n<p>关于本脚本</p>\n</blockquote>\n<pre><code>1. 一键安装 Shadowsocks-Python， ShadowsocksR， Shadowsocks-Go， Shadowsocks-libev 版（四选一）服务端；\n2. 各版本的启动脚本及配置文件名不再重合；\n3. 每次运行可安装一种版本；\n4. 支持以多次运行来安装多个版本，且各个版本可以共存（注意端口号需设成不同）；\n5. 若已安装多个版本，则卸载时也需多次运行（每次卸载一种）；\n6. Shadowsocks-Python 和 ShadowsocksR 安装后不可同时启动（因为本质上都属 Python 版）。\n</code></pre><blockquote>\n<p>默认配置</p>\n</blockquote>\n<pre><code>服务器端口：自己设定（如不设定，默认为 8989）\n密码：自己设定（如不设定，默认为 teddysun.com）\n加密方式：自己设定（如不设定，Python 和 libev 版默认为 aes-256-gcm，R 和 Go 版默认为 aes-256-cfb）\n协议（protocol）：自己设定（如不设定，默认为 origin）（仅限 ShadowsocksR 版）\n混淆（obfs）：自己设定（如不设定，默认为 plain）（仅限 ShadowsocksR 版）\n</code></pre><p>备注：脚本默认创建单用户配置文件，如需配置多用户，请手动修改相应的配置文件后重启即可。</p>\n<blockquote>\n<p>客户端下载</p>\n</blockquote>\n<pre><code>常规版 Windows 客户端\n</code></pre><p> <a href=\"https://github.com/shadowsocks/shadowsocks-windows/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/shadowsocks/shadowsocks-windows/releases</a></p>\n<pre><code>ShadowsocksR 版 Windows 客户端\n</code></pre><p><a href=\"https://github.com/shadowsocksr/shadowsocksr-csharp/releases\" target=\"_blank\" rel=\"noopener\">https://github.com/shadowsocksr/shadowsocksr-csharp/releases</a></p>\n<hr>\n<h2 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h2><blockquote>\n<p>使用root用户登录，运行以下命令：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh</span><br><span class=\"line\">chmod +x shadowsocks-all.sh</span><br><span class=\"line\">./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>安装完成后，脚本提示如下</p>\n</blockquote>\n<pre><code>Congratulations, your_shadowsocks_version install completed!\nYour Server IP        :your_server_ip\nYour Server Port      :your_server_port\nYour Password         :your_password\nYour Encryption Method:your_encryption_method\nWelcome to visit:https://teddysun.com/486.html\nEnjoy it!\n</code></pre><blockquote>\n<p>卸载方法</p>\n</blockquote>\n<pre><code>若已安装多个版本，则卸载时也需多次运行（每次卸载一种）\n使用root用户登录，运行以下命令：\n./shadowsocks-all.sh uninstall\n</code></pre><blockquote>\n<p>启动脚本 </p>\n</blockquote>\n<pre><code>启动脚本后面的参数含义，从左至右依次为：启动，停止，重启，查看状态。\n\nShadowsocks-Python 版：\n/etc/init.d/shadowsocks-python start | stop | restart | status\n\nShadowsocksR 版：\n/etc/init.d/shadowsocks-r start | stop | restart | status\n\nShadowsocks-Go 版：\n/etc/init.d/shadowsocks-go start | stop | restart | status\n\nShadowsocks-libev 版：\n/etc/init.d/shadowsocks-libev start | stop | restart | status\n</code></pre><blockquote>\n<p>各版本默认配置文件</p>\n</blockquote>\n<pre><code>Shadowsocks-Python 版：\n/etc/shadowsocks-python/config.json\n\nShadowsocksR 版：\n/etc/shadowsocks-r/config.json\n\nShadowsocks-Go 版：\n/etc/shadowsocks-go/config.json\n\nShadowsocks-libev 版：\n/etc/shadowsocks-libev/config.json\n</code></pre>"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ntags: live\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2018-03-26T09:46:34.653Z","updated":"2018-03-26T09:46:34.653Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60l7001hxo7kl5cvm7yz","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n"},{"title":"Hadoop(十一)（kafka）","author":"小小冰弟","date":"2018-03-29T09:25:29.000Z","_content":"#### 一What is the Kafka?\n###### 1/kafka是一个分布式的消息缓存系统\n###### 2/kafka集群中的服务器都叫做broker\n###### 3/kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和broker服务器之间采用tcp协议连接\n###### 4/kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载\n###### 5/每一个分区都可以有多个副本，以防止数据的丢失\n###### 6/某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新\n###### 7/消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order_info,A和B所消费的消息不会重复比如 order_info 中有100个消息，每个消息有一个id,编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号\n###### 8/消费者在具体消费某个topic中的消息时，可以指定起始偏移量\n\n\n\n\n#### 二、Kafka集群安装\n###### 1、解压\n###### 2、修改server.properties\nbroker.id=1(每一台kafka都要给个编号)\nzookeeper.connect=hadoop01:2181,hadoop02:2181,hadoop03:2181\n\n###### 3、将zookeeper集群启动\n\n###### 4、在每一台节点上启动broker\nbin/kafka-server-start.sh config/server.properties\n\n###### 5、在kafka集群中创建一个topic\nbin/kafka-topics.sh --create --zookeeper hadoop01:2181 --replication-factor 3 --partitions 1 --topic order\n\n###### 6、用一个producer向某一个topic中写入消息\nbin/kafka-console-producer.sh --broker-list hadoop01:9092 --topic order\n\n###### 7、用一个comsumer从某一个topic中读取信息\nbin/kafka-console-consumer.sh --zookeeper hadoop01:2181 --from-beginning --topic order\n\n###### 8、查看一个topic的分区及副本状态信息\nbin/kafka-topics.sh --describe --zookeeper hadoop01:2181 --topic order\n\n\n#### 三、Kafka整合storm的Java客户端编写\n\n##### 1.Topology\n    public class KafkaTopo {\n\n\tpublic static void main(String[] args) throws Exception {\n\t\t\n\t\tString topic = \"wordcount\"; （配置主题名称）\n\t\tString zkRoot = \"/kafka-storm\";（设置zookeeper节点）\n\t\tString spoutId = \"KafkaSpout\";\n\t\tBrokerHosts brokerHosts = new ZkHosts(\"hadoop01:2181,hadoop02:2181,hadoop03:2181\"); \n\t\tSpoutConfig spoutConfig = new SpoutConfig(brokerHosts, \"wordcount\", zkRoot, spoutId);\n\t\tspoutConfig.forceFromStart = true;\n\t\tspoutConfig.scheme = new SchemeAsMultiScheme(new MessageScheme());（自己定义的）\n\t\tTopologyBuilder builder = new TopologyBuilder();\n\t\t//设置一个spout用来从kaflka消息队列中读取数据并发送给下一级的bolt组件，此处用的spout组件并非自定义的，而是storm中已经开发好的KafkaSpout\n\t\tbuilder.setSpout(\"KafkaSpout\", new KafkaSpout(spoutConfig));\n\t\tbuilder.setBolt(\"word-spilter\", new WordSpliter()).shuffleGrouping(spoutId);\n\t\tbuilder.setBolt(\"writer\", new WriterBolt(), 4).fieldsGrouping(\"word-spilter\", new Fields(\"word\"));\n\t\tConfig conf = new Config();\n\t\tconf.setNumWorkers(4);\n\t\tconf.setNumAckers(0);\n\t\tconf.setDebug(false);\n\t\t\n\t\t//LocalCluster用来将topology提交到本地模拟器运行，方便开发调试\n\t\tLocalCluster cluster = new LocalCluster();\n\t\tcluster.submitTopology(\"WordCount\", conf, builder.createTopology());\n\t\t\n\t\t//提交topology到storm集群中运行\n    // StormSubmitter.submitTopology(\"sufei-topo\", conf, builder.createTopology());\n\t}\n\n    }\n    \n    \n##### 2.MessageScheme\n\n    public class MessageScheme implements Scheme {\n\t\n\tprivate static final long serialVersionUID = 8423372426211017613L;\n\n\t@Override\n\tpublic List<Object> deserialize(byte[] bytes) {\n\t\t\ttry {\n\t\t\t\tString msg = new String(bytes, \"UTF-8\");\n\t\t\t\treturn new Values(msg); \n\t\t\t} catch (UnsupportedEncodingException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\treturn null;\n\t}\n\n\t@Override\n\tpublic Fields getOutputFields() {\n\t\treturn new Fields(\"msg\");\n\t}\n\n    }\n    \n##### 3.Bolts\n\n    public class WordSpliter extends BaseBasicBolt {\n\n\tprivate static final long serialVersionUID = -5653803832498574866L;\n\n\t@Override\n\tpublic void execute(Tuple input, BasicOutputCollector collector) {\n\t\tString line = input.getString(0);\n\t\tString[] words = line.split(\" \");\n\t\tfor (String word : words) {\n\t\t\tword = word.trim();\n\t\t\tif (StringUtils.isNotBlank(word)) {\n\t\t\t\tword = word.toLowerCase();\n\t\t\t\tcollector.emit(new Values(word));\n\t\t\t}\n\t\t}\n\t}\n\n\t@Override\n\tpublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\t\tdeclarer.declare(new Fields(\"word\"));\n\n\t}\n\n    }\n    \n   \n 将数据写入文件\n \n \n    public class WriterBolt extends BaseBasicBolt {\n\n\tprivate static final long serialVersionUID = -6586283337287975719L;\n\t\n\tprivate FileWriter writer = null;\n\t\n\t@Override\n\tpublic void prepare(Map stormConf, TopologyContext context) {\n\t\ttry {\n\t\t\twriter = new FileWriter(\"c:\\\\storm-kafka\\\\\" + \"wordcount\"+UUID.randomUUID().toString());\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t\n\t@Override\n\tpublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\t}\n\t\n\t\n\t@Override\n\tpublic void execute(Tuple input, BasicOutputCollector collector) {\n\t\tString s = input.getString(0);\n\t\ttry {\n\t\t\twriter.write(s);\n\t\t\twriter.write(\"\\n\");\n\t\t\twriter.flush();\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n}\n \n    \n    \n    \n\n","source":"_posts/Hadoop-十一-（kafka）.md","raw":"title: Hadoop(十一)（kafka）\nauthor: 小小冰弟\ndate: 2018-03-29 17:25:29\ntags: study\ncategories: Hadoop\n---\n#### 一What is the Kafka?\n###### 1/kafka是一个分布式的消息缓存系统\n###### 2/kafka集群中的服务器都叫做broker\n###### 3/kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和broker服务器之间采用tcp协议连接\n###### 4/kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载\n###### 5/每一个分区都可以有多个副本，以防止数据的丢失\n###### 6/某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新\n###### 7/消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order_info,A和B所消费的消息不会重复比如 order_info 中有100个消息，每个消息有一个id,编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号\n###### 8/消费者在具体消费某个topic中的消息时，可以指定起始偏移量\n\n\n\n\n#### 二、Kafka集群安装\n###### 1、解压\n###### 2、修改server.properties\nbroker.id=1(每一台kafka都要给个编号)\nzookeeper.connect=hadoop01:2181,hadoop02:2181,hadoop03:2181\n\n###### 3、将zookeeper集群启动\n\n###### 4、在每一台节点上启动broker\nbin/kafka-server-start.sh config/server.properties\n\n###### 5、在kafka集群中创建一个topic\nbin/kafka-topics.sh --create --zookeeper hadoop01:2181 --replication-factor 3 --partitions 1 --topic order\n\n###### 6、用一个producer向某一个topic中写入消息\nbin/kafka-console-producer.sh --broker-list hadoop01:9092 --topic order\n\n###### 7、用一个comsumer从某一个topic中读取信息\nbin/kafka-console-consumer.sh --zookeeper hadoop01:2181 --from-beginning --topic order\n\n###### 8、查看一个topic的分区及副本状态信息\nbin/kafka-topics.sh --describe --zookeeper hadoop01:2181 --topic order\n\n\n#### 三、Kafka整合storm的Java客户端编写\n\n##### 1.Topology\n    public class KafkaTopo {\n\n\tpublic static void main(String[] args) throws Exception {\n\t\t\n\t\tString topic = \"wordcount\"; （配置主题名称）\n\t\tString zkRoot = \"/kafka-storm\";（设置zookeeper节点）\n\t\tString spoutId = \"KafkaSpout\";\n\t\tBrokerHosts brokerHosts = new ZkHosts(\"hadoop01:2181,hadoop02:2181,hadoop03:2181\"); \n\t\tSpoutConfig spoutConfig = new SpoutConfig(brokerHosts, \"wordcount\", zkRoot, spoutId);\n\t\tspoutConfig.forceFromStart = true;\n\t\tspoutConfig.scheme = new SchemeAsMultiScheme(new MessageScheme());（自己定义的）\n\t\tTopologyBuilder builder = new TopologyBuilder();\n\t\t//设置一个spout用来从kaflka消息队列中读取数据并发送给下一级的bolt组件，此处用的spout组件并非自定义的，而是storm中已经开发好的KafkaSpout\n\t\tbuilder.setSpout(\"KafkaSpout\", new KafkaSpout(spoutConfig));\n\t\tbuilder.setBolt(\"word-spilter\", new WordSpliter()).shuffleGrouping(spoutId);\n\t\tbuilder.setBolt(\"writer\", new WriterBolt(), 4).fieldsGrouping(\"word-spilter\", new Fields(\"word\"));\n\t\tConfig conf = new Config();\n\t\tconf.setNumWorkers(4);\n\t\tconf.setNumAckers(0);\n\t\tconf.setDebug(false);\n\t\t\n\t\t//LocalCluster用来将topology提交到本地模拟器运行，方便开发调试\n\t\tLocalCluster cluster = new LocalCluster();\n\t\tcluster.submitTopology(\"WordCount\", conf, builder.createTopology());\n\t\t\n\t\t//提交topology到storm集群中运行\n    // StormSubmitter.submitTopology(\"sufei-topo\", conf, builder.createTopology());\n\t}\n\n    }\n    \n    \n##### 2.MessageScheme\n\n    public class MessageScheme implements Scheme {\n\t\n\tprivate static final long serialVersionUID = 8423372426211017613L;\n\n\t@Override\n\tpublic List<Object> deserialize(byte[] bytes) {\n\t\t\ttry {\n\t\t\t\tString msg = new String(bytes, \"UTF-8\");\n\t\t\t\treturn new Values(msg); \n\t\t\t} catch (UnsupportedEncodingException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\treturn null;\n\t}\n\n\t@Override\n\tpublic Fields getOutputFields() {\n\t\treturn new Fields(\"msg\");\n\t}\n\n    }\n    \n##### 3.Bolts\n\n    public class WordSpliter extends BaseBasicBolt {\n\n\tprivate static final long serialVersionUID = -5653803832498574866L;\n\n\t@Override\n\tpublic void execute(Tuple input, BasicOutputCollector collector) {\n\t\tString line = input.getString(0);\n\t\tString[] words = line.split(\" \");\n\t\tfor (String word : words) {\n\t\t\tword = word.trim();\n\t\t\tif (StringUtils.isNotBlank(word)) {\n\t\t\t\tword = word.toLowerCase();\n\t\t\t\tcollector.emit(new Values(word));\n\t\t\t}\n\t\t}\n\t}\n\n\t@Override\n\tpublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\t\tdeclarer.declare(new Fields(\"word\"));\n\n\t}\n\n    }\n    \n   \n 将数据写入文件\n \n \n    public class WriterBolt extends BaseBasicBolt {\n\n\tprivate static final long serialVersionUID = -6586283337287975719L;\n\t\n\tprivate FileWriter writer = null;\n\t\n\t@Override\n\tpublic void prepare(Map stormConf, TopologyContext context) {\n\t\ttry {\n\t\t\twriter = new FileWriter(\"c:\\\\storm-kafka\\\\\" + \"wordcount\"+UUID.randomUUID().toString());\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t\n\t@Override\n\tpublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\t}\n\t\n\t\n\t@Override\n\tpublic void execute(Tuple input, BasicOutputCollector collector) {\n\t\tString s = input.getString(0);\n\t\ttry {\n\t\t\twriter.write(s);\n\t\t\twriter.write(\"\\n\");\n\t\t\twriter.flush();\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n}\n \n    \n    \n    \n\n","slug":"Hadoop-十一-（kafka）","published":1,"updated":"2018-03-29T09:46:13.193Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60l9001lxo7kdzufhrar","content":"<h4 id=\"一What-is-the-Kafka\"><a href=\"#一What-is-the-Kafka\" class=\"headerlink\" title=\"一What is the Kafka?\"></a>一What is the Kafka?</h4><h6 id=\"1-kafka是一个分布式的消息缓存系统\"><a href=\"#1-kafka是一个分布式的消息缓存系统\" class=\"headerlink\" title=\"1/kafka是一个分布式的消息缓存系统\"></a>1/kafka是一个分布式的消息缓存系统</h6><h6 id=\"2-kafka集群中的服务器都叫做broker\"><a href=\"#2-kafka集群中的服务器都叫做broker\" class=\"headerlink\" title=\"2/kafka集群中的服务器都叫做broker\"></a>2/kafka集群中的服务器都叫做broker</h6><h6 id=\"3-kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和broker服务器之间采用tcp协议连接\"><a href=\"#3-kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和broker服务器之间采用tcp协议连接\" class=\"headerlink\" title=\"3/kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和broker服务器之间采用tcp协议连接\"></a>3/kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和broker服务器之间采用tcp协议连接</h6><h6 id=\"4-kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载\"><a href=\"#4-kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载\" class=\"headerlink\" title=\"4/kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载\"></a>4/kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载</h6><h6 id=\"5-每一个分区都可以有多个副本，以防止数据的丢失\"><a href=\"#5-每一个分区都可以有多个副本，以防止数据的丢失\" class=\"headerlink\" title=\"5/每一个分区都可以有多个副本，以防止数据的丢失\"></a>5/每一个分区都可以有多个副本，以防止数据的丢失</h6><h6 id=\"6-某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新\"><a href=\"#6-某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新\" class=\"headerlink\" title=\"6/某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新\"></a>6/某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新</h6><h6 id=\"7-消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order-info-A和B所消费的消息不会重复比如-order-info-中有100个消息，每个消息有一个id-编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号\"><a href=\"#7-消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order-info-A和B所消费的消息不会重复比如-order-info-中有100个消息，每个消息有一个id-编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号\" class=\"headerlink\" title=\"7/消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order_info,A和B所消费的消息不会重复比如 order_info 中有100个消息，每个消息有一个id,编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号\"></a>7/消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order_info,A和B所消费的消息不会重复比如 order_info 中有100个消息，每个消息有一个id,编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号</h6><h6 id=\"8-消费者在具体消费某个topic中的消息时，可以指定起始偏移量\"><a href=\"#8-消费者在具体消费某个topic中的消息时，可以指定起始偏移量\" class=\"headerlink\" title=\"8/消费者在具体消费某个topic中的消息时，可以指定起始偏移量\"></a>8/消费者在具体消费某个topic中的消息时，可以指定起始偏移量</h6><h4 id=\"二、Kafka集群安装\"><a href=\"#二、Kafka集群安装\" class=\"headerlink\" title=\"二、Kafka集群安装\"></a>二、Kafka集群安装</h4><h6 id=\"1、解压\"><a href=\"#1、解压\" class=\"headerlink\" title=\"1、解压\"></a>1、解压</h6><h6 id=\"2、修改server-properties\"><a href=\"#2、修改server-properties\" class=\"headerlink\" title=\"2、修改server.properties\"></a>2、修改server.properties</h6><p>broker.id=1(每一台kafka都要给个编号)<br>zookeeper.connect=hadoop01:2181,hadoop02:2181,hadoop03:2181</p>\n<h6 id=\"3、将zookeeper集群启动\"><a href=\"#3、将zookeeper集群启动\" class=\"headerlink\" title=\"3、将zookeeper集群启动\"></a>3、将zookeeper集群启动</h6><h6 id=\"4、在每一台节点上启动broker\"><a href=\"#4、在每一台节点上启动broker\" class=\"headerlink\" title=\"4、在每一台节点上启动broker\"></a>4、在每一台节点上启动broker</h6><p>bin/kafka-server-start.sh config/server.properties</p>\n<h6 id=\"5、在kafka集群中创建一个topic\"><a href=\"#5、在kafka集群中创建一个topic\" class=\"headerlink\" title=\"5、在kafka集群中创建一个topic\"></a>5、在kafka集群中创建一个topic</h6><p>bin/kafka-topics.sh –create –zookeeper hadoop01:2181 –replication-factor 3 –partitions 1 –topic order</p>\n<h6 id=\"6、用一个producer向某一个topic中写入消息\"><a href=\"#6、用一个producer向某一个topic中写入消息\" class=\"headerlink\" title=\"6、用一个producer向某一个topic中写入消息\"></a>6、用一个producer向某一个topic中写入消息</h6><p>bin/kafka-console-producer.sh –broker-list hadoop01:9092 –topic order</p>\n<h6 id=\"7、用一个comsumer从某一个topic中读取信息\"><a href=\"#7、用一个comsumer从某一个topic中读取信息\" class=\"headerlink\" title=\"7、用一个comsumer从某一个topic中读取信息\"></a>7、用一个comsumer从某一个topic中读取信息</h6><p>bin/kafka-console-consumer.sh –zookeeper hadoop01:2181 –from-beginning –topic order</p>\n<h6 id=\"8、查看一个topic的分区及副本状态信息\"><a href=\"#8、查看一个topic的分区及副本状态信息\" class=\"headerlink\" title=\"8、查看一个topic的分区及副本状态信息\"></a>8、查看一个topic的分区及副本状态信息</h6><p>bin/kafka-topics.sh –describe –zookeeper hadoop01:2181 –topic order</p>\n<h4 id=\"三、Kafka整合storm的Java客户端编写\"><a href=\"#三、Kafka整合storm的Java客户端编写\" class=\"headerlink\" title=\"三、Kafka整合storm的Java客户端编写\"></a>三、Kafka整合storm的Java客户端编写</h4><h5 id=\"1-Topology\"><a href=\"#1-Topology\" class=\"headerlink\" title=\"1.Topology\"></a>1.Topology</h5><pre><code>public class KafkaTopo {\n\npublic static void main(String[] args) throws Exception {\n\n    String topic = &quot;wordcount&quot;; （配置主题名称）\n    String zkRoot = &quot;/kafka-storm&quot;;（设置zookeeper节点）\n    String spoutId = &quot;KafkaSpout&quot;;\n    BrokerHosts brokerHosts = new ZkHosts(&quot;hadoop01:2181,hadoop02:2181,hadoop03:2181&quot;); \n    SpoutConfig spoutConfig = new SpoutConfig(brokerHosts, &quot;wordcount&quot;, zkRoot, spoutId);\n    spoutConfig.forceFromStart = true;\n    spoutConfig.scheme = new SchemeAsMultiScheme(new MessageScheme());（自己定义的）\n    TopologyBuilder builder = new TopologyBuilder();\n    //设置一个spout用来从kaflka消息队列中读取数据并发送给下一级的bolt组件，此处用的spout组件并非自定义的，而是storm中已经开发好的KafkaSpout\n    builder.setSpout(&quot;KafkaSpout&quot;, new KafkaSpout(spoutConfig));\n    builder.setBolt(&quot;word-spilter&quot;, new WordSpliter()).shuffleGrouping(spoutId);\n    builder.setBolt(&quot;writer&quot;, new WriterBolt(), 4).fieldsGrouping(&quot;word-spilter&quot;, new Fields(&quot;word&quot;));\n    Config conf = new Config();\n    conf.setNumWorkers(4);\n    conf.setNumAckers(0);\n    conf.setDebug(false);\n\n    //LocalCluster用来将topology提交到本地模拟器运行，方便开发调试\n    LocalCluster cluster = new LocalCluster();\n    cluster.submitTopology(&quot;WordCount&quot;, conf, builder.createTopology());\n\n    //提交topology到storm集群中运行\n// StormSubmitter.submitTopology(&quot;sufei-topo&quot;, conf, builder.createTopology());\n}\n\n}\n</code></pre><h5 id=\"2-MessageScheme\"><a href=\"#2-MessageScheme\" class=\"headerlink\" title=\"2.MessageScheme\"></a>2.MessageScheme</h5><pre><code>public class MessageScheme implements Scheme {\n\nprivate static final long serialVersionUID = 8423372426211017613L;\n\n@Override\npublic List&lt;Object&gt; deserialize(byte[] bytes) {\n        try {\n            String msg = new String(bytes, &quot;UTF-8&quot;);\n            return new Values(msg); \n        } catch (UnsupportedEncodingException e) {\n            e.printStackTrace();\n        }\n        return null;\n}\n\n@Override\npublic Fields getOutputFields() {\n    return new Fields(&quot;msg&quot;);\n}\n\n}\n</code></pre><h5 id=\"3-Bolts\"><a href=\"#3-Bolts\" class=\"headerlink\" title=\"3.Bolts\"></a>3.Bolts</h5><pre><code>public class WordSpliter extends BaseBasicBolt {\n\nprivate static final long serialVersionUID = -5653803832498574866L;\n\n@Override\npublic void execute(Tuple input, BasicOutputCollector collector) {\n    String line = input.getString(0);\n    String[] words = line.split(&quot; &quot;);\n    for (String word : words) {\n        word = word.trim();\n        if (StringUtils.isNotBlank(word)) {\n            word = word.toLowerCase();\n            collector.emit(new Values(word));\n        }\n    }\n}\n\n@Override\npublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n    declarer.declare(new Fields(&quot;word&quot;));\n\n}\n\n}\n</code></pre><p> 将数据写入文件</p>\n<pre><code>public class WriterBolt extends BaseBasicBolt {\n\nprivate static final long serialVersionUID = -6586283337287975719L;\n\nprivate FileWriter writer = null;\n\n@Override\npublic void prepare(Map stormConf, TopologyContext context) {\n    try {\n        writer = new FileWriter(&quot;c:\\\\storm-kafka\\\\&quot; + &quot;wordcount&quot;+UUID.randomUUID().toString());\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n\n\n@Override\npublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n}\n\n\n@Override\npublic void execute(Tuple input, BasicOutputCollector collector) {\n    String s = input.getString(0);\n    try {\n        writer.write(s);\n        writer.write(&quot;\\n&quot;);\n        writer.flush();\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n</code></pre><p>}</p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"一What-is-the-Kafka\"><a href=\"#一What-is-the-Kafka\" class=\"headerlink\" title=\"一What is the Kafka?\"></a>一What is the Kafka?</h4><h6 id=\"1-kafka是一个分布式的消息缓存系统\"><a href=\"#1-kafka是一个分布式的消息缓存系统\" class=\"headerlink\" title=\"1/kafka是一个分布式的消息缓存系统\"></a>1/kafka是一个分布式的消息缓存系统</h6><h6 id=\"2-kafka集群中的服务器都叫做broker\"><a href=\"#2-kafka集群中的服务器都叫做broker\" class=\"headerlink\" title=\"2/kafka集群中的服务器都叫做broker\"></a>2/kafka集群中的服务器都叫做broker</h6><h6 id=\"3-kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和broker服务器之间采用tcp协议连接\"><a href=\"#3-kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和broker服务器之间采用tcp协议连接\" class=\"headerlink\" title=\"3/kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和broker服务器之间采用tcp协议连接\"></a>3/kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和broker服务器之间采用tcp协议连接</h6><h6 id=\"4-kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载\"><a href=\"#4-kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载\" class=\"headerlink\" title=\"4/kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载\"></a>4/kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载</h6><h6 id=\"5-每一个分区都可以有多个副本，以防止数据的丢失\"><a href=\"#5-每一个分区都可以有多个副本，以防止数据的丢失\" class=\"headerlink\" title=\"5/每一个分区都可以有多个副本，以防止数据的丢失\"></a>5/每一个分区都可以有多个副本，以防止数据的丢失</h6><h6 id=\"6-某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新\"><a href=\"#6-某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新\" class=\"headerlink\" title=\"6/某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新\"></a>6/某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新</h6><h6 id=\"7-消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order-info-A和B所消费的消息不会重复比如-order-info-中有100个消息，每个消息有一个id-编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号\"><a href=\"#7-消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order-info-A和B所消费的消息不会重复比如-order-info-中有100个消息，每个消息有一个id-编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号\" class=\"headerlink\" title=\"7/消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order_info,A和B所消费的消息不会重复比如 order_info 中有100个消息，每个消息有一个id,编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号\"></a>7/消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order_info,A和B所消费的消息不会重复比如 order_info 中有100个消息，每个消息有一个id,编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号</h6><h6 id=\"8-消费者在具体消费某个topic中的消息时，可以指定起始偏移量\"><a href=\"#8-消费者在具体消费某个topic中的消息时，可以指定起始偏移量\" class=\"headerlink\" title=\"8/消费者在具体消费某个topic中的消息时，可以指定起始偏移量\"></a>8/消费者在具体消费某个topic中的消息时，可以指定起始偏移量</h6><h4 id=\"二、Kafka集群安装\"><a href=\"#二、Kafka集群安装\" class=\"headerlink\" title=\"二、Kafka集群安装\"></a>二、Kafka集群安装</h4><h6 id=\"1、解压\"><a href=\"#1、解压\" class=\"headerlink\" title=\"1、解压\"></a>1、解压</h6><h6 id=\"2、修改server-properties\"><a href=\"#2、修改server-properties\" class=\"headerlink\" title=\"2、修改server.properties\"></a>2、修改server.properties</h6><p>broker.id=1(每一台kafka都要给个编号)<br>zookeeper.connect=hadoop01:2181,hadoop02:2181,hadoop03:2181</p>\n<h6 id=\"3、将zookeeper集群启动\"><a href=\"#3、将zookeeper集群启动\" class=\"headerlink\" title=\"3、将zookeeper集群启动\"></a>3、将zookeeper集群启动</h6><h6 id=\"4、在每一台节点上启动broker\"><a href=\"#4、在每一台节点上启动broker\" class=\"headerlink\" title=\"4、在每一台节点上启动broker\"></a>4、在每一台节点上启动broker</h6><p>bin/kafka-server-start.sh config/server.properties</p>\n<h6 id=\"5、在kafka集群中创建一个topic\"><a href=\"#5、在kafka集群中创建一个topic\" class=\"headerlink\" title=\"5、在kafka集群中创建一个topic\"></a>5、在kafka集群中创建一个topic</h6><p>bin/kafka-topics.sh –create –zookeeper hadoop01:2181 –replication-factor 3 –partitions 1 –topic order</p>\n<h6 id=\"6、用一个producer向某一个topic中写入消息\"><a href=\"#6、用一个producer向某一个topic中写入消息\" class=\"headerlink\" title=\"6、用一个producer向某一个topic中写入消息\"></a>6、用一个producer向某一个topic中写入消息</h6><p>bin/kafka-console-producer.sh –broker-list hadoop01:9092 –topic order</p>\n<h6 id=\"7、用一个comsumer从某一个topic中读取信息\"><a href=\"#7、用一个comsumer从某一个topic中读取信息\" class=\"headerlink\" title=\"7、用一个comsumer从某一个topic中读取信息\"></a>7、用一个comsumer从某一个topic中读取信息</h6><p>bin/kafka-console-consumer.sh –zookeeper hadoop01:2181 –from-beginning –topic order</p>\n<h6 id=\"8、查看一个topic的分区及副本状态信息\"><a href=\"#8、查看一个topic的分区及副本状态信息\" class=\"headerlink\" title=\"8、查看一个topic的分区及副本状态信息\"></a>8、查看一个topic的分区及副本状态信息</h6><p>bin/kafka-topics.sh –describe –zookeeper hadoop01:2181 –topic order</p>\n<h4 id=\"三、Kafka整合storm的Java客户端编写\"><a href=\"#三、Kafka整合storm的Java客户端编写\" class=\"headerlink\" title=\"三、Kafka整合storm的Java客户端编写\"></a>三、Kafka整合storm的Java客户端编写</h4><h5 id=\"1-Topology\"><a href=\"#1-Topology\" class=\"headerlink\" title=\"1.Topology\"></a>1.Topology</h5><pre><code>public class KafkaTopo {\n\npublic static void main(String[] args) throws Exception {\n\n    String topic = &quot;wordcount&quot;; （配置主题名称）\n    String zkRoot = &quot;/kafka-storm&quot;;（设置zookeeper节点）\n    String spoutId = &quot;KafkaSpout&quot;;\n    BrokerHosts brokerHosts = new ZkHosts(&quot;hadoop01:2181,hadoop02:2181,hadoop03:2181&quot;); \n    SpoutConfig spoutConfig = new SpoutConfig(brokerHosts, &quot;wordcount&quot;, zkRoot, spoutId);\n    spoutConfig.forceFromStart = true;\n    spoutConfig.scheme = new SchemeAsMultiScheme(new MessageScheme());（自己定义的）\n    TopologyBuilder builder = new TopologyBuilder();\n    //设置一个spout用来从kaflka消息队列中读取数据并发送给下一级的bolt组件，此处用的spout组件并非自定义的，而是storm中已经开发好的KafkaSpout\n    builder.setSpout(&quot;KafkaSpout&quot;, new KafkaSpout(spoutConfig));\n    builder.setBolt(&quot;word-spilter&quot;, new WordSpliter()).shuffleGrouping(spoutId);\n    builder.setBolt(&quot;writer&quot;, new WriterBolt(), 4).fieldsGrouping(&quot;word-spilter&quot;, new Fields(&quot;word&quot;));\n    Config conf = new Config();\n    conf.setNumWorkers(4);\n    conf.setNumAckers(0);\n    conf.setDebug(false);\n\n    //LocalCluster用来将topology提交到本地模拟器运行，方便开发调试\n    LocalCluster cluster = new LocalCluster();\n    cluster.submitTopology(&quot;WordCount&quot;, conf, builder.createTopology());\n\n    //提交topology到storm集群中运行\n// StormSubmitter.submitTopology(&quot;sufei-topo&quot;, conf, builder.createTopology());\n}\n\n}\n</code></pre><h5 id=\"2-MessageScheme\"><a href=\"#2-MessageScheme\" class=\"headerlink\" title=\"2.MessageScheme\"></a>2.MessageScheme</h5><pre><code>public class MessageScheme implements Scheme {\n\nprivate static final long serialVersionUID = 8423372426211017613L;\n\n@Override\npublic List&lt;Object&gt; deserialize(byte[] bytes) {\n        try {\n            String msg = new String(bytes, &quot;UTF-8&quot;);\n            return new Values(msg); \n        } catch (UnsupportedEncodingException e) {\n            e.printStackTrace();\n        }\n        return null;\n}\n\n@Override\npublic Fields getOutputFields() {\n    return new Fields(&quot;msg&quot;);\n}\n\n}\n</code></pre><h5 id=\"3-Bolts\"><a href=\"#3-Bolts\" class=\"headerlink\" title=\"3.Bolts\"></a>3.Bolts</h5><pre><code>public class WordSpliter extends BaseBasicBolt {\n\nprivate static final long serialVersionUID = -5653803832498574866L;\n\n@Override\npublic void execute(Tuple input, BasicOutputCollector collector) {\n    String line = input.getString(0);\n    String[] words = line.split(&quot; &quot;);\n    for (String word : words) {\n        word = word.trim();\n        if (StringUtils.isNotBlank(word)) {\n            word = word.toLowerCase();\n            collector.emit(new Values(word));\n        }\n    }\n}\n\n@Override\npublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n    declarer.declare(new Fields(&quot;word&quot;));\n\n}\n\n}\n</code></pre><p> 将数据写入文件</p>\n<pre><code>public class WriterBolt extends BaseBasicBolt {\n\nprivate static final long serialVersionUID = -6586283337287975719L;\n\nprivate FileWriter writer = null;\n\n@Override\npublic void prepare(Map stormConf, TopologyContext context) {\n    try {\n        writer = new FileWriter(&quot;c:\\\\storm-kafka\\\\&quot; + &quot;wordcount&quot;+UUID.randomUUID().toString());\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n\n\n@Override\npublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n}\n\n\n@Override\npublic void execute(Tuple input, BasicOutputCollector collector) {\n    String s = input.getString(0);\n    try {\n        writer.write(s);\n        writer.write(&quot;\\n&quot;);\n        writer.flush();\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n</code></pre><p>}</p>\n"},{"title":"两台电脑的测试","author":"小小冰弟","date":"2018-03-26T09:49:13.000Z","_content":"这仅仅就是一个普通的测试文件，并没有什么意义。","source":"_posts/两台电脑的测试.md","raw":"title: 两台电脑的测试\nauthor: 小小冰弟\ndate: 2018-03-26 17:49:13\ntags:\n---\n这仅仅就是一个普通的测试文件，并没有什么意义。","slug":"两台电脑的测试","published":1,"updated":"2018-03-26T09:49:34.188Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60lb001pxo7k4988qif3","content":"<p>这仅仅就是一个普通的测试文件，并没有什么意义。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>这仅仅就是一个普通的测试文件，并没有什么意义。</p>\n"},{"title":"常用的基本操作链接","author":"小小冰弟","date":"2018-02-05T00:53:59.000Z","_content":"#### <center>博客篇\n  \n##### [一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）](http://blog.csdn.net/gdutxiaoxu/article/details/53576018)  \n\n##### [二、hexo-admin 博客后端管理工具](https://blog.kinpzz.com/2016/12/31/hexo-admin-backend-management/)\n\n##### [三、hexo换电脑怎么处理](github.com/xxbd/xxbd.github.io/blob/master/index.html)\n\n##### [四、VM虚拟机下安装Centos7.0图文教程](http://www.centoscn.com/image-text/setup/2014/0723/3341.html)\n\n##### [五、SpringBoot](http://www.spring4all.com/article/246)\n\n##### [六、NATAPP1分钟快速新手图文教程（映射公网ip）](https://natapp.cn/article/natapp_newbie)\n\n##### 注：new post是文章，而new pages只是个主页分类(比如about,diary...)。","source":"_posts/常用的基本操作链接.md","raw":"title: 常用的基本操作链接\nauthor: 小小冰弟\ncategories: link\ntags: study\ndate: 2018-02-05 08:53:59\n---\n#### <center>博客篇\n  \n##### [一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）](http://blog.csdn.net/gdutxiaoxu/article/details/53576018)  \n\n##### [二、hexo-admin 博客后端管理工具](https://blog.kinpzz.com/2016/12/31/hexo-admin-backend-management/)\n\n##### [三、hexo换电脑怎么处理](github.com/xxbd/xxbd.github.io/blob/master/index.html)\n\n##### [四、VM虚拟机下安装Centos7.0图文教程](http://www.centoscn.com/image-text/setup/2014/0723/3341.html)\n\n##### [五、SpringBoot](http://www.spring4all.com/article/246)\n\n##### [六、NATAPP1分钟快速新手图文教程（映射公网ip）](https://natapp.cn/article/natapp_newbie)\n\n##### 注：new post是文章，而new pages只是个主页分类(比如about,diary...)。","slug":"常用的基本操作链接","published":1,"updated":"2018-03-26T09:46:34.654Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfcc60lc001sxo7ka3pbzszy","content":"<h4 id=\"博客篇\"><a href=\"#博客篇\" class=\"headerlink\" title=\"博客篇\"></a><center>博客篇</center></h4><h5 id=\"一、手把手教你用Hexo-Github-搭建属于自己的博客（我觉得写得很详细）\"><a href=\"#一、手把手教你用Hexo-Github-搭建属于自己的博客（我觉得写得很详细）\" class=\"headerlink\" title=\"一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）\"></a><a href=\"http://blog.csdn.net/gdutxiaoxu/article/details/53576018\" target=\"_blank\" rel=\"noopener\">一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）</a></h5><h5 id=\"二、hexo-admin-博客后端管理工具\"><a href=\"#二、hexo-admin-博客后端管理工具\" class=\"headerlink\" title=\"二、hexo-admin 博客后端管理工具\"></a><a href=\"https://blog.kinpzz.com/2016/12/31/hexo-admin-backend-management/\" target=\"_blank\" rel=\"noopener\">二、hexo-admin 博客后端管理工具</a></h5><h5 id=\"三、hexo换电脑怎么处理\"><a href=\"#三、hexo换电脑怎么处理\" class=\"headerlink\" title=\"三、hexo换电脑怎么处理\"></a><a href=\"github.com/xxbd/xxbd.github.io/blob/master/index.html\">三、hexo换电脑怎么处理</a></h5><h5 id=\"四、VM虚拟机下安装Centos7-0图文教程\"><a href=\"#四、VM虚拟机下安装Centos7-0图文教程\" class=\"headerlink\" title=\"四、VM虚拟机下安装Centos7.0图文教程\"></a><a href=\"http://www.centoscn.com/image-text/setup/2014/0723/3341.html\" target=\"_blank\" rel=\"noopener\">四、VM虚拟机下安装Centos7.0图文教程</a></h5><h5 id=\"五、SpringBoot\"><a href=\"#五、SpringBoot\" class=\"headerlink\" title=\"五、SpringBoot\"></a><a href=\"http://www.spring4all.com/article/246\" target=\"_blank\" rel=\"noopener\">五、SpringBoot</a></h5><h5 id=\"六、NATAPP1分钟快速新手图文教程（映射公网ip）\"><a href=\"#六、NATAPP1分钟快速新手图文教程（映射公网ip）\" class=\"headerlink\" title=\"六、NATAPP1分钟快速新手图文教程（映射公网ip）\"></a><a href=\"https://natapp.cn/article/natapp_newbie\" target=\"_blank\" rel=\"noopener\">六、NATAPP1分钟快速新手图文教程（映射公网ip）</a></h5><h5 id=\"注：new-post是文章，而new-pages只是个主页分类-比如about-diary…-。\"><a href=\"#注：new-post是文章，而new-pages只是个主页分类-比如about-diary…-。\" class=\"headerlink\" title=\"注：new post是文章，而new pages只是个主页分类(比如about,diary…)。\"></a>注：new post是文章，而new pages只是个主页分类(比如about,diary…)。</h5>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"博客篇\"><a href=\"#博客篇\" class=\"headerlink\" title=\"博客篇\"></a><center>博客篇</center></h4><h5 id=\"一、手把手教你用Hexo-Github-搭建属于自己的博客（我觉得写得很详细）\"><a href=\"#一、手把手教你用Hexo-Github-搭建属于自己的博客（我觉得写得很详细）\" class=\"headerlink\" title=\"一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）\"></a><a href=\"http://blog.csdn.net/gdutxiaoxu/article/details/53576018\" target=\"_blank\" rel=\"noopener\">一、手把手教你用Hexo+Github 搭建属于自己的博客（我觉得写得很详细）</a></h5><h5 id=\"二、hexo-admin-博客后端管理工具\"><a href=\"#二、hexo-admin-博客后端管理工具\" class=\"headerlink\" title=\"二、hexo-admin 博客后端管理工具\"></a><a href=\"https://blog.kinpzz.com/2016/12/31/hexo-admin-backend-management/\" target=\"_blank\" rel=\"noopener\">二、hexo-admin 博客后端管理工具</a></h5><h5 id=\"三、hexo换电脑怎么处理\"><a href=\"#三、hexo换电脑怎么处理\" class=\"headerlink\" title=\"三、hexo换电脑怎么处理\"></a><a href=\"github.com/xxbd/xxbd.github.io/blob/master/index.html\">三、hexo换电脑怎么处理</a></h5><h5 id=\"四、VM虚拟机下安装Centos7-0图文教程\"><a href=\"#四、VM虚拟机下安装Centos7-0图文教程\" class=\"headerlink\" title=\"四、VM虚拟机下安装Centos7.0图文教程\"></a><a href=\"http://www.centoscn.com/image-text/setup/2014/0723/3341.html\" target=\"_blank\" rel=\"noopener\">四、VM虚拟机下安装Centos7.0图文教程</a></h5><h5 id=\"五、SpringBoot\"><a href=\"#五、SpringBoot\" class=\"headerlink\" title=\"五、SpringBoot\"></a><a href=\"http://www.spring4all.com/article/246\" target=\"_blank\" rel=\"noopener\">五、SpringBoot</a></h5><h5 id=\"六、NATAPP1分钟快速新手图文教程（映射公网ip）\"><a href=\"#六、NATAPP1分钟快速新手图文教程（映射公网ip）\" class=\"headerlink\" title=\"六、NATAPP1分钟快速新手图文教程（映射公网ip）\"></a><a href=\"https://natapp.cn/article/natapp_newbie\" target=\"_blank\" rel=\"noopener\">六、NATAPP1分钟快速新手图文教程（映射公网ip）</a></h5><h5 id=\"注：new-post是文章，而new-pages只是个主页分类-比如about-diary…-。\"><a href=\"#注：new-post是文章，而new-pages只是个主页分类-比如about-diary…-。\" class=\"headerlink\" title=\"注：new post是文章，而new pages只是个主页分类(比如about,diary…)。\"></a>注：new post是文章，而new pages只是个主页分类(比如about,diary…)。</h5>"},{"title":"飘","author":"小小冰弟","date":"2018-03-30T07:10:16.000Z","_content":"*其实我早就想写点读书笔记的，但我实在是太懒了，眼看着这本《飘》都已经读了四百页了，我觉得该是时候了。*\n<p align=\"right\">2018.3.30</p>\n\n*今天读了关于艾希礼圣诞节回来与家人团聚的部分，思嘉依然向他表示了爱意，也许是出于上等人的自尊，他无情的拒绝她继续下去，随后南部联盟已经是日薄西山了，而艾希礼本人也失踪了，当思嘉听见媚兰怀了身孕的惊慌看的我发笑，书中说仿佛她的老公背着她偷情般，但我忽然转念一想，如果自己心爱的人怀了身孕，当然是其他人的，不知道我会是怎样的感受呢？瑞德巴特勒应该完全拿捏住了思嘉的心，就像他说的一样，她还是个孩子，他在等她长大，不得不说是生意必须还是怎的，巴特勒总是会及时出现帮助思嘉，或更确切的说是恰合时宜的时候，他一定是喜欢她的，毕竟喜欢一个人你就会关心她的一切，但如果你仅仅是关心却并不能提供什么的话，那真是个可悲的故事，巴特勒的处事观点还是让人向往的，至少我也本就不是什么上流人士吧！哈哈!*\n<p align=\"right\">2018.3.30</p>\n\n\n*不知不觉间，思嘉回到了塔拉，但曾经的家已经面目全非了，最让她难过的是她的母亲在她回来的前一天也离世了，父亲也因为接连而来的打击而昏昏沉沉，思嘉成了房子的新主人，思嘉的心中是住着一头猛兽的，这不同于其它周围的女生，或许这是她吸引巴特勒的地方吧，她很勇敢，虽然对于艾希礼的那份爱是那么的幼稚，深处于爱情中的人真的无论哪里都是一样的呢！媚兰真的是个做妻子再适合不过的人了，心地善良的觉察不到别人的任何不好，用自己的爱去对待周围的人，与这样的人一起同行，大概是每个男生最终的理想归宿，但男人嘛，年轻时候应该会更爱思嘉点，毕竟她可是个迷人的小妖精啊，哈哈哈！书中的黑人也都挺可爱，很善良，但他们的奴隶思想感觉的确是太深沉了，估计时间太久的缘故，我挺同情小韦德的，对于他，思嘉真的是不怎么上心，不过对于思嘉为他要回那把汉密尔顿的刀时候，还是可以感受到母爱的光辉的，即使她并不爱查尔斯，一点也不爱，但或许后来会爱上的吧，就像平凡的世界中的润叶姐一样吧.*\n<p align=\"right\">2018.4.3</p>","source":"_posts/飘.md","raw":"title: 飘\nauthor: 小小冰弟\ntags: live\ncategories: Feel\ndate: 2018-03-30 15:10:16\n---\n*其实我早就想写点读书笔记的，但我实在是太懒了，眼看着这本《飘》都已经读了四百页了，我觉得该是时候了。*\n<p align=\"right\">2018.3.30</p>\n\n*今天读了关于艾希礼圣诞节回来与家人团聚的部分，思嘉依然向他表示了爱意，也许是出于上等人的自尊，他无情的拒绝她继续下去，随后南部联盟已经是日薄西山了，而艾希礼本人也失踪了，当思嘉听见媚兰怀了身孕的惊慌看的我发笑，书中说仿佛她的老公背着她偷情般，但我忽然转念一想，如果自己心爱的人怀了身孕，当然是其他人的，不知道我会是怎样的感受呢？瑞德巴特勒应该完全拿捏住了思嘉的心，就像他说的一样，她还是个孩子，他在等她长大，不得不说是生意必须还是怎的，巴特勒总是会及时出现帮助思嘉，或更确切的说是恰合时宜的时候，他一定是喜欢她的，毕竟喜欢一个人你就会关心她的一切，但如果你仅仅是关心却并不能提供什么的话，那真是个可悲的故事，巴特勒的处事观点还是让人向往的，至少我也本就不是什么上流人士吧！哈哈!*\n<p align=\"right\">2018.3.30</p>\n\n\n*不知不觉间，思嘉回到了塔拉，但曾经的家已经面目全非了，最让她难过的是她的母亲在她回来的前一天也离世了，父亲也因为接连而来的打击而昏昏沉沉，思嘉成了房子的新主人，思嘉的心中是住着一头猛兽的，这不同于其它周围的女生，或许这是她吸引巴特勒的地方吧，她很勇敢，虽然对于艾希礼的那份爱是那么的幼稚，深处于爱情中的人真的无论哪里都是一样的呢！媚兰真的是个做妻子再适合不过的人了，心地善良的觉察不到别人的任何不好，用自己的爱去对待周围的人，与这样的人一起同行，大概是每个男生最终的理想归宿，但男人嘛，年轻时候应该会更爱思嘉点，毕竟她可是个迷人的小妖精啊，哈哈哈！书中的黑人也都挺可爱，很善良，但他们的奴隶思想感觉的确是太深沉了，估计时间太久的缘故，我挺同情小韦德的，对于他，思嘉真的是不怎么上心，不过对于思嘉为他要回那把汉密尔顿的刀时候，还是可以感受到母爱的光辉的，即使她并不爱查尔斯，一点也不爱，但或许后来会爱上的吧，就像平凡的世界中的润叶姐一样吧.*\n<p align=\"right\">2018.4.3</p>","slug":"飘","published":1,"updated":"2018-04-03T07:10:52.783Z","_id":"cjfdlynzr0001j87krcoeh0hi","comments":1,"layout":"post","photos":[],"link":"","content":"<p><em>其实我早就想写点读书笔记的，但我实在是太懒了，眼看着这本《飘》都已经读了四百页了，我觉得该是时候了。</em></p>\n<p align=\"right\">2018.3.30</p>\n\n<p><em>今天读了关于艾希礼圣诞节回来与家人团聚的部分，思嘉依然向他表示了爱意，也许是出于上等人的自尊，他无情的拒绝她继续下去，随后南部联盟已经是日薄西山了，而艾希礼本人也失踪了，当思嘉听见媚兰怀了身孕的惊慌看的我发笑，书中说仿佛她的老公背着她偷情般，但我忽然转念一想，如果自己心爱的人怀了身孕，当然是其他人的，不知道我会是怎样的感受呢？瑞德巴特勒应该完全拿捏住了思嘉的心，就像他说的一样，她还是个孩子，他在等她长大，不得不说是生意必须还是怎的，巴特勒总是会及时出现帮助思嘉，或更确切的说是恰合时宜的时候，他一定是喜欢她的，毕竟喜欢一个人你就会关心她的一切，但如果你仅仅是关心却并不能提供什么的话，那真是个可悲的故事，巴特勒的处事观点还是让人向往的，至少我也本就不是什么上流人士吧！哈哈!</em></p>\n<p align=\"right\">2018.3.30</p>\n\n\n<p><em>不知不觉间，思嘉回到了塔拉，但曾经的家已经面目全非了，最让她难过的是她的母亲在她回来的前一天也离世了，父亲也因为接连而来的打击而昏昏沉沉，思嘉成了房子的新主人，思嘉的心中是住着一头猛兽的，这不同于其它周围的女生，或许这是她吸引巴特勒的地方吧，她很勇敢，虽然对于艾希礼的那份爱是那么的幼稚，深处于爱情中的人真的无论哪里都是一样的呢！媚兰真的是个做妻子再适合不过的人了，心地善良的觉察不到别人的任何不好，用自己的爱去对待周围的人，与这样的人一起同行，大概是每个男生最终的理想归宿，但男人嘛，年轻时候应该会更爱思嘉点，毕竟她可是个迷人的小妖精啊，哈哈哈！书中的黑人也都挺可爱，很善良，但他们的奴隶思想感觉的确是太深沉了，估计时间太久的缘故，我挺同情小韦德的，对于他，思嘉真的是不怎么上心，不过对于思嘉为他要回那把汉密尔顿的刀时候，还是可以感受到母爱的光辉的，即使她并不爱查尔斯，一点也不爱，但或许后来会爱上的吧，就像平凡的世界中的润叶姐一样吧.</em></p>\n<p align=\"right\">2018.4.3</p>","site":{"data":{}},"excerpt":"","more":"<p><em>其实我早就想写点读书笔记的，但我实在是太懒了，眼看着这本《飘》都已经读了四百页了，我觉得该是时候了。</em></p>\n<p align=\"right\">2018.3.30</p>\n\n<p><em>今天读了关于艾希礼圣诞节回来与家人团聚的部分，思嘉依然向他表示了爱意，也许是出于上等人的自尊，他无情的拒绝她继续下去，随后南部联盟已经是日薄西山了，而艾希礼本人也失踪了，当思嘉听见媚兰怀了身孕的惊慌看的我发笑，书中说仿佛她的老公背着她偷情般，但我忽然转念一想，如果自己心爱的人怀了身孕，当然是其他人的，不知道我会是怎样的感受呢？瑞德巴特勒应该完全拿捏住了思嘉的心，就像他说的一样，她还是个孩子，他在等她长大，不得不说是生意必须还是怎的，巴特勒总是会及时出现帮助思嘉，或更确切的说是恰合时宜的时候，他一定是喜欢她的，毕竟喜欢一个人你就会关心她的一切，但如果你仅仅是关心却并不能提供什么的话，那真是个可悲的故事，巴特勒的处事观点还是让人向往的，至少我也本就不是什么上流人士吧！哈哈!</em></p>\n<p align=\"right\">2018.3.30</p>\n\n\n<p><em>不知不觉间，思嘉回到了塔拉，但曾经的家已经面目全非了，最让她难过的是她的母亲在她回来的前一天也离世了，父亲也因为接连而来的打击而昏昏沉沉，思嘉成了房子的新主人，思嘉的心中是住着一头猛兽的，这不同于其它周围的女生，或许这是她吸引巴特勒的地方吧，她很勇敢，虽然对于艾希礼的那份爱是那么的幼稚，深处于爱情中的人真的无论哪里都是一样的呢！媚兰真的是个做妻子再适合不过的人了，心地善良的觉察不到别人的任何不好，用自己的爱去对待周围的人，与这样的人一起同行，大概是每个男生最终的理想归宿，但男人嘛，年轻时候应该会更爱思嘉点，毕竟她可是个迷人的小妖精啊，哈哈哈！书中的黑人也都挺可爱，很善良，但他们的奴隶思想感觉的确是太深沉了，估计时间太久的缘故，我挺同情小韦德的，对于他，思嘉真的是不怎么上心，不过对于思嘉为他要回那把汉密尔顿的刀时候，还是可以感受到母爱的光辉的，即使她并不爱查尔斯，一点也不爱，但或许后来会爱上的吧，就像平凡的世界中的润叶姐一样吧.</em></p>\n<p align=\"right\">2018.4.3</p>"},{"title":"SpringBoot","author":"小小冰弟","date":"2018-04-03T07:11:34.000Z","_content":"#### 一、什么是Spring Boot?\n###### Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。\n\n特性：\n- 创建独立的Spring应用程序\n- 嵌入的Tomcat，无需部署WAR文件\n- 简化Maven配置，自动配置Spring\n- 提供生产就绪型功能，如指标，健康检查和外部配置\n- 开箱即用，没有代码生成，也无需XML配置。\n\n\n#### 二、Spring Boot完美使用FastJson解析JSON数据\n##### 1.引入fastjson依赖库\n           \n           \n           <dependency>\n\t\t\t<groupId>com.alibaba</groupId>\n\t\t\t<artifactId>fastjson</artifactId>\n\t\t\t<version>1.2.15</version>\n          </dependency>\n\n##### 2.启动类继承extends WebMvcConfigurerAdapter\n\n##### 3.覆盖方法configureMessageConverters\n\n    @SpringBootApplication\n    public class ApiCoreApp  extends WebMvcConfigurerAdapter {\n\t\n\t@Override\n\tpublic void configureMessageConverters(List<HttpMessageConverter<?>> converters) {\n    \tsuper.configureMessageConverters(converters);\n\t\t\n        FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter();\n \n        FastJsonConfig fastJsonConfig = new FastJsonConfig();\n        fastJsonConfig.setSerializerFeatures(\n                SerializerFeature.PrettyFormat\n        );\n        fastConverter.setFastJsonConfig(fastJsonConfig);\n\t\t\n    \tconverters.add(fastConverter);\n\t}\n    }\n    \n #### 三、Spring Boot热部署\n \n \n为什么需要热部署呢，因为你会发现即使做了一点点的变更，你也许也需要重新部署，这在工作上简直太耽误时间了。\n \n 解决方法：\n          \n     在pom.xml文件添加依赖包：\n     <plugin>\n\t          \t\t<groupId>org.springframework.boot</groupId>\n\t          \t\t<artifactId>spring-boot-maven-plugin </artifactId>\n\t          \t\t<dependencies>  \n\t\t\t           <!--springloaded  hot deploy -->  \n\t\t\t           <dependency>  \n\t\t\t               <groupId>org.springframework</groupId>  \n\t\t\t               <artifactId>springloaded</artifactId>  \n\t\t\t               <version>1.2.4.RELEASE</version>\n\t\t\t           </dependency>  \n\t\t\t        </dependencies>  \n\t\t\t        <executions>  \n\t\t\t           <execution>  \n\t\t\t               <goals>  \n\t\t\t                   <goal>repackage</goal>  \n\t\t\t               </goals>  \n\t\t\t               <configuration>  \n\t\t\t                   <classifier>exec</classifier>  \n\t\t\t               </configuration>  \n\t\t\t           </execution>  \n\t\t       \t\t</executions>\n    </plugin>\n \n 使用spring-boot:run 作为 Goals（run as maven build）\n \n \n#### 四、springboot + devtools（热部署）\n\n- spring-boot-devtools 是一个为开发者服务的一个模块，其中最重要的功能就是自动应用代码更改到最新的App上面去。原理是在发现代码有更改之后，重新启动应用，但是速度比手动停止后再启动还要更快，更快指的不是节省出来的手工操作的时间。\n- 其深层原理是使用了两个ClassLoader，一个Classloader加载那些不会改变的类（第三方Jar包），另一个ClassLoader加载会更改的类，称为  restart ClassLoader,这样在有代码更改的时候，原来的restart ClassLoader 被丢弃，重新创建一个restart ClassLoader，由于需要加载的类相比较少，所以实现了较快的重启时间（5秒以内）\n\n ###### 步骤说明\n \n    添加依赖包： \n    <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <optional>true</optional>\n           <scope>true</scope>\n    </dependency>\n      添加spring-boot-maven-plugin：\n      <build>\n\t\t<plugins>\n\t\t    <plugin>\n\t            <groupId>org.springframework.boot</groupId>\n\t            <artifactId>spring-boot-maven-plugin</artifactId>\n\t            <configuration>\n\t          \t\t<!--fork :  如果没有该项配置，肯呢个devtools不会起作用，即应用不会restart -->\n\t                <fork>true</fork>\n\t            </configuration>\n\t        </plugin>\n\t\t</plugins>\n    </build>\n    \n###### 补充说明    \n1. devtools会监听classpath下的文件变动，并且会立即重启应用（发生在保存时机），注意：因为其采用的虚拟机机制，该项重启是很快的。\n2. devtools可以实现页面热部署（即页面修改后会立即生效，这个可以直接在application.properties文件中配置spring.thymeleaf.cache=false来实现(这里注意不同的模板配置不一样)\n \n    \n    \n#### 五、Spring Data\n*Spring Data是一个用于简化数据库访问，并支持云服务的开源框架。其主要目标是使得数据库的访问变得方便快捷，并支持map-reduce框架和云计算数据服务。此外，它还支持基于关系型数据库的数据服务，如Oracle RAC等。对于拥有海量数据的项目，可以用Spring Data来简化项目的开发，就如Spring Framework对JDBC、ORM的支持一样，Spring Data会让数据的访问变得更加方便*\n\n*可以极大的简化JPA的写法，可以在几乎不用写实现的情况下，实现对数据的访问和操作。除了CRUD外，还包括如分页、排序等一些常用的功能。所以Spring Data JPA的出现就是为了简化JPA的写法，让你只需要编写一个接口继承一个类就能实现CRUD操作了*\n\n\n\n步骤：\n    \n  >1.在pom.xml添加mysql,spring-data-jpa依赖;\n  \n  \n  \n  \n    <dependency>\n\t\t<groupId>mysql</groupId>\n\t\t<artifactId>mysql-connector-java</artifactId>\n    </dependency>\n\n\n    <dependency>\n\t\t    <groupId>org.springframework.boot</groupId>\n\t\t    <artifactId>spring-boot-starter-data-jpa</artifactId>\n    </dependency>\n\n\n>2.在application.properties文件中配置mysql连接配置文件;\n\n    spring.datasource.url = jdbc:mysql://localhost:3306/test\n    spring.datasource.username = root\n    spring.datasource.password = root\n    spring.datasource.driverClassName = com.mysql.jdbc.Driver\n    spring.datasource.max-active=20\n    spring.datasource.max-idle=8\n    spring.datasource.min-idle=8\n    spring.datasource.initial-size=10\n\n>3.在application.properties文件中配置JPA配置信息;\n\n    spring.jpa.database = MYSQL\n    #Show or not log for each sql query\n    spring.jpa.show-sql = true\n    #Hibernate ddl auto (create, create-drop, update)\n    spring.jpa.hibernate.ddl-auto = update\n    #Naming strategy\n    #[org.hibernate.cfg.ImprovedNamingStrategy  #org.hibernate.cfg.DefaultNamingStrategy]\n    spring.jpa.hibernate.naming-strategy = org.hibernate.cfg.ImprovedNamingStrategy\n    #stripped before adding them to the entity manager)\n    spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.MySQL5Dialect\n\n\n##### 重点：Repository接口\n\n 有这么几点需要强调下：\n1. Repository是一个空接口，即是一个标记接口；\n2. 若我们定义的接口继承了Repository，则该接口会被IOC容器识别为一个Repository Bean纳入到IOC容器中，进而可以在该接口中定义满足一定规范的方法。\n3. 实际上也可以通过@RepositoryDefinition,注解来替代继承Repository接口，查询方法以find | read | get开头；\n4. 涉及查询条件时，条件的属性用条件关键字连接，要注意的是条件属性以首字母大写。\n5. 使用@Query注解可以自定义JPQL语句实现更灵活的查询。\n\n\n\n\n\n\n\n\n##### CrudRepository 接口提供了最基本的对实体类的添删改查操作\n\n --T save(T entity);//保存单个实体   \n --Iterable<T> save(Iterable<? extends T> entities);//保存集合         \n --T findOne(ID id);//根据id查找实体          \n --Iterable<T> findAll();//查询所有实体,不用或慎用!          \n --long count();//查询实体数量          \n --void delete(ID id);//根据Id删除实体          \n --void delete(T entity);//删除一个实体   \n --void delete(Iterable<? extends T> entities);//删除一个实体的集合          \n --void deleteAll();//删除所有实体,不用或慎用!   \n\n\n\n#### 六、全局异常捕捉\n\n##### 步骤：\n\n\n    新建一个类GlobalDefaultExceptionHandler，\n    在class注解上@ControllerAdvice,\n    在方法上注解上@ExceptionHandler(value = Exception.class)\n    根据返回值判断要不要添加@responsebody注解\n    @ControllerAdvice\n    public class GlobalDefaultExceptionHandler{\n\t\n\t@ExceptionHandler(value = Exception.class)\n\tpublic void defaultErrorHandler(HttpServletRequest req, Exception e)  {\n    }\n\n #### 七、配置Server\n \n ##### 在application.properties进行配置：\n\n    #server.port=8080  端口号\n    #server.address= # bind to a specific NIC\n    #server.session-timeout= # session timeout in seconds\n    #the context path, defaults to '/'\n    #server.context-path=/spring-boot  访问路径\n    #server.servlet-path= # the servlet path, defaults to '/'\n    #server.tomcat.access-log-pattern= # log pattern of the access log\n    #server.tomcat.access-log-enabled=false # is access logging enabled\n    #server.tomcat.protocol-header=x-forwarded-proto # ssl forward headers\n    #server.tomcat.remote-ip-header=x-forwarded-for\n    #server.tomcat.basedir=/tmp # base dir (usually not needed, defaults to tmp)\n    #server.tomcat.background-processor-delay=30; # in seconds\n    #server.tomcat.max-threads = 0 # number of threads in protocol handler\n    #server.tomcat.uri-encoding = UTF-8 # character encoding to use for URL decoding\n\n\n#### 八、thymeleaf的使用\n\n\n##### 1.在pom.xml中引入thymeleaf\n\n\n    <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-thymeleaf</artifactId>\n    </dependency>\n\n\n##### 2.如何关闭thymeleaf缓存\n     ########################################################\n     ###THYMELEAF (ThymeleafAutoConfiguration)\n     ########################################################\n     #spring.thymeleaf.prefix=classpath:/templates/\n     #spring.thymeleaf.suffix=.html\n     #spring.thymeleaf.mode=HTML5\n     #spring.thymeleaf.encoding=UTF-8\n     # ;charset=<encoding> is added\n     #spring.thymeleaf.content-type=text/html \n     # set to false for hot refresh\n     spring.thymeleaf.cache=false   关闭缓存\n\n###### 3.编写模板文件.html\n\n    编写模板文件src/main/resouces/templates/hello.html:\n\n    <!DOCTYPE html>\n    <html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:th=\"http://www.thymeleaf.org\"\n          xmlns:sec=\"http://www.thymeleaf.org/thymeleaf-extras-springsecurity3\">\n        <head>\n            <title>Hello World!</title>\n        </head>\n        <body>\n            <h1 th:inline=\"text\">Hello.v.2</h1>\n            <p th:text=\"${hello}\"></p>\n        </body>\n    </html>\n\n##### 4.编写访问模板文件controller\n\n    @Controller\n    public class TemplateController {\n\n        /**\n         * 返回html模板.\n         */\n        @RequestMapping(\"/helloHtml\")\n        public String helloHtml(Map<String,Object> map){\n            map.put(\"hello\",\"from TemplateController.helloHtml\");\n            return \"/helloHtml\";\n        }\n\n    }\n\n#### 九、freemarker的使用\n\n##### 1.在pom.xml中引入freemarker\n\n    <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-freemarker</artifactId>\n    </dependency>\n\n##### 2.如何关闭freemarker缓存\n\n\n    ########################################################\n    ###FREEMARKER (FreeMarkerAutoConfiguration)\n    ########################################################\n    spring.freemarker.allow-request-override=false\n    spring.freemarker.cache=true\n    spring.freemarker.check-template-location=true\n    spring.freemarker.charset=UTF-8\n    spring.freemarker.content-type=text/html\n    spring.freemarker.expose-request-attributes=false\n    spring.freemarker.expose-session-attributes=false\n    spring.freemarker.expose-spring-macro-helpers=false\n    #spring.freemarker.prefix=\n    #spring.freemarker.request-context-attribute=\n    #spring.freemarker.settings.*=\n    #spring.freemarker.suffix=.ftl\n    #spring.freemarker.template-loader-path=classpath:/templates/ #comma-separated list\n    #spring.freemarker.view-names= # whitelist of view names that can be resolved\n\n\n##### 3.编写模板文件.ftl\n\n\n    <!DOCTYPE html>\n    <html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:th=\"http://www.thymeleaf.org\"\n          xmlns:sec=\"http://www.thymeleaf.org/thymeleaf-extras-springsecurity3\">\n        <head>\n            <title>Hello World!</title>\n        </head>\n        <body>\n            <h1>Hello.v.2</h1>\n            <p>${hello}</p>\n        </body>\n    </html>\n\n\n##### 4.编写访问文件的controller\n  \n  \n     @RequestMapping(\"/helloFtl\")\n      public String helloFtl(Map<String,Object> map){\n          map.put(\"hello\",\"from TemplateController.helloFtl\");\n          return \"/helloFtl\";\n      }\n\n\n#### 十、jsp的使用\n\n\n##### 1.创建Maven web project\n\n##### 2.在pom.xml文件添加依赖\n\n\n      <!-- web支持: 1、web mvc; 2、restful; 3、jackjson支持; 4、aop ........ -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-web</artifactId>\n\t\t</dependency>\n\n     <!-- servlet 依赖. -->\n\t\t<dependency>\n\t\t\t<groupId>javax.servlet</groupId>\n\t\t\t<artifactId>javax.servlet-api</artifactId>\n\t\t\t<scope>provided</scope>\n\t\t</dependency>\n\n\n\n    JSTL（JSP Standard Tag Library，JSP标准标签库)是一个不断完善的开放源代码的JSP标签库，是由apache的jakarta小组来维护的。\n    <dependency>\n                <groupId>javax.servlet</groupId>\n                <artifactId>jstl</artifactId>\n            </dependency>\n\n    <!-- tomcat 的支持.-->\n            <dependency>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-starter-tomcat</artifactId>\n                <scope>provided</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.tomcat.embed</groupId>\n                <artifactId>tomcat-embed-jasper</artifactId>\n                <scope>provided</scope>\n            </dependency>\n\n##### 3.application.properties配置\n\n    添加src/main/resources/application.properties：\n\n    # 页面默认前缀目录\n    spring.mvc.view.prefix=/WEB-INF/jsp/\n    # 响应页面默认后缀\n    spring.mvc.view.suffix=.jsp\n    # 自定义属性，可以在Controller中读取\n    application.hello=Hello Angel From application\n\n##### 4.编写controller\n\n\n    @Controller\n    public class HelloController {\n    private String hello;    \n\n        @RequestMapping(\"/helloJsp\")\n        public String helloJsp(Map<String,Object> map){\n            System.out.println(\"HelloController.helloJsp().hello=hello\");\n            map.put(\"hello\", hello);\n            return \"helloJsp\";\n        }\n    }\n##### 5.编写jsp页面\n\n    在 src/main 下面创建 webapp/WEB-INF/jsp 目录用来存放我们的jsp页面：helloJsp.jsp:\n\n    <%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\"\n        pageEncoding=\"UTF-8\"%>\n    <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n    <html>\n    <head>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n    <title>Insert title here</title>\n    </head>\n    <body>\n        helloJsp\n        <hr>\n        ${hello}\n\n    </body>\n    </html>\n\n#### 十一、Mybatis的引用\n\n\n##### 1.在pom.xml文件中引入相关依赖\n\n\n    （1）基本依赖，jdk版本号；\n    （2）mysql驱动，mybatis依赖包，mysql分页PageHelper:\n\n    <!-- mysql 数据库驱动. -->\n        <dependency>\n            <groupId>mysql</groupId>\n            <artifactId>mysql-connector-java</artifactId>\n    </dependency>\t\n    \n    \n    <!-- \n    \tMyBatis提供了拦截器接口，我们可以实现自己的拦截器，\n    \t将其作为一个plugin装入到SqlSessionFactory中。 \n\t\tGithub上有位开发者写了一个分页插件，我觉得使用起来还可以，挺方便的。 \n\t\tGithub项目地址： https://github.com/pagehelper/Mybatis-PageHelper\n     -->\t\n    <dependency>\n\t    <groupId>com.github.pagehelper</groupId>\n\t    <artifactId>pagehelper</artifactId>\n\t    <version>4.1.0</version>\n\t</dependency>\t\n\n    \n    \n    \n\n\n##### 2.在application.properties添加配置文件\n\n    ########################################################\n    ###datasource\n    ########################################################\n    spring.datasource.url = jdbc:mysql://localhost:3306/test\n    spring.datasource.username = root\n    spring.datasource.password = root\n    spring.datasource.driverClassName = com.mysql.jdbc.Driver\n    spring.datasource.max-active=20\n    spring.datasource.max-idle=8\n    spring.datasource.min-idle=8\n    spring.datasource.initial-size=10\n\n\n\n##### 3.编写Demo测试类\n\n\n    public class Demo {\n\tprivate long id;\n\tprivate String name;\n      //省略getter and setter….\n    }\n\n\n\n##### 4.编写demoMapper\n\n    public interface DemoMappper {\n\t\n\t@Select(\"select *from Demo where name = #{name}\")\n\tpublic List<Demo> likeName(String name);\n\t\n\t@Select(\"select *from Demo where id = #{id}\")\n\tpublic Demo getById(long id);\n\t\n\t@Select(\"select name from Demo where id = #{id}\")\n\tpublic String getNameById(long id);\n    }\n\n\n##### 5.编写demoService\n\n    @Service\n    public class DemoService {\n        @Autowired\n        private DemoMappper demoMappper;\n\n        public List<Demo> likeName(String name){\n            return demoMappper.likeName(name);\n        }\n    }\n\n\n##### 6.编写demoController\n    @RestController\n    public class DemoController {\n        @Autowired\n        private DemoService demoService;\n\n        @RequestMapping(\"/likeName\")\n        public List<Demo> likeName(String name){\n            return demoService.likeName(name);\n        }\n\n    }\n\n##### 7.加入PageHelper\n\n\n    @Configuration\n    public class MyBatisConfiguration {\n\n        @Bean\n        public PageHelper pageHelper() {\n            System.out.println(\"MyBatisConfiguration.pageHelper()\");\n            PageHelper pageHelper = new PageHelper();\n            Properties p = new Properties();\n            p.setProperty(\"offsetAsPageNum\", \"true\");\n            p.setProperty(\"rowBoundsWithCount\", \"true\");\n            p.setProperty(\"reasonable\", \"true\");\n            pageHelper.setProperties(p);\n            return pageHelper;\n        }\n    }\n\n\n\n    @RequestMapping(\"/likeName\")\n    public List<Demo> likeName(String name){\n             PageHelper.startPage(1,1);\n             return demoService.likeName(name);\n    }\n\n\n##### 8.获取自增长ID\n\n\n    @Insert(\"insert into Demo(name,password) values(#{name},#{password})\")\n    public long save(Demo name);\n    \n    \n    @Options(useGeneratedKeys = true, keyProperty = \"id\", keyColumn = \"id\") \n\n\n\n\n\n\n\n","source":"_posts/SpringBoot.md","raw":"title: SpringBoot\nauthor: 小小冰弟\ndate: 2018-04-03 15:11:34\ntags: study\ncategories: Spring Boot\n---\n#### 一、什么是Spring Boot?\n###### Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。\n\n特性：\n- 创建独立的Spring应用程序\n- 嵌入的Tomcat，无需部署WAR文件\n- 简化Maven配置，自动配置Spring\n- 提供生产就绪型功能，如指标，健康检查和外部配置\n- 开箱即用，没有代码生成，也无需XML配置。\n\n\n#### 二、Spring Boot完美使用FastJson解析JSON数据\n##### 1.引入fastjson依赖库\n           \n           \n           <dependency>\n\t\t\t<groupId>com.alibaba</groupId>\n\t\t\t<artifactId>fastjson</artifactId>\n\t\t\t<version>1.2.15</version>\n          </dependency>\n\n##### 2.启动类继承extends WebMvcConfigurerAdapter\n\n##### 3.覆盖方法configureMessageConverters\n\n    @SpringBootApplication\n    public class ApiCoreApp  extends WebMvcConfigurerAdapter {\n\t\n\t@Override\n\tpublic void configureMessageConverters(List<HttpMessageConverter<?>> converters) {\n    \tsuper.configureMessageConverters(converters);\n\t\t\n        FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter();\n \n        FastJsonConfig fastJsonConfig = new FastJsonConfig();\n        fastJsonConfig.setSerializerFeatures(\n                SerializerFeature.PrettyFormat\n        );\n        fastConverter.setFastJsonConfig(fastJsonConfig);\n\t\t\n    \tconverters.add(fastConverter);\n\t}\n    }\n    \n #### 三、Spring Boot热部署\n \n \n为什么需要热部署呢，因为你会发现即使做了一点点的变更，你也许也需要重新部署，这在工作上简直太耽误时间了。\n \n 解决方法：\n          \n     在pom.xml文件添加依赖包：\n     <plugin>\n\t          \t\t<groupId>org.springframework.boot</groupId>\n\t          \t\t<artifactId>spring-boot-maven-plugin </artifactId>\n\t          \t\t<dependencies>  \n\t\t\t           <!--springloaded  hot deploy -->  \n\t\t\t           <dependency>  \n\t\t\t               <groupId>org.springframework</groupId>  \n\t\t\t               <artifactId>springloaded</artifactId>  \n\t\t\t               <version>1.2.4.RELEASE</version>\n\t\t\t           </dependency>  \n\t\t\t        </dependencies>  \n\t\t\t        <executions>  \n\t\t\t           <execution>  \n\t\t\t               <goals>  \n\t\t\t                   <goal>repackage</goal>  \n\t\t\t               </goals>  \n\t\t\t               <configuration>  \n\t\t\t                   <classifier>exec</classifier>  \n\t\t\t               </configuration>  \n\t\t\t           </execution>  \n\t\t       \t\t</executions>\n    </plugin>\n \n 使用spring-boot:run 作为 Goals（run as maven build）\n \n \n#### 四、springboot + devtools（热部署）\n\n- spring-boot-devtools 是一个为开发者服务的一个模块，其中最重要的功能就是自动应用代码更改到最新的App上面去。原理是在发现代码有更改之后，重新启动应用，但是速度比手动停止后再启动还要更快，更快指的不是节省出来的手工操作的时间。\n- 其深层原理是使用了两个ClassLoader，一个Classloader加载那些不会改变的类（第三方Jar包），另一个ClassLoader加载会更改的类，称为  restart ClassLoader,这样在有代码更改的时候，原来的restart ClassLoader 被丢弃，重新创建一个restart ClassLoader，由于需要加载的类相比较少，所以实现了较快的重启时间（5秒以内）\n\n ###### 步骤说明\n \n    添加依赖包： \n    <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <optional>true</optional>\n           <scope>true</scope>\n    </dependency>\n      添加spring-boot-maven-plugin：\n      <build>\n\t\t<plugins>\n\t\t    <plugin>\n\t            <groupId>org.springframework.boot</groupId>\n\t            <artifactId>spring-boot-maven-plugin</artifactId>\n\t            <configuration>\n\t          \t\t<!--fork :  如果没有该项配置，肯呢个devtools不会起作用，即应用不会restart -->\n\t                <fork>true</fork>\n\t            </configuration>\n\t        </plugin>\n\t\t</plugins>\n    </build>\n    \n###### 补充说明    \n1. devtools会监听classpath下的文件变动，并且会立即重启应用（发生在保存时机），注意：因为其采用的虚拟机机制，该项重启是很快的。\n2. devtools可以实现页面热部署（即页面修改后会立即生效，这个可以直接在application.properties文件中配置spring.thymeleaf.cache=false来实现(这里注意不同的模板配置不一样)\n \n    \n    \n#### 五、Spring Data\n*Spring Data是一个用于简化数据库访问，并支持云服务的开源框架。其主要目标是使得数据库的访问变得方便快捷，并支持map-reduce框架和云计算数据服务。此外，它还支持基于关系型数据库的数据服务，如Oracle RAC等。对于拥有海量数据的项目，可以用Spring Data来简化项目的开发，就如Spring Framework对JDBC、ORM的支持一样，Spring Data会让数据的访问变得更加方便*\n\n*可以极大的简化JPA的写法，可以在几乎不用写实现的情况下，实现对数据的访问和操作。除了CRUD外，还包括如分页、排序等一些常用的功能。所以Spring Data JPA的出现就是为了简化JPA的写法，让你只需要编写一个接口继承一个类就能实现CRUD操作了*\n\n\n\n步骤：\n    \n  >1.在pom.xml添加mysql,spring-data-jpa依赖;\n  \n  \n  \n  \n    <dependency>\n\t\t<groupId>mysql</groupId>\n\t\t<artifactId>mysql-connector-java</artifactId>\n    </dependency>\n\n\n    <dependency>\n\t\t    <groupId>org.springframework.boot</groupId>\n\t\t    <artifactId>spring-boot-starter-data-jpa</artifactId>\n    </dependency>\n\n\n>2.在application.properties文件中配置mysql连接配置文件;\n\n    spring.datasource.url = jdbc:mysql://localhost:3306/test\n    spring.datasource.username = root\n    spring.datasource.password = root\n    spring.datasource.driverClassName = com.mysql.jdbc.Driver\n    spring.datasource.max-active=20\n    spring.datasource.max-idle=8\n    spring.datasource.min-idle=8\n    spring.datasource.initial-size=10\n\n>3.在application.properties文件中配置JPA配置信息;\n\n    spring.jpa.database = MYSQL\n    #Show or not log for each sql query\n    spring.jpa.show-sql = true\n    #Hibernate ddl auto (create, create-drop, update)\n    spring.jpa.hibernate.ddl-auto = update\n    #Naming strategy\n    #[org.hibernate.cfg.ImprovedNamingStrategy  #org.hibernate.cfg.DefaultNamingStrategy]\n    spring.jpa.hibernate.naming-strategy = org.hibernate.cfg.ImprovedNamingStrategy\n    #stripped before adding them to the entity manager)\n    spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.MySQL5Dialect\n\n\n##### 重点：Repository接口\n\n 有这么几点需要强调下：\n1. Repository是一个空接口，即是一个标记接口；\n2. 若我们定义的接口继承了Repository，则该接口会被IOC容器识别为一个Repository Bean纳入到IOC容器中，进而可以在该接口中定义满足一定规范的方法。\n3. 实际上也可以通过@RepositoryDefinition,注解来替代继承Repository接口，查询方法以find | read | get开头；\n4. 涉及查询条件时，条件的属性用条件关键字连接，要注意的是条件属性以首字母大写。\n5. 使用@Query注解可以自定义JPQL语句实现更灵活的查询。\n\n\n\n\n\n\n\n\n##### CrudRepository 接口提供了最基本的对实体类的添删改查操作\n\n --T save(T entity);//保存单个实体   \n --Iterable<T> save(Iterable<? extends T> entities);//保存集合         \n --T findOne(ID id);//根据id查找实体          \n --Iterable<T> findAll();//查询所有实体,不用或慎用!          \n --long count();//查询实体数量          \n --void delete(ID id);//根据Id删除实体          \n --void delete(T entity);//删除一个实体   \n --void delete(Iterable<? extends T> entities);//删除一个实体的集合          \n --void deleteAll();//删除所有实体,不用或慎用!   \n\n\n\n#### 六、全局异常捕捉\n\n##### 步骤：\n\n\n    新建一个类GlobalDefaultExceptionHandler，\n    在class注解上@ControllerAdvice,\n    在方法上注解上@ExceptionHandler(value = Exception.class)\n    根据返回值判断要不要添加@responsebody注解\n    @ControllerAdvice\n    public class GlobalDefaultExceptionHandler{\n\t\n\t@ExceptionHandler(value = Exception.class)\n\tpublic void defaultErrorHandler(HttpServletRequest req, Exception e)  {\n    }\n\n #### 七、配置Server\n \n ##### 在application.properties进行配置：\n\n    #server.port=8080  端口号\n    #server.address= # bind to a specific NIC\n    #server.session-timeout= # session timeout in seconds\n    #the context path, defaults to '/'\n    #server.context-path=/spring-boot  访问路径\n    #server.servlet-path= # the servlet path, defaults to '/'\n    #server.tomcat.access-log-pattern= # log pattern of the access log\n    #server.tomcat.access-log-enabled=false # is access logging enabled\n    #server.tomcat.protocol-header=x-forwarded-proto # ssl forward headers\n    #server.tomcat.remote-ip-header=x-forwarded-for\n    #server.tomcat.basedir=/tmp # base dir (usually not needed, defaults to tmp)\n    #server.tomcat.background-processor-delay=30; # in seconds\n    #server.tomcat.max-threads = 0 # number of threads in protocol handler\n    #server.tomcat.uri-encoding = UTF-8 # character encoding to use for URL decoding\n\n\n#### 八、thymeleaf的使用\n\n\n##### 1.在pom.xml中引入thymeleaf\n\n\n    <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-thymeleaf</artifactId>\n    </dependency>\n\n\n##### 2.如何关闭thymeleaf缓存\n     ########################################################\n     ###THYMELEAF (ThymeleafAutoConfiguration)\n     ########################################################\n     #spring.thymeleaf.prefix=classpath:/templates/\n     #spring.thymeleaf.suffix=.html\n     #spring.thymeleaf.mode=HTML5\n     #spring.thymeleaf.encoding=UTF-8\n     # ;charset=<encoding> is added\n     #spring.thymeleaf.content-type=text/html \n     # set to false for hot refresh\n     spring.thymeleaf.cache=false   关闭缓存\n\n###### 3.编写模板文件.html\n\n    编写模板文件src/main/resouces/templates/hello.html:\n\n    <!DOCTYPE html>\n    <html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:th=\"http://www.thymeleaf.org\"\n          xmlns:sec=\"http://www.thymeleaf.org/thymeleaf-extras-springsecurity3\">\n        <head>\n            <title>Hello World!</title>\n        </head>\n        <body>\n            <h1 th:inline=\"text\">Hello.v.2</h1>\n            <p th:text=\"${hello}\"></p>\n        </body>\n    </html>\n\n##### 4.编写访问模板文件controller\n\n    @Controller\n    public class TemplateController {\n\n        /**\n         * 返回html模板.\n         */\n        @RequestMapping(\"/helloHtml\")\n        public String helloHtml(Map<String,Object> map){\n            map.put(\"hello\",\"from TemplateController.helloHtml\");\n            return \"/helloHtml\";\n        }\n\n    }\n\n#### 九、freemarker的使用\n\n##### 1.在pom.xml中引入freemarker\n\n    <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-freemarker</artifactId>\n    </dependency>\n\n##### 2.如何关闭freemarker缓存\n\n\n    ########################################################\n    ###FREEMARKER (FreeMarkerAutoConfiguration)\n    ########################################################\n    spring.freemarker.allow-request-override=false\n    spring.freemarker.cache=true\n    spring.freemarker.check-template-location=true\n    spring.freemarker.charset=UTF-8\n    spring.freemarker.content-type=text/html\n    spring.freemarker.expose-request-attributes=false\n    spring.freemarker.expose-session-attributes=false\n    spring.freemarker.expose-spring-macro-helpers=false\n    #spring.freemarker.prefix=\n    #spring.freemarker.request-context-attribute=\n    #spring.freemarker.settings.*=\n    #spring.freemarker.suffix=.ftl\n    #spring.freemarker.template-loader-path=classpath:/templates/ #comma-separated list\n    #spring.freemarker.view-names= # whitelist of view names that can be resolved\n\n\n##### 3.编写模板文件.ftl\n\n\n    <!DOCTYPE html>\n    <html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:th=\"http://www.thymeleaf.org\"\n          xmlns:sec=\"http://www.thymeleaf.org/thymeleaf-extras-springsecurity3\">\n        <head>\n            <title>Hello World!</title>\n        </head>\n        <body>\n            <h1>Hello.v.2</h1>\n            <p>${hello}</p>\n        </body>\n    </html>\n\n\n##### 4.编写访问文件的controller\n  \n  \n     @RequestMapping(\"/helloFtl\")\n      public String helloFtl(Map<String,Object> map){\n          map.put(\"hello\",\"from TemplateController.helloFtl\");\n          return \"/helloFtl\";\n      }\n\n\n#### 十、jsp的使用\n\n\n##### 1.创建Maven web project\n\n##### 2.在pom.xml文件添加依赖\n\n\n      <!-- web支持: 1、web mvc; 2、restful; 3、jackjson支持; 4、aop ........ -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-web</artifactId>\n\t\t</dependency>\n\n     <!-- servlet 依赖. -->\n\t\t<dependency>\n\t\t\t<groupId>javax.servlet</groupId>\n\t\t\t<artifactId>javax.servlet-api</artifactId>\n\t\t\t<scope>provided</scope>\n\t\t</dependency>\n\n\n\n    JSTL（JSP Standard Tag Library，JSP标准标签库)是一个不断完善的开放源代码的JSP标签库，是由apache的jakarta小组来维护的。\n    <dependency>\n                <groupId>javax.servlet</groupId>\n                <artifactId>jstl</artifactId>\n            </dependency>\n\n    <!-- tomcat 的支持.-->\n            <dependency>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-starter-tomcat</artifactId>\n                <scope>provided</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.tomcat.embed</groupId>\n                <artifactId>tomcat-embed-jasper</artifactId>\n                <scope>provided</scope>\n            </dependency>\n\n##### 3.application.properties配置\n\n    添加src/main/resources/application.properties：\n\n    # 页面默认前缀目录\n    spring.mvc.view.prefix=/WEB-INF/jsp/\n    # 响应页面默认后缀\n    spring.mvc.view.suffix=.jsp\n    # 自定义属性，可以在Controller中读取\n    application.hello=Hello Angel From application\n\n##### 4.编写controller\n\n\n    @Controller\n    public class HelloController {\n    private String hello;    \n\n        @RequestMapping(\"/helloJsp\")\n        public String helloJsp(Map<String,Object> map){\n            System.out.println(\"HelloController.helloJsp().hello=hello\");\n            map.put(\"hello\", hello);\n            return \"helloJsp\";\n        }\n    }\n##### 5.编写jsp页面\n\n    在 src/main 下面创建 webapp/WEB-INF/jsp 目录用来存放我们的jsp页面：helloJsp.jsp:\n\n    <%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\"\n        pageEncoding=\"UTF-8\"%>\n    <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n    <html>\n    <head>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n    <title>Insert title here</title>\n    </head>\n    <body>\n        helloJsp\n        <hr>\n        ${hello}\n\n    </body>\n    </html>\n\n#### 十一、Mybatis的引用\n\n\n##### 1.在pom.xml文件中引入相关依赖\n\n\n    （1）基本依赖，jdk版本号；\n    （2）mysql驱动，mybatis依赖包，mysql分页PageHelper:\n\n    <!-- mysql 数据库驱动. -->\n        <dependency>\n            <groupId>mysql</groupId>\n            <artifactId>mysql-connector-java</artifactId>\n    </dependency>\t\n    \n    \n    <!-- \n    \tMyBatis提供了拦截器接口，我们可以实现自己的拦截器，\n    \t将其作为一个plugin装入到SqlSessionFactory中。 \n\t\tGithub上有位开发者写了一个分页插件，我觉得使用起来还可以，挺方便的。 \n\t\tGithub项目地址： https://github.com/pagehelper/Mybatis-PageHelper\n     -->\t\n    <dependency>\n\t    <groupId>com.github.pagehelper</groupId>\n\t    <artifactId>pagehelper</artifactId>\n\t    <version>4.1.0</version>\n\t</dependency>\t\n\n    \n    \n    \n\n\n##### 2.在application.properties添加配置文件\n\n    ########################################################\n    ###datasource\n    ########################################################\n    spring.datasource.url = jdbc:mysql://localhost:3306/test\n    spring.datasource.username = root\n    spring.datasource.password = root\n    spring.datasource.driverClassName = com.mysql.jdbc.Driver\n    spring.datasource.max-active=20\n    spring.datasource.max-idle=8\n    spring.datasource.min-idle=8\n    spring.datasource.initial-size=10\n\n\n\n##### 3.编写Demo测试类\n\n\n    public class Demo {\n\tprivate long id;\n\tprivate String name;\n      //省略getter and setter….\n    }\n\n\n\n##### 4.编写demoMapper\n\n    public interface DemoMappper {\n\t\n\t@Select(\"select *from Demo where name = #{name}\")\n\tpublic List<Demo> likeName(String name);\n\t\n\t@Select(\"select *from Demo where id = #{id}\")\n\tpublic Demo getById(long id);\n\t\n\t@Select(\"select name from Demo where id = #{id}\")\n\tpublic String getNameById(long id);\n    }\n\n\n##### 5.编写demoService\n\n    @Service\n    public class DemoService {\n        @Autowired\n        private DemoMappper demoMappper;\n\n        public List<Demo> likeName(String name){\n            return demoMappper.likeName(name);\n        }\n    }\n\n\n##### 6.编写demoController\n    @RestController\n    public class DemoController {\n        @Autowired\n        private DemoService demoService;\n\n        @RequestMapping(\"/likeName\")\n        public List<Demo> likeName(String name){\n            return demoService.likeName(name);\n        }\n\n    }\n\n##### 7.加入PageHelper\n\n\n    @Configuration\n    public class MyBatisConfiguration {\n\n        @Bean\n        public PageHelper pageHelper() {\n            System.out.println(\"MyBatisConfiguration.pageHelper()\");\n            PageHelper pageHelper = new PageHelper();\n            Properties p = new Properties();\n            p.setProperty(\"offsetAsPageNum\", \"true\");\n            p.setProperty(\"rowBoundsWithCount\", \"true\");\n            p.setProperty(\"reasonable\", \"true\");\n            pageHelper.setProperties(p);\n            return pageHelper;\n        }\n    }\n\n\n\n    @RequestMapping(\"/likeName\")\n    public List<Demo> likeName(String name){\n             PageHelper.startPage(1,1);\n             return demoService.likeName(name);\n    }\n\n\n##### 8.获取自增长ID\n\n\n    @Insert(\"insert into Demo(name,password) values(#{name},#{password})\")\n    public long save(Demo name);\n    \n    \n    @Options(useGeneratedKeys = true, keyProperty = \"id\", keyColumn = \"id\") \n\n\n\n\n\n\n\n","slug":"SpringBoot","published":1,"updated":"2018-04-04T06:28:00.538Z","_id":"cjfjbw8ji0000io7kmi5xgkcr","comments":1,"layout":"post","photos":[],"link":"","content":"<h4 id=\"一、什么是Spring-Boot\"><a href=\"#一、什么是Spring-Boot\" class=\"headerlink\" title=\"一、什么是Spring Boot?\"></a>一、什么是Spring Boot?</h4><h6 id=\"Spring-Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。\"><a href=\"#Spring-Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。\" class=\"headerlink\" title=\"Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。\"></a>Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。</h6><p>特性：</p>\n<ul>\n<li>创建独立的Spring应用程序</li>\n<li>嵌入的Tomcat，无需部署WAR文件</li>\n<li>简化Maven配置，自动配置Spring</li>\n<li>提供生产就绪型功能，如指标，健康检查和外部配置</li>\n<li>开箱即用，没有代码生成，也无需XML配置。</li>\n</ul>\n<h4 id=\"二、Spring-Boot完美使用FastJson解析JSON数据\"><a href=\"#二、Spring-Boot完美使用FastJson解析JSON数据\" class=\"headerlink\" title=\"二、Spring Boot完美使用FastJson解析JSON数据\"></a>二、Spring Boot完美使用FastJson解析JSON数据</h4><h5 id=\"1-引入fastjson依赖库\"><a href=\"#1-引入fastjson依赖库\" class=\"headerlink\" title=\"1.引入fastjson依赖库\"></a>1.引入fastjson依赖库</h5><pre><code> &lt;dependency&gt;\n  &lt;groupId&gt;com.alibaba&lt;/groupId&gt;\n  &lt;artifactId&gt;fastjson&lt;/artifactId&gt;\n  &lt;version&gt;1.2.15&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre><h5 id=\"2-启动类继承extends-WebMvcConfigurerAdapter\"><a href=\"#2-启动类继承extends-WebMvcConfigurerAdapter\" class=\"headerlink\" title=\"2.启动类继承extends WebMvcConfigurerAdapter\"></a>2.启动类继承extends WebMvcConfigurerAdapter</h5><h5 id=\"3-覆盖方法configureMessageConverters\"><a href=\"#3-覆盖方法configureMessageConverters\" class=\"headerlink\" title=\"3.覆盖方法configureMessageConverters\"></a>3.覆盖方法configureMessageConverters</h5><pre><code>@SpringBootApplication\npublic class ApiCoreApp  extends WebMvcConfigurerAdapter {\n\n@Override\npublic void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {\n    super.configureMessageConverters(converters);\n\n    FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter();\n\n    FastJsonConfig fastJsonConfig = new FastJsonConfig();\n    fastJsonConfig.setSerializerFeatures(\n            SerializerFeature.PrettyFormat\n    );\n    fastConverter.setFastJsonConfig(fastJsonConfig);\n\n    converters.add(fastConverter);\n}\n}\n</code></pre><h4 id=\"三、Spring-Boot热部署\"><a href=\"#三、Spring-Boot热部署\" class=\"headerlink\" title=\"三、Spring Boot热部署\"></a>三、Spring Boot热部署</h4><p>为什么需要热部署呢，因为你会发现即使做了一点点的变更，你也许也需要重新部署，这在工作上简直太耽误时间了。</p>\n<p> 解决方法：</p>\n<pre><code> 在pom.xml文件添加依赖包：\n &lt;plugin&gt;\n                  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                  &lt;artifactId&gt;spring-boot-maven-plugin &lt;/artifactId&gt;\n                  &lt;dependencies&gt;  \n                   &lt;!--springloaded  hot deploy --&gt;  \n                   &lt;dependency&gt;  \n                       &lt;groupId&gt;org.springframework&lt;/groupId&gt;  \n                       &lt;artifactId&gt;springloaded&lt;/artifactId&gt;  \n                       &lt;version&gt;1.2.4.RELEASE&lt;/version&gt;\n                   &lt;/dependency&gt;  \n                &lt;/dependencies&gt;  \n                &lt;executions&gt;  \n                   &lt;execution&gt;  \n                       &lt;goals&gt;  \n                           &lt;goal&gt;repackage&lt;/goal&gt;  \n                       &lt;/goals&gt;  \n                       &lt;configuration&gt;  \n                           &lt;classifier&gt;exec&lt;/classifier&gt;  \n                       &lt;/configuration&gt;  \n                   &lt;/execution&gt;  \n                   &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre><p> 使用spring-boot:run 作为 Goals（run as maven build）</p>\n<h4 id=\"四、springboot-devtools（热部署）\"><a href=\"#四、springboot-devtools（热部署）\" class=\"headerlink\" title=\"四、springboot + devtools（热部署）\"></a>四、springboot + devtools（热部署）</h4><ul>\n<li>spring-boot-devtools 是一个为开发者服务的一个模块，其中最重要的功能就是自动应用代码更改到最新的App上面去。原理是在发现代码有更改之后，重新启动应用，但是速度比手动停止后再启动还要更快，更快指的不是节省出来的手工操作的时间。</li>\n<li><p>其深层原理是使用了两个ClassLoader，一个Classloader加载那些不会改变的类（第三方Jar包），另一个ClassLoader加载会更改的类，称为  restart ClassLoader,这样在有代码更改的时候，原来的restart ClassLoader 被丢弃，重新创建一个restart ClassLoader，由于需要加载的类相比较少，所以实现了较快的重启时间（5秒以内）</p>\n<h6 id=\"步骤说明\"><a href=\"#步骤说明\" class=\"headerlink\" title=\"步骤说明\"></a>步骤说明</h6><p>  添加依赖包：<br>  <dependency></dependency></p>\n<pre><code> &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;\n &lt;optional&gt;true&lt;/optional&gt;\n&lt;scope&gt;true&lt;/scope&gt;\n</code></pre><p>  </p>\n<pre><code>添加spring-boot-maven-plugin：\n&lt;build&gt;\n  &lt;plugins&gt;\n      &lt;plugin&gt;\n          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n          &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n          &lt;configuration&gt;\n                &lt;!--fork :  如果没有该项配置，肯呢个devtools不会起作用，即应用不会restart --&gt;\n              &lt;fork&gt;true&lt;/fork&gt;\n          &lt;/configuration&gt;\n      &lt;/plugin&gt;\n  &lt;/plugins&gt;\n</code></pre><p>  </p>\n</li>\n</ul>\n<h6 id=\"补充说明\"><a href=\"#补充说明\" class=\"headerlink\" title=\"补充说明\"></a>补充说明</h6><ol>\n<li>devtools会监听classpath下的文件变动，并且会立即重启应用（发生在保存时机），注意：因为其采用的虚拟机机制，该项重启是很快的。</li>\n<li>devtools可以实现页面热部署（即页面修改后会立即生效，这个可以直接在application.properties文件中配置spring.thymeleaf.cache=false来实现(这里注意不同的模板配置不一样)</li>\n</ol>\n<h4 id=\"五、Spring-Data\"><a href=\"#五、Spring-Data\" class=\"headerlink\" title=\"五、Spring Data\"></a>五、Spring Data</h4><p><em>Spring Data是一个用于简化数据库访问，并支持云服务的开源框架。其主要目标是使得数据库的访问变得方便快捷，并支持map-reduce框架和云计算数据服务。此外，它还支持基于关系型数据库的数据服务，如Oracle RAC等。对于拥有海量数据的项目，可以用Spring Data来简化项目的开发，就如Spring Framework对JDBC、ORM的支持一样，Spring Data会让数据的访问变得更加方便</em></p>\n<p><em>可以极大的简化JPA的写法，可以在几乎不用写实现的情况下，实现对数据的访问和操作。除了CRUD外，还包括如分页、排序等一些常用的功能。所以Spring Data JPA的出现就是为了简化JPA的写法，让你只需要编写一个接口继承一个类就能实现CRUD操作了</em></p>\n<p>步骤：</p>\n<blockquote>\n<p>1.在pom.xml添加mysql,spring-data-jpa依赖;</p>\n</blockquote>\n<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;mysql&lt;/groupId&gt;\n    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n\n&lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre><blockquote>\n<p>2.在application.properties文件中配置mysql连接配置文件;</p>\n</blockquote>\n<pre><code>spring.datasource.url = jdbc:mysql://localhost:3306/test\nspring.datasource.username = root\nspring.datasource.password = root\nspring.datasource.driverClassName = com.mysql.jdbc.Driver\nspring.datasource.max-active=20\nspring.datasource.max-idle=8\nspring.datasource.min-idle=8\nspring.datasource.initial-size=10\n</code></pre><blockquote>\n<p>3.在application.properties文件中配置JPA配置信息;</p>\n</blockquote>\n<pre><code>spring.jpa.database = MYSQL\n#Show or not log for each sql query\nspring.jpa.show-sql = true\n#Hibernate ddl auto (create, create-drop, update)\nspring.jpa.hibernate.ddl-auto = update\n#Naming strategy\n#[org.hibernate.cfg.ImprovedNamingStrategy  #org.hibernate.cfg.DefaultNamingStrategy]\nspring.jpa.hibernate.naming-strategy = org.hibernate.cfg.ImprovedNamingStrategy\n#stripped before adding them to the entity manager)\nspring.jpa.properties.hibernate.dialect = org.hibernate.dialect.MySQL5Dialect\n</code></pre><h5 id=\"重点：Repository接口\"><a href=\"#重点：Repository接口\" class=\"headerlink\" title=\"重点：Repository接口\"></a>重点：Repository接口</h5><p> 有这么几点需要强调下：</p>\n<ol>\n<li>Repository是一个空接口，即是一个标记接口；</li>\n<li>若我们定义的接口继承了Repository，则该接口会被IOC容器识别为一个Repository Bean纳入到IOC容器中，进而可以在该接口中定义满足一定规范的方法。</li>\n<li>实际上也可以通过@RepositoryDefinition,注解来替代继承Repository接口，查询方法以find | read | get开头；</li>\n<li>涉及查询条件时，条件的属性用条件关键字连接，要注意的是条件属性以首字母大写。</li>\n<li>使用@Query注解可以自定义JPQL语句实现更灵活的查询。</li>\n</ol>\n<h5 id=\"CrudRepository-接口提供了最基本的对实体类的添删改查操作\"><a href=\"#CrudRepository-接口提供了最基本的对实体类的添删改查操作\" class=\"headerlink\" title=\"CrudRepository 接口提供了最基本的对实体类的添删改查操作\"></a>CrudRepository 接口提供了最基本的对实体类的添删改查操作</h5><p> –T save(T entity);//保存单个实体<br> –Iterable<t> save(Iterable&lt;? extends T&gt; entities);//保存集合<br> –T findOne(ID id);//根据id查找实体<br> –Iterable<t> findAll();//查询所有实体,不用或慎用!<br> –long count();//查询实体数量<br> –void delete(ID id);//根据Id删除实体<br> –void delete(T entity);//删除一个实体<br> –void delete(Iterable&lt;? extends T&gt; entities);//删除一个实体的集合<br> –void deleteAll();//删除所有实体,不用或慎用!   </t></t></p>\n<h4 id=\"六、全局异常捕捉\"><a href=\"#六、全局异常捕捉\" class=\"headerlink\" title=\"六、全局异常捕捉\"></a>六、全局异常捕捉</h4><h5 id=\"步骤：\"><a href=\"#步骤：\" class=\"headerlink\" title=\"步骤：\"></a>步骤：</h5><pre><code>新建一个类GlobalDefaultExceptionHandler，\n在class注解上@ControllerAdvice,\n在方法上注解上@ExceptionHandler(value = Exception.class)\n根据返回值判断要不要添加@responsebody注解\n@ControllerAdvice\npublic class GlobalDefaultExceptionHandler{\n\n@ExceptionHandler(value = Exception.class)\npublic void defaultErrorHandler(HttpServletRequest req, Exception e)  {\n}\n</code></pre><h4 id=\"七、配置Server\"><a href=\"#七、配置Server\" class=\"headerlink\" title=\"七、配置Server\"></a>七、配置Server</h4><h5 id=\"在application-properties进行配置：\"><a href=\"#在application-properties进行配置：\" class=\"headerlink\" title=\"在application.properties进行配置：\"></a>在application.properties进行配置：</h5><pre><code>#server.port=8080  端口号\n#server.address= # bind to a specific NIC\n#server.session-timeout= # session timeout in seconds\n#the context path, defaults to &apos;/&apos;\n#server.context-path=/spring-boot  访问路径\n#server.servlet-path= # the servlet path, defaults to &apos;/&apos;\n#server.tomcat.access-log-pattern= # log pattern of the access log\n#server.tomcat.access-log-enabled=false # is access logging enabled\n#server.tomcat.protocol-header=x-forwarded-proto # ssl forward headers\n#server.tomcat.remote-ip-header=x-forwarded-for\n#server.tomcat.basedir=/tmp # base dir (usually not needed, defaults to tmp)\n#server.tomcat.background-processor-delay=30; # in seconds\n#server.tomcat.max-threads = 0 # number of threads in protocol handler\n#server.tomcat.uri-encoding = UTF-8 # character encoding to use for URL decoding\n</code></pre><h4 id=\"八、thymeleaf的使用\"><a href=\"#八、thymeleaf的使用\" class=\"headerlink\" title=\"八、thymeleaf的使用\"></a>八、thymeleaf的使用</h4><h5 id=\"1-在pom-xml中引入thymeleaf\"><a href=\"#1-在pom-xml中引入thymeleaf\" class=\"headerlink\" title=\"1.在pom.xml中引入thymeleaf\"></a>1.在pom.xml中引入thymeleaf</h5><pre><code>&lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre><h5 id=\"2-如何关闭thymeleaf缓存\"><a href=\"#2-如何关闭thymeleaf缓存\" class=\"headerlink\" title=\"2.如何关闭thymeleaf缓存\"></a>2.如何关闭thymeleaf缓存</h5><pre><code>########################################################\n###THYMELEAF (ThymeleafAutoConfiguration)\n########################################################\n#spring.thymeleaf.prefix=classpath:/templates/\n#spring.thymeleaf.suffix=.html\n#spring.thymeleaf.mode=HTML5\n#spring.thymeleaf.encoding=UTF-8\n# ;charset=&lt;encoding&gt; is added\n#spring.thymeleaf.content-type=text/html \n# set to false for hot refresh\nspring.thymeleaf.cache=false   关闭缓存\n</code></pre><h6 id=\"3-编写模板文件-html\"><a href=\"#3-编写模板文件-html\" class=\"headerlink\" title=\"3.编写模板文件.html\"></a>3.编写模板文件.html</h6><pre><code>编写模板文件src/main/resouces/templates/hello.html:\n\n&lt;!DOCTYPE html&gt;\n&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;\n      xmlns:sec=&quot;http://www.thymeleaf.org/thymeleaf-extras-springsecurity3&quot;&gt;\n    &lt;head&gt;\n        &lt;title&gt;Hello World!&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1 th:inline=&quot;text&quot;&gt;Hello.v.2&lt;/h1&gt;\n        &lt;p th:text=&quot;${hello}&quot;&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre><h5 id=\"4-编写访问模板文件controller\"><a href=\"#4-编写访问模板文件controller\" class=\"headerlink\" title=\"4.编写访问模板文件controller\"></a>4.编写访问模板文件controller</h5><pre><code>@Controller\npublic class TemplateController {\n\n    /**\n     * 返回html模板.\n     */\n    @RequestMapping(&quot;/helloHtml&quot;)\n    public String helloHtml(Map&lt;String,Object&gt; map){\n        map.put(&quot;hello&quot;,&quot;from TemplateController.helloHtml&quot;);\n        return &quot;/helloHtml&quot;;\n    }\n\n}\n</code></pre><h4 id=\"九、freemarker的使用\"><a href=\"#九、freemarker的使用\" class=\"headerlink\" title=\"九、freemarker的使用\"></a>九、freemarker的使用</h4><h5 id=\"1-在pom-xml中引入freemarker\"><a href=\"#1-在pom-xml中引入freemarker\" class=\"headerlink\" title=\"1.在pom.xml中引入freemarker\"></a>1.在pom.xml中引入freemarker</h5><pre><code>&lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre><h5 id=\"2-如何关闭freemarker缓存\"><a href=\"#2-如何关闭freemarker缓存\" class=\"headerlink\" title=\"2.如何关闭freemarker缓存\"></a>2.如何关闭freemarker缓存</h5><pre><code>########################################################\n###FREEMARKER (FreeMarkerAutoConfiguration)\n########################################################\nspring.freemarker.allow-request-override=false\nspring.freemarker.cache=true\nspring.freemarker.check-template-location=true\nspring.freemarker.charset=UTF-8\nspring.freemarker.content-type=text/html\nspring.freemarker.expose-request-attributes=false\nspring.freemarker.expose-session-attributes=false\nspring.freemarker.expose-spring-macro-helpers=false\n#spring.freemarker.prefix=\n#spring.freemarker.request-context-attribute=\n#spring.freemarker.settings.*=\n#spring.freemarker.suffix=.ftl\n#spring.freemarker.template-loader-path=classpath:/templates/ #comma-separated list\n#spring.freemarker.view-names= # whitelist of view names that can be resolved\n</code></pre><h5 id=\"3-编写模板文件-ftl\"><a href=\"#3-编写模板文件-ftl\" class=\"headerlink\" title=\"3.编写模板文件.ftl\"></a>3.编写模板文件.ftl</h5><pre><code>&lt;!DOCTYPE html&gt;\n&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;\n      xmlns:sec=&quot;http://www.thymeleaf.org/thymeleaf-extras-springsecurity3&quot;&gt;\n    &lt;head&gt;\n        &lt;title&gt;Hello World!&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1&gt;Hello.v.2&lt;/h1&gt;\n        &lt;p&gt;${hello}&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre><h5 id=\"4-编写访问文件的controller\"><a href=\"#4-编写访问文件的controller\" class=\"headerlink\" title=\"4.编写访问文件的controller\"></a>4.编写访问文件的controller</h5><pre><code>@RequestMapping(&quot;/helloFtl&quot;)\n public String helloFtl(Map&lt;String,Object&gt; map){\n     map.put(&quot;hello&quot;,&quot;from TemplateController.helloFtl&quot;);\n     return &quot;/helloFtl&quot;;\n }\n</code></pre><h4 id=\"十、jsp的使用\"><a href=\"#十、jsp的使用\" class=\"headerlink\" title=\"十、jsp的使用\"></a>十、jsp的使用</h4><h5 id=\"1-创建Maven-web-project\"><a href=\"#1-创建Maven-web-project\" class=\"headerlink\" title=\"1.创建Maven web project\"></a>1.创建Maven web project</h5><h5 id=\"2-在pom-xml文件添加依赖\"><a href=\"#2-在pom-xml文件添加依赖\" class=\"headerlink\" title=\"2.在pom.xml文件添加依赖\"></a>2.在pom.xml文件添加依赖</h5><pre><code>  &lt;!-- web支持: 1、web mvc; 2、restful; 3、jackjson支持; 4、aop ........ --&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n\n &lt;!-- servlet 依赖. --&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;javax.servlet&lt;/groupId&gt;\n        &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;\n        &lt;scope&gt;provided&lt;/scope&gt;\n    &lt;/dependency&gt;\n\n\n\nJSTL（JSP Standard Tag Library，JSP标准标签库)是一个不断完善的开放源代码的JSP标签库，是由apache的jakarta小组来维护的。\n&lt;dependency&gt;\n            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;\n            &lt;artifactId&gt;jstl&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n&lt;!-- tomcat 的支持.--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;\n            &lt;scope&gt;provided&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;\n            &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;\n            &lt;scope&gt;provided&lt;/scope&gt;\n        &lt;/dependency&gt;\n</code></pre><h5 id=\"3-application-properties配置\"><a href=\"#3-application-properties配置\" class=\"headerlink\" title=\"3.application.properties配置\"></a>3.application.properties配置</h5><pre><code>添加src/main/resources/application.properties：\n\n# 页面默认前缀目录\nspring.mvc.view.prefix=/WEB-INF/jsp/\n# 响应页面默认后缀\nspring.mvc.view.suffix=.jsp\n# 自定义属性，可以在Controller中读取\napplication.hello=Hello Angel From application\n</code></pre><h5 id=\"4-编写controller\"><a href=\"#4-编写controller\" class=\"headerlink\" title=\"4.编写controller\"></a>4.编写controller</h5><pre><code>@Controller\npublic class HelloController {\nprivate String hello;    \n\n    @RequestMapping(&quot;/helloJsp&quot;)\n    public String helloJsp(Map&lt;String,Object&gt; map){\n        System.out.println(&quot;HelloController.helloJsp().hello=hello&quot;);\n        map.put(&quot;hello&quot;, hello);\n        return &quot;helloJsp&quot;;\n    }\n}\n</code></pre><h5 id=\"5-编写jsp页面\"><a href=\"#5-编写jsp页面\" class=\"headerlink\" title=\"5.编写jsp页面\"></a>5.编写jsp页面</h5><pre><code>在 src/main 下面创建 webapp/WEB-INF/jsp 目录用来存放我们的jsp页面：helloJsp.jsp:\n\n&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot;\n    pageEncoding=&quot;UTF-8&quot;%&gt;\n&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;\n&lt;title&gt;Insert title here&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    helloJsp\n    &lt;hr&gt;\n    ${hello}\n\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre><h4 id=\"十一、Mybatis的引用\"><a href=\"#十一、Mybatis的引用\" class=\"headerlink\" title=\"十一、Mybatis的引用\"></a>十一、Mybatis的引用</h4><h5 id=\"1-在pom-xml文件中引入相关依赖\"><a href=\"#1-在pom-xml文件中引入相关依赖\" class=\"headerlink\" title=\"1.在pom.xml文件中引入相关依赖\"></a>1.在pom.xml文件中引入相关依赖</h5><pre><code>（1）基本依赖，jdk版本号；\n（2）mysql驱动，mybatis依赖包，mysql分页PageHelper:\n\n&lt;!-- mysql 数据库驱动. --&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;mysql&lt;/groupId&gt;\n        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;\n&lt;/dependency&gt;    \n\n\n&lt;!-- \n    MyBatis提供了拦截器接口，我们可以实现自己的拦截器，\n    将其作为一个plugin装入到SqlSessionFactory中。 \n    Github上有位开发者写了一个分页插件，我觉得使用起来还可以，挺方便的。 \n    Github项目地址： https://github.com/pagehelper/Mybatis-PageHelper\n --&gt;    \n&lt;dependency&gt;\n    &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;\n    &lt;artifactId&gt;pagehelper&lt;/artifactId&gt;\n    &lt;version&gt;4.1.0&lt;/version&gt;\n&lt;/dependency&gt;    \n</code></pre><h5 id=\"2-在application-properties添加配置文件\"><a href=\"#2-在application-properties添加配置文件\" class=\"headerlink\" title=\"2.在application.properties添加配置文件\"></a>2.在application.properties添加配置文件</h5><pre><code>########################################################\n###datasource\n########################################################\nspring.datasource.url = jdbc:mysql://localhost:3306/test\nspring.datasource.username = root\nspring.datasource.password = root\nspring.datasource.driverClassName = com.mysql.jdbc.Driver\nspring.datasource.max-active=20\nspring.datasource.max-idle=8\nspring.datasource.min-idle=8\nspring.datasource.initial-size=10\n</code></pre><h5 id=\"3-编写Demo测试类\"><a href=\"#3-编写Demo测试类\" class=\"headerlink\" title=\"3.编写Demo测试类\"></a>3.编写Demo测试类</h5><pre><code>public class Demo {\nprivate long id;\nprivate String name;\n  //省略getter and setter….\n}\n</code></pre><h5 id=\"4-编写demoMapper\"><a href=\"#4-编写demoMapper\" class=\"headerlink\" title=\"4.编写demoMapper\"></a>4.编写demoMapper</h5><pre><code>public interface DemoMappper {\n\n@Select(&quot;select *from Demo where name = #{name}&quot;)\npublic List&lt;Demo&gt; likeName(String name);\n\n@Select(&quot;select *from Demo where id = #{id}&quot;)\npublic Demo getById(long id);\n\n@Select(&quot;select name from Demo where id = #{id}&quot;)\npublic String getNameById(long id);\n}\n</code></pre><h5 id=\"5-编写demoService\"><a href=\"#5-编写demoService\" class=\"headerlink\" title=\"5.编写demoService\"></a>5.编写demoService</h5><pre><code>@Service\npublic class DemoService {\n    @Autowired\n    private DemoMappper demoMappper;\n\n    public List&lt;Demo&gt; likeName(String name){\n        return demoMappper.likeName(name);\n    }\n}\n</code></pre><h5 id=\"6-编写demoController\"><a href=\"#6-编写demoController\" class=\"headerlink\" title=\"6.编写demoController\"></a>6.编写demoController</h5><pre><code>@RestController\npublic class DemoController {\n    @Autowired\n    private DemoService demoService;\n\n    @RequestMapping(&quot;/likeName&quot;)\n    public List&lt;Demo&gt; likeName(String name){\n        return demoService.likeName(name);\n    }\n\n}\n</code></pre><h5 id=\"7-加入PageHelper\"><a href=\"#7-加入PageHelper\" class=\"headerlink\" title=\"7.加入PageHelper\"></a>7.加入PageHelper</h5><pre><code>@Configuration\npublic class MyBatisConfiguration {\n\n    @Bean\n    public PageHelper pageHelper() {\n        System.out.println(&quot;MyBatisConfiguration.pageHelper()&quot;);\n        PageHelper pageHelper = new PageHelper();\n        Properties p = new Properties();\n        p.setProperty(&quot;offsetAsPageNum&quot;, &quot;true&quot;);\n        p.setProperty(&quot;rowBoundsWithCount&quot;, &quot;true&quot;);\n        p.setProperty(&quot;reasonable&quot;, &quot;true&quot;);\n        pageHelper.setProperties(p);\n        return pageHelper;\n    }\n}\n\n\n\n@RequestMapping(&quot;/likeName&quot;)\npublic List&lt;Demo&gt; likeName(String name){\n         PageHelper.startPage(1,1);\n         return demoService.likeName(name);\n}\n</code></pre><h5 id=\"8-获取自增长ID\"><a href=\"#8-获取自增长ID\" class=\"headerlink\" title=\"8.获取自增长ID\"></a>8.获取自增长ID</h5><pre><code>@Insert(&quot;insert into Demo(name,password) values(#{name},#{password})&quot;)\npublic long save(Demo name);\n\n\n@Options(useGeneratedKeys = true, keyProperty = &quot;id&quot;, keyColumn = &quot;id&quot;) \n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"一、什么是Spring-Boot\"><a href=\"#一、什么是Spring-Boot\" class=\"headerlink\" title=\"一、什么是Spring Boot?\"></a>一、什么是Spring Boot?</h4><h6 id=\"Spring-Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。\"><a href=\"#Spring-Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。\" class=\"headerlink\" title=\"Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。\"></a>Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。</h6><p>特性：</p>\n<ul>\n<li>创建独立的Spring应用程序</li>\n<li>嵌入的Tomcat，无需部署WAR文件</li>\n<li>简化Maven配置，自动配置Spring</li>\n<li>提供生产就绪型功能，如指标，健康检查和外部配置</li>\n<li>开箱即用，没有代码生成，也无需XML配置。</li>\n</ul>\n<h4 id=\"二、Spring-Boot完美使用FastJson解析JSON数据\"><a href=\"#二、Spring-Boot完美使用FastJson解析JSON数据\" class=\"headerlink\" title=\"二、Spring Boot完美使用FastJson解析JSON数据\"></a>二、Spring Boot完美使用FastJson解析JSON数据</h4><h5 id=\"1-引入fastjson依赖库\"><a href=\"#1-引入fastjson依赖库\" class=\"headerlink\" title=\"1.引入fastjson依赖库\"></a>1.引入fastjson依赖库</h5><pre><code> &lt;dependency&gt;\n  &lt;groupId&gt;com.alibaba&lt;/groupId&gt;\n  &lt;artifactId&gt;fastjson&lt;/artifactId&gt;\n  &lt;version&gt;1.2.15&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre><h5 id=\"2-启动类继承extends-WebMvcConfigurerAdapter\"><a href=\"#2-启动类继承extends-WebMvcConfigurerAdapter\" class=\"headerlink\" title=\"2.启动类继承extends WebMvcConfigurerAdapter\"></a>2.启动类继承extends WebMvcConfigurerAdapter</h5><h5 id=\"3-覆盖方法configureMessageConverters\"><a href=\"#3-覆盖方法configureMessageConverters\" class=\"headerlink\" title=\"3.覆盖方法configureMessageConverters\"></a>3.覆盖方法configureMessageConverters</h5><pre><code>@SpringBootApplication\npublic class ApiCoreApp  extends WebMvcConfigurerAdapter {\n\n@Override\npublic void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {\n    super.configureMessageConverters(converters);\n\n    FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter();\n\n    FastJsonConfig fastJsonConfig = new FastJsonConfig();\n    fastJsonConfig.setSerializerFeatures(\n            SerializerFeature.PrettyFormat\n    );\n    fastConverter.setFastJsonConfig(fastJsonConfig);\n\n    converters.add(fastConverter);\n}\n}\n</code></pre><h4 id=\"三、Spring-Boot热部署\"><a href=\"#三、Spring-Boot热部署\" class=\"headerlink\" title=\"三、Spring Boot热部署\"></a>三、Spring Boot热部署</h4><p>为什么需要热部署呢，因为你会发现即使做了一点点的变更，你也许也需要重新部署，这在工作上简直太耽误时间了。</p>\n<p> 解决方法：</p>\n<pre><code> 在pom.xml文件添加依赖包：\n &lt;plugin&gt;\n                  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                  &lt;artifactId&gt;spring-boot-maven-plugin &lt;/artifactId&gt;\n                  &lt;dependencies&gt;  \n                   &lt;!--springloaded  hot deploy --&gt;  \n                   &lt;dependency&gt;  \n                       &lt;groupId&gt;org.springframework&lt;/groupId&gt;  \n                       &lt;artifactId&gt;springloaded&lt;/artifactId&gt;  \n                       &lt;version&gt;1.2.4.RELEASE&lt;/version&gt;\n                   &lt;/dependency&gt;  \n                &lt;/dependencies&gt;  \n                &lt;executions&gt;  \n                   &lt;execution&gt;  \n                       &lt;goals&gt;  \n                           &lt;goal&gt;repackage&lt;/goal&gt;  \n                       &lt;/goals&gt;  \n                       &lt;configuration&gt;  \n                           &lt;classifier&gt;exec&lt;/classifier&gt;  \n                       &lt;/configuration&gt;  \n                   &lt;/execution&gt;  \n                   &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre><p> 使用spring-boot:run 作为 Goals（run as maven build）</p>\n<h4 id=\"四、springboot-devtools（热部署）\"><a href=\"#四、springboot-devtools（热部署）\" class=\"headerlink\" title=\"四、springboot + devtools（热部署）\"></a>四、springboot + devtools（热部署）</h4><ul>\n<li>spring-boot-devtools 是一个为开发者服务的一个模块，其中最重要的功能就是自动应用代码更改到最新的App上面去。原理是在发现代码有更改之后，重新启动应用，但是速度比手动停止后再启动还要更快，更快指的不是节省出来的手工操作的时间。</li>\n<li><p>其深层原理是使用了两个ClassLoader，一个Classloader加载那些不会改变的类（第三方Jar包），另一个ClassLoader加载会更改的类，称为  restart ClassLoader,这样在有代码更改的时候，原来的restart ClassLoader 被丢弃，重新创建一个restart ClassLoader，由于需要加载的类相比较少，所以实现了较快的重启时间（5秒以内）</p>\n<h6 id=\"步骤说明\"><a href=\"#步骤说明\" class=\"headerlink\" title=\"步骤说明\"></a>步骤说明</h6><p>  添加依赖包：<br>  <dependency></dependency></p>\n<pre><code> &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;\n &lt;optional&gt;true&lt;/optional&gt;\n&lt;scope&gt;true&lt;/scope&gt;\n</code></pre><p>  </p>\n<pre><code>添加spring-boot-maven-plugin：\n&lt;build&gt;\n  &lt;plugins&gt;\n      &lt;plugin&gt;\n          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n          &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n          &lt;configuration&gt;\n                &lt;!--fork :  如果没有该项配置，肯呢个devtools不会起作用，即应用不会restart --&gt;\n              &lt;fork&gt;true&lt;/fork&gt;\n          &lt;/configuration&gt;\n      &lt;/plugin&gt;\n  &lt;/plugins&gt;\n</code></pre><p>  </p>\n</li>\n</ul>\n<h6 id=\"补充说明\"><a href=\"#补充说明\" class=\"headerlink\" title=\"补充说明\"></a>补充说明</h6><ol>\n<li>devtools会监听classpath下的文件变动，并且会立即重启应用（发生在保存时机），注意：因为其采用的虚拟机机制，该项重启是很快的。</li>\n<li>devtools可以实现页面热部署（即页面修改后会立即生效，这个可以直接在application.properties文件中配置spring.thymeleaf.cache=false来实现(这里注意不同的模板配置不一样)</li>\n</ol>\n<h4 id=\"五、Spring-Data\"><a href=\"#五、Spring-Data\" class=\"headerlink\" title=\"五、Spring Data\"></a>五、Spring Data</h4><p><em>Spring Data是一个用于简化数据库访问，并支持云服务的开源框架。其主要目标是使得数据库的访问变得方便快捷，并支持map-reduce框架和云计算数据服务。此外，它还支持基于关系型数据库的数据服务，如Oracle RAC等。对于拥有海量数据的项目，可以用Spring Data来简化项目的开发，就如Spring Framework对JDBC、ORM的支持一样，Spring Data会让数据的访问变得更加方便</em></p>\n<p><em>可以极大的简化JPA的写法，可以在几乎不用写实现的情况下，实现对数据的访问和操作。除了CRUD外，还包括如分页、排序等一些常用的功能。所以Spring Data JPA的出现就是为了简化JPA的写法，让你只需要编写一个接口继承一个类就能实现CRUD操作了</em></p>\n<p>步骤：</p>\n<blockquote>\n<p>1.在pom.xml添加mysql,spring-data-jpa依赖;</p>\n</blockquote>\n<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;mysql&lt;/groupId&gt;\n    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n\n&lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre><blockquote>\n<p>2.在application.properties文件中配置mysql连接配置文件;</p>\n</blockquote>\n<pre><code>spring.datasource.url = jdbc:mysql://localhost:3306/test\nspring.datasource.username = root\nspring.datasource.password = root\nspring.datasource.driverClassName = com.mysql.jdbc.Driver\nspring.datasource.max-active=20\nspring.datasource.max-idle=8\nspring.datasource.min-idle=8\nspring.datasource.initial-size=10\n</code></pre><blockquote>\n<p>3.在application.properties文件中配置JPA配置信息;</p>\n</blockquote>\n<pre><code>spring.jpa.database = MYSQL\n#Show or not log for each sql query\nspring.jpa.show-sql = true\n#Hibernate ddl auto (create, create-drop, update)\nspring.jpa.hibernate.ddl-auto = update\n#Naming strategy\n#[org.hibernate.cfg.ImprovedNamingStrategy  #org.hibernate.cfg.DefaultNamingStrategy]\nspring.jpa.hibernate.naming-strategy = org.hibernate.cfg.ImprovedNamingStrategy\n#stripped before adding them to the entity manager)\nspring.jpa.properties.hibernate.dialect = org.hibernate.dialect.MySQL5Dialect\n</code></pre><h5 id=\"重点：Repository接口\"><a href=\"#重点：Repository接口\" class=\"headerlink\" title=\"重点：Repository接口\"></a>重点：Repository接口</h5><p> 有这么几点需要强调下：</p>\n<ol>\n<li>Repository是一个空接口，即是一个标记接口；</li>\n<li>若我们定义的接口继承了Repository，则该接口会被IOC容器识别为一个Repository Bean纳入到IOC容器中，进而可以在该接口中定义满足一定规范的方法。</li>\n<li>实际上也可以通过@RepositoryDefinition,注解来替代继承Repository接口，查询方法以find | read | get开头；</li>\n<li>涉及查询条件时，条件的属性用条件关键字连接，要注意的是条件属性以首字母大写。</li>\n<li>使用@Query注解可以自定义JPQL语句实现更灵活的查询。</li>\n</ol>\n<h5 id=\"CrudRepository-接口提供了最基本的对实体类的添删改查操作\"><a href=\"#CrudRepository-接口提供了最基本的对实体类的添删改查操作\" class=\"headerlink\" title=\"CrudRepository 接口提供了最基本的对实体类的添删改查操作\"></a>CrudRepository 接口提供了最基本的对实体类的添删改查操作</h5><p> –T save(T entity);//保存单个实体<br> –Iterable<t> save(Iterable&lt;? extends T&gt; entities);//保存集合<br> –T findOne(ID id);//根据id查找实体<br> –Iterable<t> findAll();//查询所有实体,不用或慎用!<br> –long count();//查询实体数量<br> –void delete(ID id);//根据Id删除实体<br> –void delete(T entity);//删除一个实体<br> –void delete(Iterable&lt;? extends T&gt; entities);//删除一个实体的集合<br> –void deleteAll();//删除所有实体,不用或慎用!   </t></t></p>\n<h4 id=\"六、全局异常捕捉\"><a href=\"#六、全局异常捕捉\" class=\"headerlink\" title=\"六、全局异常捕捉\"></a>六、全局异常捕捉</h4><h5 id=\"步骤：\"><a href=\"#步骤：\" class=\"headerlink\" title=\"步骤：\"></a>步骤：</h5><pre><code>新建一个类GlobalDefaultExceptionHandler，\n在class注解上@ControllerAdvice,\n在方法上注解上@ExceptionHandler(value = Exception.class)\n根据返回值判断要不要添加@responsebody注解\n@ControllerAdvice\npublic class GlobalDefaultExceptionHandler{\n\n@ExceptionHandler(value = Exception.class)\npublic void defaultErrorHandler(HttpServletRequest req, Exception e)  {\n}\n</code></pre><h4 id=\"七、配置Server\"><a href=\"#七、配置Server\" class=\"headerlink\" title=\"七、配置Server\"></a>七、配置Server</h4><h5 id=\"在application-properties进行配置：\"><a href=\"#在application-properties进行配置：\" class=\"headerlink\" title=\"在application.properties进行配置：\"></a>在application.properties进行配置：</h5><pre><code>#server.port=8080  端口号\n#server.address= # bind to a specific NIC\n#server.session-timeout= # session timeout in seconds\n#the context path, defaults to &apos;/&apos;\n#server.context-path=/spring-boot  访问路径\n#server.servlet-path= # the servlet path, defaults to &apos;/&apos;\n#server.tomcat.access-log-pattern= # log pattern of the access log\n#server.tomcat.access-log-enabled=false # is access logging enabled\n#server.tomcat.protocol-header=x-forwarded-proto # ssl forward headers\n#server.tomcat.remote-ip-header=x-forwarded-for\n#server.tomcat.basedir=/tmp # base dir (usually not needed, defaults to tmp)\n#server.tomcat.background-processor-delay=30; # in seconds\n#server.tomcat.max-threads = 0 # number of threads in protocol handler\n#server.tomcat.uri-encoding = UTF-8 # character encoding to use for URL decoding\n</code></pre><h4 id=\"八、thymeleaf的使用\"><a href=\"#八、thymeleaf的使用\" class=\"headerlink\" title=\"八、thymeleaf的使用\"></a>八、thymeleaf的使用</h4><h5 id=\"1-在pom-xml中引入thymeleaf\"><a href=\"#1-在pom-xml中引入thymeleaf\" class=\"headerlink\" title=\"1.在pom.xml中引入thymeleaf\"></a>1.在pom.xml中引入thymeleaf</h5><pre><code>&lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre><h5 id=\"2-如何关闭thymeleaf缓存\"><a href=\"#2-如何关闭thymeleaf缓存\" class=\"headerlink\" title=\"2.如何关闭thymeleaf缓存\"></a>2.如何关闭thymeleaf缓存</h5><pre><code>########################################################\n###THYMELEAF (ThymeleafAutoConfiguration)\n########################################################\n#spring.thymeleaf.prefix=classpath:/templates/\n#spring.thymeleaf.suffix=.html\n#spring.thymeleaf.mode=HTML5\n#spring.thymeleaf.encoding=UTF-8\n# ;charset=&lt;encoding&gt; is added\n#spring.thymeleaf.content-type=text/html \n# set to false for hot refresh\nspring.thymeleaf.cache=false   关闭缓存\n</code></pre><h6 id=\"3-编写模板文件-html\"><a href=\"#3-编写模板文件-html\" class=\"headerlink\" title=\"3.编写模板文件.html\"></a>3.编写模板文件.html</h6><pre><code>编写模板文件src/main/resouces/templates/hello.html:\n\n&lt;!DOCTYPE html&gt;\n&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;\n      xmlns:sec=&quot;http://www.thymeleaf.org/thymeleaf-extras-springsecurity3&quot;&gt;\n    &lt;head&gt;\n        &lt;title&gt;Hello World!&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1 th:inline=&quot;text&quot;&gt;Hello.v.2&lt;/h1&gt;\n        &lt;p th:text=&quot;${hello}&quot;&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre><h5 id=\"4-编写访问模板文件controller\"><a href=\"#4-编写访问模板文件controller\" class=\"headerlink\" title=\"4.编写访问模板文件controller\"></a>4.编写访问模板文件controller</h5><pre><code>@Controller\npublic class TemplateController {\n\n    /**\n     * 返回html模板.\n     */\n    @RequestMapping(&quot;/helloHtml&quot;)\n    public String helloHtml(Map&lt;String,Object&gt; map){\n        map.put(&quot;hello&quot;,&quot;from TemplateController.helloHtml&quot;);\n        return &quot;/helloHtml&quot;;\n    }\n\n}\n</code></pre><h4 id=\"九、freemarker的使用\"><a href=\"#九、freemarker的使用\" class=\"headerlink\" title=\"九、freemarker的使用\"></a>九、freemarker的使用</h4><h5 id=\"1-在pom-xml中引入freemarker\"><a href=\"#1-在pom-xml中引入freemarker\" class=\"headerlink\" title=\"1.在pom.xml中引入freemarker\"></a>1.在pom.xml中引入freemarker</h5><pre><code>&lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre><h5 id=\"2-如何关闭freemarker缓存\"><a href=\"#2-如何关闭freemarker缓存\" class=\"headerlink\" title=\"2.如何关闭freemarker缓存\"></a>2.如何关闭freemarker缓存</h5><pre><code>########################################################\n###FREEMARKER (FreeMarkerAutoConfiguration)\n########################################################\nspring.freemarker.allow-request-override=false\nspring.freemarker.cache=true\nspring.freemarker.check-template-location=true\nspring.freemarker.charset=UTF-8\nspring.freemarker.content-type=text/html\nspring.freemarker.expose-request-attributes=false\nspring.freemarker.expose-session-attributes=false\nspring.freemarker.expose-spring-macro-helpers=false\n#spring.freemarker.prefix=\n#spring.freemarker.request-context-attribute=\n#spring.freemarker.settings.*=\n#spring.freemarker.suffix=.ftl\n#spring.freemarker.template-loader-path=classpath:/templates/ #comma-separated list\n#spring.freemarker.view-names= # whitelist of view names that can be resolved\n</code></pre><h5 id=\"3-编写模板文件-ftl\"><a href=\"#3-编写模板文件-ftl\" class=\"headerlink\" title=\"3.编写模板文件.ftl\"></a>3.编写模板文件.ftl</h5><pre><code>&lt;!DOCTYPE html&gt;\n&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;\n      xmlns:sec=&quot;http://www.thymeleaf.org/thymeleaf-extras-springsecurity3&quot;&gt;\n    &lt;head&gt;\n        &lt;title&gt;Hello World!&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1&gt;Hello.v.2&lt;/h1&gt;\n        &lt;p&gt;${hello}&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre><h5 id=\"4-编写访问文件的controller\"><a href=\"#4-编写访问文件的controller\" class=\"headerlink\" title=\"4.编写访问文件的controller\"></a>4.编写访问文件的controller</h5><pre><code>@RequestMapping(&quot;/helloFtl&quot;)\n public String helloFtl(Map&lt;String,Object&gt; map){\n     map.put(&quot;hello&quot;,&quot;from TemplateController.helloFtl&quot;);\n     return &quot;/helloFtl&quot;;\n }\n</code></pre><h4 id=\"十、jsp的使用\"><a href=\"#十、jsp的使用\" class=\"headerlink\" title=\"十、jsp的使用\"></a>十、jsp的使用</h4><h5 id=\"1-创建Maven-web-project\"><a href=\"#1-创建Maven-web-project\" class=\"headerlink\" title=\"1.创建Maven web project\"></a>1.创建Maven web project</h5><h5 id=\"2-在pom-xml文件添加依赖\"><a href=\"#2-在pom-xml文件添加依赖\" class=\"headerlink\" title=\"2.在pom.xml文件添加依赖\"></a>2.在pom.xml文件添加依赖</h5><pre><code>  &lt;!-- web支持: 1、web mvc; 2、restful; 3、jackjson支持; 4、aop ........ --&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n\n &lt;!-- servlet 依赖. --&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;javax.servlet&lt;/groupId&gt;\n        &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;\n        &lt;scope&gt;provided&lt;/scope&gt;\n    &lt;/dependency&gt;\n\n\n\nJSTL（JSP Standard Tag Library，JSP标准标签库)是一个不断完善的开放源代码的JSP标签库，是由apache的jakarta小组来维护的。\n&lt;dependency&gt;\n            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;\n            &lt;artifactId&gt;jstl&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n&lt;!-- tomcat 的支持.--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;\n            &lt;scope&gt;provided&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;\n            &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;\n            &lt;scope&gt;provided&lt;/scope&gt;\n        &lt;/dependency&gt;\n</code></pre><h5 id=\"3-application-properties配置\"><a href=\"#3-application-properties配置\" class=\"headerlink\" title=\"3.application.properties配置\"></a>3.application.properties配置</h5><pre><code>添加src/main/resources/application.properties：\n\n# 页面默认前缀目录\nspring.mvc.view.prefix=/WEB-INF/jsp/\n# 响应页面默认后缀\nspring.mvc.view.suffix=.jsp\n# 自定义属性，可以在Controller中读取\napplication.hello=Hello Angel From application\n</code></pre><h5 id=\"4-编写controller\"><a href=\"#4-编写controller\" class=\"headerlink\" title=\"4.编写controller\"></a>4.编写controller</h5><pre><code>@Controller\npublic class HelloController {\nprivate String hello;    \n\n    @RequestMapping(&quot;/helloJsp&quot;)\n    public String helloJsp(Map&lt;String,Object&gt; map){\n        System.out.println(&quot;HelloController.helloJsp().hello=hello&quot;);\n        map.put(&quot;hello&quot;, hello);\n        return &quot;helloJsp&quot;;\n    }\n}\n</code></pre><h5 id=\"5-编写jsp页面\"><a href=\"#5-编写jsp页面\" class=\"headerlink\" title=\"5.编写jsp页面\"></a>5.编写jsp页面</h5><pre><code>在 src/main 下面创建 webapp/WEB-INF/jsp 目录用来存放我们的jsp页面：helloJsp.jsp:\n\n&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot;\n    pageEncoding=&quot;UTF-8&quot;%&gt;\n&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;\n&lt;title&gt;Insert title here&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    helloJsp\n    &lt;hr&gt;\n    ${hello}\n\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre><h4 id=\"十一、Mybatis的引用\"><a href=\"#十一、Mybatis的引用\" class=\"headerlink\" title=\"十一、Mybatis的引用\"></a>十一、Mybatis的引用</h4><h5 id=\"1-在pom-xml文件中引入相关依赖\"><a href=\"#1-在pom-xml文件中引入相关依赖\" class=\"headerlink\" title=\"1.在pom.xml文件中引入相关依赖\"></a>1.在pom.xml文件中引入相关依赖</h5><pre><code>（1）基本依赖，jdk版本号；\n（2）mysql驱动，mybatis依赖包，mysql分页PageHelper:\n\n&lt;!-- mysql 数据库驱动. --&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;mysql&lt;/groupId&gt;\n        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;\n&lt;/dependency&gt;    \n\n\n&lt;!-- \n    MyBatis提供了拦截器接口，我们可以实现自己的拦截器，\n    将其作为一个plugin装入到SqlSessionFactory中。 \n    Github上有位开发者写了一个分页插件，我觉得使用起来还可以，挺方便的。 \n    Github项目地址： https://github.com/pagehelper/Mybatis-PageHelper\n --&gt;    \n&lt;dependency&gt;\n    &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;\n    &lt;artifactId&gt;pagehelper&lt;/artifactId&gt;\n    &lt;version&gt;4.1.0&lt;/version&gt;\n&lt;/dependency&gt;    \n</code></pre><h5 id=\"2-在application-properties添加配置文件\"><a href=\"#2-在application-properties添加配置文件\" class=\"headerlink\" title=\"2.在application.properties添加配置文件\"></a>2.在application.properties添加配置文件</h5><pre><code>########################################################\n###datasource\n########################################################\nspring.datasource.url = jdbc:mysql://localhost:3306/test\nspring.datasource.username = root\nspring.datasource.password = root\nspring.datasource.driverClassName = com.mysql.jdbc.Driver\nspring.datasource.max-active=20\nspring.datasource.max-idle=8\nspring.datasource.min-idle=8\nspring.datasource.initial-size=10\n</code></pre><h5 id=\"3-编写Demo测试类\"><a href=\"#3-编写Demo测试类\" class=\"headerlink\" title=\"3.编写Demo测试类\"></a>3.编写Demo测试类</h5><pre><code>public class Demo {\nprivate long id;\nprivate String name;\n  //省略getter and setter….\n}\n</code></pre><h5 id=\"4-编写demoMapper\"><a href=\"#4-编写demoMapper\" class=\"headerlink\" title=\"4.编写demoMapper\"></a>4.编写demoMapper</h5><pre><code>public interface DemoMappper {\n\n@Select(&quot;select *from Demo where name = #{name}&quot;)\npublic List&lt;Demo&gt; likeName(String name);\n\n@Select(&quot;select *from Demo where id = #{id}&quot;)\npublic Demo getById(long id);\n\n@Select(&quot;select name from Demo where id = #{id}&quot;)\npublic String getNameById(long id);\n}\n</code></pre><h5 id=\"5-编写demoService\"><a href=\"#5-编写demoService\" class=\"headerlink\" title=\"5.编写demoService\"></a>5.编写demoService</h5><pre><code>@Service\npublic class DemoService {\n    @Autowired\n    private DemoMappper demoMappper;\n\n    public List&lt;Demo&gt; likeName(String name){\n        return demoMappper.likeName(name);\n    }\n}\n</code></pre><h5 id=\"6-编写demoController\"><a href=\"#6-编写demoController\" class=\"headerlink\" title=\"6.编写demoController\"></a>6.编写demoController</h5><pre><code>@RestController\npublic class DemoController {\n    @Autowired\n    private DemoService demoService;\n\n    @RequestMapping(&quot;/likeName&quot;)\n    public List&lt;Demo&gt; likeName(String name){\n        return demoService.likeName(name);\n    }\n\n}\n</code></pre><h5 id=\"7-加入PageHelper\"><a href=\"#7-加入PageHelper\" class=\"headerlink\" title=\"7.加入PageHelper\"></a>7.加入PageHelper</h5><pre><code>@Configuration\npublic class MyBatisConfiguration {\n\n    @Bean\n    public PageHelper pageHelper() {\n        System.out.println(&quot;MyBatisConfiguration.pageHelper()&quot;);\n        PageHelper pageHelper = new PageHelper();\n        Properties p = new Properties();\n        p.setProperty(&quot;offsetAsPageNum&quot;, &quot;true&quot;);\n        p.setProperty(&quot;rowBoundsWithCount&quot;, &quot;true&quot;);\n        p.setProperty(&quot;reasonable&quot;, &quot;true&quot;);\n        pageHelper.setProperties(p);\n        return pageHelper;\n    }\n}\n\n\n\n@RequestMapping(&quot;/likeName&quot;)\npublic List&lt;Demo&gt; likeName(String name){\n         PageHelper.startPage(1,1);\n         return demoService.likeName(name);\n}\n</code></pre><h5 id=\"8-获取自增长ID\"><a href=\"#8-获取自增长ID\" class=\"headerlink\" title=\"8.获取自增长ID\"></a>8.获取自增长ID</h5><pre><code>@Insert(&quot;insert into Demo(name,password) values(#{name},#{password})&quot;)\npublic long save(Demo name);\n\n\n@Options(useGeneratedKeys = true, keyProperty = &quot;id&quot;, keyColumn = &quot;id&quot;) \n</code></pre>"},{"title":"Optimize","author":"小小冰弟","date":"2018-04-08T07:58:10.000Z","_content":"#### 高并发下的查询速度慢（皮皮迪贡献）\n##### 解决方法：\n\n###### 1.你先代码优化，一些没必要的或者重复代码给他优化下，优化的不能再优化了，速度还是很低就去看逻辑，是不是循环或者递归这样的影响了代码效率，然后就是建立缓存了和多线程了，前提是sql很复杂，很难优化的情况\n\n\n###### 2.优化sql，因为觉得还是有些慢就优化sql把一些distinct这类不会影响结果但是影响效率的东西去掉还有看看子查询能不能拆成很多个sql，最好不要有子查询\n\n\n\n###### 3.再看看逻辑那还有是不是有更简便的方法来代替现在的代码，效率提升很多便捷很多的，没有的话就没必要改了\n\n###### 4.分析的时候可以同时多方面分析，不分先后顺序","source":"_posts/Optimize.md","raw":"title: Optimize\nauthor: 小小冰弟\ndate: 2018-04-08 15:58:10\ntags: study\ncategories: optimize\n---\n#### 高并发下的查询速度慢（皮皮迪贡献）\n##### 解决方法：\n\n###### 1.你先代码优化，一些没必要的或者重复代码给他优化下，优化的不能再优化了，速度还是很低就去看逻辑，是不是循环或者递归这样的影响了代码效率，然后就是建立缓存了和多线程了，前提是sql很复杂，很难优化的情况\n\n\n###### 2.优化sql，因为觉得还是有些慢就优化sql把一些distinct这类不会影响结果但是影响效率的东西去掉还有看看子查询能不能拆成很多个sql，最好不要有子查询\n\n\n\n###### 3.再看看逻辑那还有是不是有更简便的方法来代替现在的代码，效率提升很多便捷很多的，没有的话就没必要改了\n\n###### 4.分析的时候可以同时多方面分析，不分先后顺序","slug":"Optimize","published":1,"updated":"2018-04-08T08:05:41.387Z","_id":"cjfqimicc0000qo7khcn0glsz","comments":1,"layout":"post","photos":[],"link":"","content":"<h4 id=\"高并发下的查询速度慢（皮皮迪贡献）\"><a href=\"#高并发下的查询速度慢（皮皮迪贡献）\" class=\"headerlink\" title=\"高并发下的查询速度慢（皮皮迪贡献）\"></a>高并发下的查询速度慢（皮皮迪贡献）</h4><h5 id=\"解决方法：\"><a href=\"#解决方法：\" class=\"headerlink\" title=\"解决方法：\"></a>解决方法：</h5><h6 id=\"1-你先代码优化，一些没必要的或者重复代码给他优化下，优化的不能再优化了，速度还是很低就去看逻辑，是不是循环或者递归这样的影响了代码效率，然后就是建立缓存了和多线程了，前提是sql很复杂，很难优化的情况\"><a href=\"#1-你先代码优化，一些没必要的或者重复代码给他优化下，优化的不能再优化了，速度还是很低就去看逻辑，是不是循环或者递归这样的影响了代码效率，然后就是建立缓存了和多线程了，前提是sql很复杂，很难优化的情况\" class=\"headerlink\" title=\"1.你先代码优化，一些没必要的或者重复代码给他优化下，优化的不能再优化了，速度还是很低就去看逻辑，是不是循环或者递归这样的影响了代码效率，然后就是建立缓存了和多线程了，前提是sql很复杂，很难优化的情况\"></a>1.你先代码优化，一些没必要的或者重复代码给他优化下，优化的不能再优化了，速度还是很低就去看逻辑，是不是循环或者递归这样的影响了代码效率，然后就是建立缓存了和多线程了，前提是sql很复杂，很难优化的情况</h6><h6 id=\"2-优化sql，因为觉得还是有些慢就优化sql把一些distinct这类不会影响结果但是影响效率的东西去掉还有看看子查询能不能拆成很多个sql，最好不要有子查询\"><a href=\"#2-优化sql，因为觉得还是有些慢就优化sql把一些distinct这类不会影响结果但是影响效率的东西去掉还有看看子查询能不能拆成很多个sql，最好不要有子查询\" class=\"headerlink\" title=\"2.优化sql，因为觉得还是有些慢就优化sql把一些distinct这类不会影响结果但是影响效率的东西去掉还有看看子查询能不能拆成很多个sql，最好不要有子查询\"></a>2.优化sql，因为觉得还是有些慢就优化sql把一些distinct这类不会影响结果但是影响效率的东西去掉还有看看子查询能不能拆成很多个sql，最好不要有子查询</h6><h6 id=\"3-再看看逻辑那还有是不是有更简便的方法来代替现在的代码，效率提升很多便捷很多的，没有的话就没必要改了\"><a href=\"#3-再看看逻辑那还有是不是有更简便的方法来代替现在的代码，效率提升很多便捷很多的，没有的话就没必要改了\" class=\"headerlink\" title=\"3.再看看逻辑那还有是不是有更简便的方法来代替现在的代码，效率提升很多便捷很多的，没有的话就没必要改了\"></a>3.再看看逻辑那还有是不是有更简便的方法来代替现在的代码，效率提升很多便捷很多的，没有的话就没必要改了</h6><h6 id=\"4-分析的时候可以同时多方面分析，不分先后顺序\"><a href=\"#4-分析的时候可以同时多方面分析，不分先后顺序\" class=\"headerlink\" title=\"4.分析的时候可以同时多方面分析，不分先后顺序\"></a>4.分析的时候可以同时多方面分析，不分先后顺序</h6>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"高并发下的查询速度慢（皮皮迪贡献）\"><a href=\"#高并发下的查询速度慢（皮皮迪贡献）\" class=\"headerlink\" title=\"高并发下的查询速度慢（皮皮迪贡献）\"></a>高并发下的查询速度慢（皮皮迪贡献）</h4><h5 id=\"解决方法：\"><a href=\"#解决方法：\" class=\"headerlink\" title=\"解决方法：\"></a>解决方法：</h5><h6 id=\"1-你先代码优化，一些没必要的或者重复代码给他优化下，优化的不能再优化了，速度还是很低就去看逻辑，是不是循环或者递归这样的影响了代码效率，然后就是建立缓存了和多线程了，前提是sql很复杂，很难优化的情况\"><a href=\"#1-你先代码优化，一些没必要的或者重复代码给他优化下，优化的不能再优化了，速度还是很低就去看逻辑，是不是循环或者递归这样的影响了代码效率，然后就是建立缓存了和多线程了，前提是sql很复杂，很难优化的情况\" class=\"headerlink\" title=\"1.你先代码优化，一些没必要的或者重复代码给他优化下，优化的不能再优化了，速度还是很低就去看逻辑，是不是循环或者递归这样的影响了代码效率，然后就是建立缓存了和多线程了，前提是sql很复杂，很难优化的情况\"></a>1.你先代码优化，一些没必要的或者重复代码给他优化下，优化的不能再优化了，速度还是很低就去看逻辑，是不是循环或者递归这样的影响了代码效率，然后就是建立缓存了和多线程了，前提是sql很复杂，很难优化的情况</h6><h6 id=\"2-优化sql，因为觉得还是有些慢就优化sql把一些distinct这类不会影响结果但是影响效率的东西去掉还有看看子查询能不能拆成很多个sql，最好不要有子查询\"><a href=\"#2-优化sql，因为觉得还是有些慢就优化sql把一些distinct这类不会影响结果但是影响效率的东西去掉还有看看子查询能不能拆成很多个sql，最好不要有子查询\" class=\"headerlink\" title=\"2.优化sql，因为觉得还是有些慢就优化sql把一些distinct这类不会影响结果但是影响效率的东西去掉还有看看子查询能不能拆成很多个sql，最好不要有子查询\"></a>2.优化sql，因为觉得还是有些慢就优化sql把一些distinct这类不会影响结果但是影响效率的东西去掉还有看看子查询能不能拆成很多个sql，最好不要有子查询</h6><h6 id=\"3-再看看逻辑那还有是不是有更简便的方法来代替现在的代码，效率提升很多便捷很多的，没有的话就没必要改了\"><a href=\"#3-再看看逻辑那还有是不是有更简便的方法来代替现在的代码，效率提升很多便捷很多的，没有的话就没必要改了\" class=\"headerlink\" title=\"3.再看看逻辑那还有是不是有更简便的方法来代替现在的代码，效率提升很多便捷很多的，没有的话就没必要改了\"></a>3.再看看逻辑那还有是不是有更简便的方法来代替现在的代码，效率提升很多便捷很多的，没有的话就没必要改了</h6><h6 id=\"4-分析的时候可以同时多方面分析，不分先后顺序\"><a href=\"#4-分析的时候可以同时多方面分析，不分先后顺序\" class=\"headerlink\" title=\"4.分析的时候可以同时多方面分析，不分先后顺序\"></a>4.分析的时候可以同时多方面分析，不分先后顺序</h6>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjfcc60k90000xo7k7wmhu1rc","category_id":"cjfcc60kg0004xo7k7qr3tvdl","_id":"cjfcc60kr000gxo7kd46qra7s"},{"post_id":"cjfcc60kd0002xo7k0q46rijp","category_id":"cjfcc60km000axo7ksyo3a2yb","_id":"cjfcc60kw000oxo7kj3n4pvua"},{"post_id":"cjfcc60kq000fxo7ki6piatl1","category_id":"cjfcc60km000axo7ksyo3a2yb","_id":"cjfcc60kx000sxo7krrvrzl11"},{"post_id":"cjfcc60ki0006xo7k9klsapui","category_id":"cjfcc60km000axo7ksyo3a2yb","_id":"cjfcc60kz000wxo7khazk9kep"},{"post_id":"cjfcc60kj0008xo7kmhg6abiy","category_id":"cjfcc60km000axo7ksyo3a2yb","_id":"cjfcc60l10011xo7kk9tnuhkt"},{"post_id":"cjfcc60kz000yxo7kjqq1618s","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60l40017xo7k678a8xag"},{"post_id":"cjfcc60kl0009xo7kfy2d19la","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60l5001bxo7kbcknc68r"},{"post_id":"cjfcc60l00010xo7ka6qj1hto","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60l6001exo7kc7ok3k19"},{"post_id":"cjfcc60l20014xo7kpyad7t9a","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60l8001ixo7ktzrfu45i"},{"post_id":"cjfcc60kn000dxo7kufhug235","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60la001mxo7kfxdfjw9z"},{"post_id":"cjfcc60l30016xo7kbpqwyxa3","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60lb001qxo7k6z3raeex"},{"post_id":"cjfcc60kt000kxo7kk185ao38","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60ld001txo7krzskfgzg"},{"post_id":"cjfcc60ku000mxo7k8p1vvquh","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60le001wxo7k16j9ttqr"},{"post_id":"cjfcc60l9001lxo7kdzufhrar","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60le001yxo7kg81tslv4"},{"post_id":"cjfcc60kx000rxo7k0x6sc15u","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60lf0021xo7k12wtr8jm"},{"post_id":"cjfcc60ky000uxo7kcgl695z7","category_id":"cjfcc60kz000vxo7klrkhqc6d","_id":"cjfcc60lf0023xo7kqqdvdlwe"},{"post_id":"cjfcc60l4001axo7kvvhxd7wl","category_id":"cjfcc60le001zxo7ka60h5y8h","_id":"cjfcc60lg0025xo7kr32nrogf"},{"post_id":"cjfcc60l6001dxo7k8ktwe038","category_id":"cjfcc60lf0024xo7kdal7or82","_id":"cjfcc60lg0027xo7kl46wef9f"},{"post_id":"cjfcc60lc001sxo7ka3pbzszy","category_id":"cjfcc60lg0026xo7knd991mj1","_id":"cjfcc60lg0028xo7k321g4ntu"},{"post_id":"cjfdlynzr0001j87krcoeh0hi","category_id":"cjfdmks4k0002j87k5hzriccb","_id":"cjfdmks4l0004j87k2zi4cq77"},{"post_id":"cjfjbw8ji0000io7kmi5xgkcr","category_id":"cjfkpo1cq0000pc7k96qj1hik","_id":"cjfkpo1cu0002pc7knw2kbwm2"},{"post_id":"cjfqimicc0000qo7khcn0glsz","category_id":"cjfqiwwb30001qo7kzvawyyli","_id":"cjfqiwwb40003qo7kr99rrb46"}],"PostTag":[{"post_id":"cjfcc60k90000xo7k7wmhu1rc","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60kn000cxo7k4d2tcyqd"},{"post_id":"cjfcc60kl0009xo7kfy2d19la","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60kp000exo7ktnb0zq0h"},{"post_id":"cjfcc60kn000dxo7kufhug235","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60kt000jxo7kujtzkrbo"},{"post_id":"cjfcc60kd0002xo7k0q46rijp","tag_id":"cjfcc60kn000bxo7kodmwve87","_id":"cjfcc60ku000lxo7kdaslwitd"},{"post_id":"cjfcc60kq000fxo7ki6piatl1","tag_id":"cjfcc60kn000bxo7kodmwve87","_id":"cjfcc60kw000qxo7kkrfx0e70"},{"post_id":"cjfcc60kt000kxo7kk185ao38","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60ky000txo7kbhzbo17t"},{"post_id":"cjfcc60ki0006xo7k9klsapui","tag_id":"cjfcc60kn000bxo7kodmwve87","_id":"cjfcc60kz000xxo7khoaqfad7"},{"post_id":"cjfcc60ku000mxo7k8p1vvquh","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60l0000zxo7krve679ua"},{"post_id":"cjfcc60kx000rxo7k0x6sc15u","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60l20013xo7kw3z3i5of"},{"post_id":"cjfcc60kj0008xo7kmhg6abiy","tag_id":"cjfcc60kn000bxo7kodmwve87","_id":"cjfcc60l30015xo7kq94hyhxv"},{"post_id":"cjfcc60ky000uxo7kcgl695z7","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60l40019xo7karyvl7nb"},{"post_id":"cjfcc60kz000yxo7kjqq1618s","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60l5001cxo7kwmn3ichc"},{"post_id":"cjfcc60l00010xo7ka6qj1hto","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60l7001gxo7knu2a841e"},{"post_id":"cjfcc60l20014xo7kpyad7t9a","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60l9001kxo7ke1sp9z0s"},{"post_id":"cjfcc60l30016xo7kbpqwyxa3","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60la001oxo7kgureb67t"},{"post_id":"cjfcc60l4001axo7kvvhxd7wl","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60lc001rxo7k2kum9k7l"},{"post_id":"cjfcc60l7001hxo7kl5cvm7yz","tag_id":"cjfcc60kn000bxo7kodmwve87","_id":"cjfcc60le001vxo7k7zkmk7qy"},{"post_id":"cjfcc60l9001lxo7kdzufhrar","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60le001xxo7kaztj93za"},{"post_id":"cjfcc60l6001dxo7k8ktwe038","tag_id":"cjfcc60l8001jxo7kuap9iy26","_id":"cjfcc60lf0020xo7kiyzw2i8v"},{"post_id":"cjfcc60lc001sxo7ka3pbzszy","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfcc60lf0022xo7kva42ddyq"},{"post_id":"cjfdlynzr0001j87krcoeh0hi","tag_id":"cjfcc60kn000bxo7kodmwve87","_id":"cjfdmks4k0003j87kcg9nkiex"},{"post_id":"cjfjbw8ji0000io7kmi5xgkcr","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfkpo1ct0001pc7kknxzdu7k"},{"post_id":"cjfqimicc0000qo7khcn0glsz","tag_id":"cjfcc60kh0005xo7kyxc2biub","_id":"cjfqiwwb30002qo7kp1satxog"}],"Tag":[{"name":"study","_id":"cjfcc60kh0005xo7kyxc2biub"},{"name":"live","_id":"cjfcc60kn000bxo7kodmwve87"},{"name":"free","_id":"cjfcc60l8001jxo7kuap9iy26"}]}}